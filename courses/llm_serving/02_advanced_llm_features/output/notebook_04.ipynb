{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Getting Structured JSON Output\n",
    "\n",
    "Many applications need consistent, parseable output from LLMs. Ray Serve LLM supports structured output generation, ensuring your model returns data in the exact format you need.\n",
    "\n",
    "### Why Structured Output Matters\n",
    "\n",
    "- **Consistent Format**: Guaranteed JSON structure for downstream processing\n",
    "- **Integration Ready**: Easy to parse and use in applications\n",
    "- **Reliability**: Reduces parsing errors and improves system robustness\n",
    "- **Type Safety**: Enforces data types and required fields\n",
    "\n",
    "### Example: Car type description\n",
    "\n",
    "Let's deploy a model. It is recommended to research the performance of your model in structured output benchmarks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# serve_my_qwen.yaml\n",
    "applications:\n",
    "- name: json-mode-app\n",
    "  route_prefix: \"/\"\n",
    "  import_path: ray.serve.llm:build_openai_app\n",
    "  args:\n",
    "    llm_configs:\n",
    "      - model_loading_config:\n",
    "          model_id: my-qwen\n",
    "          model_source: Qwen/Qwen2.5-3B-Instruct\n",
    "        accelerator_type: L4\n",
    "        ### Uncomment if your model is gated and need your Huggingface Token to access it\n",
    "        #runtime_env:\n",
    "        #  env_vars:\n",
    "        #    HF_TOKEN: <YOUR-TOKEN-HERE>\n",
    "        engine_kwargs:\n",
    "          max_model_len: 8192\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!serve run serve_my_qwen.yaml --non-blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Structured Output\n",
    "\n",
    "Now let's test our structured output model with some product descriptions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_method1.py\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "\n",
    "client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"FAKE_KEY\")\n",
    "\n",
    "# (Optional) We use Pydantic model to handle schema definition/validation\n",
    "class CarType(str, Enum):\n",
    "    sedan = \"sedan\"\n",
    "    suv = \"SUV\"\n",
    "    truck = \"Truck\"\n",
    "    coupe = \"Coupe\"\n",
    "\n",
    "class CarDescription(BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "    car_type: CarType\n",
    "\n",
    "# 1. Define your schema\n",
    "json_schema = CarDescription.model_json_schema()\n",
    "\n",
    "# 2. Send a request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"my-qwen\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Generate a JSON with the brand, model and car_type of the most iconic car from the 90's\",\n",
    "        }\n",
    "    ],\n",
    "    # 3. Set `response_format` of type `json_schema`\n",
    "    response_format= {\n",
    "        \"type\": \"json_schema\",\n",
    "        # 4. Provide `name`and `schema` (both required)\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"car-description\", # arbitrary\n",
    "            \"schema\": json_schema # your JSON schema\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "The model will return a consistent JSON structure like:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"brand\": \"Lexus\",\n",
    "  \"model\": \"IS F\",\n",
    "  \"car_type\": \"SUV\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!serve shutdown -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Benefits\n",
    "\n",
    "- **Guaranteed Structure**: Always returns valid JSON matching your schema\n",
    "- **Type Safety**: Enforces data types (strings, numbers, arrays)\n",
    "- **Required Fields**: Ensures all specified fields are present\n",
    "- **Easy Integration**: Directly usable in applications without parsing\n",
    "\n",
    "### Learn More\n",
    "\n",
    "For comprehensive structured output guides, see:\n",
    "- [LLM deployment with structured output on Anyscale](https://docs.anyscale.com/llm/serving/structured-output) - Complete guide with all output formats\n",
    "- [Request structured output (vLLM documentation)](https://docs.vllm.ai/en/stable/features/structured_outputs.html) - Complete guide on vLLM API for structured outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}