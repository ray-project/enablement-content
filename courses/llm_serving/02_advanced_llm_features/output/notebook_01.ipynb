{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced LLM Features with Ray Serve LLM\n",
    "\n",
    "\u00a9 2025, Anyscale. All Rights Reserved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\ud83d\udcbb **Launch Locally**: You can run this notebook locally, but you'll need access to GPUs.\n",
    "\n",
    "\ud83d\ude80 **Launch on Cloud**: A Ray Cluster with GPUs (Click [here](http://console.anyscale.com/register) to easily start a Ray cluster on Anyscale) is recommended to run this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores advanced features and capabilities of Ray Serve LLM beyond basic model deployment. We'll dive into practical examples that showcase the power and flexibility of production LLM serving.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> Here is the roadmap for this notebook:</b>\n",
    "<ul>\n",
    "    <li>Overview: Advanced Features Preview</li>\n",
    "    <li>Example: Deploying LoRA Adapters</li>\n",
    "    <li>Example: Getting Structured JSON Output</li>\n",
    "    <li>Example: Setting up Tool Calling</li>\n",
    "    <li>How to Choose an LLM?</li>\n",
    "    <li>Conclusion: Next Steps</li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}