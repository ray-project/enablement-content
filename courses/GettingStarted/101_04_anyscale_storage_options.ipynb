{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 101 -- Storage Options in the Anyscale Platform\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Most AI workloads require access to large amounts of data, whether to obtain training data or to offload model checkpoints. In this notebook, we will explore the different storage options provided by Anyscale and how to use them effectively for AI/ML workloads.\n",
    "\n",
    "1. Object storage  \n",
    "2. Network file system (NFS) shared across nodes  \n",
    "3. Local storage for a node  \n",
    "4. Local File Store\n",
    "\n",
    "To see the storage options, open your existing **Anyscale Workspace.** Or create a new one. \n",
    "\n",
    "<img src=\"https://lz-public-demo.s3.us-east-1.amazonaws.com/anyscale101/workspace2.png\"  width=\"500\"/>\n",
    "\n",
    "Once the Anyscale Workspace is running, head over to the **Files Tab**. Click on the Workspace Working Directory to get an UI overview of various storage options, let's review them in greater detail.  \n",
    "\n",
    "<img src=\"https://lz-public-demo.s3.us-east-1.amazonaws.com/anyscale101/storage3.png\"  width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cloud Object Store\n",
    "\n",
    "Every Anyscale Cloud includes a default Cloud Storage Bucket. For accessing large volumes of data (such as inputs for model training), each workspace contains environment variables to reference this shared bucket.\n",
    "\n",
    "Information about the bucket is stored within the following environment variables:\n",
    "\n",
    "- **ANYSCALE_CLOUD_STORAGE_BUCKET**: Name of the default bucket  \n",
    "  - The root bucket (**ANYSCALE_CLOUD_STORAGE_BUCKET**) is managed by Anyscale and contains system-critical files.  \n",
    "  - Do not modify or delete anything inside the root bucket—only make changes within the **ANYSCALE_ARTIFACT_STORAGE** path—as it may impact platform functionality.\n",
    "- **ANYSCALE_CLOUD_STORAGE_BUCKET_REGION**: Region of the default bucket.  \n",
    "- **ANYSCALE_ARTIFACT_STORAGE**: Pre-generated URI path for storing user artifacts separately.\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Create a Python notebook file (.ipynb extension)\n",
    "\n",
    "<img src=\"https://lz-public-demo.s3.us-east-1.amazonaws.com/anyscale101/storage2.png\"  width=\"500\"/>\n",
    "\n",
    "\n",
    "Print the details about the Cloud Storage Bucket by running this code snippet in a new code cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"ANYSCALE_CLOUD_STORAGE_BUCKET:\", os.getenv(\"ANYSCALE_CLOUD_STORAGE_BUCKET\"))\n",
    "print(\"ANYSCALE_CLOUD_STORAGE_BUCKET_REGION:\", os.getenv(\"ANYSCALE_CLOUD_STORAGE_BUCKET_REGION\"))\n",
    "print(\"ANYSCALE_ARTIFACT_STORAGE:\", os.getenv(\"ANYSCALE_ARTIFACT_STORAGE\"))\n",
    "\n",
    "# ANYSCALE_CLOUD_STORAGE_BUCKET: anyscale-production-data-cld-g54aiirwj1s8t9ktgzikqur41k\n",
    "# ANYSCALE_CLOUD_STORAGE_BUCKET_REGION: us-west-2\n",
    "# ANYSCALE_ARTIFACT_STORAGE: s3://anyscale-production-data-cld-g54aiirwj1s8t9ktgzikqur41k/org_967t9ah1lbk1yqf1zau6a1v247/cld_g54aiirwj1s8t9ktgzikqur41k/artifact_storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(If Anyscale Cloud is connected to Amazon S3)**\n",
    "\n",
    "Upload a sample file to the S3 Bucket, then find the file by sorting by the most recent upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "bucket, prefix = os.environ[\"ANYSCALE_ARTIFACT_STORAGE\"].replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "\n",
    "local_file = \"hello.txt\"\n",
    "s3_key = f\"{prefix.rstrip('/')}/{local_file}\"\n",
    "\n",
    "# Write a simple text file to the Bucket\n",
    "with open(local_file, \"w\") as f:\n",
    "    f.write(\"Sample File\\n\")\n",
    "s3.upload_file(local_file, bucket, s3_key)\n",
    "print(f\"Uploaded {local_file} to s3://{bucket}/{s3_key}\")\n",
    "\n",
    "# List objects in artifact folder and get most recent\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "files = response.get(\"Contents\", [])\n",
    "most_recent = max(files, key=lambda obj: obj[\"LastModified\"])\n",
    "recent_key = most_recent[\"Key\"]\n",
    "recent_name = recent_key.replace(prefix, \"\").lstrip(\"/\")\n",
    "print(f\"Most recent file: {recent_name} (LastModified: {most_recent['LastModified']})\")\n",
    "\n",
    "\n",
    "# Uploaded hello.txt to s3://anyscale-production-data-cld-g54aiirwj1.../hello.txt\n",
    "# Most recent file: hello.txt (LastModified: 2025-06-17 20:19:18+00:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Workspace clusters already have role permissions to access S3, authentication is not required when using the AWS CLI.\n",
    "\n",
    "Delete the created file by running this in a new cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.delete_object(Bucket=bucket, Key=s3_key)\n",
    "print(f\"Deleted s3://{bucket}/{s3_key}\")\n",
    "\n",
    "# Deleted s3://anyscale-production-data-cld.../artifact_storage/hello.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Shared File Storage \n",
    "\n",
    "Every Anyscale Cluster is started with the following mount points. This storage option (NFS) is not intended for extremely large datasets, use Cloud Object Storage instead.\n",
    "\n",
    "- **User Storage:** `/mnt/user_storage`  \n",
    "  - Private to the Anyscale user but accessible from every node of all their workspace, job, and service clusters in the same cloud.  \n",
    "  - Persisted independently of Anyscale Workspace/Job/Service lifecycle.\n",
    "\n",
    "- **Shared Storage:** `/mnt/shared_storage`  \n",
    "  - Accessible to all Anyscale users of the same Anyscale cloud. Anyscale mounts it on every node of all the clusters in the same cloud.  \n",
    "  - Persisted independently of Anyscale Workspace/Job/Service lifecycle.\n",
    "\n",
    "Anyscale Cloud has some tutorials installed by default. Let’s check if it’s stored in the **Shared Storage** mount.\n",
    "\n",
    "You can also inspect using the UI from the **Files Tab**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "shared_path = \"/mnt/shared_storage\"\n",
    "all_files = []\n",
    "\n",
    "for root, dirs, files in os.walk(shared_path):\n",
    "    for name in files:\n",
    "        all_files.append(os.path.join(root, name))\n",
    "\n",
    "# Print first 4 files\n",
    "for path in all_files[:4]:\n",
    "    print(path)\n",
    "    \n",
    "# /mnt/shared_storage/dummy_data_xxl.csv\n",
    "# /mnt/shared_storage/dummy_data_1000_500.parquet\n",
    "# /mnt/shared_storage/dummy_data_1000_500.csv\n",
    "# /mnt/shared_storage/dummy_data_1000_720.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Local Cluster Storage \n",
    "\n",
    "Anyscale provides each node with its own volume and disk and doesn’t share them with other nodes. This storage option enables higher access speed, lower latency, and scalability.\n",
    "\n",
    "**Local storage can be accessed:** `/mnt/cluster_storage`\n",
    "\n",
    "- Scoped to the nodes in the specific cluster.\n",
    "- Used for sharing files and pip package installations across cluster nodes during workspace development (e.g. `pip install <package> --user`).\n",
    "\n",
    "To demonstrate where new libraries are located in the **Local Cluster Storage**, download a unique library not pre-installed bythe default Anyscale Container image and print out the path. Run the following in the terminal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "pip install shapely --user\n",
    "python3 -c \"import shapely; print(shapely.__file__)\"\n",
    "\n",
    "# /mnt/cluster_storage/pypi/lib/python3.12/site-packages/shapely/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "You can also inspect using the UI from the **Files Tab**.\n",
    "\n",
    "<img src=\"https://lz-public-demo.s3.us-east-1.amazonaws.com/anyscale101/storage4.png\"  width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Local File Store\n",
    "\n",
    "Anyscale Workspaces persist files and folders within your project directory, `/home/ray/default`, across restarts. This capability maintains project continuity and facilitates seamless transitions between workspace sessions.\n",
    "\n",
    "For performance reasons, Anyscale limits snapshots to 10 GB per workspace. For larger files, save to File Storage or Cloud Object Store.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
