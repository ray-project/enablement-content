
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>ğŸ–¼ï¸ 04a Â· Computer-Vision Pattern with Ray Train &#8212; Course Notebooks</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom_hide.css?v=af9667c8" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'courses/ray-train-201/04a_vision_pattern';</script>
    <script src="../../_static/custom_toggle.js?v=1235ef5b"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Course Notebooks</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Ray Enablement Content
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Intro to Ray</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_01.html">Introduction to Ray Core: Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_02.html">0. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_03.html">1. Creating Remote Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_04.html">2. Executing Remote Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_05.html">4. Putting It All Together</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_01.html">Introduction to Ray Core (Advancement): Object store, Tasks, Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_02.html">1. Object store</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_03.html">2. Chaining Tasks and Passing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_04.html">3. Task retries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_05.html">4. Task Runtime Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_06.html">5. Resource allocation and management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_07.html">6. Nested Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_08.html">7. Pattern: Pipeline data processing and waiting for results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_09.html">8. Ray Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_01.html">Introduction to the Ray AI Libraries: An example of using Ray data, Ray Train, Ray Tune, Ray Serve to implement a XGBoost regression model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_02.html">1. Overview of the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_03.html">2. Quick end-to-end example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_01.html">Introduction to Ray Train + PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_02.html">1. When to use Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_03.html">2. Single GPU Training with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_04.html">3. Distributed Data Parallel Training with Ray Train and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_01.html">Introduction to Ray Train: Ray Train + PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_02.html">1. When to use Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_03.html">2. Single GPU Training with PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_04.html">3. Distributed Training with Ray Train and PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_05.html">4. Ray Train in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_01.html">Introduction to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_02.html">1. Loading the data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_03.html">2. Starting out with vanilla PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_04.html">3. Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_05.html">4. Ray Tune in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_01.html">Introduction to Ray Data: Industry Landscape</a></li>

<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_02.html">The Compute Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_03.html">The Orchestration Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_04.html">Distributed Computing Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_05.html">Data Processing with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_06.html">Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_01.html">Introduction to Ray Data: Ray Data + Structured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_02.html">0. What is Ray Data?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_03.html">2. Loading Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_04.html">3. Transforming Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_05.html">4. Writing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_06.html">5. Data Operations: Shuffling, Grouping and Aggregation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_07.html">6. When to use Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_01.html">Intro to Ray Data:  Ray Data + Unstructured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_02.html">1. When to Consider Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_03.html">2. How to work with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_04.html">3. Loading data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_05.html">3. Lazy execution mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_06.html">4. Transforming data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_07.html">5. Stateful transformations with Ray Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_08.html">6. Materializing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_09.html">7. Data Operations: grouping, aggregation, and shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_10.html">8. Persisting data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_11.html">9. Ray Data in production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_01.html">Introduction to Ray Serve with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_02.html">1. When to Consider Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_03.html">2. Overview of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_04.html">3. Implement an image classification service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_05.html">4. Development workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/README_01.html">Introduction to Ray: Developer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">01 Examples</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/01_Ray_Data_batch_inference_01.html">Batch Inference with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/01_Ray_Data_batch_inference_02.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/01_Ray_Data_batch_inference_03.html">Load a dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/01_Ray_Data_batch_inference_04.html">Batch Inference Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/01_Ray_Data_batch_inference_05.html">Create a batch data and call the model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/01_Ray_Data_batch_inference_06.html">Run inference on the entire dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/02_Ray_Data_data_processing_01.html">Data Processing with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/02_Ray_Data_data_processing_02.html">Library Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/02_Ray_Data_data_processing_03.html">Convert to Ray Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/02_Ray_Data_data_processing_04.html">Filter Ray Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/02_Ray_Data_data_processing_05.html">Join Two Ray Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/02_Ray_Data_data_processing_06.html">Preprocessing with a Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/03_Ray_Serve_online_serving_01.html">Online Model Serving with Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/03_Ray_Serve_online_serving_02.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/03_Ray_Serve_online_serving_03.html">FastAPI webservice and deploy a model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/03_Ray_Serve_online_serving_04.html">Simulate Client: Send test requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/04_Ray_Train_distributed_training_01.html">Distributed training with Ray Train, PyTorch and Hugging Face</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/04_Ray_Train_distributed_training_02.html">1. Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/04_Ray_Train_distributed_training_03.html">3. Metrics Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/04_Ray_Train_distributed_training_04.html">4. Training function per worker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/04_Ray_Train_distributed_training_05.html">5. Main Training Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/04_Ray_Train_distributed_training_06.html">6. Start Training</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">02 Anyscale Admin</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_01.html">Anyscale Administrator Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_02.html">1. What is an Anyscale Cloud?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_03.html">2. Cloud Deployment Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_04.html">3. A Demonstrative Example of Resource Creation with AWS EC2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_05.html">3.1 IAM Role Definition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_06.html">4. Register Anyscale Cloud to Your Cloud Provider</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_01.html">Deployment Options: Virtual Machines vs. Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_02.html">2. Virtual Machines (VM) vs. Kubernetes (K8s)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_03.html">3. (Optional) More Kubernetes Deployments Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_01.html">Introduction: Deploy Anyscale Ray on AWS EC2 Instances</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_02.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_03.html">2. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_04.html">3. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_05.html">4. Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_06.html">5. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_01.html">Introduction: Deploy Anyscale Ray on GCP Compute Engine Instances (GCE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_03.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_04.html">2. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_05.html">3. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_06.html">4. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_07.html">5. Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_01.html">Introduction: Deploy Anyscale Ray on A New AWS EKS Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_02.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_03.html">2. Install Kubernetes Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_04.html">3. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_05.html">4. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_06.html">5. Verify the Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_07.html">6. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_08.html">7. Clean up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_09.html">8. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_01.html">Introduction: Deploy Anyscale Ray on An Existing AWS EKS Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_03.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_04.html">2. Attach Required IAM Policies to Your existing EKSâ€™s Node Role</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_05.html">3. Install Kubernetes Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_06.html">4. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_07.html">5. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_08.html">6. Verify the Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_09.html">7. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_10.html">8. Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_11.html">9. Clean up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_12.html">10. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_01.html">Introduction: Deploy Anyscale Ray on A New Google Kubernetes Engine (GKE) Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_03.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_04.html">2. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_05.html">3. Troubleshooting GPU Availability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_06.html">4. kubectl Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_07.html">5. Install NGINX Ingress Controller</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_08.html">6. (Optional) Upgrade Anyscale Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_09.html">7. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_10.html">8. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_11.html">8. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_12.html">9. Cleanup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Gettingstarted</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_01_anyscale_intro_workspace_01.html">101 â€” Introduction to Anyscale Workspaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_02_anyscale_development_intro_01.html">101 â€“ Developing Application with Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_03_anyscale_compute_runtime_intro_01.html">101 â€“ Compute Configs and Execution Environments in Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_04_anyscale_storage_options_01.html">101 â€“ Storage Options in the Anyscale Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_05_anyscale_logging_metrics_01.html">101 â€“ Debug and Monitor Your Anyscale Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_06_anyscale_intro_jobs_01.html">101 â€“ Introduction to Anyscale Jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_07_anyscale_intro_services_01.html">101 â€“  Introduction to Anyscale Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_08_anyscale_collaboration_01.html">101 â€“ Collaboration on Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_09_anyscale_org_setup_01.html">101 - Anyscale Organization and Cloud Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_09_anyscale_org_setup_02.html">ğŸ“Œ Overview of Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_09_anyscale_org_setup_03.html">ğŸ§  Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_anyscale_intro_jobs_01.html">Content Used</a></li>

<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_anyscale_intro_jobs_02.html">Part 1. Creating and Submitting your first job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_anyscale_intro_jobs_03.html">Part 2. Automation and Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_anyscale_intro_services_01.html">Sources</a></li>

<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_anyscale_intro_services_02.html">Part 1: Starting your first Anyscale Service</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Anyscale 101</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../anyscale_101/output/101_anyscale_intro_jobs_01.html">Content Used</a></li>

<li class="toctree-l1"><a class="reference internal" href="../anyscale_101/output/101_anyscale_intro_jobs_02.html">Part 1. Creating and Submitting your first job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../anyscale_101/output/101_anyscale_intro_jobs_03.html">Part 2. Automation and Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../anyscale_101/output/101_anyscale_intro_services_01.html">Sources</a></li>

<li class="toctree-l1"><a class="reference internal" href="../anyscale_101/output/101_anyscale_intro_services_02.html">Part 1: Starting your first Anyscale Service</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray 101</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/1_AI_Libs_Intro_01.html">Introduction to the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/1_AI_Libs_Intro_02.html">1. Overview of the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/1_AI_Libs_Intro_03.html">2. End-to-end example: predicting taxi tips in New York</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/1_AI_Libs_Intro_04.html">3. Running an experiment with Ray AI libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_01.html">Introduction to Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_02.html">1. PyTorch introductory example (single GPU)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_03.html">2. Distributed Data Parallel Training with Ray Train and PyTorch (multiple GPUs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_04.html">3. Overview of the training loop in Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_05.html">4. Migrating the model and dataset to Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_06.html">5. Reporting checkpoints and metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_07.html">6. Launching the distributed training job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_08.html">7. Accessing the training results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_09.html">8. Ray Train in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/3_Intro_Tune_01.html">Intro to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/3_Intro_Tune_02.html">1. Loading and visualizing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/3_Intro_Tune_03.html">2. Setting up a PyTorch model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/3_Intro_Tune_04.html">3. Introduction to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/3_Intro_Tune_05.html">4. Diving deeper into Ray Tune concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/3_Intro_Tune_06.html">5. Hyperparameter tuning the PyTorch model using Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/4_Intro_Data_01.html">Intro to Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/4_Intro_Data_02.html">1. When to use Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/4_Intro_Data_03.html">2. Loading Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/4_Intro_Data_04.html">3. Transforming Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/4_Intro_Data_05.html">4. Data Operations: Grouping, Aggregation, and Shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/4_Intro_Data_06.html">5. Persisting Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/5_Intro_Serve_01.html">Intro to Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/5_Intro_Serve_02.html">1. Overview of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/5_Intro_Serve_03.html">2. Implement an Classifier service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/5_Intro_Serve_04.html">3. Advanced features of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/5_Intro_Serve_05.html">4. Ray Serve in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/5_Intro_Serve_06.html">Clean up</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Train 201</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_01.html">ğŸ“š 01 Â· Introduction to Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_02.html">01 Â· Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_03.html">04 Â· Define ResNet-18 Model for MNIST</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_04.html">05 Â· Define the Ray Train Loop (DDP per-worker)</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_05.html">06 Â· Define <code class="docutils literal notranslate"><span class="pre">train_loop_config</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_06.html">07 Â· Configure Scaling with <code class="docutils literal notranslate"><span class="pre">ScalingConfig</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_07.html">08 Â· Wrap the Model with <code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_08.html">09 Â· Build the DataLoader with <code class="docutils literal notranslate"><span class="pre">prepare_data_loader()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_09.html">10 Â· Report Training Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_10.html">11 Â· Save Checkpoints and Report Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_11.html">14 Â· Create the <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_12.html">16 Â· Inspect the Training Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_13.html">18 Â· Load a Checkpoint for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_14.html">ğŸ”„ 02 Â· Integrating Ray Train with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_15.html">01 Â· Define Training Loop with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_16.html">02 Â· Build DataLoader from Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_17.html">03 Â· Prepare Dataset for Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_18.html">05 Â· Define Image Transformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_19.html">07 Â· Configure <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_20.html">ğŸ›¡ï¸ 03 Â· Fault Tolerance in Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_21.html">01 Â· Modify Training Loop to Enable Checkpoint Loading</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_22.html">02 Â· Save Full Checkpoint with Extra State</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_23.html">04 Â· Launch Fault-Tolerant Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_24.html">05 Â· Manual Restoration from Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_25.html">07 Â· Clean Up Cluster Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/01_02_03_intro_to_ray_train_26.html">ğŸ‰ Wrapping Up &amp; Next Steps</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_01.html">ğŸ–¼ï¸ 04a Â· Computer-Vision Pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_02.html">01 Â· Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_03.html">06 Â· Custom <code class="docutils literal notranslate"><span class="pre">Food101Dataset</span></code> for Parquet</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_04.html">10 Â· Helper: Ray-Prepared DataLoaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_05.html">11 Â· <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_06.html">12 Â· Launch Distributed Training with <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_07.html">13 Â· Plot Loss Curves</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_08.html">14 Â· Demonstrate Fault-Tolerant Resume</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_09.html">15 Â· Remote Inference Helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04b_tabular_workload_pattern_01.html">ğŸ”ï¸ 04b Â· Tabular Workload Pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04b_tabular_workload_pattern_02.html">1 Â· Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04b_tabular_workload_pattern_03.html">8 Â· Custom per-worker training loop</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04b_tabular_workload_pattern_04.html">12 Â· Evaluate the trained model</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04b_tabular_workload_pattern_05.html">16 Â· Continue training from the latest checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04b_tabular_workload_pattern_06.html">ğŸ‰ Wrapping Up &amp; Next Steps</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04c_time_series_workload_pattern_01.html">ğŸ•’ 04c Â· Time-Series Workload Pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04c_time_series_workload_pattern_02.html">1 Â· Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04c_time_series_workload_pattern_03.html">9 Â· PositionalEncoding + Transformer model</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04c_time_series_workload_pattern_04.html">11 Â· Launch training on 8 GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04c_time_series_workload_pattern_05.html">13 Â· Resume training from checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04c_time_series_workload_pattern_06.html">15 Â· Run inference and visualise prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04d1_generative_cv_pattern_01.html">ğŸ–¼ï¸ 04-d1 Â· Generative Computer-Vision Pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04d1_generative_cv_pattern_02.html">01 Â· Imports &amp; Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04d1_generative_cv_pattern_03.html">08 Â· Pixel Diffusion LightningModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04d1_generative_cv_pattern_04.html">09 Â· Ray Train <code class="docutils literal notranslate"><span class="pre">train_loop</span></code> (Checkpoint + Resume)</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04d1_generative_cv_pattern_05.html">12 Â· Demonstrate Resume from Latest Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04d1_generative_cv_pattern_06.html">13 Â· Reverse Diffusion Sampler</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04d1_generative_cv_pattern_07.html">ğŸ‰ Wrapping Up &amp; Next Steps</a></li>

<li class="toctree-l1"><a class="reference internal" href="output/04d2_policy_learning_pattern_01.html">ğŸŒ€ 04-d2 Â· Diffusion-Policy Pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04d2_policy_learning_pattern_02.html">01. Imports &amp; Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04d2_policy_learning_pattern_03.html">04. DiffusionPolicy LightningModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04d2_policy_learning_pattern_04.html">05. Distributed Train Loop w/ Checkpointing</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04d2_policy_learning_pattern_05.html">08. Reverse Diffusion Helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04e_rec_sys_workload_pattern_01.html">ğŸ§  04e Â· Recommendation System Pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04e_rec_sys_workload_pattern_02.html">01 Â· Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04e_rec_sys_workload_pattern_03.html">07 Â· Define Matrix Factorization Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04e_rec_sys_workload_pattern_04.html">08 Â· Define Ray Train Loop (with Validation, Logging, and Checkpointing)</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04e_rec_sys_workload_pattern_05.html">11 Â· Resume Training from Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04e_rec_sys_workload_pattern_06.html">12 Â· Inference: Recommend Top-N Items for a User</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/courses/ray-train-201/04a_vision_pattern.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>ğŸ–¼ï¸ 04a Â· Computer-Vision Pattern with Ray Train</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">ğŸ–¼ï¸ 04a Â· Computer-Vision Pattern with Ray Train</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-youll-learn-take-away">What youâ€™ll learn &amp; take away</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-problem-are-you-solving-image-classification-with-food-101-lite">ğŸ”¢ What problem are you solving? (Image classification with Food-101-Lite)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inputs">Inputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#labels">Labels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-does-the-model-learn">What does the model learn?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-you-migrate-this-computer-vision-workload-to-a-distributed-setup-using-ray-on-anyscale">ğŸ§­ How you migrate this computer vision workload to a distributed setup using Ray on Anyscale</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">01 Â· Imports</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-10-of-food-101">02 Â· Load 10 % of Food-101</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resize-and-encode-images">03 Â· Resize and Encode Images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visual-sanity-check">04 Â· Visual Sanity Check</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#persist-to-parquet">05 Â· Persist to Parquet</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-food101dataset-for-parquet">06 Â· Custom <code class="docutils literal notranslate"><span class="pre">Food101Dataset</span></code> for Parquet</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-transform">07 Â· Image Transform</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trainvalidation-split">08 Â· Trainâ€“Validation Split</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inspect-a-dataloader-batch">09 Â· Inspect a DataLoader Batch</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-ray-prepared-dataloaders">10 Â· Helper: Ray-Prepared DataLoaders</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#train-loop-per-worker">11 Â· <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-distributed-training-with-torchtrainer">12 Â· Launch Distributed Training with <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-loss-curves">13 Â· Plot Loss Curves</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstrate-fault-tolerant-resume">14 Â· Demonstrate Fault-Tolerant Resume</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#remote-inference-helper">15 Â· Remote Inference Helper</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-and-visualise-inference">16 Â· Run and Visualise Inference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cleanup">17 Â· Cleanup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wrapping-up-next-steps">ğŸ‰ Wrapping Up &amp; Next Steps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where-can-you-take-this-next">ğŸš€ Where can you take this next?</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="a-computer-vision-pattern-with-ray-train">
<h1>ğŸ–¼ï¸ 04a Â· Computer-Vision Pattern with Ray Train<a class="headerlink" href="#a-computer-vision-pattern-with-ray-train" title="Link to this heading">#</a></h1>
<p>This notebook walks through an end-to-end, <strong>real-world computer-vision workflow</strong> that runs seamlessly on an Anyscale cluster using <strong>Ray Train</strong>. You start by pulling a slice of the Food-101 dataset, push it through a lightweight preprocessing pipeline, store it efficiently in Parquet, and then fine-tune a ResNet-18 in a fault-tolerant, distributed manner. Along the way, you  lean on Rayâ€™s helpers to prepare data loaders, coordinate workers, checkpoint automatically, resume after failure, and even launch GPU inference jobsâ€”all without writing a single line of low-level distributed code.</p>
<section id="what-youll-learn-take-away">
<h2>What youâ€™ll learn &amp; take away<a class="headerlink" href="#what-youll-learn-take-away" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Launch distributed training with <strong>Ray Trainâ€™s <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></strong> and configure it for multi-GPU, multi-node execution.</p></li>
<li><p>Use <strong>Ray Trainâ€™s built-in utilities</strong> (<code class="docutils literal notranslate"><span class="pre">prepare_model</span></code>, <code class="docutils literal notranslate"><span class="pre">prepare_data_loader</span></code>, <code class="docutils literal notranslate"><span class="pre">get_checkpoint</span></code>, <code class="docutils literal notranslate"><span class="pre">train.report</span></code>) to wrap your existing PyTorch code without modifying your modeling logic.</p></li>
<li><p>Save and resume from <strong>automatic, fault-tolerant checkpoints</strong> across epochs.</p></li>
<li><p>Offload batch <strong>inference as a Ray remote task</strong>, allowing you to treat inference as a scalable workload.</p></li>
<li><p>Run end-to-end training and evaluation without needing to understand the low-level mechanics of distributed systems.</p></li>
</ul>
<p>By the end of the tutorial you have a working model, clear loss curves, and a hands-on feel for how Ray Train simplifies distributed computer-vision workloads.</p>
</section>
<section id="what-problem-are-you-solving-image-classification-with-food-101-lite">
<h2>ğŸ”¢ What problem are you solving? (Image classification with Food-101-Lite)<a class="headerlink" href="#what-problem-are-you-solving-image-classification-with-food-101-lite" title="Link to this heading">#</a></h2>
<p>In this notebook you train a neural network to <strong>classify food photos</strong> into one of <strong>10 categories</strong><br />
using the <strong>Food-101-Lite</strong> datasetâ€”a compact, 10-class subset of the original Food-101 benchmark.</p>
</section>
<hr class="docutils" />
<section id="inputs">
<h2>Inputs<a class="headerlink" href="#inputs" title="Link to this heading">#</a></h2>
<p>Every sample is a 3-channel Red-Green-Blue (RGB) image, resized to <span class="math notranslate nohighlight">\(224 \times 224\)</span>:</p>
<div class="math notranslate nohighlight">
\[
x \;\in\; [0,1]^{3 \times 224 \times 224}\;.
\]</div>
<p>You apply standard vision transforms (normalization, random crop/flip) and batch the data with plain <strong>PyTorch DataLoader</strong> (wrapped by <code class="docutils literal notranslate"><span class="pre">ray.train.torch.prepare_data_loader</span></code> for distributed training).</p>
</section>
<hr class="docutils" />
<section id="labels">
<h2>Labels<a class="headerlink" href="#labels" title="Link to this heading">#</a></h2>
<p>Each image belongs to one of ten classes:</p>
<p>[â€˜pizzaâ€™, â€˜hamburgerâ€™, â€˜sushiâ€™, â€˜ramenâ€™, â€˜fried riceâ€™,
â€˜steakâ€™, â€˜hot dogâ€™, â€˜pancakeâ€™, â€˜burritoâ€™, â€˜caesar saladâ€™]</p>
<p>The label is an integer <span class="math notranslate nohighlight">\(y \in \{0, \dots, 9\}\)</span> used for supervision.</p>
</section>
<hr class="docutils" />
<section id="what-does-the-model-learn">
<h2>What does the model learn?<a class="headerlink" href="#what-does-the-model-learn" title="Link to this heading">#</a></h2>
<p>You train a compact CNN (For example, <strong>ResNet-18</strong>) to map an image (x) to class probabilities:</p>
<div class="math notranslate nohighlight">
\[
f_\theta(x)\;=\;\hat{y}\;\in\;\mathbb{R}^{10}.
\]</div>
<p>Training minimizes the <strong>cross-entropy loss</strong></p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(x,y)\;=\;-\log \bigl(\hat{y}_{\,y}\bigr),
\]</div>
<p>so the network assigns high likelihood to the correct class.</p>
</section>
<hr class="docutils" />
<section id="how-you-migrate-this-computer-vision-workload-to-a-distributed-setup-using-ray-on-anyscale">
<h2>ğŸ§­ How you migrate this computer vision workload to a distributed setup using Ray on Anyscale<a class="headerlink" href="#how-you-migrate-this-computer-vision-workload-to-a-distributed-setup-using-ray-on-anyscale" title="Link to this heading">#</a></h2>
<p>In this tutorial, you start with a small PyTorch-based image classification taskâ€”training a ResNet-18 on a 10% slice of the Food-101 dataset, and progressively migrate it into a fully distributed, fault-tolerant training job using <strong>Ray Train on Anyscale</strong>. Your goal is to show you exactly how to scale <em>your existing workflow</em> without rewriting it from scratch.</p>
<p>Hereâ€™s how you do itâ€™:</p>
<ol class="arabic">
<li><p><strong>Preprocess data and persist it in a distributed-friendly format</strong><br />
You take raw images from Hugging Faceâ€™s <code class="docutils literal notranslate"><span class="pre">food101</span></code> dataset, apply <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> resizing and center-cropping, and serialize them to <strong>Parquet</strong> using <code class="docutils literal notranslate"><span class="pre">pyarrow</span></code>. The system writes these Parquet files to the <strong>Anyscale clusterâ€™s shared storage volume</strong> (<code class="docutils literal notranslate"><span class="pre">/mnt/cluster_storage</span></code>), so any node can access them, on any worker, without duplication or sync issues.</p></li>
<li><p><strong>Create a lightweight PyTorch <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> for Parquet ingestion</strong><br />
Instead of using Ray Data or Hugging Face <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>, you implement a custom <code class="docutils literal notranslate"><span class="pre">Food101Dataset</span></code> that reads directly from the Parquet files. This provides control over the way the system reads rows and row groups. While this isnâ€™t yet fully distributed, it allows you to simulate a real-world scenario where a developer starts with something simple before optimizing. <strong>Note:</strong> you use Pytorch style data loading in this tutorial to demonstrate (1) low level control in a pytorch native environment and (2) how to move pre-existing pytorch code into a distributed Anyscale environment. Other tutorials in this module incorporate Ray Data, so you can see how the two approaches differ.</p></li>
<li><p><strong>Integrate Ray Train into the training loop</strong><br />
You encapsulate your existing PyTorch training logic in a <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker()</span></code> function, which Ray Train executes on each worker (typically one per GPU). Inside this loop, you:</p>
<ul class="simple">
<li><p>Wrap the model with <code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code> to make it compatible with distributed data parallelism.</p></li>
<li><p>Wrap the <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> with <code class="docutils literal notranslate"><span class="pre">prepare_data_loader()</span></code> to enable device placement and Ray worker context handling.</p></li>
<li><p>Add a <code class="docutils literal notranslate"><span class="pre">torch.utils.data.DistributedSampler</span></code> to each <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>, so that <strong>data is correctly sharded across workers</strong>â€”each worker only processes a unique subset of the training and validation datasets.</p></li>
<li><p>As required by the <code class="docutils literal notranslate"><span class="pre">DistributedSampler</span></code>, all <code class="docutils literal notranslate"><span class="pre">sampler.set_epoch(epoch)</span></code> at the start of each epoch to reshuffle the data correctly.</p></li>
<li><p>Use Rayâ€™s <code class="docutils literal notranslate"><span class="pre">Checkpoint</span></code> API to save and resume from checkpoints as needed.</p></li>
<li><p>Report training and validation metrics with <code class="docutils literal notranslate"><span class="pre">train.report()</span></code> after each epoch.</p></li>
</ul>
</li>
<li><p><strong>Launch training with <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> on an Anyscale cluster</strong><br />
You instantiate a <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> that runs:</p>
<ul class="simple">
<li><p>With <code class="docutils literal notranslate"><span class="pre">num_workers=8</span></code> and <code class="docutils literal notranslate"><span class="pre">use_gpu=True</span></code> (For example, across 8 A10 or A100 GPUs on Anyscale).</p></li>
<li><p>With <code class="docutils literal notranslate"><span class="pre">RunConfig</span></code> that sets checkpoint retention and auto-resume (with <code class="docutils literal notranslate"><span class="pre">max_failures=3</span></code>).</p></li>
<li><p>On infrastructure thatâ€™s provisioned and scheduled by Anyscale with no manual Ray cluster setup required.</p></li>
</ul>
<p>Once launched, Ray automatically handles:</p>
<ul class="simple">
<li><p>Multi-node orchestration</p></li>
<li><p>Worker assignment and device pinning</p></li>
<li><p>Failure recovery and retry logic</p></li>
<li><p>Checkpointing and logging</p></li>
</ul>
</li>
<li><p><strong>Validate fault tolerance</strong><br />
You run <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code> a second time. If manual intervention or failure interrupts the previous training, Ray picks up from the latest checkpoint. This shows <strong>real-world robustness</strong> without any manual checkpoint management or scripting.</p></li>
<li><p><strong>Launch distributed GPU inference tasks</strong><br />
At the end, you define a Ray remote function (<code class="docutils literal notranslate"><span class="pre">&#64;ray.remote(num_gpus=1)</span></code>) that loads the best checkpoint and runs inference on a single image from the validation set. You run this task on one GPU from the cluster.</p></li>
</ol>
<p>All of this runs inside a <strong>managed Anyscale workspace</strong>. You donâ€™t need to start or SSH into clusters, worry about node IP, or configure NCCL. The entire setup is <strong>declarative and self-contained in this notebook</strong>, and can be re-run or scaled up by changing a single parameter (<code class="docutils literal notranslate"><span class="pre">num_workers</span></code>).</p>
<p>This tutorial mirrors how many ML teams operate in practice: starting with a working PyTorch training loop and migrating it to the cloud without rewriting core logic. With Ray Train on Anyscale, the migration is clean, incremental, and production-ready.</p>
</section>
</section>
<section id="imports">
<h1>01 Â· Imports<a class="headerlink" href="#imports" title="Link to this heading">#</a></h1>
<p>Before you start, gather every library youâ€™re going to rely on throughout this notebook. Pull in core Python utilities for file handling and plotting, PyTorch and TorchVision for deep-learning components, Ray Train for distributed orchestration, Hugging Face Datasets for quick data access, and PyArrow plus Pandas for fast Parquet IO. Importing everything up-front keeps the rest of the tutorial clean and predictable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 01. Imports</span>

<span class="c1"># â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</span>
<span class="c1"># Standard Library Utilities</span>
<span class="c1"># â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span><span class="o">,</span><span class="w"> </span><span class="nn">io</span><span class="o">,</span><span class="w"> </span><span class="nn">tempfile</span><span class="o">,</span><span class="w"> </span><span class="nn">shutil</span>  <span class="c1"># file I/O and temp dirs</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>                      <span class="c1"># reading/writing configs</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span><span class="o">,</span><span class="w"> </span><span class="nn">uuid</span>              <span class="c1"># randomness and unique IDs</span>

<span class="c1"># â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</span>
<span class="c1"># Core Data &amp; Storage Libraries</span>
<span class="c1"># â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>              <span class="c1"># tabular data handling</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>               <span class="c1"># numerical ops</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pa</span>             <span class="c1"># in-memory columnar format</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow.parquet</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pq</span>     <span class="c1"># reading/writing Parquet files</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>            <span class="c1"># progress bars</span>

<span class="c1"># â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</span>
<span class="c1"># Image Handling &amp; Visualization</span>
<span class="c1"># â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>  <span class="c1"># plotting loss curves, images</span>

<span class="c1"># â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</span>
<span class="c1"># PyTorch + TorchVision Core</span>
<span class="c1"># â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span> <span class="k">as</span> <span class="n">T</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">resnet18</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">Compose</span><span class="p">,</span> <span class="n">Resize</span><span class="p">,</span> <span class="n">CenterCrop</span>

<span class="c1"># â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</span>
<span class="c1"># Ray Train: Distributed Training Primitives</span>
<span class="c1"># â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ray.train</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">train</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.train.torch</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">prepare_model</span><span class="p">,</span>
    <span class="n">prepare_data_loader</span><span class="p">,</span>
    <span class="n">TorchTrainer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.train</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ScalingConfig</span><span class="p">,</span>
    <span class="n">RunConfig</span><span class="p">,</span>
    <span class="n">FailureConfig</span><span class="p">,</span>
    <span class="n">CheckpointConfig</span><span class="p">,</span>
    <span class="n">Checkpoint</span><span class="p">,</span>
    <span class="n">get_checkpoint</span><span class="p">,</span>
    <span class="n">get_context</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</span>
<span class="c1"># Dataset Access</span>
<span class="c1"># â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>  <span class="c1"># Hugging Face Datasets</span>
</pre></div>
</div>
</div>
</div>
<section id="load-10-of-food-101">
<h2>02 Â· Load 10 % of Food-101<a class="headerlink" href="#load-10-of-food-101" title="Link to this heading">#</a></h2>
<p>Next, grab roughly 7,500 images, exactly 10% of Food-101â€”using a single call to <code class="docutils literal notranslate"><span class="pre">load_dataset</span></code>. This trimmed subset trains quickly while still being large enough to demonstrate Rayâ€™s scaling behavior.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 02. Load 10% of food101 (~7,500 images)</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;food101&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train[:10%]&quot;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</section>
<section id="resize-and-encode-images">
<h2>03 Â· Resize and Encode Images<a class="headerlink" href="#resize-and-encode-images" title="Link to this heading">#</a></h2>
<p>Here you preprocess each image: resize to 256 pixels, center-crop to 224 pixels (the size expected by most ImageNet models), and then convert the result to raw Joint Photographic Experts Group (JPEG) bytes. By storing bytes instead of full Python Imaging Library (PIL) objects, you| keep the dataset compact and Parquet-friendly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 03. Resize + encode as JPEG bytes</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">([</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span> <span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">)])</span>
<span class="n">records</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Preprocessing images&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;img&quot;</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
        <span class="n">buf</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
        <span class="n">img</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;JPEG&quot;</span><span class="p">)</span>
        <span class="n">records</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;image_bytes&quot;</span><span class="p">:</span> <span class="n">buf</span><span class="o">.</span><span class="n">getvalue</span><span class="p">(),</span>
            <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="n">example</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>
        <span class="p">})</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">continue</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visual-sanity-check">
<h2>04 Â· Visual Sanity Check<a class="headerlink" href="#visual-sanity-check" title="Link to this heading">#</a></h2>
<p>Before committing to hours of training, take nine random samples and plot them with their class names. This quick inspection lets you properly align labels and confirm that images are correctly resized.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 04. Visualize the dataset</span>

<span class="n">label_names</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span>  <span class="c1"># maps int â†’ string</span>

<span class="n">samples</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">records</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Sample Resized Images from food101-lite&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">rec</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">samples</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">rec</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">]))</span>
    <span class="n">label_name</span> <span class="o">=</span> <span class="n">label_names</span><span class="p">[</span><span class="n">rec</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label_name</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="persist-to-parquet">
<h2>05 Â· Persist to Parquet<a class="headerlink" href="#persist-to-parquet" title="Link to this heading">#</a></h2>
<p>Now write the images and labels to a Parquet file. Because Parquet is columnar, you can read just the columns you need during training, which speeds up IOâ€”especially when multiple workers are reading in parallel under Ray.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 05. Write Dataset to Parquet</span>

<span class="n">output_dir</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite/parquet_256&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">table</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="o">.</span><span class="n">from_pydict</span><span class="p">({</span>
    <span class="s2">&quot;image_bytes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">records</span><span class="p">],</span>
    <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">records</span><span class="p">]</span>
<span class="p">})</span>
<span class="n">pq</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;shard_0.parquet&quot;</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Wrote </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">records</span><span class="p">)</span><span class="si">}</span><span class="s2"> records to </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="custom-food101dataset-for-parquet">
<h1>06 Â· Custom <code class="docutils literal notranslate"><span class="pre">Food101Dataset</span></code> for Parquet<a class="headerlink" href="#custom-food101dataset-for-parquet" title="Link to this heading">#</a></h1>
<p>To feed data into PyTorch, define a custom <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>. You cache Parquet metadata, map global indices to specific row groups, and pull only the row you need. Each <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> returns an <code class="docutils literal notranslate"><span class="pre">(image,</span> <span class="pre">label)</span></code> pair thatâ€™s immediately ready for further transforms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 06. Define PyTorch Dataset that loads from Parquet</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Food101Dataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parquet_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parquet_file</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">ParquetFile</span><span class="p">(</span><span class="n">parquet_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

        <span class="c1"># Precompute a global row index to (row_group_idx, local_idx) map</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">row_group_map</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">rg_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parquet_file</span><span class="o">.</span><span class="n">num_row_groups</span><span class="p">):</span>
            <span class="n">rg_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parquet_file</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">row_group</span><span class="p">(</span><span class="n">rg_idx</span><span class="p">)</span>
            <span class="n">num_rows</span> <span class="o">=</span> <span class="n">rg_meta</span><span class="o">.</span><span class="n">num_rows</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">row_group_map</span><span class="o">.</span><span class="n">extend</span><span class="p">([(</span><span class="n">rg_idx</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_rows</span><span class="p">)])</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_group_map</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">row_group_idx</span><span class="p">,</span> <span class="n">local_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_group_map</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="c1"># Read only the relevant row group (in memory-efficient batch---for scalability)</span>
        <span class="n">table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parquet_file</span><span class="o">.</span><span class="n">read_row_group</span><span class="p">(</span><span class="n">row_group_idx</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">])</span>
        <span class="n">row</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">local_idx</span><span class="p">]</span>

        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">]))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<section id="image-transform">
<h2>07 Â· Image Transform<a class="headerlink" href="#image-transform" title="Link to this heading">#</a></h2>
<p>Here you create a transform pipeline: <code class="docutils literal notranslate"><span class="pre">ToTensor()</span></code> followed by ImageNet mean and standard-deviation normalisation. By applying the transform inside the dataset, you make sure every worker, no matter where it runs, processes images in exactly the same way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 07. Define data preprocessing transform</span>
<span class="n">IMAGENET_MEAN</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">]</span>
<span class="n">IMAGENET_STD</span>  <span class="o">=</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">T</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">IMAGENET_MEAN</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">IMAGENET_STD</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="trainvalidation-split">
<h2>08 Â· Trainâ€“Validation Split<a class="headerlink" href="#trainvalidation-split" title="Link to this heading">#</a></h2>
<p>Shuffle the full Parquet table once (seeded for reproducibility) and then slice off the last 500 rows to construct the validation set. Write the train and validation partitions to their own Parquet files so you can load them independently later.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 08. Create train/val Parquet splits </span>
<span class="n">full_path</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite/parquet_256/shard_0.parquet&quot;</span>

<span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">pq</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">full_path</span><span class="p">)</span>
    <span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>
    <span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># shuffle for reproducibility</span>
<span class="p">)</span>

<span class="n">df</span><span class="p">[:</span><span class="o">-</span><span class="mi">500</span><span class="p">]</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s2">&quot;/mnt/cluster_storage/food101_lite/train.parquet&quot;</span><span class="p">)</span>   <span class="c1"># training</span>
<span class="n">df</span><span class="p">[</span><span class="o">-</span><span class="mi">500</span><span class="p">:]</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s2">&quot;/mnt/cluster_storage/food101_lite/val.parquet&quot;</span><span class="p">)</span>     <span class="c1"># validation</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="inspect-a-dataloader-batch">
<h2>09 Â· Inspect a DataLoader Batch<a class="headerlink" href="#inspect-a-dataloader-batch" title="Link to this heading">#</a></h2>
<p>Before you scale out, build a regular single-process <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>, pull one batch, and print its shape. This tiny test reassures you that batching, multiprocessing, and transforms work correctly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 09. Observe data shape</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">Food101Dataset</span><span class="p">(</span><span class="s2">&quot;/mnt/cluster_storage/food101_lite/train.parquet&quot;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="helper-ray-prepared-dataloaders">
<h1>10 Â· Helper: Ray-Prepared DataLoaders<a class="headerlink" href="#helper-ray-prepared-dataloaders" title="Link to this heading">#</a></h1>
<p>Wrap the DataLoader with <code class="docutils literal notranslate"><span class="pre">prepare_data_loader</span></code>. Ray injects a <code class="docutils literal notranslate"><span class="pre">DistributedSampler</span></code>, pins the loader to the correct GPU, and handles worker-rank bookkeeping. Thanks to this helper, your training loop can stay blissfully unaware of distributed details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 10. Define helper to create prepared DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">DistributedSampler</span>

<span class="k">def</span><span class="w"> </span><span class="nf">build_dataloader</span><span class="p">(</span><span class="n">parquet_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">Food101Dataset</span><span class="p">(</span><span class="n">parquet_path</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

    <span class="c1"># Add a DistributedSampler to shard data across workers</span>
    <span class="n">sampler</span> <span class="o">=</span> <span class="n">DistributedSampler</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">num_replicas</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">(),</span>
        <span class="n">rank</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_world_rank</span><span class="p">(),</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">prepare_data_loader</span><span class="p">(</span><span class="n">loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-loop-per-worker">
<h1>11 Â· <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code><a class="headerlink" href="#train-loop-per-worker" title="Link to this heading">#</a></h1>
<p>This is the workhorse called by each Ray worker. Inside, build the model, optimiser, and loss, try to resume from any existing checkpoint, run the training and validation loops, log metrics, and (on rank 0) save new checkpoints and append results to a history file. At the end, compute a final validation accuracy for good measure.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 11. Define Ray Train train_loop_per_worker</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_loop_per_worker</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>

    <span class="c1"># === Model ===</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">prepare_model</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

    <span class="c1"># === Optimizer / Loss ===</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">])</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="c1"># === Resume from Checkpoint ===</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">get_checkpoint</span><span class="p">()</span>
    <span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">checkpoint</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">as_directory</span><span class="p">()</span> <span class="k">as</span> <span class="n">ckpt_dir</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">)))</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;optimizer.pt&quot;</span><span class="p">)))</span>
            <span class="n">start_epoch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;extra.pt&quot;</span><span class="p">))[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Rank </span><span class="si">{</span><span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_world_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">] Resumed from checkpoint at epoch </span><span class="si">{</span><span class="n">start_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># === DataLoaders ===</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">build_dataloader</span><span class="p">(</span>
        <span class="s2">&quot;/mnt/cluster_storage/food101_lite/train.parquet&quot;</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">build_dataloader</span><span class="p">(</span>
        <span class="s2">&quot;/mnt/cluster_storage/food101_lite/val.parquet&quot;</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>

    <span class="c1"># === Training Loop ===</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">]):</span>
        <span class="n">train_loader</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">set_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>  <span class="c1"># required when using DistributedSampler</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">train_loss_total</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">train_batches</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">train_loss_total</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">train_batches</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_loss_total</span> <span class="o">/</span> <span class="n">train_batches</span>

        <span class="c1"># === Validation Loop ===</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">val_loss_total</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">val_batches</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">val_xb</span><span class="p">,</span> <span class="n">val_yb</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
                <span class="n">val_loss_total</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">val_xb</span><span class="p">),</span> <span class="n">val_yb</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">val_batches</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">val_loss_total</span> <span class="o">/</span> <span class="n">val_batches</span>

        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;train_loss&quot;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">,</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">train</span><span class="o">.</span><span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_world_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>

        <span class="c1"># === Save checkpoint only on rank 0 ===</span>
        <span class="k">if</span> <span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_world_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">ckpt_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;/mnt/cluster_storage/food101_lite/tmp_checkpoints/epoch_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">hex</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">))</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;optimizer.pt&quot;</span><span class="p">))</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">},</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;extra.pt&quot;</span><span class="p">))</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_directory</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Append metrics to a file (only on rank 0)</span>
        <span class="k">if</span> <span class="n">train</span><span class="o">.</span><span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_world_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;/mnt/cluster_storage/food101_lite/results/history.csv&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">val_loss</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">train</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="n">checkpoint</span><span class="p">)</span>

    <span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
        <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">xb</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">yb</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">yb</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">yb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Val Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="launch-distributed-training-with-torchtrainer">
<h1>12 Â· Launch Distributed Training with <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code><a class="headerlink" href="#launch-distributed-training-with-torchtrainer" title="Link to this heading">#</a></h1>
<p>Now, instantiate a <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code>. Ask for eight GPU workers, enable up to three automatic retries, and tell Ray to keep the five checkpoints with the lowest validation loss. One call to <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code> kicks off a fault-tolerant job on your Anyscale cluster.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 12. Run Training with Ray Train </span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
    <span class="n">train_loop_per_worker</span><span class="o">=</span><span class="n">train_loop_per_worker</span><span class="p">,</span>
    <span class="n">train_loop_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span> <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">run_config</span><span class="o">=</span><span class="n">RunConfig</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;food101_ft_resume&quot;</span><span class="p">,</span>
        <span class="n">storage_path</span><span class="o">=</span><span class="s2">&quot;/mnt/cluster_storage/food101_lite/results&quot;</span><span class="p">,</span>
        <span class="n">checkpoint_config</span><span class="o">=</span><span class="n">CheckpointConfig</span><span class="p">(</span>
            <span class="n">num_to_keep</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
            <span class="n">checkpoint_frequency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">checkpoint_score_attribute</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
            <span class="n">checkpoint_score_order</span><span class="o">=</span><span class="s2">&quot;min&quot;</span>
        <span class="p">),</span>
        <span class="n">failure_config</span><span class="o">=</span><span class="n">FailureConfig</span><span class="p">(</span><span class="n">max_failures</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
    <span class="p">),</span>
<span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final metrics:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
<span class="n">best_ckpt</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span>  <span class="c1"># this is the one with lowest val_loss</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-loss-curves">
<h1>13 Â· Plot Loss Curves<a class="headerlink" href="#plot-loss-curves" title="Link to this heading">#</a></h1>
<p>When training finishes, read the CSV history file and plot training and validation losses for every epoch. Seeing the two curves together helps you spot over-fitting or under-fitting at a glance. In this example, given enough epochs, itâ€™s expected to see some over-fitting, as indicated by the decrease in training loss but increase in validation loss. As you are saving the checkpoints of the model with the lowest validation curve, you can test inference prior to this phenomenon.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 13. Plot training / validation loss curves</span>
<span class="n">history_path</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite/results/history.csv&quot;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">history_path</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">])</span>

<span class="c1"># Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Train Loss&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Val Loss&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Train/Val Loss across Epochs&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="demonstrate-fault-tolerant-resume">
<h1>14 Â· Demonstrate Fault-Tolerant Resume<a class="headerlink" href="#demonstrate-fault-tolerant-resume" title="Link to this heading">#</a></h1>
<p>To prove that checkpointing works, run <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code> a second time without changing a thing. If the earlier run crashed mid-epoch, Ray automatically picks up the latest checkpoint and continue. If it already finished, Ray simply starts a clean new experiment.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 14. Run the trainer again to demonstrate resuming from latest checkpoint  </span>

<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final metrics:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="remote-inference-helper">
<h1>15 Â· Remote Inference Helper<a class="headerlink" href="#remote-inference-helper" title="Link to this heading">#</a></h1>
<p>Define a lightweight Ray remote function that loads a chosen checkpoint into a fresh <code class="docutils literal notranslate"><span class="pre">resnet18</span></code>, runs inference on one image, and returns both the predicted and true labels. Because the function requests one GPU, Ray schedules it on an appropriate node.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 15. Define batch inference function</span>

<span class="nd">@ray</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">run_inference_from_checkpoint</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">parquet_path</span><span class="p">,</span> <span class="n">idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="c1"># === Load model ===</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_directory</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">as_directory</span><span class="p">()</span> <span class="k">as</span> <span class="n">ckpt_dir</span><span class="p">:</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">),</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

        <span class="c1"># Strip &quot;module.&quot; prefix from distributed data parallelism trained weights</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;module.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="c1"># === Define transform ===</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">T</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">IMAGENET_MEAN</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">IMAGENET_STD</span><span class="p">),</span>
    <span class="p">])</span>

    <span class="c1"># === Load dataset ===</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">Food101Dataset</span><span class="p">(</span><span class="n">parquet_path</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
    <span class="n">img</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>  <span class="c1"># batch size 1</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;predicted_label&quot;</span><span class="p">:</span> <span class="n">pred</span><span class="p">,</span> <span class="s2">&quot;true_label&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">),</span> <span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="n">idx</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<section id="run-and-visualise-inference">
<h2>16 Â· Run and Visualise Inference<a class="headerlink" href="#run-and-visualise-inference" title="Link to this heading">#</a></h2>
<p>Using the checkpoint with the lowest validation loss, invoke your remote inference helper on a validation image. Then plot the image while displaying both the modelâ€™s prediction and the ground-truth class, giving you an immediate, intuitive sense of performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 16. Perform inference with best trained model (i.e. lowest validation loss for a checkpointed model)</span>
 
<span class="n">checkpoint_root</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite/results/food101_ft_resume&quot;</span>

<span class="n">checkpoint_dirs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">checkpoint_root</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">d</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;checkpoint_&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_root</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
    <span class="p">],</span>
    <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">checkpoint_dirs</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="s2">&quot;No checkpoint directories found.&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">as_directory</span><span class="p">()</span> <span class="k">as</span> <span class="n">ckpt_dir</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best checkpoint contents:&quot;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">))</span>
    <span class="n">best_ckpt_path</span> <span class="o">=</span> <span class="n">ckpt_dir</span> 
<span class="n">parquet_path</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite/val.parquet&quot;</span>

<span class="c1"># Define which image to use</span>
<span class="n">idx</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Launch GPU inference task with Ray</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">run_inference_from_checkpoint</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">best_ckpt_path</span><span class="p">,</span> <span class="n">parquet_path</span><span class="p">,</span> <span class="n">idx</span><span class="o">=</span><span class="n">idx</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="c1"># Load label map from Hugging Face</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;food101&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train[:1%]&quot;</span><span class="p">)</span>  <span class="c1"># load just to get label names</span>
<span class="n">label_names</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span>

<span class="c1"># Load image from the same dataset locally</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">Food101Dataset</span><span class="p">(</span><span class="n">parquet_path</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># No transform = raw image</span>
<span class="n">img</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="c1"># Plot the image with predicted and true labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pred: </span><span class="si">{</span><span class="n">label_names</span><span class="p">[</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;predicted_label&#39;</span><span class="p">]]</span><span class="si">}</span><span class="se">\n</span><span class="s2">True: </span><span class="si">{</span><span class="n">label_names</span><span class="p">[</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;true_label&#39;</span><span class="p">]]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cleanup">
<h2>17 Â· Cleanup<a class="headerlink" href="#cleanup" title="Link to this heading">#</a></h2>
<p>Finally, tidy up by deleting temporary checkpoint folders, the metrics CSV, and any intermediate result directories. Clearing out old artefacts frees disk space and leaves your workspace clean for whatever comes next.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 17. Cleanup---delete checkpoints and metrics from model training</span>

<span class="c1"># Base directory</span>
<span class="n">BASE_DIR</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite&quot;</span>

<span class="c1"># Paths to clean</span>
<span class="n">paths_to_delete</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s2">&quot;tmp_checkpoints&quot;</span><span class="p">),</span>           <span class="c1"># custom checkpoints</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s2">&quot;results&quot;</span><span class="p">,</span> <span class="s2">&quot;history.csv&quot;</span><span class="p">),</span>    <span class="c1"># metrics history file</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s2">&quot;results&quot;</span><span class="p">,</span> <span class="s2">&quot;food101_ft_resume&quot;</span><span class="p">),</span>  <span class="c1"># ray trainer run dir</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s2">&quot;results&quot;</span><span class="p">,</span> <span class="s2">&quot;food101_ft_run&quot;</span><span class="p">),</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s2">&quot;results&quot;</span><span class="p">,</span> <span class="s2">&quot;food101_single_run&quot;</span><span class="p">),</span>
<span class="p">]</span>

<span class="c1"># Delete each path if it exists</span>
<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths_to_delete</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Deleted file: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Deleted directory: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Not found (skipped): </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="wrapping-up-next-steps">
<h2>ğŸ‰ Wrapping Up &amp; Next Steps<a class="headerlink" href="#wrapping-up-next-steps" title="Link to this heading">#</a></h2>
<p>Great job making it to the end. Youâ€™ve taken a realistic computer-vision workload, from raw images all the way to distributed training and GPU inference, and run it on Ray Train with zero boilerplate around GPUs, data parallelism, or fault-tolerance. You should now feel comfortable:</p>
<ul class="simple">
<li><p>Using <strong>Ray Trainâ€™s TorchTrainer</strong> to scale PyTorch training across multiple GPUs and nodes with minimal code changes</p></li>
<li><p>Wrapping models and data loaders with <strong><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></strong> and <strong><code class="docutils literal notranslate"><span class="pre">prepare_data_loader()</span></code></strong> to enable Ray-managed device placement and distributed execution</p></li>
<li><p>Sharding data across workers using <strong><code class="docutils literal notranslate"><span class="pre">DistributedSampler</span></code></strong>, and coordinating training epochs across Ray workers</p></li>
<li><p>Configuring <strong>automatic checkpointing and failure recovery</strong> using Ray Trainâ€™s built-in <code class="docutils literal notranslate"><span class="pre">Checkpoint</span></code>, <code class="docutils literal notranslate"><span class="pre">RunConfig</span></code>, and <code class="docutils literal notranslate"><span class="pre">FailureConfig</span></code> APIs</p></li>
<li><p>Running <strong>GPU-backed Ray tasks</strong> for distributed inference, showing how to serve and scale model predictions across a Ray cluster</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="where-can-you-take-this-next">
<h2>ğŸš€ Where can you take this next?<a class="headerlink" href="#where-can-you-take-this-next" title="Link to this heading">#</a></h2>
<p>Below are a few directions you might explore to adapt or extend the pattern:</p>
<ol class="arabic simple">
<li><p><strong>Larger or Custom Datasets</strong></p>
<ul class="simple">
<li><p>Swap in the full 75 k-image Food-101 splitâ€”or your own dataset in any storage backend (S3, GCS, Azure Blob).</p></li>
<li><p>Add multi-file Parquet sharding and let each worker read a different shard.</p></li>
</ul>
</li>
<li><p><strong>Model Architectures</strong></p>
<ul class="simple">
<li><p>Drop in Vision Transformers (<code class="docutils literal notranslate"><span class="pre">vit_b_16</span></code>, <code class="docutils literal notranslate"><span class="pre">vit_l_32</span></code>) or ConvNeXt; the prepare helpers work exactly the same.</p></li>
<li><p>Experiment with transfer learning vs. training from scratch.</p></li>
</ul>
</li>
<li><p><strong>Mixed Precision &amp; Performance Tuning</strong></p>
<ul class="simple">
<li><p>Enable automatic mixed precision (<code class="docutils literal notranslate"><span class="pre">torch.cuda.amp</span></code>) or bfloat16 to speed up training and save memory.</p></li>
<li><p>Profile data-loading throughput and play with <code class="docutils literal notranslate"><span class="pre">num_workers</span></code>, prefetching, and caching.</p></li>
</ul>
</li>
<li><p><strong>Hyperparameter Sweeps</strong></p>
<ul class="simple">
<li><p>Wrap the training loop in <strong>Ray Tune</strong> to search over learning rates, augmentations, or optimisers.</p></li>
<li><p>Use Rayâ€™s integrated reporting to schedule early stopping.</p></li>
</ul>
</li>
<li><p><strong>Data Augmentation Pipelines</strong></p>
<ul class="simple">
<li><p>Integrate additional transforms inside the dataset class for image augmentation.</p></li>
<li><p>Compare CPU vs. GPU-side augmentations for throughput.</p></li>
</ul>
</li>
<li><p><strong>Distributed Validation &amp; Metrics</strong></p>
<ul class="simple">
<li><p>Replace your simple accuracy printout with more advanced metrics (F1, top-5 accuracy, confusion matrices).</p></li>
</ul>
</li>
<li><p><strong>Model Serving</strong></p>
<ul class="simple">
<li><p>Convert the remote inference helper into a <strong>Ray Serve</strong> deployment for low-latency online predictions.</p></li>
<li><p>Auto-scale replicas based on request volume.</p></li>
</ul>
</li>
<li><p><strong>End-to-End MLOps</strong></p>
<ul class="simple">
<li><p>Register checkpoints in a model registry (For example, MLflow, Weights &amp; Biases, or Rayâ€™s built-in MLflow integration).</p></li>
<li><p>Schedule the notebook as a Ray Job or CI/CD pipeline for regular retraining runs.</p></li>
</ul>
</li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./courses/ray-train-201"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">ğŸ–¼ï¸ 04a Â· Computer-Vision Pattern with Ray Train</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-youll-learn-take-away">What youâ€™ll learn &amp; take away</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-problem-are-you-solving-image-classification-with-food-101-lite">ğŸ”¢ What problem are you solving? (Image classification with Food-101-Lite)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inputs">Inputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#labels">Labels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-does-the-model-learn">What does the model learn?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-you-migrate-this-computer-vision-workload-to-a-distributed-setup-using-ray-on-anyscale">ğŸ§­ How you migrate this computer vision workload to a distributed setup using Ray on Anyscale</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">01 Â· Imports</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-10-of-food-101">02 Â· Load 10 % of Food-101</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resize-and-encode-images">03 Â· Resize and Encode Images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visual-sanity-check">04 Â· Visual Sanity Check</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#persist-to-parquet">05 Â· Persist to Parquet</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-food101dataset-for-parquet">06 Â· Custom <code class="docutils literal notranslate"><span class="pre">Food101Dataset</span></code> for Parquet</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-transform">07 Â· Image Transform</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trainvalidation-split">08 Â· Trainâ€“Validation Split</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inspect-a-dataloader-batch">09 Â· Inspect a DataLoader Batch</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-ray-prepared-dataloaders">10 Â· Helper: Ray-Prepared DataLoaders</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#train-loop-per-worker">11 Â· <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-distributed-training-with-torchtrainer">12 Â· Launch Distributed Training with <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-loss-curves">13 Â· Plot Loss Curves</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstrate-fault-tolerant-resume">14 Â· Demonstrate Fault-Tolerant Resume</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#remote-inference-helper">15 Â· Remote Inference Helper</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-and-visualise-inference">16 Â· Run and Visualise Inference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cleanup">17 Â· Cleanup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wrapping-up-next-steps">ğŸ‰ Wrapping Up &amp; Next Steps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where-can-you-take-this-next">ğŸš€ Where can you take this next?</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book community
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>