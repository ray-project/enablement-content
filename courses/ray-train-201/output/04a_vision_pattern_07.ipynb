{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 \u00b7 Plot Loss Curves  \n",
    "When training finishes, read the CSV history file and plot training and validation losses for every epoch. Seeing the two curves together helps you spot over-fitting or under-fitting at a glance. In this example, given enough epochs, it's expected to see some over-fitting, as indicated by the decrease in training loss but increase in validation loss. As you are saving the checkpoints of the model with the lowest validation curve, you can test inference prior to this phenomenon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Plot training / validation loss curves\n",
    "history_path = \"/mnt/cluster_storage/food101_lite/results/history.csv\"\n",
    "df = pd.read_csv(history_path, names=[\"epoch\", \"train_loss\", \"val_loss\"])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(df[\"epoch\"], df[\"train_loss\"], label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(df[\"epoch\"], df[\"val_loss\"], label=\"Val Loss\", marker=\"o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train/Val Loss across Epochs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}