{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reverse diffusion helper\n",
    "\n",
    "Iteratively de-noise a random action vector **50 steps** back to a feasible Pendulum command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08. Reverse diffusion sampling for 1-D action\n",
    "\n",
    "# Function to simulate reverse diffusion process\n",
    "def sample_action(model, obs, n_steps=50, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Runs reverse diffusion starting from noise to generate a Pendulum action.\n",
    "    obs: torch.Tensor of shape (3,)\n",
    "    returns: torch.Tensor of shape (1,)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        obs = obs.unsqueeze(0).to(device)      # [1, 3]\n",
    "        obs = obs / np.pi                      # Same normalization used in training\n",
    "\n",
    "        x = torch.randn(1, 1).to(device)       # Start from noise in action space\n",
    "\n",
    "        for step in reversed(range(n_steps)):\n",
    "            t = torch.tensor([step], device=device)\n",
    "            pred_noise = model(obs, x, t)\n",
    "            x = x - pred_noise * 0.1\n",
    "\n",
    "        return x.squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Sample an action from the trained policy\n",
    "\n",
    "Finally, load the **latest epoch checkpoint**, supply a sample state  \n",
    "`[cos \u03b8 = 1, sin \u03b8 = 0, \u03b8\u0307 = 0]`, and generate a 1-D torque command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 09. In-notebook sampling from trained model (Ray Lightning checkpoint)\n",
    "\n",
    "# A plausible pendulum state: [cos(theta), sin(theta), theta_dot]\n",
    "obs_sample = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float32)   # shape (3,)\n",
    "\n",
    "assert best_ckpt is not None, \"No checkpoint found \u2014 did training complete successfully?\"\n",
    "\n",
    "# Load the trained model from Ray's latest Lightning checkpoint\n",
    "model = DiffusionPolicy(obs_dim=3, act_dim=1)\n",
    "\n",
    "with best_ckpt.as_directory() as ckpt_dir:\n",
    "    # RayTrainReportCallback saves a file named \"checkpoint.ckpt\"\n",
    "    ckpt_file = os.path.join(ckpt_dir, \"checkpoint.ckpt\")\n",
    "    if not os.path.exists(ckpt_file):\n",
    "        # Fallback: search any .ckpt file if name differs\n",
    "        candidates = glob.glob(os.path.join(ckpt_dir, \"*.ckpt\"))\n",
    "        ckpt_file = candidates[0] if candidates else None\n",
    "\n",
    "    assert ckpt_file is not None, f\"No Lightning checkpoint found in {ckpt_dir}\"\n",
    "    state = torch.load(ckpt_file, map_location=\"cpu\")\n",
    "    model.load_state_dict(state.get(\"state_dict\", state), strict=False)\n",
    "\n",
    "# Move to device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# Run reverse diffusion sampling\n",
    "action = sample_action(model, obs_sample, n_steps=50, device=device)\n",
    "print(\"Sampled action:\", action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Clean up\n",
    "\n",
    "When you're finished, release Ray resources and clear any temporary files.  \n",
    "This ensures the cluster is ready for other jobs and avoids unnecessary storage costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Cleanup -- delete checkpoints and metrics from model training\n",
    "\n",
    "TARGET_PATH = \"/mnt/cluster_storage/pendulum_diffusion\"\n",
    "\n",
    "if os.path.exists(TARGET_PATH):\n",
    "    shutil.rmtree(TARGET_PATH)\n",
    "    print(f\"\u2705 Deleted everything under {TARGET_PATH}\")\n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f Path does not exist: {TARGET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap up and next steps  \n",
    "\n",
    "You transformed a synthetic control demo into a **Ray-native, real-data pipeline**, training a diffusion policy across multiple GPUs, surviving worker restarts, and sampling feasible actions, all within a distributed Ray environment.\n",
    "\n",
    "You should now feel confident:\n",
    "\n",
    "* Logging continuous-control trajectories directly into a **Ray Dataset** for scalable preprocessing  \n",
    "* Streaming data into a **Ray Train** workload using Ray Data and Lightning with minimal integration overhead  \n",
    "* Saving structured checkpoints automatically through **Lightning + Ray Train callbacks**, ensuring seamless **fault-tolerant recovery**  \n",
    "* Running reverse diffusion sampling directly in-notebook\n",
    "\n",
    "---\n",
    "\n",
    "### Where can you take this next?\n",
    "\n",
    "The following are a few directions you can explore to extend or adapt this workload:\n",
    "\n",
    "1. **Evaluate in the environment**  \n",
    "   * Load the best checkpoint, deploy the policy in Gym\u2019s `Pendulum-v1`, and log episode returns.  \n",
    "   * Compare against baseline behavior cloning or TD3/TD3+BC.\n",
    "\n",
    "2. **Larger and richer datasets**  \n",
    "   * Generate 100 k+ steps with a scripted controller or collect data from a learned agent.  \n",
    "   * Swap in other classic-control tasks like `CartPole` or `MountainCar`.\n",
    "\n",
    "3. **Model and loss upgrades**  \n",
    "   * Add timestep embeddings or a small transformer for better temporal reasoning.  \n",
    "   * Experiment with different noise schedules or auxiliary consistency losses.\n",
    "\n",
    "4. **Hyperparameter sweeps**  \n",
    "   * Wrap the training loop in **Ray Tune** and grid-search learning rate, hidden size, or diffusion steps.  \n",
    "   * Use Tune\u2019s automatic checkpoint pruning to keep only the top-N runs.\n",
    "\n",
    "5. **Mixed precision and performance**  \n",
    "   * Enable `torch.set_float32_matmul_precision('high')` to leverage A10G Tensor Cores.  \n",
    "   * Profile GPU utilization across workers and tune batch size accordingly.\n",
    "\n",
    "6. **Real robotics logs**  \n",
    "   * Replace Pendulum with logs from a real robotic apparatus stored in Parquet; Ray Data shards them the same way.\n",
    "\n",
    "7. **Serving the policy**  \n",
    "   * Export the trained MLP to TorchScript and deploy with **Ray Serve** for low-latency inference.  \n",
    "   * Hook it to a real-time simulator or a web dashboard.\n",
    "\n",
    "8. **End-to-end MLOps**  \n",
    "   * Track checkpoints and metrics with MLflow or Weights & Biases.  \n",
    "   * Schedule nightly Ray jobs on Anyscale to retrain as new data arrives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}