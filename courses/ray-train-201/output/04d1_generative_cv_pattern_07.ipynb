{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf89 Wrapping Up & Next Steps\n",
    "\n",
    "Awesome work making it to the end. In this tutorial, you used **Ray Train and Ray Data on Anyscale** to scale a compact diffusion-policy workload, from raw JPEG bytes to distributed training and sampling, without changing the core PyTorch logic. You should now feel confident:\n",
    "\n",
    "* Using **Ray Data** to decode, normalize, and shard large image datasets in parallel  \n",
    "* Scaling training across multiple GPUs using **TorchTrainer** and a Ray-native `train_loop`  \n",
    "* Managing distributed training state with **Ray Checkpoints** and automatic resume  \n",
    "* Running fault-tolerant multi-node jobs on Anyscale without orchestration scripts  \n",
    "* Performing post-training sampling or evaluation using **Ray tasks** on GPU workers\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\ude80 Where can you take this next?\n",
    "\n",
    "Below are a few directions you might explore to adapt or extend the pattern:\n",
    "\n",
    "1. **Backbones & Architecture Upgrades**  \n",
    "   * Swap in a larger ResNet or another vision model for much better generative performance.  \n",
    "   * Try pre-trained encoders and fine-tune only the diffusion-specific layers.\n",
    "\n",
    "2. **Conditional Diffusion**  \n",
    "   * Use the `label` column to condition the model (For example, class-conditioning).  \n",
    "   * Compare unconditional vs. conditional generation side by side.\n",
    "\n",
    "3. **Sampling Improvements**  \n",
    "   * Replace naive reverse diffusion with De-noising Diffusion Implicit Models (DDIM), Pseudo Numerical Methods for Diffusion Models (PNDM), or learned de-noisers.  \n",
    "   * Add timestep embeddings or noise schedules to increase model expressiveness.\n",
    "\n",
    "4. **Longer Training & Mixed Precision**  \n",
    "   * Increase the `max_epochs` and enable Automatic Mixed Precision (AMP) for faster training with less memory.  \n",
    "   * Visualize convergence and training stability across longer runs.\n",
    "\n",
    "5. **Hyperparameter Sweeps**  \n",
    "   * Use **Ray Tune** to search over learning rates, model size, or sampling steps.  \n",
    "   * Leverage Tune\u2019s reporting to schedule early stopping or checkpoint pruning.\n",
    "\n",
    "6. **Data Handling & Scaling**  \n",
    "   * Shard the dataset into multiple Parquet files and distribute across more workers.  \n",
    "   * Store and load datasets from S3 or other cloud storage.\n",
    "\n",
    "7. **Image Quality Evaluation**  \n",
    "   * Log Fr\u00e9chet Inception Distance (FID) scores, perceptual similarity, or diffusion-specific metrics.  \n",
    "   * Compare generated samples from different checkpoints or backbones.\n",
    "\n",
    "8. **Model Serving**  \n",
    "   * Package the reverse sampler into a Ray task or **Ray Serve** endpoint.  \n",
    "   * Run a demo app that generates images on demand from a class name or random seed.\n",
    "\n",
    "9. **End-to-End MLOps**  \n",
    "   * Register the best checkpoint with MLflow or Weights & Biases.  \n",
    "   * Wrap the training loop in a Ray Job and run it on a schedule with Anyscale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}