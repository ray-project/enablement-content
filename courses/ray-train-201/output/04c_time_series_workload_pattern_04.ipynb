{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 \u00b7 Launch training on 8 GPUs  \n",
    "Here you construct a `TorchTrainer` and run it. Ray automatically distributes the model across 8 GPUs, prepares the datasets for each worker, and starts training. Also configure checkpointing to retain the top-performing models and set failure recovery to 3 attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Launch training\n",
    "\n",
    "os.makedirs(os.path.join(DATA_DIR, \"results\"), exist_ok=True)\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\"lr\": 1e-3, \"bs\": 4, \"epochs\": 20,\n",
    "                       \"d_model\": 128, \"nhead\": 4, \"num_layers\": 3},\n",
    "    scaling_config=ScalingConfig(num_workers=8, use_gpu=True),\n",
    "    run_config=RunConfig(\n",
    "        name=\"nyc_taxi_transformer\",\n",
    "        storage_path=os.path.join(DATA_DIR, \"results\"),\n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=4, checkpoint_frequency=1,\n",
    "            checkpoint_score_attribute=\"val_loss\", checkpoint_score_order=\"min\"),\n",
    "        failure_config=FailureConfig(max_failures=3),\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = trainer.fit()\n",
    "print(\"Final metrics:\", result.metrics)\n",
    "best_ckpt = result.checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 \u00b7 Plot training + validation loss  \n",
    "After training, visualise the saved `history.csv` to assess whether the model is over-fitting, under-fitting, or improving steadily. A healthy curve shows decreasing train and validation loss, with convergence over time. This diagnostic is especially useful when comparing different model configurations. In this tutorial, You aren't using substantial amounts of data, and so you see the validation curve remains primarily stagnant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Plot loss curves \n",
    "\n",
    "hist_path = os.path.join(DATA_DIR, \"results\", \"history.csv\")\n",
    "\n",
    "if os.path.exists(hist_path):\n",
    "    df_hist = pd.read_csv(hist_path, names=[\"epoch\", \"train_loss\", \"val_loss\"])\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(df_hist[\"epoch\"], df_hist[\"train_loss\"], label=\"Train\", marker=\"o\")\n",
    "    plt.plot(df_hist[\"epoch\"], df_hist[\"val_loss\"], label=\"Val\",   marker=\"o\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"MSE Loss\"); plt.grid(True); plt.legend()\n",
    "    plt.title(\"Train vs. Val Loss\"); plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"No history.csv found. Make sure to log it in the training loop.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}