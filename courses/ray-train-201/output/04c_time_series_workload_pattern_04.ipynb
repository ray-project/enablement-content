{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Ray Train training loop (with teacher forcing)  \n",
    "This is the heart of Ray Train. Each worker executes this loop independently, but Ray orchestrates everything from checkpointing to failure recovery. Include teacher forcing, feeding the shifted ground-truth to the decoder, which allows the model to learn more quickly than starting from zero. Also log training and validation loss per epoch and save checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Ray Train train_loop_per_worker with checkpointing, teacher forcing, and clean structure\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    import tempfile\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from ray import train\n",
    "    from ray.train import Checkpoint, get_context\n",
    "    from ray.train import get_checkpoint\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    # 1) Model (DDP-prepared)\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    model = TimeSeriesTransformer(\n",
    "        input_window=INPUT_WINDOW,\n",
    "        horizon=HORIZON,\n",
    "        d_model=config[\"d_model\"],\n",
    "        nhead=config[\"nhead\"],\n",
    "        num_layers=config[\"num_layers\"],\n",
    "    )\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    # 2) Optimizer / Loss\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    # 3) Resume from checkpoint (if provided by Ray)\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    rank = get_context().get_world_rank()\n",
    "    start_epoch = 0\n",
    "    ckpt = get_checkpoint()\n",
    "    if ckpt:\n",
    "        with ckpt.as_directory() as ckpt_dir:\n",
    "            # Safe CPU load in case of device mismatch on resume\n",
    "            model.load_state_dict(torch.load(os.path.join(ckpt_dir, \"model.pt\"), map_location=\"cpu\"))\n",
    "            opt_state_path = os.path.join(ckpt_dir, \"optim.pt\")\n",
    "            if os.path.exists(opt_state_path):\n",
    "                optimizer.load_state_dict(torch.load(opt_state_path, map_location=\"cpu\"))\n",
    "            meta = torch.load(os.path.join(ckpt_dir, \"meta.pt\"))\n",
    "            start_epoch = int(meta.get(\"epoch\", -1)) + 1\n",
    "        if rank == 0:\n",
    "            print(f\"[Rank {rank}] \u2705 Resumed from checkpoint at epoch {start_epoch}\")\n",
    "\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    # 4) Dataloaders for this worker\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    train_loader = build_dataloader(\n",
    "        os.path.join(PARQUET_DIR, \"train.parquet\"),\n",
    "        batch_size=config[\"bs\"],\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_loader = build_dataloader(\n",
    "        os.path.join(PARQUET_DIR, \"val.parquet\"),\n",
    "        batch_size=config[\"bs\"],\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    # 5) Epoch loop\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    for epoch in range(start_epoch, config[\"epochs\"]):\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "        for past, future in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Teacher forcing: shift future targets to use as decoder input\n",
    "            future = future.unsqueeze(-1)                                # (B, F, 1)\n",
    "            start_token = torch.zeros_like(future[:, :1])                # (B, 1, 1)\n",
    "            decoder_input = torch.cat([start_token, future[:, :-1]], 1)  # (B, F, 1)\n",
    "\n",
    "            pred = model(past, decoder_input)                            # (B, F)\n",
    "            loss = loss_fn(pred, future.squeeze(-1))                     # (B, F) vs (B, F)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_sum += float(loss.item())\n",
    "\n",
    "        avg_train_loss = train_loss_sum / max(1, len(train_loader))\n",
    "\n",
    "        # ---- Validate ----\n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for past, future in val_loader:\n",
    "                pred = model(past)                                       # zeros-as-decoder-input path\n",
    "                loss = loss_fn(pred, future)\n",
    "                val_loss_sum += float(loss.item())\n",
    "        avg_val_loss = val_loss_sum / max(1, len(val_loader))\n",
    "\n",
    "        if rank == 0:\n",
    "            print({\"epoch\": epoch, \"train_loss\": avg_train_loss, \"val_loss\": avg_val_loss})\n",
    "\n",
    "        metrics = {\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"val_loss\": avg_val_loss,\n",
    "        }\n",
    "\n",
    "        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        # 6) Report + temp checkpoint (rank 0 attaches; others metrics-only)\n",
    "        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        if rank == 0:\n",
    "            with tempfile.TemporaryDirectory() as tmpdir:\n",
    "                torch.save(model.state_dict(), os.path.join(tmpdir, \"model.pt\"))\n",
    "                torch.save(optimizer.state_dict(), os.path.join(tmpdir, \"optim.pt\"))\n",
    "                torch.save({\"epoch\": epoch}, os.path.join(tmpdir, \"meta.pt\"))\n",
    "                ckpt_out = Checkpoint.from_directory(tmpdir)\n",
    "                train.report(metrics, checkpoint=ckpt_out)\n",
    "        else:\n",
    "            train.report(metrics, checkpoint=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Launch training on 8 GPUs  \n",
    "Construct a `TorchTrainer` and run it. Ray automatically distributes the model across 8 GPUs, prepares the datasets for each worker, and starts training. Also configure checkpointing to retain the top-performing models and set failure recovery to 3 attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Launch training\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\"lr\": 1e-3, \"bs\": 4, \"epochs\": 20,\n",
    "                       \"d_model\": 128, \"nhead\": 4, \"num_layers\": 3},\n",
    "    scaling_config=ScalingConfig(num_workers=8, use_gpu=True),\n",
    "    run_config=RunConfig(\n",
    "        name=\"nyc_taxi_transformer\",\n",
    "        storage_path=os.path.join(DATA_DIR, \"results\"),  \n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=20,\n",
    "            # Let your loop decide when to checkpoint (each epoch). Scoring still applies.\n",
    "            checkpoint_score_attribute=\"val_loss\",\n",
    "            checkpoint_score_order=\"min\",\n",
    "            # (Optional) If you want the last epoch\u2019s checkpoint regardless of score:\n",
    "            # checkpoint_at_end=True,\n",
    "        ),\n",
    "        failure_config=FailureConfig(max_failures=3),\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = trainer.fit()\n",
    "print(\"Final metrics:\", result.metrics)\n",
    "\n",
    "# Best checkpoint (by val_loss) thanks to checkpoint_score_* above:\n",
    "best_ckpt = result.checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Plot training and validation loss  \n",
    "After training, visualize the saved metrics to assess whether the model is over-fitting, under-fitting, or improving steadily. A healthy curve shows decreasing train and validation loss, with convergence over time. This diagnostic is especially useful when comparing different model configurations. In this tutorial, you aren't using substantial amounts of data, so you see the validation curve remains primarily stagnant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Plot train/val loss curves (from Ray Train results)\n",
    "\n",
    "# Pull full metrics history Ray stored for this run\n",
    "df = result.metrics_dataframe.copy()\n",
    "\n",
    "# Keep only relevant columns (defensive in case Ray adds extras)\n",
    "cols = [c for c in [\"epoch\", \"train_loss\", \"val_loss\"] if c in df.columns]\n",
    "df = df[cols].dropna()\n",
    "\n",
    "# If multiple reports per epoch exist, keep the latest one\n",
    "if \"epoch\" in df.columns:\n",
    "    df = df.sort_index().groupby(\"epoch\", as_index=False).last()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7, 4))\n",
    "if \"train_loss\" in df.columns:\n",
    "    plt.plot(df[\"epoch\"], df[\"train_loss\"], marker=\"o\", label=\"Train\")\n",
    "if \"val_loss\" in df.columns:\n",
    "    plt.plot(df[\"epoch\"], df[\"val_loss\"], marker=\"o\", label=\"Val\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"SmoothL1 Loss\")\n",
    "plt.title(\"TimeSeriesTransformer \u2014 Train vs. Val Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}