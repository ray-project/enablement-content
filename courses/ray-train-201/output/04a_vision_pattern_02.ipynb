{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 \u00b7 Imports  \n",
    "Before you start, gather every library you're going to rely on throughout this notebook. Pull in core Python utilities for file handling and plotting, PyTorch and TorchVision for deep-learning components, Ray Train for distributed orchestration, Hugging Face Datasets for quick data access, and PyArrow plus Pandas for fast Parquet IO. Importing everything up-front keeps the rest of the tutorial clean and predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. Imports\n",
    "\n",
    "# \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n",
    "# Standard Library Utilities\n",
    "# \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n",
    "import os, io, tempfile, shutil  # file I/O and temp dirs\n",
    "import json                      # reading/writing configs\n",
    "import random, uuid              # randomness and unique IDs\n",
    "\n",
    "# \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n",
    "# Core Data & Storage Libraries\n",
    "# \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n",
    "import pandas as pd              # tabular data handling\n",
    "import numpy as np               # numerical ops\n",
    "import pyarrow as pa             # in-memory columnar format\n",
    "import pyarrow.parquet as pq     # reading/writing Parquet files\n",
    "from tqdm import tqdm            # progress bars\n",
    "\n",
    "# \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n",
    "# Image Handling & Visualization\n",
    "# \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt  # plotting loss curves, images\n",
    "\n",
    "# \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n",
    "# PyTorch + TorchVision Core\n",
    "# \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop\n",
    "\n",
    "# \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n",
    "# Ray Train: Distributed Training Primitives\n",
    "# \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n",
    "import ray\n",
    "import ray.train as train\n",
    "from ray.train.torch import (\n",
    "    prepare_model,\n",
    "    prepare_data_loader,\n",
    "    TorchTrainer,\n",
    ")\n",
    "from ray.train import (\n",
    "    ScalingConfig,\n",
    "    RunConfig,\n",
    "    FailureConfig,\n",
    "    CheckpointConfig,\n",
    "    Checkpoint,\n",
    "    get_checkpoint,\n",
    "    get_context,\n",
    ")\n",
    "\n",
    "# \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n",
    "# Dataset Access\n",
    "# \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n",
    "from datasets import load_dataset  # Hugging Face Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 \u00b7 Load 10 % of Food-101  \n",
    "Next, grab roughly 7,500 images, exactly 10% of Food-101\u2014using a single call to `load_dataset`. This trimmed subset trains quickly while still being large enough to demonstrate Ray\u2019s scaling behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02. Load 10% of food101 (~7,500 images)\n",
    "ds = load_dataset(\"food101\", split=\"train[:10%]\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 \u00b7 Resize and Encode Images  \n",
    "Here you preprocess each image: resize to 256 pixels, center-crop to 224 pixels (the size expected by most ImageNet models), and then convert the result to raw Joint Photographic Experts Group (JPEG) bytes. By storing bytes instead of full Python Imaging Library (PIL) objects, you| keep the dataset compact and Parquet-friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03. Resize + encode as JPEG bytes\n",
    "transform = Compose([Resize(256), CenterCrop(224)])\n",
    "records = []\n",
    "\n",
    "for example in tqdm(ds, desc=\"Preprocessing images\", unit=\"img\"):\n",
    "    try:\n",
    "        img = transform(example[\"image\"])\n",
    "        buf = io.BytesIO()\n",
    "        img.save(buf, format=\"JPEG\")\n",
    "        records.append({\n",
    "            \"image_bytes\": buf.getvalue(),\n",
    "            \"label\": example[\"label\"]\n",
    "        })\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 \u00b7 Visual Sanity Check  \n",
    "Before committing to hours of training, take nine random samples and plot them with their class names. This quick inspection lets you properly align labels and confirm that images are correctly resized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04. Visualize the dataset\n",
    "\n",
    "label_names = ds.features[\"label\"].names  # maps int \u2192 string\n",
    "\n",
    "samples = random.sample(records, 9)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(8, 8))\n",
    "fig.suptitle(\"Sample Resized Images from food101-lite\", fontsize=16)\n",
    "\n",
    "for ax, rec in zip(axs.flatten(), samples):\n",
    "    img = Image.open(io.BytesIO(rec[\"image_bytes\"]))\n",
    "    label_name = label_names[rec[\"label\"]]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(label_name)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 \u00b7 Persist to Parquet  \n",
    "Now write the images and labels to a Parquet file. Because Parquet is columnar, you can read just the columns you need during training, which speeds up IO---especially when multiple workers are reading in parallel under Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05. Write Dataset to Parquet\n",
    "\n",
    "output_dir = \"/mnt/cluster_storage/food101_lite/parquet_256\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "table = pa.Table.from_pydict({\n",
    "    \"image_bytes\": [r[\"image_bytes\"] for r in records],\n",
    "    \"label\": [r[\"label\"] for r in records]\n",
    "})\n",
    "pq.write_table(table, os.path.join(output_dir, \"shard_0.parquet\"))\n",
    "\n",
    "print(f\"Wrote {len(records)} records to {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}