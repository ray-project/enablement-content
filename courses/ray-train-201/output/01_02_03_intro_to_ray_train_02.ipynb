{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 \u00b7 Imports  \n",
    "\n",
    "Start by importing all the libraries you\u2019ll need for this tutorial.  \n",
    "\n",
    "- **Standard utilities**: `os`, `datetime`, `tempfile`, `csv`, `shutil`, and `gc` help with file paths, checkpointing, cleanup, and general housekeeping.  \n",
    "- **Data and visualization**: `pandas`, `numpy`, `matplotlib`, and `PIL` are used for inspecting the dataset and plotting sample images.  \n",
    "- **PyTorch**: core deep learning components (`torch`, `CrossEntropyLoss`, `Adam`) plus `torchvision` for loading MNIST and building a ResNet-18 model.  \n",
    "- **Ray Train**: the key imports for distributed training\u2014`ScalingConfig`, `RunConfig`, and `TorchTrainer`. These handle cluster scaling, experiment output storage, and execution of your training loop across GPUs.  \n",
    "\n",
    "This notebook assumes Ray is already running (for example, inside an Anyscale cluster), so you don\u2019t need to call `ray.init()` manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 01. Imports\n",
    "\n",
    "# --- Standard library: file IO, paths, timestamps, temp dirs, cleanup ---\n",
    "import csv            # Simple CSV logging for metrics in single-GPU section\n",
    "import datetime       # Timestamps for run directories / filenames\n",
    "import os             # Filesystem utilities (paths, env vars)\n",
    "import tempfile       # Ephemeral dirs for checkpoint staging with ray.train.report()\n",
    "import shutil         # Cleanup of artifacts (later cells)\n",
    "import gc             # Manual garbage collection to cleanup after inference\n",
    "\n",
    "from pathlib import Path  # Convenient, cross-platform path handling\n",
    "\n",
    "# --- Visualization & data wrangling ---\n",
    "import matplotlib.pyplot as plt  # Plot sample digits and metrics curves\n",
    "from PIL import Image            # Image utilities for inspection/debug\n",
    "import numpy as np               # Numeric helpers (random sampling, arrays)\n",
    "import pandas as pd              # Read metrics.csv into a DataFrame\n",
    "\n",
    "# --- PyTorch & TorchVision (model + dataset) ---\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss      # Classification loss for MNIST\n",
    "from torch.optim import Adam               # Optimizer\n",
    "from torchvision.models import resnet18    # Baseline CNN (we\u2019ll adapt for 1-channel input)\n",
    "from torchvision.datasets import MNIST     # Dataset\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose  # Preprocessing pipeline\n",
    "\n",
    "# --- Ray Train (distributed orchestration) ---\n",
    "import ray\n",
    "from ray.train import ScalingConfig, RunConfig      # Configure scale and storage\n",
    "from ray.train.torch import TorchTrainer            # Multi-GPU PyTorch trainer (DDP/FSDP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 \u00b7 Download MNIST Dataset  \n",
    "\n",
    "Next, download the **MNIST dataset** using `torchvision.datasets.MNIST`.  \n",
    "- This will automatically fetch the dataset (if not already present) into a local `./data` directory.  \n",
    "- MNIST consists of **60,000 grayscale images of handwritten digits (0\u20139)**, each sized **28\u00d728 pixels**.  \n",
    "- By setting `train=True`, we load the training split of the dataset.  \n",
    "\n",
    "Once downloaded, we\u2019ll later wrap this dataset in a `DataLoader` and apply normalization so it can be used for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 02. Download MNIST Dataset  \n",
    "\n",
    "dataset = MNIST(root=\"/mnt/cluster_storage/data\", train=True, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Note about Anyscale storage options</b>\n",
    "\n",
    "In this example, the MNIST dataset is stored under <code>/mnt/cluster_storage/</code>, which is Anyscale\u2019s **persistent cluster storage**.  \n",
    "\n",
    "* Unlike node-local NVMe volumes, cluster storage is **shared across nodes** in your cluster.  \n",
    "* Data written here will **persist across cluster restarts**, making it a safe place for datasets, checkpoints, and results.  \n",
    "* This is the recommended location for training data and artifacts you want to reuse.  \n",
    "\n",
    "* Anyscale also provides each node with its own volume and disk and doesn\u2019t share them with other nodes.\n",
    "* Local storage is very fast - Anyscale supports the Non-Volatile Memory Express (NVMe) interface.\n",
    "* Local storage is not a persisent storage, Anyscale deletes data in the local storage after instances are terminated. \n",
    "\n",
    "Read more about available <a href=\"https://docs.anyscale.com/configuration/storage\" target=\"_blank\">storage</a> options.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 \u00b7 Visualize Sample Digits  \n",
    "\n",
    "Before training, let\u2019s take a quick look at the dataset.  \n",
    "- We\u2019ll randomly sample **9 images** from the MNIST training set.  \n",
    "- Each image is a **28\u00d728 grayscale digit**, with its ground-truth label shown above the plot.  \n",
    "- This simple visualization is a good sanity check to confirm that the dataset downloaded correctly and that labels align with the images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 03. Visualize Sample Digits\n",
    "\n",
    "# Create a square figure for plotting 9 samples (3x3 grid)\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "# Loop through grid slots and plot a random digit each time\n",
    "for i in range(1, cols * rows + 1):\n",
    "    # Randomly select an index from the dataset\n",
    "    sample_idx = np.random.randint(0, len(dataset.data))\n",
    "    img, label = dataset[sample_idx]  # image (PIL) and its digit label\n",
    "    \n",
    "    # Add subplot to the figure\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)         # show the digit label above each subplot\n",
    "    plt.axis(\"off\")          # remove axes for cleaner visualization\n",
    "    plt.imshow(img, cmap=\"gray\")  # display as grayscale image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orphan": true,
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}