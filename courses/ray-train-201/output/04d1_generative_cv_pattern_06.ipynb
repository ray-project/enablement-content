{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 \u00b7 Reverse Diffusion Sampler  \n",
    "A simple Euler-style loop that starts from Gaussian noise and iteratively subtracts the model\u2019s predicted noise.  \n",
    "Not production-grade sampling, but perfect for illustrating inference after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Reverse Diffusion Sampling\n",
    "\n",
    "def sample_image(model, steps=50, device=\"cpu\"):\n",
    "    \"\"\"Generate an image by iteratively de-noising random noise.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        img = torch.randn(1, 3, 224, 224, device=device)\n",
    "        for step in reversed(range(steps)):\n",
    "            t = torch.tensor([step], device=device)\n",
    "            pred_noise = model(img, t)\n",
    "            img = img - pred_noise * 0.1                      # simple Euler update\n",
    "        # Rescale back to [0,1]\n",
    "        img = torch.clamp((img * 0.5 + 0.5), 0.0, 1.0)\n",
    "        return img.squeeze(0).cpu().permute(1,2,0).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14 \u00b7 Generate & Display Samples from **best checkpoint**  \n",
    "Load the model weights from `best_ckpt`, move to GPU if available, generate three images, and show them side-by-side.  \n",
    "Remember: with a tiny CNN and only 10 epochs, these samples look noise-like. If you replace the backbone or train longer you'd expect to see better quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Generate & Display Samples\n",
    "\n",
    "# Load model from Ray Train checkpoint\n",
    "from ray.train import Checkpoint\n",
    "\n",
    "assert best_ckpt is not None, \"Checkpoint is missing. Did training run and complete?\"\n",
    "\n",
    "with best_ckpt.as_directory() as ckpt_dir:\n",
    "    model = PixelDiffusion()\n",
    "    model.load_state_dict(torch.load(os.path.join(ckpt_dir, \"model.pt\"), map_location=\"cpu\"))\n",
    "\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate three images\n",
    "samples = [sample_image(model, steps=50, device=model.device) for _ in range(3)]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(9, 3))\n",
    "for ax, img in zip(axs, samples):\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"Food\u2011101 Diffusion Samples (unconditional)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 \u00b7 Cleanup Shared Storage  \n",
    "Reclaim cluster disk space by deleting the entire tutorial output directory.  \n",
    "Run this only when you\u2019re **sure** you don\u2019t need the checkpoints or metrics anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Cleanup -- delete checkpoints and metrics from model training\n",
    "\n",
    "TARGET_PATH = \"/mnt/cluster_storage/generative_cv\"\n",
    "\n",
    "if os.path.exists(TARGET_PATH):\n",
    "    shutil.rmtree(TARGET_PATH)\n",
    "    print(f\"\u2705 Deleted everything under {TARGET_PATH}\")\n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f Path does not exist: {TARGET_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}