{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd04 02 \u00b7 Integrating Ray Train with Ray Data  \n",
    "In this module you\u2019ll extend distributed training with **Ray Train** by adding **Ray Data** to the pipeline. Instead of relying on a local PyTorch DataLoader, you\u2019ll stream batches directly from a distributed **Ray Dataset**, enabling scalable preprocessing and just-in-time data loading across the cluster.  \n",
    "\n",
    "### What you\u2019ll learn & take away  \n",
    "* When to integrate **Ray Data** with Ray Train \u2014 e.g., for CPU-heavy preprocessing, online augmentations, or multi-format data ingestion  \n",
    "* How to replace `DataLoader` with **`iter_torch_batches()`** to stream batches into your training loop  \n",
    "* How to shard, shuffle, and preprocess data in parallel across the cluster before feeding it into GPUs  \n",
    "* How to define a **training loop** that consumes Ray Dataset shards instead of DataLoader tuples  \n",
    "* How to prepare datasets (For example, Parquet format) so they can be efficiently read and transformed with Ray Data  \n",
    "* How to pass Ray Datasets into the `TorchTrainer` with the `datasets` parameter  \n",
    "\n",
    "> With Ray Data, you can scale preprocessing and training independently \u2014 CPUs handle input pipelines, GPUs focus on training \u2014 ensuring **higher utilization and throughput** in your distributed workloads.  \n",
    "\n",
    "Note that the code blocks for this module will depend on the previous module, **Introduction to Ray Train**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udd0e Integrating Ray Train with Ray Data  \n",
    "\n",
    "Use both Ray Train and Ray Data when you face one of the following challenges:  \n",
    "| Challenge | Detail | Solution |\n",
    "| --- | --- | --- |\n",
    "| Need to perform online or just-in-time data processing | The training pipeline requires processing data on the fly, such as data augmentation, normalization, or other transformations that may differ for each training epoch. | Ray Train's integration with Ray Data makes it easy to implement just-in-time data processing. |\n",
    "| Need to improve hardware utilization | Training and data processing need to be scaled independently to keep GPUs fully utilized, especially when preprocessing is CPU-intensive. | Ray Data can distribute data processing across multiple CPU nodes, while Ray Train runs the training loop on GPUs. |\n",
    "| Need a consistent interface for loading data | The training process may need to load data from various sources, such as Parquet, CSV, or lakehouses. | Ray Data provides a consistent interface for loading, shuffling, sharding, and batching data for training loops. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orphan": true,
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}