
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>üñºÔ∏è 04-d1 ¬∑ Generative Computer-Vision Pattern with Ray Train &#8212; Course Notebooks</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom_hide.css?v=af9667c8" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'courses/ray-train-201/04d1_generative_cv_pattern';</script>
    <script src="../../_static/custom_toggle.js?v=1235ef5b"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Course Notebooks</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Ray Enablement Content
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Intro to Ray</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_01.html">Introduction to Ray Core: Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_02.html">0. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_03.html">1. Creating Remote Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_04.html">2. Executing Remote Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_05.html">4. Putting It All Together</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_01.html">Introduction to Ray Core (Advancement): Object store, Tasks, Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_02.html">1. Object store</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_03.html">2. Chaining Tasks and Passing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_04.html">3. Task retries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_05.html">4. Task Runtime Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_06.html">5. Resource allocation and management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_07.html">6. Nested Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_08.html">7. Pattern: Pipeline data processing and waiting for results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_09.html">8. Ray Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_01.html">Introduction to the Ray AI Libraries: An example of using Ray data, Ray Train, Ray Tune, Ray Serve to implement a XGBoost regression model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_02.html">1. Overview of the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_03.html">2. Quick end-to-end example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_01.html">Introduction to Ray Train + PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_02.html">1. When to use Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_03.html">2. Single GPU Training with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_04.html">3. Distributed Data Parallel Training with Ray Train and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_01.html">Introduction to Ray Train: Ray Train + PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_02.html">1. When to use Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_03.html">2. Single GPU Training with PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_04.html">3. Distributed Training with Ray Train and PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_05.html">4. Ray Train in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_01.html">Introduction to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_02.html">1. Loading the data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_03.html">2. Starting out with vanilla PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_04.html">3. Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_05.html">4. Ray Tune in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_01.html">Introduction to Ray Data: Industry Landscape</a></li>

<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_02.html">The Compute Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_03.html">The Orchestration Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_04.html">Distributed Computing Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_05.html">Data Processing with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_06.html">Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_01.html">Introduction to Ray Data: Ray Data + Structured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_02.html">0. What is Ray Data?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_03.html">2. Loading Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_04.html">3. Transforming Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_05.html">4. Writing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_06.html">5. Data Operations: Shuffling, Grouping and Aggregation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_07.html">6. When to use Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_01.html">Intro to Ray Data:  Ray Data + Unstructured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_02.html">1. When to Consider Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_03.html">2. How to work with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_04.html">3. Loading data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_05.html">3. Lazy execution mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_06.html">4. Transforming data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_07.html">5. Stateful transformations with Ray Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_08.html">6. Materializing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_09.html">7. Data Operations: grouping, aggregation, and shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_10.html">8. Persisting data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_11.html">9. Ray Data in production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_01.html">Introduction to Ray Serve with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_02.html">1. When to Consider Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_03.html">2. Overview of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_04.html">3. Implement an image classification service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_05.html">4. Development workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Developer_Intro_to_Ray/output/README_01.html">Introduction to Ray: Developer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">01 Examples</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/01_Ray_Data_batch_inference_01.html">Batch Inference with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/01_Ray_Data_batch_inference_02.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/01_Ray_Data_batch_inference_03.html">Load a dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/01_Ray_Data_batch_inference_04.html">Batch Inference Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/01_Ray_Data_batch_inference_05.html">Create a batch data and call the model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/01_Ray_Data_batch_inference_06.html">Run inference on the entire dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/02_Ray_Data_data_processing_01.html">Data Processing with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/02_Ray_Data_data_processing_02.html">Library Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/02_Ray_Data_data_processing_03.html">Convert to Ray Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/02_Ray_Data_data_processing_04.html">Filter Ray Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/02_Ray_Data_data_processing_05.html">Join Two Ray Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/02_Ray_Data_data_processing_06.html">Preprocessing with a Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/03_Ray_Serve_online_serving_01.html">Online Model Serving with Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/03_Ray_Serve_online_serving_02.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/03_Ray_Serve_online_serving_03.html">FastAPI webservice and deploy a model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/03_Ray_Serve_online_serving_04.html">Simulate Client: Send test requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/04_Ray_Train_distributed_training_01.html">Distributed training with Ray Train, PyTorch and Hugging Face</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/04_Ray_Train_distributed_training_02.html">1. Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/04_Ray_Train_distributed_training_03.html">3. Metrics Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/04_Ray_Train_distributed_training_04.html">4. Training function per worker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/04_Ray_Train_distributed_training_05.html">5. Main Training Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_examples/output/04_Ray_Train_distributed_training_06.html">6. Start Training</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">02 Anyscale Admin</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_01.html">Anyscale Administrator Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_02.html">1. What is an Anyscale Cloud?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_03.html">2. Cloud Deployment Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_04.html">3. A Demonstrative Example of Resource Creation with AWS EC2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_05.html">3.1 IAM Role Definition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_06.html">4. Register Anyscale Cloud to Your Cloud Provider</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_01.html">Deployment Options: Virtual Machines vs. Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_02.html">2. Virtual Machines (VM) vs. Kubernetes (K8s)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_03.html">3. (Optional) More Kubernetes Deployments Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_01.html">Introduction: Deploy Anyscale Ray on AWS EC2 Instances</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_02.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_03.html">2. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_04.html">3. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_05.html">4. Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_06.html">5. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_01.html">Introduction: Deploy Anyscale Ray on GCP Compute Engine Instances (GCE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_03.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_04.html">2. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_05.html">3. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_06.html">4. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_07.html">5. Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_01.html">Introduction: Deploy Anyscale Ray on A New AWS EKS Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_02.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_03.html">2. Install Kubernetes Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_04.html">3. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_05.html">4. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_06.html">5. Verify the Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_07.html">6. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_08.html">7. Clean up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_09.html">8. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_01.html">Introduction: Deploy Anyscale Ray on An Existing AWS EKS Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_03.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_04.html">2. Attach Required IAM Policies to Your existing EKS‚Äôs Node Role</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_05.html">3. Install Kubernetes Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_06.html">4. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_07.html">5. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_08.html">6. Verify the Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_09.html">7. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_10.html">8. Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_11.html">9. Clean up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_12.html">10. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_01.html">Introduction: Deploy Anyscale Ray on A New Google Kubernetes Engine (GKE) Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_03.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_04.html">2. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_05.html">3. Troubleshooting GPU Availability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_06.html">4. kubectl Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_07.html">5. Install NGINX Ingress Controller</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_08.html">6. (Optional) Upgrade Anyscale Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_09.html">7. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_10.html">8. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_11.html">8. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Anyscale_Admin/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_12.html">9. Cleanup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Gettingstarted</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_01_anyscale_intro_workspace_01.html">101 ‚Äî Introduction to Anyscale Workspaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_02_anyscale_development_intro_01.html">101 ‚Äì Developing Application with Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_03_anyscale_compute_runtime_intro_01.html">101 ‚Äì Compute Configs and Execution Environments in Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_04_anyscale_storage_options_01.html">101 ‚Äì Storage Options in the Anyscale Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_05_anyscale_logging_metrics_01.html">101 ‚Äì Debug and Monitor Your Anyscale Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_06_anyscale_intro_jobs_01.html">101 ‚Äì Introduction to Anyscale Jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_07_anyscale_intro_services_01.html">101 ‚Äì  Introduction to Anyscale Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_08_anyscale_collaboration_01.html">101 ‚Äì Collaboration on Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_09_anyscale_org_setup_01.html">101 - Anyscale Organization and Cloud Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_09_anyscale_org_setup_02.html">üìå Overview of Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_09_anyscale_org_setup_03.html">üß† Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_anyscale_intro_jobs_01.html">Content Used</a></li>

<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_anyscale_intro_jobs_02.html">Part 1. Creating and Submitting your first job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_anyscale_intro_jobs_03.html">Part 2. Automation and Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_anyscale_intro_services_01.html">Sources</a></li>

<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/output/101_anyscale_intro_services_02.html">Part 1: Starting your first Anyscale Service</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Anyscale 101</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../anyscale_101/output/101_anyscale_intro_jobs_01.html">Content Used</a></li>

<li class="toctree-l1"><a class="reference internal" href="../anyscale_101/output/101_anyscale_intro_jobs_02.html">Part 1. Creating and Submitting your first job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../anyscale_101/output/101_anyscale_intro_jobs_03.html">Part 2. Automation and Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../anyscale_101/output/101_anyscale_intro_services_01.html">Sources</a></li>

<li class="toctree-l1"><a class="reference internal" href="../anyscale_101/output/101_anyscale_intro_services_02.html">Part 1: Starting your first Anyscale Service</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray 101</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/1_AI_Libs_Intro_01.html">Introduction to the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/1_AI_Libs_Intro_02.html">1. Overview of the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/1_AI_Libs_Intro_03.html">2. End-to-end example: predicting taxi tips in New York</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/1_AI_Libs_Intro_04.html">3. Running an experiment with Ray AI libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_01.html">Introduction to Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_02.html">1. PyTorch introductory example (single GPU)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_03.html">2. Distributed Data Parallel Training with Ray Train and PyTorch (multiple GPUs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_04.html">3. Overview of the training loop in Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_05.html">4. Migrating the model and dataset to Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_06.html">5. Reporting checkpoints and metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_07.html">6. Launching the distributed training job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_08.html">7. Accessing the training results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/2_Intro_Train_09.html">8. Ray Train in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/3_Intro_Tune_01.html">Intro to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/3_Intro_Tune_02.html">1. Loading and visualizing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/3_Intro_Tune_03.html">2. Setting up a PyTorch model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/3_Intro_Tune_04.html">3. Introduction to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/3_Intro_Tune_05.html">4. Diving deeper into Ray Tune concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/3_Intro_Tune_06.html">5. Hyperparameter tuning the PyTorch model using Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/4_Intro_Data_01.html">Intro to Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/4_Intro_Data_02.html">1. When to use Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/4_Intro_Data_03.html">2. Loading Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/4_Intro_Data_04.html">3. Transforming Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/4_Intro_Data_05.html">4. Data Operations: Grouping, Aggregation, and Shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/4_Intro_Data_06.html">5. Persisting Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/5_Intro_Serve_01.html">Intro to Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/5_Intro_Serve_02.html">1. Overview of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/5_Intro_Serve_03.html">2. Implement an Classifier service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/5_Intro_Serve_04.html">3. Advanced features of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/5_Intro_Serve_05.html">4. Ray Serve in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ray-101/output/5_Intro_Serve_06.html">Clean up</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/courses/ray-train-201/04d1_generative_cv_pattern.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>üñºÔ∏è 04-d1 ¬∑ Generative Computer-Vision Pattern with Ray Train</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">üñºÔ∏è 04-d1 ¬∑ Generative Computer-Vision Pattern with Ray Train</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-youll-learn-take-away">What you‚Äôll learn &amp; take away</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-problem-are-you-solving-diffusion-as-image-de-noising">üî¢ What problem are you solving? (Diffusion as image de-noising)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input-images-as-tensors">Input: Images as tensors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-process-adding-noise">Forward process: adding noise</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-objective">Training objective</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reverse-diffusion-sampling-new-images">Reverse diffusion: sampling new images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-this-works">Why this works</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-youll-migrate-this-diffusion-policy-workload-to-a-distributed-setup-using-ray-on-anyscale">üß≠ How you‚Äôll migrate this diffusion-policy workload to a distributed setup using Ray on Anyscale</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#imports-setup">01 ¬∑ Imports &amp; Setup</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-10-of-food-101">02 ¬∑ Load 10 % of Food-101</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resize-and-encode-images">03 ¬∑ Resize and Encode Images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visual-sanity-check">04 ¬∑ Visual Sanity Check</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#persist-to-parquet">05 ¬∑ Persist to Parquet</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-decode-with-ray-data">06 ¬∑ Load &amp; Decode with Ray Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shuffle-train-val-split">07 ¬∑ Shuffle &amp; Train/Val Split</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pixel-diffusion-lightningmodule">08 ¬∑ Pixel Diffusion LightningModule</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ray-train-train-loop-checkpoint-resume">09 ¬∑ Ray Train <code class="docutils literal notranslate"><span class="pre">train_loop</span></code> (Checkpoint + Resume)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-distributed-training-with-torchtrainer">10 ¬∑ Launch Distributed Training with TorchTrainer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-loss-curves">11 ¬∑ Plot Loss Curves</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstrate-resume-from-latest-checkpoint">12 ¬∑ Demonstrate Resume from Latest Checkpoint</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#reverse-diffusion-sampler">13 ¬∑ Reverse Diffusion Sampler</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-display-samples-from-best-checkpoint">14 ¬∑ Generate &amp; Display Samples from <strong>best checkpoint</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cleanup-shared-storage">15 ¬∑ Cleanup Shared Storage</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#wrapping-up-next-steps">üéâ Wrapping Up &amp; Next Steps</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#where-can-you-take-this-next">üöÄ Where can you take this next?</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="d1-generative-computer-vision-pattern-with-ray-train">
<h1>üñºÔ∏è 04-d1 ¬∑ Generative Computer-Vision Pattern with Ray Train<a class="headerlink" href="#d1-generative-computer-vision-pattern-with-ray-train" title="Link to this heading">#</a></h1>
<p>In this notebook you build a <strong>mini diffusion pipeline</strong> on the <strong>Food-101-Lite</strong> dataset and run it end-to-end on an Anyscale cluster with <strong>Ray Train V2</strong>.</p>
<section id="what-youll-learn-take-away">
<h2>What you‚Äôll learn &amp; take away<a class="headerlink" href="#what-youll-learn-take-away" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>How to use <strong>Ray Data</strong> to decode and preprocess large image datasets in parallel</p></li>
<li><p>How to split and shard datasets for <strong>distributed training</strong> across multiple Ray workers</p></li>
<li><p>How to wrap a custom <code class="docutils literal notranslate"><span class="pre">LightningModule</span></code> with Ray Train to scale out <strong>PyTorch code without boilerplate</strong></p></li>
<li><p>How to <strong>enable fault tolerance</strong> by saving and restoring model checkpoints with <code class="docutils literal notranslate"><span class="pre">ray.train.report()</span></code></p></li>
<li><p>How to run training and evaluation with <strong>no changes to your core model code</strong> as Ray handles multi-node orchestration</p></li>
<li><p>How to generate images post-training using the same Ray-hosted environment</p></li>
</ul>
</section>
<section id="what-problem-are-you-solving-diffusion-as-image-de-noising">
<h2>üî¢ What problem are you solving? (Diffusion as image de-noising)<a class="headerlink" href="#what-problem-are-you-solving-diffusion-as-image-de-noising" title="Link to this heading">#</a></h2>
<p>You‚Äôre training a <strong>generative model</strong> that learns to produce realistic Red-Green-Blue (RGB) images from pure noise<br />
by learning how to <em>reverse</em> a noising process.</p>
<p>This approach builds on <strong>de-noising diffusion models</strong>: instead of modeling the full image distribution <span class="math notranslate nohighlight">\(p(x)\)</span> directly,<br />
teach the model to reverse a <em>known</em> corruption process that gradually adds noise to clean images.</p>
</section>
<hr class="docutils" />
<section id="input-images-as-tensors">
<h2>Input: Images as tensors<a class="headerlink" href="#input-images-as-tensors" title="Link to this heading">#</a></h2>
<p>Each training example is a 3-channel RGB image:</p>
<div class="math notranslate nohighlight">
\[
x_0 \in [-1, 1]^{3 \times H \times W}
\]</div>
<p>Normalize pixel values to [-1, 1] and train on <strong>Food-101-Lite</strong>, a small 10-class subset of Food-101.</p>
</section>
<hr class="docutils" />
<section id="forward-process-adding-noise">
<h2>Forward process: adding noise<a class="headerlink" href="#forward-process-adding-noise" title="Link to this heading">#</a></h2>
<p>During training, sample a timestep <span class="math notranslate nohighlight">\(t \in \{0, \dots, T{-}1\}\)</span><br />
and inject Gaussian noise into the image:</p>
<div class="math notranslate nohighlight">
\[\varepsilon \sim \mathcal{N}(0, 1), \quad x_{t} = x_0 + \varepsilon\]</div>
<p>The model sees <span class="math notranslate nohighlight">\(x_{t}\)</span> and must learn to recover the corrupting noise <span class="math notranslate nohighlight">\(\varepsilon\)</span>.</p>
</section>
<hr class="docutils" />
<section id="training-objective">
<h2>Training objective<a class="headerlink" href="#training-objective" title="Link to this heading">#</a></h2>
<p>Train a convolutional network <span class="math notranslate nohighlight">\(f_\theta\)</span> to predict the noise:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L} = \mathbb{E}_{x_0, \varepsilon, t}\ \big\|f_\theta(x_{t}, t) - \varepsilon\big\|_2^2\]</div>
<p>This is an <strong>Mean Squared Error (MSE) loss</strong>, and it encourages the model to de-noise corrupted images.</p>
</section>
<hr class="docutils" />
<section id="reverse-diffusion-sampling-new-images">
<h2>Reverse diffusion: sampling new images<a class="headerlink" href="#reverse-diffusion-sampling-new-images" title="Link to this heading">#</a></h2>
<p>At generation time, start from pure noise <span class="math notranslate nohighlight">\(x_T \sim \mathcal{N}(0, 1)\)</span> and step backward:</p>
<div class="math notranslate nohighlight">
\[x_{t} \leftarrow x_{t} - \eta \cdot f_\theta(x_{t}, t), \quad t = T{-}1, \dots, 0\]</div>
<p>After <span class="math notranslate nohighlight">\(T\)</span> steps, <span class="math notranslate nohighlight">\(x_0\)</span> is a fully generated image ‚Äî a sample from the learned data distribution.</p>
</section>
<hr class="docutils" />
<section id="why-this-works">
<h2>Why this works<a class="headerlink" href="#why-this-works" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Diffusion models sidestep unstable Generative Adversarial Network (GAN) training and can model complex, multimodal image distributions</p></li>
<li><p>The forward process stays fixed and simple (just add noise), which makes the learning problem tractable</p></li>
<li><p>At inference time, sampling becomes iterative de-noising ‚Äî easy to debug, modify, and extend</p></li>
</ul>
</section>
<section id="how-youll-migrate-this-diffusion-policy-workload-to-a-distributed-setup-using-ray-on-anyscale">
<h2>üß≠ How you‚Äôll migrate this diffusion-policy workload to a distributed setup using Ray on Anyscale<a class="headerlink" href="#how-youll-migrate-this-diffusion-policy-workload-to-a-distributed-setup-using-ray-on-anyscale" title="Link to this heading">#</a></h2>
<p>This tutorial walks through the end-to-end process of <strong>migrating a local image-based diffusion policy to a distributed Ray cluster running on Anyscale</strong>.</p>
<p>Here‚Äôs how you make that transition:</p>
<ol class="arabic simple">
<li><p><strong>Local Joint Photographic Experts Groups (JPEG) ‚Üí Distributed Ray Dataset</strong><br />
Preprocess and store Food-101 images as Parquet, then use <strong>Ray Data</strong> to load and decode the dataset in parallel across the cluster. Each worker gets its own shard, streamed efficiently for GPU training.</p></li>
<li><p><strong>Single-GPU PyTorch ‚Üí Multi-node Distributed Training</strong><br />
Wrap your Lightning model in a Ray Train <code class="docutils literal notranslate"><span class="pre">train_loop</span></code>, then launch distributed training using <strong>TorchTrainer</strong> with 8 GPU workers‚Äîeach operating on its own data partition with no manual coordination.</p></li>
<li><p><strong>Manual Checkpoints ‚Üí Automatic Fault Tolerance</strong><br />
Save a checkpoint after every epoch using <code class="docutils literal notranslate"><span class="pre">ray.train.report(checkpoint=...)</span></code>, and configure Ray to <strong>auto-resume from the most recent checkpoint</strong> if a job fails or you relaunch it.</p></li>
<li><p><strong>Manual Data Management ‚Üí Declarative Scaling with Ray</strong><br />
Instead of slicing data or managing worker processes yourself, declare your intent with <code class="docutils literal notranslate"><span class="pre">ScalingConfig</span></code>, <code class="docutils literal notranslate"><span class="pre">CheckpointConfig</span></code>, and <code class="docutils literal notranslate"><span class="pre">FailureConfig</span></code>, and let <strong>Ray + Anyscale handle the orchestration</strong>.</p></li>
<li><p><strong>Single-node Sampling ‚Üí Remote Inference Tasks</strong><br />
After training, run <strong>reverse diffusion sampling</strong> as Ray tasks on GPU nodes, making it easy to scale post-training inference or build a lightweight visual demo.</p></li>
</ol>
<p>This pattern transforms a simple single-node PyTorch loop into a <strong>scalable, fault-tolerant, multi-node training pipeline</strong> with just a few lines of Ray-specific code, and it runs seamlessly on any cluster provisioned with Anyscale.</p>
</section>
</section>
<section id="imports-setup">
<h1>01 ¬∑ Imports &amp; Setup<a class="headerlink" href="#imports-setup" title="Link to this heading">#</a></h1>
<p>Pull in standard Python utilities, Ray (core, Data, Train, Lightning), and PyTorch Lightning.<br />
Make sure you set the Anyscale cluster to Ray ‚â• 2.48, so you get Ray Train V2 semantics automatically enabled.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 01. Imports</span>

<span class="c1"># Standard libraries</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span><span class="o">,</span><span class="w"> </span><span class="nn">io</span><span class="o">,</span><span class="w"> </span><span class="nn">json</span><span class="o">,</span><span class="w"> </span><span class="nn">shutil</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>

<span class="c1"># Ray</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ray</span><span class="o">,</span><span class="w"> </span><span class="nn">ray.data</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.train</span><span class="w"> </span><span class="kn">import</span> <span class="n">ScalingConfig</span><span class="p">,</span> <span class="n">get_context</span><span class="p">,</span> <span class="n">RunConfig</span><span class="p">,</span> <span class="n">FailureConfig</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">Checkpoint</span><span class="p">,</span> <span class="n">get_checkpoint</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.train.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">TorchTrainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.train.lightning</span><span class="w"> </span><span class="kn">import</span> <span class="n">RayLightningEnvironment</span>

<span class="c1"># PyTorch / Lightning</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">lightning.pytorch</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># Dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pa</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow.parquet</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pq</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>  
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">Compose</span><span class="p">,</span> <span class="n">Resize</span><span class="p">,</span> <span class="n">CenterCrop</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
</pre></div>
</div>
</div>
</div>
<section id="load-10-of-food-101">
<h2>02 ¬∑ Load 10 % of Food-101<a class="headerlink" href="#load-10-of-food-101" title="Link to this heading">#</a></h2>
<p>Next, grab roughly 7 500 images, exactly 10 % of Food-101‚Äîusing a single call to <code class="docutils literal notranslate"><span class="pre">load_dataset</span></code>. This trimmed subset trains quickly while still being large enough to demonstrate Ray‚Äôs scaling behaviour.</p>
<p>NOTE: skip cells 02-05 if the dataset is already downloaded, as this is the same dataset as in tutorial 04a.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 02. Load 10% of food101 (~7,500 images)</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;food101&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train[:10%]&quot;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</section>
<section id="resize-and-encode-images">
<h2>03 ¬∑ Resize and Encode Images<a class="headerlink" href="#resize-and-encode-images" title="Link to this heading">#</a></h2>
<p>Preprocess each image: resize to 256 pixel, center-crop to 224 pixel (the size expected by most ImageNet models), and then convert the result to raw JPEG bytes. By storing bytes instead of full Python Imaging Library (PIL) objects, you keep the dataset compact and Parquet-friendly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 03. Resize + encode as JPEG bytes</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">([</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span> <span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">)])</span>
<span class="n">records</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Preprocessing images&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;img&quot;</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
        <span class="n">buf</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
        <span class="n">img</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;JPEG&quot;</span><span class="p">)</span>
        <span class="n">records</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;image_bytes&quot;</span><span class="p">:</span> <span class="n">buf</span><span class="o">.</span><span class="n">getvalue</span><span class="p">(),</span>
            <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="n">example</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>
        <span class="p">})</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">continue</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visual-sanity-check">
<h2>04 ¬∑ Visual Sanity Check<a class="headerlink" href="#visual-sanity-check" title="Link to this heading">#</a></h2>
<p>Before committing to hours of training, take nine random samples and plot them with their class names. This quick inspection lets you confirm that images are correctly resized and preprocessed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 04. Visualize the dataset</span>

<span class="n">label_names</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span>  <span class="c1"># maps int ‚Üí string</span>

<span class="n">samples</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">records</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Sample Resized Images from food101-lite&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">rec</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">samples</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">rec</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">]))</span>
    <span class="n">label_name</span> <span class="o">=</span> <span class="n">label_names</span><span class="p">[</span><span class="n">rec</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label_name</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="persist-to-parquet">
<h2>05 ¬∑ Persist to Parquet<a class="headerlink" href="#persist-to-parquet" title="Link to this heading">#</a></h2>
<p>Now, write the images and labels to a Parquet file. Because Parquet is columnar, you can read just the columns you need during training, which speeds up IO‚Äîespecially when multiple workers are reading in parallel under Ray.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 05. Write Dataset to Parquet</span>

<span class="n">output_dir</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite/parquet_256&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">table</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="o">.</span><span class="n">from_pydict</span><span class="p">({</span>
    <span class="s2">&quot;image_bytes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">records</span><span class="p">],</span>
    <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">records</span><span class="p">]</span>
<span class="p">})</span>
<span class="n">pq</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;shard_0.parquet&quot;</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Wrote </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">records</span><span class="p">)</span><span class="si">}</span><span class="s2"> records to </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="load-decode-with-ray-data">
<h2>06 ¬∑ Load &amp; Decode with Ray Data<a class="headerlink" href="#load-decode-with-ray-data" title="Link to this heading">#</a></h2>
<p>Read the Parquet shard into a <strong>Ray Dataset</strong>, decode the JPEG bytes to ** Channel-Height-Width (CHW) float32 tensors**, scale to [-1, 1], and drop the original byte column.<br />
Because <code class="docutils literal notranslate"><span class="pre">decode_and_normalize</span></code> is stateless, the default <strong>task-based</strong> execution is perfect.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 06. Load &amp; Decode Food-101-Lite</span>

<span class="c1"># Path to Parquet shards written earlier</span>
<span class="n">PARQUET_PATH</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite/parquet_256&quot;</span>

<span class="c1"># Read the Parquet files (‚âà7‚ÄØ500 rows with JPEG bytes + label)</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">PARQUET_PATH</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Raw rows:&quot;</span><span class="p">,</span> <span class="n">ds</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>

<span class="c1"># Decode JPEG ‚Üí CHW float32 in [‚Äë1,‚ÄØ1]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">decode_and_normalize</span><span class="p">(</span><span class="n">batch_df</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Decode JPEG bytes and scale to [-1, 1].&quot;&quot;&quot;</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch_df</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">]:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">b</span><span class="p">))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>       <span class="c1"># H‚ÄØ√ó‚ÄØW‚ÄØ√ó‚ÄØ3, 0‚Äë1</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="p">(</span><span class="n">arr</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.5</span>                               <span class="c1"># ‚Äë1‚ÄØ‚Ä¶‚ÄØ1</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>                          <span class="c1"># 3‚ÄØ√ó‚ÄØH‚ÄØ√ó‚ÄØW (CHW)</span>
        <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;image&quot;</span><span class="p">:</span> <span class="n">images</span><span class="p">}</span>

<span class="c1"># Apply in parallel</span>
<span class="c1">#   batch_format=&quot;pandas&quot; ‚Üí batch_df is a DataFrame, return dict of lists.</span>
<span class="c1">#   default task‚Äëbased compute is sufficient for a stateless function.</span>

<span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span>
    <span class="n">decode_and_normalize</span><span class="p">,</span>
    <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span>
    <span class="c1"># Use the default (task‚Äëbased) compute strategy since `decode_and_normalize` is a plain function.</span>
    <span class="n">num_cpus</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Drop the original JPEG column to save memory</span>
<span class="k">if</span> <span class="s2">&quot;image_bytes&quot;</span> <span class="ow">in</span> <span class="n">ds</span><span class="o">.</span><span class="n">schema</span><span class="p">()</span><span class="o">.</span><span class="n">names</span><span class="p">:</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">drop_columns</span><span class="p">([</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Decoded rows:&quot;</span><span class="p">,</span> <span class="n">ds</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="shuffle-train-val-split">
<h2>07 ¬∑ Shuffle &amp; Train/Val Split<a class="headerlink" href="#shuffle-train-val-split" title="Link to this heading">#</a></h2>
<p>Perform a reproducible shuffle, then split 80 % / 20 % into <code class="docutils literal notranslate"><span class="pre">train_ds</span></code> and <code class="docutils literal notranslate"><span class="pre">val_ds</span></code>.<br />
Each split remains a first-class Ray Dataset, enabling distributed, sharded DataLoaders later on.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 07. Shuffle &amp; Train/Val Split</span>

<span class="c1"># Typical 80‚ÄØ/‚ÄØ20 split</span>
<span class="n">TOTAL</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="n">train_count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">TOTAL</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">random_shuffle</span><span class="p">()</span>
<span class="n">train_ds</span><span class="p">,</span> <span class="n">val_ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">split_at_indices</span><span class="p">([</span><span class="n">train_count</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train rows:&quot;</span><span class="p">,</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Val rows:&quot;</span><span class="p">,</span>   <span class="n">val_ds</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="pixel-diffusion-lightningmodule">
<h1>08 ¬∑ Pixel Diffusion LightningModule<a class="headerlink" href="#pixel-diffusion-lightningmodule" title="Link to this heading">#</a></h1>
<p>A minimal <strong>de-noising diffusion</strong> policy:</p>
<ul class="simple">
<li><p>Input = noisy image + scalar timestep (packed as a 4-channel tensor)</p></li>
<li><p>Output = predicted noise œµ<br />
Log per-epoch losses and save them to a shared JSON so every worker can later plot global curves.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 08. Pixel De-noising Diffusion Model</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PixelDiffusion</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tiny CNN that predicts noise œµ given noisy image + timestep.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_t</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">log_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_t</span> <span class="o">=</span> <span class="n">max_t</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_path</span> <span class="o">=</span> <span class="n">log_path</span> <span class="ow">or</span> <span class="s2">&quot;/mnt/cluster_storage/generative_cv/epoch_metrics.json&quot;</span>

        <span class="c1"># Network: (3‚ÄØ+‚ÄØ1)‚Äëchannel input ‚Üí 3‚Äëchannel noise prediction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_losses</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_losses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="c1"># ---------- forward ----------</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noisy_img</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;noisy_img: Bx3xHxW,  t: B (int) or Bx1 scalar&quot;&quot;&quot;</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">noisy_img</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">t_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_t</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">noisy_img</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">t_img</span> <span class="o">=</span> <span class="n">t_scaled</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">noisy_img</span><span class="p">,</span> <span class="n">t_img</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 4 channels</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="c1"># ---------- training / validation steps ----------</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_shared_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="n">clean</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>             <span class="c1"># Bx3xHxW, ‚Äë1‚Ä¶1</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">clean</span><span class="p">)</span>                    <span class="c1"># œµ ~ N(0,‚ÄØ1)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_t</span><span class="p">,</span> <span class="p">(</span><span class="n">clean</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">noisy</span> <span class="o">=</span> <span class="n">clean</span> <span class="o">+</span> <span class="n">noise</span>                              <span class="c1"># x_t = x_0 + œµ</span>
        <span class="n">pred_noise</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">noisy</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">pred_noise</span><span class="p">,</span> <span class="n">noise</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shared_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shared_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="c1"># ---------- epoch end logging ----------</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_world_rank</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">train_avg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_losses</span><span class="p">)</span>
            <span class="n">val_avg</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_val_losses</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_losses</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">val_avg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Epoch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span><span class="si">}</span><span class="s2">] train=</span><span class="si">{</span><span class="n">train_avg</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  val=</span><span class="si">{</span><span class="n">val_avg</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Epoch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span><span class="si">}</span><span class="s2">] train=</span><span class="si">{</span><span class="n">train_avg</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  val=N/A&quot;</span><span class="p">)</span>

            <span class="c1"># Append to shared JSON so you can plot later</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_path</span><span class="p">):</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="n">logs</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">logs</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;train_loss&quot;</span><span class="p">:</span> <span class="n">train_avg</span><span class="p">,</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">:</span> <span class="n">val_avg</span><span class="p">})</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

        <span class="c1"># Clear per‚Äëepoch trackers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_losses</span><span class="o">.</span><span class="n">clear</span><span class="p">();</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_losses</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="ray-train-train-loop-checkpoint-resume">
<h1>09 ¬∑ Ray Train <code class="docutils literal notranslate"><span class="pre">train_loop</span></code> (Checkpoint + Resume)<a class="headerlink" href="#ray-train-train-loop-checkpoint-resume" title="Link to this heading">#</a></h1>
<p>Core training logic run <strong>once per Ray worker</strong>:</p>
<ol class="arabic simple">
<li><p>Shard-aware DataLoaders with <code class="docutils literal notranslate"><span class="pre">get_dataset_shard</span></code>.</p></li>
<li><p>Auto-resume from the latest Ray Checkpoint (if present).</p></li>
<li><p>Manual per-epoch checkpointing: save <code class="docutils literal notranslate"><span class="pre">model.pt</span></code> + <code class="docutils literal notranslate"><span class="pre">meta.pt</span></code>, then call <code class="docutils literal notranslate"><span class="pre">report(metrics,</span> <span class="pre">checkpoint=‚Ä¶)</span></code>.<br />
This makes the run fully <strong>fault-tolerant</strong>‚Äîif a worker crashes, Ray restarts the group and re-enters the loop with the latest checkpoint.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 09. Train Loop for Ray TorchTrainer</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train_loop</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Ray Train per-worker function with checkpointing and resume support.&quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">os</span><span class="o">,</span><span class="w"> </span><span class="nn">torch</span><span class="o">,</span><span class="w"> </span><span class="nn">uuid</span><span class="o">,</span><span class="w"> </span><span class="nn">json</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">ray.train</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_checkpoint</span><span class="p">,</span> <span class="n">get_context</span><span class="p">,</span> <span class="n">report</span><span class="p">,</span> <span class="n">Checkpoint</span>

    <span class="c1"># Paths</span>
    <span class="n">LOG_PATH</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/generative_cv/epoch_metrics.json&quot;</span>
    <span class="n">CKPT_ROOT</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/generative_cv/food101_diffusion_ckpts&quot;</span>

    <span class="n">rank</span> <span class="o">=</span> <span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_world_rank</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">CKPT_ROOT</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">get_checkpoint</span><span class="p">()</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">LOG_PATH</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">LOG_PATH</span><span class="p">)</span>

    <span class="c1"># Data</span>
    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="n">val_ds</span>   <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">iter_torch_batches</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">val_loader</span>   <span class="o">=</span> <span class="n">val_ds</span><span class="o">.</span><span class="n">iter_torch_batches</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

    <span class="c1"># Model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">PixelDiffusion</span><span class="p">()</span>
    <span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Resume from checkpoint if present</span>
    <span class="n">ckpt</span> <span class="o">=</span> <span class="n">get_checkpoint</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">ckpt</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">ckpt</span><span class="o">.</span><span class="n">as_directory</span><span class="p">()</span> <span class="k">as</span> <span class="n">d</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">),</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
            <span class="n">start_epoch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="s2">&quot;meta.pt&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">] Resumed from checkpoint at epoch </span><span class="si">{</span><span class="n">start_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Trainer</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
        <span class="n">max_epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epochs&quot;</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="n">devices</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">plugins</span><span class="o">=</span><span class="p">[</span><span class="n">RayLightningEnvironment</span><span class="p">()],</span>
        <span class="n">enable_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">check_val_every_n_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Train loop: run each epoch, checkpoint manually</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epochs&quot;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)):</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">max_epochs</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_dataloaders</span><span class="o">=</span><span class="n">val_loader</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Save model checkpoint</span>
            <span class="n">out_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">CKPT_ROOT</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;epoch_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">hex</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">))</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">},</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s2">&quot;meta.pt&quot;</span><span class="p">))</span>
            <span class="n">ckpt_out</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_directory</span><span class="p">(</span><span class="n">out_dir</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ckpt_out</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Report with checkpoint so Ray saves it</span>
        <span class="n">report</span><span class="p">({</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">},</span> <span class="n">checkpoint</span><span class="o">=</span><span class="n">ckpt_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="launch-distributed-training-with-torchtrainer">
<h2>10 ¬∑ Launch Distributed Training with TorchTrainer<a class="headerlink" href="#launch-distributed-training-with-torchtrainer" title="Link to this heading">#</a></h2>
<p>Ask for <strong>8 GPU workers</strong>, keep the five most-recent checkpoints, and allow up to three automatic retries.<br />
<code class="docutils literal notranslate"><span class="pre">result.checkpoint</span></code> captures the checkpoint from the highest epoch (because you used <code class="docutils literal notranslate"><span class="pre">epoch</span></code> as the score attribute‚Äîyou can change this to other metrics such as validation loss or training loss).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 10. Launch Distributed Training</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
    <span class="n">train_loop</span><span class="p">,</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_ds</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">:</span> <span class="n">val_ds</span><span class="p">},</span>
    <span class="n">run_config</span><span class="o">=</span><span class="n">RunConfig</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;food101_diffusion_ft&quot;</span><span class="p">,</span>
        <span class="n">storage_path</span><span class="o">=</span><span class="s2">&quot;/mnt/cluster_storage/generative_cv/food101_diffusion_results&quot;</span><span class="p">,</span>
        <span class="n">checkpoint_config</span><span class="o">=</span><span class="n">CheckpointConfig</span><span class="p">(</span>
            <span class="n">checkpoint_frequency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">num_to_keep</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">checkpoint_score_attribute</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
            <span class="n">checkpoint_score_order</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">failure_config</span><span class="o">=</span><span class="n">FailureConfig</span><span class="p">(</span><span class="n">max_failures</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
    <span class="p">),</span>
<span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training complete ‚Üí&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
<span class="n">best_ckpt</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span>  <span class="c1"># checkpoint from highest reported epoch (you can change score attr)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-loss-curves">
<h2>11 ¬∑ Plot Loss Curves<a class="headerlink" href="#plot-loss-curves" title="Link to this heading">#</a></h2>
<p>Parse the JSON written by <code class="docutils literal notranslate"><span class="pre">PixelDiffusion.on_train_epoch_end</span></code>, convert to a DataFrame, and render Train vs. Val MSE loss.<br />
Good practice for quick health checks without external tooling.</p>
<p><strong>Why is validation loss lower than training loss?</strong><br />
You measure training loss <em>before</em> weights update and includes fresh noise every step, while validation runs in <code class="docutils literal notranslate"><span class="pre">eval()</span></code> mode with no gradient updates, often making it slightly lower, especially early in training.<br />
This is normal behavior in this sort of scenario and usually means the model is generalizing well, and not over-fitting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 11. Plot Train/Val Loss Curves</span>

<span class="n">LOG_PATH</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/generative_cv/epoch_metrics.json&quot;</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">LOG_PATH</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;coerce&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Train&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span>   <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Val&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;MSE Loss&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Pixel Diffusion - Loss per Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="demonstrate-resume-from-latest-checkpoint">
<h1>12 ¬∑ Demonstrate Resume from Latest Checkpoint<a class="headerlink" href="#demonstrate-resume-from-latest-checkpoint" title="Link to this heading">#</a></h1>
<p>Calling <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code> again detects the run snapshot, loads the latest checkpoint, and (because <code class="docutils literal notranslate"><span class="pre">epochs=10</span></code>) exits immediately, proving that the resume path works.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 12. Run the trainer again to demonstrate resuming from latest checkpoint  </span>

<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training complete ‚Üí&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="reverse-diffusion-sampler">
<h1>13 ¬∑ Reverse Diffusion Sampler<a class="headerlink" href="#reverse-diffusion-sampler" title="Link to this heading">#</a></h1>
<p>A simple Euler-style loop that starts from Gaussian noise and iteratively subtracts the model‚Äôs predicted noise.<br />
Not production-grade sampling, but perfect for illustrating inference after training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 13. Reverse Diffusion Sampling</span>

<span class="k">def</span><span class="w"> </span><span class="nf">sample_image</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate an image by iteratively de-noising random noise.&quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">)):</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">step</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">pred_noise</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">img</span> <span class="o">-</span> <span class="n">pred_noise</span> <span class="o">*</span> <span class="mf">0.1</span>                      <span class="c1"># simple Euler update</span>
        <span class="c1"># Rescale back to [0,1]</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">((</span><span class="n">img</span> <span class="o">*</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">),</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="generate-display-samples-from-best-checkpoint">
<h2>14 ¬∑ Generate &amp; Display Samples from <strong>best checkpoint</strong><a class="headerlink" href="#generate-display-samples-from-best-checkpoint" title="Link to this heading">#</a></h2>
<p>Load the model weights from <code class="docutils literal notranslate"><span class="pre">best_ckpt</span></code>, move to GPU if available, generate three images, and show them side-by-side.<br />
Remember: with a tiny CNN and only 10 epochs, these samples look noise-like. If you replace the backbone or train longer you‚Äôd expect to see better quality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 14. Generate &amp; Display Samples</span>

<span class="c1"># Load model from Ray Train checkpoint</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.train</span><span class="w"> </span><span class="kn">import</span> <span class="n">Checkpoint</span>

<span class="k">assert</span> <span class="n">best_ckpt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Checkpoint is missing. Did training run and complete?&quot;</span>

<span class="k">with</span> <span class="n">best_ckpt</span><span class="o">.</span><span class="n">as_directory</span><span class="p">()</span> <span class="k">as</span> <span class="n">ckpt_dir</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">PixelDiffusion</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">),</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># Generate three images</span>
<span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample_image</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">img</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="n">samples</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Food‚Äë101 Diffusion Samples (unconditional)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cleanup-shared-storage">
<h2>15 ¬∑ Cleanup Shared Storage<a class="headerlink" href="#cleanup-shared-storage" title="Link to this heading">#</a></h2>
<p>Reclaim cluster disk space by deleting the entire tutorial output directory.<br />
Run this only when you‚Äôre <strong>sure</strong> you don‚Äôt need the checkpoints or metrics anymore.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 15. Cleanup -- delete checkpoints and metrics from model training</span>

<span class="n">TARGET_PATH</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/generative_cv&quot;</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">TARGET_PATH</span><span class="p">):</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">TARGET_PATH</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;‚úÖ Deleted everything under </span><span class="si">{</span><span class="n">TARGET_PATH</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;‚ö†Ô∏è Path does not exist: </span><span class="si">{</span><span class="n">TARGET_PATH</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="wrapping-up-next-steps">
<h1>üéâ Wrapping Up &amp; Next Steps<a class="headerlink" href="#wrapping-up-next-steps" title="Link to this heading">#</a></h1>
<p>Awesome work making it to the end. In this tutorial, you used <strong>Ray Train and Ray Data on Anyscale</strong> to scale a compact diffusion-policy workload, from raw JPEG bytes to distributed training and sampling, without changing the core PyTorch logic. You should now feel confident:</p>
<ul class="simple">
<li><p>Using <strong>Ray Data</strong> to decode, normalize, and shard large image datasets in parallel</p></li>
<li><p>Scaling training across multiple GPUs using <strong>TorchTrainer</strong> and a Ray-native <code class="docutils literal notranslate"><span class="pre">train_loop</span></code></p></li>
<li><p>Managing distributed training state with <strong>Ray Checkpoints</strong> and automatic resume</p></li>
<li><p>Running fault-tolerant multi-node jobs on Anyscale without orchestration scripts</p></li>
<li><p>Performing post-training sampling or evaluation using <strong>Ray tasks</strong> on GPU workers</p></li>
</ul>
<hr class="docutils" />
</section>
<section id="where-can-you-take-this-next">
<h1>üöÄ Where can you take this next?<a class="headerlink" href="#where-can-you-take-this-next" title="Link to this heading">#</a></h1>
<p>Below are a few directions you might explore to adapt or extend the pattern:</p>
<ol class="arabic simple">
<li><p><strong>Backbones &amp; Architecture Upgrades</strong></p>
<ul class="simple">
<li><p>Swap in a larger ResNet or another vision model for much better generative performance.</p></li>
<li><p>Try pre-trained encoders and fine-tune only the diffusion-specific layers.</p></li>
</ul>
</li>
<li><p><strong>Conditional Diffusion</strong></p>
<ul class="simple">
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">label</span></code> column to condition the model (For example, class-conditioning).</p></li>
<li><p>Compare unconditional vs. conditional generation side by side.</p></li>
</ul>
</li>
<li><p><strong>Sampling Improvements</strong></p>
<ul class="simple">
<li><p>Replace naive reverse diffusion with De-noising Diffusion Implicit Models (DDIM), Pseudo Numerical Methods for Diffusion Models (PNDM), or learned de-noisers.</p></li>
<li><p>Add timestep embeddings or noise schedules to increase model expressiveness.</p></li>
</ul>
</li>
<li><p><strong>Longer Training &amp; Mixed Precision</strong></p>
<ul class="simple">
<li><p>Increase the <code class="docutils literal notranslate"><span class="pre">max_epochs</span></code> and enable Automatic Mixed Precision (AMP) for faster training with less memory.</p></li>
<li><p>Visualize convergence and training stability across longer runs.</p></li>
</ul>
</li>
<li><p><strong>Hyperparameter Sweeps</strong></p>
<ul class="simple">
<li><p>Use <strong>Ray Tune</strong> to search over learning rates, model size, or sampling steps.</p></li>
<li><p>Leverage Tune‚Äôs reporting to schedule early stopping or checkpoint pruning.</p></li>
</ul>
</li>
<li><p><strong>Data Handling &amp; Scaling</strong></p>
<ul class="simple">
<li><p>Shard the dataset into multiple Parquet files and distribute across more workers.</p></li>
<li><p>Store and load datasets from S3 or other cloud storage.</p></li>
</ul>
</li>
<li><p><strong>Image Quality Evaluation</strong></p>
<ul class="simple">
<li><p>Log Fr√©chet Inception Distance (FID) scores, perceptual similarity, or diffusion-specific metrics.</p></li>
<li><p>Compare generated samples from different checkpoints or backbones.</p></li>
</ul>
</li>
<li><p><strong>Model Serving</strong></p>
<ul class="simple">
<li><p>Package the reverse sampler into a Ray task or <strong>Ray Serve</strong> endpoint.</p></li>
<li><p>Run a demo app that generates images on demand from a class name or random seed.</p></li>
</ul>
</li>
<li><p><strong>End-to-End MLOps</strong></p>
<ul class="simple">
<li><p>Register the best checkpoint with MLflow or Weights &amp; Biases.</p></li>
<li><p>Wrap the training loop in a Ray Job and run it on a schedule with Anyscale.</p></li>
</ul>
</li>
</ol>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./courses/ray-train-201"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">üñºÔ∏è 04-d1 ¬∑ Generative Computer-Vision Pattern with Ray Train</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-youll-learn-take-away">What you‚Äôll learn &amp; take away</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-problem-are-you-solving-diffusion-as-image-de-noising">üî¢ What problem are you solving? (Diffusion as image de-noising)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input-images-as-tensors">Input: Images as tensors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-process-adding-noise">Forward process: adding noise</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-objective">Training objective</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reverse-diffusion-sampling-new-images">Reverse diffusion: sampling new images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-this-works">Why this works</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-youll-migrate-this-diffusion-policy-workload-to-a-distributed-setup-using-ray-on-anyscale">üß≠ How you‚Äôll migrate this diffusion-policy workload to a distributed setup using Ray on Anyscale</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#imports-setup">01 ¬∑ Imports &amp; Setup</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-10-of-food-101">02 ¬∑ Load 10 % of Food-101</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resize-and-encode-images">03 ¬∑ Resize and Encode Images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visual-sanity-check">04 ¬∑ Visual Sanity Check</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#persist-to-parquet">05 ¬∑ Persist to Parquet</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-decode-with-ray-data">06 ¬∑ Load &amp; Decode with Ray Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shuffle-train-val-split">07 ¬∑ Shuffle &amp; Train/Val Split</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pixel-diffusion-lightningmodule">08 ¬∑ Pixel Diffusion LightningModule</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ray-train-train-loop-checkpoint-resume">09 ¬∑ Ray Train <code class="docutils literal notranslate"><span class="pre">train_loop</span></code> (Checkpoint + Resume)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-distributed-training-with-torchtrainer">10 ¬∑ Launch Distributed Training with TorchTrainer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-loss-curves">11 ¬∑ Plot Loss Curves</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstrate-resume-from-latest-checkpoint">12 ¬∑ Demonstrate Resume from Latest Checkpoint</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#reverse-diffusion-sampler">13 ¬∑ Reverse Diffusion Sampler</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-display-samples-from-best-checkpoint">14 ¬∑ Generate &amp; Display Samples from <strong>best checkpoint</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cleanup-shared-storage">15 ¬∑ Cleanup Shared Storage</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#wrapping-up-next-steps">üéâ Wrapping Up &amp; Next Steps</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#where-can-you-take-this-next">üöÄ Where can you take this next?</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book community
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>