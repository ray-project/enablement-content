{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550a64fb",
   "metadata": {},
   "source": [
    "## Distributed Computing Frameworks\n",
    "\n",
    "Distributed computing frameworks enable scalable data processing and analysis by dividing workloads across multiple machines. These frameworks are often categorized based on their primary use case, such as stream processing, batch processing, or general-purpose computing.\n",
    "\n",
    "### Streaming Applications\n",
    "\n",
    "Streaming frameworks process data as it arrives in real-time or near-real-time. They are essential for applications requiring immediate insights, such as fraud detection, monitoring, and recommendation systems.\n",
    "\n",
    "- **Apache Kafka** (JVM-Based):\n",
    "  - Distributed event streaming platform.\n",
    "  - Fault-tolerant and scalable messaging.\n",
    "  - Widely used for real-time data pipelines and log aggregation.\n",
    "  - Python integration relies on external libraries like `confluent-kafka`.\n",
    "\n",
    "- **Apache Flink** (JVM-Based):\n",
    "  - Unified engine for stream and batch processing.\n",
    "  - Features low-latency, event-time processing, and stateful computation.\n",
    "  - Commonly used for real-time dashboards, fraud detection, and IoT analytics.\n",
    "  - PyFlink API provides Python support but has fewer features compared to Java/Scala.\n",
    "\n",
    "### Batch Processing\n",
    "\n",
    "Batch processing frameworks handle large data volumes in discrete chunks, often for ETL workflows, batch inference and last-mile data processing.\n",
    "\n",
    "- **Apache Hadoop** (JVM-Based):\n",
    "  - Pioneer in distributed storage (HDFS) and batch processing (MapReduce).\n",
    "  - Reliable for large-scale, fault-tolerant data processing.\n",
    "  - Historically used for batch ETL and analytics.\n",
    "\n",
    "- **Apache Spark** (JVM-Based):\n",
    "  - Unified engine for batch and streaming workloads.\n",
    "  - Features in-memory computation, scalable processing, and rich APIs.\n",
    "  - Popular for data transformation, machine learning pipelines, and analytics.\n",
    "  - Python integration via PySpark can introduce overhead due to JVM interaction.\n",
    "\n",
    "### General-Purpose Distributed Computing\n",
    "\n",
    "These frameworks are designed for diverse tasks, including machine learning, reinforcement learning, and data processing.\n",
    "\n",
    "- **Dask**:\n",
    "  - Python-native framework for parallel and distributed computing.\n",
    "  - Frequently used in scientific computing and dataframe-based workflows.\n",
    "  - Scales efficiently from single machines to distributed clusters.\n",
    "\n",
    "- **Ray**:\n",
    "  - Flexible platform for scalable distributed applications.\n",
    "  - Rich in high-level libraries for:\n",
    "    - Reinforcement Learning (Ray RLlib)\n",
    "    - Distributed Data processing (Ray Data)\n",
    "    - Distributed Training (Ray Train)\n",
    "    - Distributed Hyperparameter Tuning (Ray Tune)\n",
    "    - Distributed Serving (Ray Serve)\n",
    "  - Seamless integration across the Ray ecosystem to build end-to-end data pipelines.\n",
    "  - Ideal for Python-centric teams needing high-performance distributed computing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e44e6d5",
   "metadata": {},
   "source": [
    "### Challenges with JVM\n",
    "\n",
    "JVM-based frameworks like Spark and Flink have historically dominated the distributed computing landscape. However, they present several challenges:\n",
    "\n",
    "Here is a diagram of the data flow in Spark:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/data-flow-jvm.png\" width=\"500\">\n",
    "   \n",
    "Here are the issues highlighted in the diagram:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/data-flow-jvm-issues.png\" width=\"500\">\n",
    "\n",
    "1. **Painful local development UX**:  \n",
    "   Getting a local development environment setup is difficult given the complexity of the dependencies.\n",
    "\n",
    "2. **Inscrutable error traces between Python and JVM**:  \n",
    "   Some tracebacks are not helpful in debugging given failures can occur across the language boundary (e.g. socket errors, JVM crashes vs Python application crashes).\n",
    "\n",
    "3. **Data/Memory Overhead**:  \n",
    "   The onus is on the user to properly type and design their UDFs and to minimize the data/memory overhead in serializing and deserializing data between Python and JVM.\n",
    "\n",
    "By contrast, frameworks like Ray and Dask avoid the JVM overhead entirely, offering Python-native performance and better alignment with modern data science workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}