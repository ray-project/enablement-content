{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a43da1a6",
   "metadata": {},
   "source": [
    "## 3. Implement an image classification service\n",
    "\n",
    "Let\u2019s jump right in and get a simple ML service up and running on Ray Serve. \n",
    "\n",
    "Here is an image classification service that performs inference on a batch of handwritten digits using an `MNISTClassifier` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb17a6-a71c-4a11-8ea8-b1b350a5fa1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MNISTClassifier:\n",
    "    def __init__(self, remote_path: str, local_path: str, device: str):\n",
    "        subprocess.run(f\"aws s3 cp {remote_path} {local_path} --no-sign-request\", shell=True, check=True)\n",
    "        \n",
    "        self.device = device\n",
    "        self.model = torch.jit.load(local_path).to(device).eval()\n",
    "\n",
    "    def __call__(self, batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "        return self.predict(batch)\n",
    "    \n",
    "    def predict(self, batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "        images = torch.tensor(batch[\"image\"]).float().to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(images).cpu().numpy()\n",
    "\n",
    "        batch[\"predicted_label\"] = np.argmax(logits, axis=1)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d148b8",
   "metadata": {},
   "source": [
    "First we need to load the classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a79961",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_folder = '/mnt/cluster_storage'  # Modify this path to your local folder if it runs on your local environment\n",
    "model_path = f\"{storage_folder}/model.pt\" # Use your local path\n",
    "classifier = MNISTClassifier(remote_path=\"s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt\", local_path=model_path, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b7dbc",
   "metadata": {},
   "source": [
    "Then we can run inference to generate predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b16400",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = classifier({\"image\": np.random.rand(1, 1, 28, 28).astype(np.float32)})  # Example input (B, C, H, W)\n",
    "output[\"predicted_label\"]  # Should be a numpy array with the predicted label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1a687",
   "metadata": {},
   "source": [
    "Now, if we want to migrate to an online inference setting, we can transform this into a Ray Serve Deployment by applying the `@serve.deployment` decorator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68888dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment() # this is the decorator to add\n",
    "class OnlineMNISTClassifier:\n",
    "    # same code as MNISTClassifier.__init__\n",
    "    def __init__(self, remote_path: str, local_path: str, device: str):\n",
    "        subprocess.run(f\"aws s3 cp {remote_path} {local_path} --no-sign-request\", shell=True, check=True)\n",
    "        \n",
    "        self.device = device\n",
    "        self.model = torch.jit.load(local_path).to(device).eval()\n",
    "\n",
    "    async def __call__(self, request: Request) -> dict[str, Any]:  # __call__ now takes a Request object\n",
    "        batch = json.loads(await request.json()) # we will need to parse the JSON body of the request\n",
    "        return await self.predict(batch)\n",
    "    \n",
    "    # same code as MNISTClassifier.predict\n",
    "    async def predict(self, batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "        images = torch.tensor(batch[\"image\"]).float().to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(images).cpu().numpy()\n",
    "\n",
    "        batch[\"predicted_label\"] = np.argmax(logits, axis=1)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033619e",
   "metadata": {},
   "source": [
    "We have now defined our Ray Serve deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "OnlineMNISTClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf85ff1",
   "metadata": {},
   "source": [
    "We can now build an Application using `OnlineMNISTClassifier` deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df46ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"{storage_folder}/model.pt\" # Use your local path\n",
    "mnist_app = OnlineMNISTClassifier.bind(remote_path=\"s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt\", local_path=model_path, device=\"cpu\")\n",
    "mnist_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098e8ac4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Note:** `.bind` is a method that takes in the arguments to pass to the Deployment constructor.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e70529",
   "metadata": {},
   "source": [
    "We can then run the application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96056cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_app_handle = serve.run(mnist_app, name='mnist_classifier', blocking=False)\n",
    "mnist_app_handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a0cdb-822a-4439-aeab-9916dd8d059c",
   "metadata": {},
   "source": [
    "We can test it as an HTTP endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a80e9-c26f-48d2-8985-ef4eab4dc580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = np.random.rand(2, 1, 28, 28).tolist()\n",
    "json_request = json.dumps({\"image\": images})\n",
    "response = requests.post(\"http://localhost:8000/\", json=json_request)\n",
    "response.json()[\"predicted_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd2cb01",
   "metadata": {},
   "source": [
    "We can also test it as a gRPC endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342928ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {\"image\": np.random.rand(10, 1, 28, 28)}\n",
    "response = await mnist_app_handle.predict.remote(batch)\n",
    "response[\"predicted_label\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray-jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}