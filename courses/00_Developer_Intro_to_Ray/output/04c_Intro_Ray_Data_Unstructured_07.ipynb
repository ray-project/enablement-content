{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stateful transformations with Ray Actors\n",
    "\n",
    "In cases like batch inference, you want to spin up a number of actor processes that are **initialized once** with your model **and reused** to process multiple batches.\n",
    "\n",
    "To implement this, you can use the `map_batches` API with a \"Callable\" class method that implements:\n",
    "\n",
    "- `__init__`: Initialize any expensive state.\n",
    "- `__call__`: Perform the stateful transformation.\n",
    "\n",
    "For example, we can implement a `MNISTClassifier` that:\n",
    "- loads a pre-trained model from a local file\n",
    "- accepts a batch of images and generates the predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cpu\" # or \"cpu\" if you want to run it locally on CPU\n",
    "class MNISTClassifier:\n",
    "    def __init__(self, remote_path: str, local_path: str):\n",
    "        subprocess.run(f\"aws s3 cp --no-sign-request {remote_path} {local_path}\", shell=True, check=True)\n",
    "\n",
    "        self.model = torch.jit.load(local_path).to(device).eval()\n",
    "\n",
    "\n",
    "    def __call__(self, batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "        images = torch.tensor(batch[\"image\"]).float().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(images).cpu().numpy()\n",
    "\n",
    "        batch[\"predicted_label\"] = np.argmax(logits, axis=1)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `map_batches` API to apply the transformation to each batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storage_folder = 'mnt/cluster_storage'  # Modify this path to your local folder if it runs on your local environment\n",
    "local_path = f\"{storage_folder}/model.pt\"\n",
    "\n",
    "mnist_classifier_args = {\n",
    "    \"remote_path\": \"s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt\",\n",
    "    \"local_path\": local_path,\n",
    "}\n",
    "\n",
    "ds_preds = ds_normalized.map_batches(\n",
    "    MNISTClassifier,\n",
    "    fn_constructor_kwargs=mnist_classifier_args,\n",
    "    num_gpus= 1 if device == 'cuda' else None,  # Use GPU if available\n",
    "    concurrency=3,\n",
    "    batch_size=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Resource specification for stateful transformations\n",
    "\n",
    "It is common when you have varying hardware types in your cluster to want to further specify which accelerators to use for each stage of your pipeline.\n",
    "\n",
    "Let's show how to achieve this with the `resources` parameter.\n",
    "\n",
    "To use a GPU for following examples, we suggest to run them on Anyscale Ray Cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_preds = ds_normalized.map_batches(\n",
    "    MNISTClassifier,\n",
    "    fn_constructor_kwargs=mnist_classifier_args,\n",
    "    num_gpus= 1 if device == 'cuda' else None,  # Use GPU if available\n",
    "    concurrency=3,\n",
    "    batch_size=100,\n",
    "    resources={\"accelerator_type:T4\": 0.0001},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Note:</b> Pass in the Callable class uninitialized. Your driver will not execute the class constructor. Ray will pass in the arguments to the class constructor when the class is actually used in a transformation.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Note on autoscaling for stateful transformations\n",
    "\n",
    "For stateless transformations, Ray Data will automatically scale up the number of tasks to match the number of input blocks.\n",
    "\n",
    "For stateful transformations, Ray Data will schedule tasks proportional to the number of actors (workers) in the pool. \n",
    "\n",
    "To specify an autoscaling pool, use a tuple of `(min_size, max_size)` for the `concurrency` parameter.\n",
    "\n",
    "Ray Data will start with `min_size` actors and automatically scale up to `max_size` as needed.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_preds = ds_normalized.map_batches(\n",
    "    MNISTClassifier,\n",
    "    fn_constructor_kwargs=mnist_classifier_args,\n",
    "    num_gpus= 1 if device == 'cuda' else None,  # Use GPU if available\n",
    "    concurrency=(1, 4),  # Autoscale pool based on blocks, resources and limits\n",
    "    batch_size=100,\n",
    "    #resources={\"accelerator_type:T4\": 0.0001}, # Optional if you run it locally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_preds = ds_preds.take_batch(100)\n",
    "batch_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray-jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}