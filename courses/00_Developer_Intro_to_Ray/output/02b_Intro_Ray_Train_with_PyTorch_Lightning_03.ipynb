{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5b883e7",
   "metadata": {},
   "source": [
    "## 2. Single GPU Training with PyTorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1288014b",
   "metadata": {},
   "source": [
    "### 2.1 Overview\n",
    "\n",
    "We will start by fitting a Stable Diffusion `Unet` model to a preprocessed image and text dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1537cf",
   "metadata": {},
   "source": [
    "This diagram shows the full-scale training architecture.\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/stable-diffusion/training_architecture_v3.jpeg\" width=\"700px\">\n",
    "\n",
    "Regardless of scale, the process is primarily composed of three main stages:\n",
    "1. **Loading the preprocessed data**\n",
    "2. **Training the model**\n",
    "3. **Storing the model checkpoints**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7c50ba",
   "metadata": {},
   "source": [
    "### 2.2. Create a torch dataloader \n",
    "\n",
    "Let's start by defining a dataset we want to use. \n",
    "\n",
    "We'll use `parquet` data that was generated using the same preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40392506-334f-4b05-9bb0-f2815daff428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParquetDataset(Dataset):\n",
    "    \"\"\"Minimal PyTorch Dataset for data stored in parquet.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        s3_path: str,\n",
    "        dtype: np.dtype = np.float16,\n",
    "    ):\n",
    "        self.columns = [\"image_latents_256\", \"caption_latents\"]\n",
    "        loaded_df = pd.read_parquet(\n",
    "            s3_path,\n",
    "            columns=[\"image_latents_256\", \"caption_latents\"],\n",
    "            filesystem=s3fs.S3FileSystem(anon=False),\n",
    "        )\n",
    "        loaded_df[\"image_latents_256\"] = loaded_df[\"image_latents_256\"].apply(\n",
    "            lambda x: x.reshape(4, 32, 32).astype(dtype)\n",
    "        )\n",
    "        loaded_df[\"caption_latents\"] = loaded_df[\"caption_latents\"].apply(\n",
    "            lambda x: x.reshape(77, 1024).astype(dtype)\n",
    "        )\n",
    "        self.df = loaded_df\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        # Convert to tensors so default collate stacks them automatically.\n",
    "        return {col: torch.as_tensor(row[col]) for col in self.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623c4905",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**Note** this Dataset implementation is very simple and loads the entire dataset into memory. Not recommended for large datasets.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b56c12",
   "metadata": {},
   "source": [
    "Let's proceed to build our custom map-style dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab0506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_storage_path = os.environ[\"ANYSCALE_ARTIFACT_STORAGE\"]\n",
    "s3_path = f\"{artifact_storage_path}/stable-diffusion/256/6_000108_000000.parquet\"\n",
    "dataset = ParquetDataset(s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f26cf6",
   "metadata": {},
   "source": [
    "We construct a torch dataloader that will be used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc36a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,  # Adjust based on memory constraints\n",
    "    shuffle=True,\n",
    "    num_workers=2,  # Adjust based on system's CPU cores\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfd9333",
   "metadata": {},
   "source": [
    "We can inspect the batches to verify their shape and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d0e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data_loader:\n",
    "    print(batch[\"image_latents_256\"].shape, batch[\"caption_latents\"].shape)\n",
    "    print(batch[\"caption_latents\"].dtype, batch[\"image_latents_256\"].dtype)\n",
    "    break  # Remove this to process the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d8b57-ded8-42c2-84a1-60e8102d17ba",
   "metadata": {},
   "source": [
    "### 2.3 Define a stable diffusion model\n",
    "\n",
    "This \"standard\" LightningModule does not explicitly refer to Ray or Ray Train, which makes migrating workloads easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7e93d-4e8f-4053-86d0-0fd5f44b5f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "small_unet_model_config = {\n",
    "    \"_class_name\": \"UNet2DConditionModel\",\n",
    "    \"_diffusers_version\": \"0.2.2\",\n",
    "    \"act_fn\": \"silu\",\n",
    "    \"attention_head_dim\": 8,\n",
    "    \"block_out_channels\": [160, 320, 640, 640],\n",
    "    \"center_input_sample\": False,\n",
    "    \"cross_attention_dim\": 1024,\n",
    "    \"down_block_types\": [\n",
    "        \"CrossAttnDownBlock2D\",\n",
    "        \"CrossAttnDownBlock2D\",\n",
    "        \"CrossAttnDownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "    ],\n",
    "    \"downsample_padding\": 1,\n",
    "    \"flip_sin_to_cos\": True,\n",
    "    \"freq_shift\": 0,\n",
    "    \"in_channels\": 4,\n",
    "    \"layers_per_block\": 2,\n",
    "    \"mid_block_scale_factor\": 1,\n",
    "    \"norm_eps\": 1e-05,\n",
    "    \"norm_num_groups\": 32,\n",
    "    \"out_channels\": 4,\n",
    "    \"sample_size\": 64,\n",
    "    \"up_block_types\": [\n",
    "        \"UpBlock2D\",\n",
    "        \"CrossAttnUpBlock2D\",\n",
    "        \"CrossAttnUpBlock2D\",\n",
    "        \"CrossAttnUpBlock2D\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "class StableDiffusion(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float,\n",
    "        resolution: int,\n",
    "        weight_decay: float,\n",
    "        num_warmup_steps: int,\n",
    "        model_name: str,\n",
    "    ) -> None:\n",
    "        self.lr = lr\n",
    "        self.resolution = resolution\n",
    "        self.weight_decay = weight_decay\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # Initialize U-Net.\n",
    "        # model_config = PretrainedConfig.get_config_dict(model_name, subfolder=\"unet\")[0]\n",
    "        model_config = small_unet_model_config\n",
    "        self.unet = UNet2DConditionModel(**model_config)\n",
    "        # Define the training noise scheduler.\n",
    "        self.noise_scheduler = DDPMScheduler.from_pretrained(\n",
    "            model_name, subfolder=\"scheduler\"\n",
    "        )\n",
    "        # Setup loss function.\n",
    "        self.loss_fn = F.mse_loss\n",
    "        self.current_training_steps = 0\n",
    "\n",
    "    def on_fit_start(self) -> None:\n",
    "        \"\"\"Move cumprod tensor to GPU in advance to avoid data movement on each step.\"\"\"\n",
    "        self.noise_scheduler.alphas_cumprod = self.noise_scheduler.alphas_cumprod.to(\n",
    "            get_device()\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, batch: dict[str, torch.Tensor]\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Forward pass of the model.\"\"\"\n",
    "        # Extract inputs.\n",
    "        latents = batch[\"image_latents_256\"]\n",
    "        conditioning = batch[\"caption_latents\"]\n",
    "        # Sample the diffusion timesteps.\n",
    "        timesteps = self._sample_timesteps(latents)\n",
    "        # Add noise to the inputs (forward diffusion).\n",
    "        noise = torch.randn_like(latents)\n",
    "        noised_latents = self.noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "        # Forward through the model.\n",
    "        outputs = self.unet(noised_latents, timesteps, conditioning)[\"sample\"]\n",
    "        return outputs, noise\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: dict[str, torch.Tensor], batch_idx: int\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Training step of the model.\"\"\"\n",
    "        outputs, targets = self.forward(batch)\n",
    "        loss = self.loss_fn(outputs, targets)\n",
    "        self.log(\n",
    "            \"train/loss_mse\", loss.item(), prog_bar=False, on_step=True, sync_dist=False\n",
    "        )\n",
    "        self.current_training_steps += 1\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        \"\"\"Configure the optimizer and learning rate scheduler.\"\"\"\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.trainer.model.parameters(),\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "        # Set a large training step here to keep lr constant after warm-up.\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.num_warmup_steps,\n",
    "            num_training_steps=100000000000,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def _sample_timesteps(self, latents: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.randint(\n",
    "            0, len(self.noise_scheduler), (latents.shape[0],), device=latents.device\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822926ee-bd2b-4977-8ffd-725881160da3",
   "metadata": {},
   "source": [
    "### 2.4. Define a PyTorch Lightning training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109df3ab",
   "metadata": {},
   "source": [
    "Here is a training loop that is specific to PyTorch Lightning.\n",
    "\n",
    "It performs the following steps:\n",
    "1. **Model Initialization:**\n",
    "   - Instantiate the diffusion model.\n",
    "2. **Trainer Setup:**\n",
    "   - Instantiate the Lightning Trainer with a `DDPStrategy` to perform data parallel training.\n",
    "3. **Training Execution:**\n",
    "   - Run the trainer using the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503c914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightning_training_loop(\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    storage_path: str,\n",
    "    model_name: str = \"stabilityai/stable-diffusion-2-base\",\n",
    "    resolution: int = 256,\n",
    "    lr: float = 1e-4,\n",
    "    max_epochs: int = 1,\n",
    "    num_warmup_steps: int = 10_000,\n",
    "    weight_decay: float = 1e-2,\n",
    ") -> None:\n",
    "    # 1. Initialize the model\n",
    "    model = StableDiffusion(\n",
    "        model_name=model_name,\n",
    "        resolution=resolution,\n",
    "        lr=lr,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    # 2. Initialize the Lightning Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=\"auto\",\n",
    "        precision=\"bf16-mixed\",\n",
    "        max_epochs=max_epochs,\n",
    "        default_root_dir=storage_path,\n",
    "        log_every_n_steps=8,\n",
    "    )\n",
    "\n",
    "    # 3. Run the trainer\n",
    "    trainer.fit(model=model, train_dataloaders=train_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6423b358",
   "metadata": {},
   "source": [
    "Here is how we would run the lightning training loop on a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5575eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_path = \"/mnt/local_storage/lightning/stable-diffusion-pretraining/\"\n",
    "lightning_training_loop(train_loader=data_loader, storage_path=storage_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a09b6",
   "metadata": {},
   "source": [
    "Let's inspect the storage path to see what files were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70a3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree {storage_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray-jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}