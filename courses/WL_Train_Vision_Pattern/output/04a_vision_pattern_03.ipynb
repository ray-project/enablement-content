{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom `Food101Dataset` for Parquet  \n",
    "To feed data into PyTorch, define a custom `Dataset`. You cache Parquet metadata, map global indices to specific row groups, and pull only the row you need. Each `__getitem__` returns an `(image, label)` pair that's immediately ready for further transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06. Define PyTorch Dataset that loads from Parquet\n",
    "\n",
    "class Food101Dataset(Dataset):\n",
    "    def __init__(self, parquet_path: str, transform=None):\n",
    "        self.parquet_file = pq.ParquetFile(parquet_path)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Precompute a global row index to (row_group_idx, local_idx) map\n",
    "        self.row_group_map = []\n",
    "        for rg_idx in range(self.parquet_file.num_row_groups):\n",
    "            rg_meta = self.parquet_file.metadata.row_group(rg_idx)\n",
    "            num_rows = rg_meta.num_rows\n",
    "            self.row_group_map.extend([(rg_idx, i) for i in range(num_rows)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.row_group_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row_group_idx, local_idx = self.row_group_map[idx]\n",
    "        # Read only the relevant row group (in memory-efficient batch---for scalability)\n",
    "        table = self.parquet_file.read_row_group(row_group_idx, columns=[\"image_bytes\", \"label\"])\n",
    "        row = table.to_pandas().iloc[local_idx]\n",
    "\n",
    "        img = Image.open(io.BytesIO(row[\"image_bytes\"])).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, row[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Image transform  \n",
    "Create a transform pipeline: `ToTensor()` followed by ImageNet mean and standard-deviation normalisation. By applying the transform inside the dataset, you make sure every worker, no matter where it runs, processes images in exactly the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07. Define data preprocessing transform\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Train/validation split  \n",
    "Shuffle the full Parquet table once (seeded for reproducibility) and then slice off the last 500 rows to construct the validation set. Write the train and validation partitions to their own Parquet files so you can load them independently later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08. Create train/val Parquet splits \n",
    "full_path = \"/mnt/cluster_storage/food101_lite/parquet_256/shard_0.parquet\"\n",
    "\n",
    "df = (\n",
    "    pq.read_table(full_path)\n",
    "    .to_pandas()\n",
    "    .sample(frac=1.0, random_state=42)  # shuffle for reproducibility\n",
    ")\n",
    "\n",
    "df[:-500].to_parquet(\"/mnt/cluster_storage/food101_lite/train.parquet\")   # training\n",
    "df[-500:].to_parquet(\"/mnt/cluster_storage/food101_lite/val.parquet\")     # validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Inspect a DataLoader batch  \n",
    "Before you scale out, build a regular single-process `DataLoader`, pull one batch, and print its shape. This tiny test reassures you that batching, multiprocessing, and transforms work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 09. Observe data shape\n",
    "\n",
    "loader = DataLoader(\n",
    "    Food101Dataset(\"/mnt/cluster_storage/food101_lite/train.parquet\", transform=transform),\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "for images, labels in loader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}