{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Ray Data\n",
    "\n",
    "This notebook will provide an overview of Ray Data and how to use it to load, and transform data in a distributed manner.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> Here is the roadmap for this notebook:</b>\n",
    "<ul>\n",
    "    <li><b>Part 0:</b> Introduction</a></li>\n",
    "    <li><b>Part 1:</b> When to use Ray Data</a></li>\n",
    "    <li><b>Part 2:</b> Loading Data</a></li>\n",
    "    <li><b>Part 3:</b> Transforming Data</a></li>\n",
    "    <li><b>Part 4:</b> Data Operations: Grouping, Aggregation, and Shuffling</a></li>\n",
    "    <li><b>Part 5:</b> Persisting Data</a></li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. When to use Ray Data\n",
    "\n",
    "- To **load and preprocess data for distributed ML workloads**.\n",
    "- Datasets are the main abstraction.\n",
    "- Compared to other loading solutions, Datasets are more **flexible** and provide [**higher overall performance**](https://www.anyscale.com/blog/why-third-generation-ml-platforms-are-more-performant). \n",
    "- Especially performant when needing to run pre-processing in a \n",
    "   - **streaming fashion** across a \n",
    "   - **large dataset** on a \n",
    "   - **heterogeneous cluster of CPUs and GPUs**.\n",
    "- Use as **last-mile bridge** from storage or ETL pipeline outputs **to distributed applications** and libraries in Ray. \n",
    "\n",
    "<img src='https://docs.ray.io/en/releases-2.34.0/_images/dataset-loading-1.svg' width=60%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Data\n",
    "\n",
    "- Datasets uses Ray tasks to read data from remote storage. \n",
    "- When reading from a file-based datasource (e.g., S3), it creates a number of read tasks proportional to the number of CPUs in the cluster. \n",
    "- Each read task reads its assigned files and produces an output block\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-summit/rag-app/dataset-read-cropped-v2.svg\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some `MNIST` data from s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE 0/\n",
      "                           PRE 1/\n",
      "                           PRE 2/\n",
      "                           PRE 3/\n",
      "                           PRE 4/\n",
      "                           PRE 5/\n",
      "                           PRE 6/\n",
      "                           PRE 7/\n",
      "                           PRE 8/\n",
      "                           PRE 9/\n"
     ]
    }
   ],
   "source": [
    "# Here is our dataset it contains 50 images per class\n",
    "!aws s3 ls s3://anyscale-public-materials/ray-ai-libraries/mnist/50_per_index/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `read_images` function to load the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:56:54,059\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:56:54,060\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e32ffe4eae490998463c6a620a73ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7882960eae5d42bea50f4585afca3b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7777647ff92d40e785779ffc4c20a688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:56:57,428\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:56:57,429\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978b065386b146a09252f866cbeecab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e879325570674bcb9c2a34be9eb28958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df21126c52f4d978fbf15db93177ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3265f9c37d43e9a2bc1f1016b50385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dataset(\n",
       "   num_rows=?,\n",
       "   schema={image: numpy.ndarray(shape=(28, 28), dtype=uint8), path: string}\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ds = ray.data.read_images(\"s3://anyscale-public-materials/ray-ai-libraries/mnist/50_per_index/\", include_paths=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the [Input/Output docs](https://docs.ray.io/en/latest/data/api/input_output.html) for a comprehensive list of read functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More about Datasets\n",
    "\n",
    "- A Dataset consists of a list of Ray object references to **blocks**. \n",
    "- Having multiple blocks in a dataset allows for **parallel transformation and ingest**.\n",
    "\n",
    "The following figure visualizes a **tabular dataset with three blocks, each block holding 1000 rows each**:\n",
    "\n",
    "<img src='https://docs.ray.io/en/releases-2.6.1/_images/dataset-arch.svg' width=50%/>\n",
    "\n",
    "- A Dataset is just a list of Ray object references.\n",
    "- Fits into Ray's general compute framework.\n",
    "- It can be freely passed between Ray tasks, actors, and other  libraries like any other object reference.\n",
    "- This flexibility is a unique characteristic of Ray Datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transforming Data\n",
    "\n",
    "- Use either Ray tasks or Ray actors to transform datasets. \n",
    "- Using actors allows for expensive state initialization (e.g., for GPU-based tasks) to be cached.\n",
    "- Ray Data simplifies general purpose parallel GPU and CPU compute in Ray. \n",
    "\n",
    "Here is a sample data pipeline for streaming image data across a classification and segmentation model on a heterogenous cluster of CPUs and GPUs.\n",
    "\n",
    "<img src='https://docs.ray.io/en/releases-2.6.1/_images/stream-example.png' width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform data, we can use the `map_batches` API. This API allows us to apply a transformation to each batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:25:49,233\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:25:49,234\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debf0cd6aa144027a1730b48d094e063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaeb35aa32174da7b0376bf1d53d7ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb630a7f713b44608c45f31e5eaaabf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5fc542b7c744978d6a76e2aeb94598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapBatches(normalize)\n",
       "+- Dataset(\n",
       "      num_rows=?,\n",
       "      schema={image: numpy.ndarray(shape=(28, 28), dtype=uint8), path: string}\n",
       "   )"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "\n",
    "def normalize(\n",
    "    batch: dict[str, np.ndarray], min_: float, max_: float\n",
    ") -> dict[str, np.ndarray]:\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    batch[\"image\"] = [transform(image) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "\n",
    "ds_normalized = ds.map_batches(normalize, fn_kwargs={\"min_\": 0, \"max_\": 255})\n",
    "ds_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution mode\n",
    "\n",
    "- Most transformations are **lazy**. \n",
    "- They **don't execute until you** write a dataset to storage or decide to **materialize** (or consume) the dataset.\n",
    "- To materialize a very small subset of the data, you can use the **`take_batch`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:26:40,187\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:26:40,188\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> LimitOperator[limit=10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81c5672e9e349eb8982271fae7bd8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c12997069324bc89a9c751574583951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd7e0ccb4c64af8b19fa1ef7985755f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(normalize) 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd832f487d884d23b5a32a4643b4474f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=10 4: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb9aa61c98b4ecc857290ead31aa1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalized_batch = ds_normalized.take_batch(batch_size=10)\n",
    "\n",
    "for image in normalized_batch[\"image\"]:\n",
    "    assert image.shape == (1, 28, 28) # channel, height, width\n",
    "    assert image.min() >= -1 and image.max() <= 1 # normalized to [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stateful transformations with actors\n",
    "\n",
    "In cases like **batch inference**, you want to spin up a number of **actor processes** that are initialized once with your model and reused to process multiple batches.\n",
    "\n",
    "To implement this, you can use the `map_batches` API with a \"Callable\" class method that implements:\n",
    "\n",
    "- `__init__`: Initialize any expensive state.\n",
    "- `__call__`: Perform the stateful transformation.\n",
    "\n",
    "For example, we can implement a `MNISTClassifier` that:\n",
    "- loads a pre-trained model from a local file\n",
    "- accepts a batch of images and generates the predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class MNISTClassifier:\n",
    "    def __init__(self, local_path: str):\n",
    "        self.model = torch.jit.load(local_path)\n",
    "        self.model.to(\"cuda\")\n",
    "        self.model.eval()\n",
    "\n",
    "    def __call__(self, batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "        images = torch.tensor(batch[\"image\"]).float().to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(images).cpu().numpy()\n",
    "\n",
    "        batch[\"predicted_label\"] = np.argmax(logits, axis=1)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt to ../../../mnt/cluster_storage/model.pt\n"
     ]
    }
   ],
   "source": [
    "# We download the model from s3 to an EFS storage\n",
    "!aws s3 cp s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt /mnt/cluster_storage/model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `map_batches` API to apply the transformation to each batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_preds = ds_normalized.map_batches(\n",
    "    MNISTClassifier,\n",
    "    fn_constructor_kwargs={\"local_path\": \"/mnt/cluster_storage/model.pt\"},\n",
    "    num_gpus=0.1,\n",
    "    concurrency=1,\n",
    "    batch_size=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<b>Note:</b> We pass in the Callable class uninitialized. Ray will pass in the arguments to the class constructor when the class is actually used in a transformation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:32:17,604\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:32:17,605\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> ActorPoolMapOperator[MapBatches(MNISTClassifier)] -> LimitOperator[limit=100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6beddafcd55b4fa39331c47dca354694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377536a77b2c46d29e581d22d439660d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5226e75c8634d66b06bc059388855db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(normalize) 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f235c00540fc42d1b61713fbde1d55cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(MNISTClassifier) 4: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67495077a9ba4f11b29c726dff36b3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=100 5: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae2d3152f184b128382fdff9b8bbf06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_preds = ds_preds.take_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materializing Data\n",
    "\n",
    "You can choose to materialize the entire dataset into the ray object store which is distributed across the cluster, primarily in memory and secondarily spilling to disk.\n",
    "\n",
    "To materialize the dataset, we can use the `materialize()` method.\n",
    "\n",
    "Use this **only** when you require the full dataset to compute downstream outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:35:32,187\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:35:32,187\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> ActorPoolMapOperator[MapBatches(MNISTClassifier)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14433956907646ab97142199354bbe66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed4da38dad143a0ab2589d323d7063f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88036718ece46b48a40d6ad1660c71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(normalize) 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d724ec1140654239ae4ea98ded56fefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(MNISTClassifier) 4: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b53b0cbca374bd7bd7507bb0497270f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5494f7ba227449dba13694a8410960dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MaterializedDataset(\n",
       "   num_blocks=1,\n",
       "   num_rows=500,\n",
       "   schema={\n",
       "      image: numpy.ndarray(shape=(1, 28, 28), dtype=float),\n",
       "      path: string,\n",
       "      predicted_label: int64\n",
       "   }\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_preds.materialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Operations: Grouping, Aggregation, and Shuffling\n",
    "\n",
    "Let's look at some more involved transformations.\n",
    "\n",
    "#### Custom batching using **`groupby`** \n",
    "\n",
    "In case you want to generate batches according to a **specific key**, you can use **`groupby` to group the data** by the key and then use **`map_groups`** to apply the transformation.\n",
    "\n",
    "For instance, let's compute the accuracy of the model by **\"ground truth label\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:59:09,827\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:59:09,828\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> ActorPoolMapOperator[MapBatches(MNISTClassifier)] -> TaskPoolMapOperator[MapBatches(add_label)] -> AllToAllOperator[Sort] -> TaskPoolMapOperator[MapBatches(compute_accuracy)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac8e055c90445dcb06ebc21ae1bd82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f776f7a1e984a819a072a868d7e5cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97b817684534aeabd6bcb11abb2abe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(normalize) 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0409b5665b744c98f7dd87d7512a4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(MNISTClassifier) 4: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb725d50cf34f178ae88cffd9170a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(add_label) 5: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3331d96804e47e49fd388dfb844f2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Sort 6: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205fe299c7344821a61000e96d9f432e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 7:   0%|          | 0/1 [00:00<?, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca90aaf95df64d3982cd3babf58eba69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 8:   0%|          | 0/1 [00:00<?, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefc59896540426b8da2872b2117fd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 9:   0%|          | 0/1 [00:00<?, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588aa6fe2c0d4c8cac153d4059e0b8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(compute_accuracy) 10: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f701b016f48441bb379729c1ac868b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a57e15f18604a4684f854b6be348507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 0:   0%|          | 0/1 [00:00<?, ? block/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>ground_truth_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.96</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.98</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.98</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  ground_truth_label\n",
       "0      0.98                   0\n",
       "1      1.00                   1\n",
       "2      1.00                   2\n",
       "3      0.96                   3\n",
       "4      1.00                   4\n",
       "5      1.00                   5\n",
       "6      0.98                   6\n",
       "7      0.98                   7\n",
       "8      1.00                   8\n",
       "9      0.98                   9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_label(batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "    batch[\"ground_truth_label\"] = [int(path.split(\"/\")[-2]) for path in batch[\"path\"]]\n",
    "    return batch\n",
    "\n",
    "\n",
    "def compute_accuracy(group: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "    return {\n",
    "        \"accuracy\": [np.mean(group[\"predicted_label\"] == group[\"ground_truth_label\"])],\n",
    "        \"ground_truth_label\": group[\"ground_truth_label\"][:1],\n",
    "    }\n",
    "\n",
    "\n",
    "ds_preds.map_batches(add_label).groupby(\"ground_truth_label\").map_groups(compute_accuracy).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<b>Note:</b> ds_preds is not re-computed given we have already materialized the dataset.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations\n",
    "\n",
    "Ray Data also supports a **variety of aggregations**. These aggregations can be **chained**.\n",
    "\n",
    "For instance, we can compute the **mean** accuracy across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 10:01:43,102\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 10:01:43,103\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> ActorPoolMapOperator[MapBatches(MNISTClassifier)] -> TaskPoolMapOperator[MapBatches(add_label)->MapBatches(compute_accuracy)] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9c97c146974c73a2445e17e647bf9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2f928543534330a796100cb7afa35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0f6c006dd54c419c9f8cccec893ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(normalize) 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143dcedc858b42f0b43b4e9b7cd3e814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(MNISTClassifier) 4: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cbeab83c97484aa47c975d73536329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(add_label)->MapBatches(compute_accuracy) 5: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bcd4440bd546fbbfaecefc820e9fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 6: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec3286455dd48a4bb3507f0ab8afbe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 7:   0%|          | 0/1 [00:00<?, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa6b8fc69df4c3e86f059670ad930dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 8:   0%|          | 0/1 [00:00<?, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b8815f68ad4ef0aaaa0149c47a411f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 9: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42894df7ca48470c9cdbcbae3f0b80a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.988"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_preds.map_batches(add_label).map_batches(compute_accuracy).mean(on=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of version 2.34.0, Ray Data provides the following aggregation functions:\n",
    "\n",
    "- `count`\n",
    "- `max`\n",
    "- `mean`\n",
    "- `min`\n",
    "- `sum`\n",
    "- `std`\n",
    "\n",
    "See relevant [docs page here](https://docs.ray.io/en/latest/data/api/grouped_data.html#ray.data.aggregate.AggregateFn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling data \n",
    "\n",
    "There are **different options to shuffle data** in Ray Data of varying degrees of randomness and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File based shuffle on read\n",
    "\n",
    "To randomly **shuffle the ordering of input files before reading**, call a read function that supports shuffling, such as `read_images()`, and use the shuffle=\"files\" parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 10:04:12,645\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 10:04:12,645\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadImage]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e40e72a8464879af56561191c7d144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadImage 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc9a1433a8c4e598471502a0467ad4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 10:04:13,055\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 10:04:13,056\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadImage]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16de9e0478854c39aa8902d60acada0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadImage 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e0e2a411a442dfa013638af7c05065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796f7b0d72474049b9a179a1ab049626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dataset(\n",
       "   num_rows=500,\n",
       "   schema={image: numpy.ndarray(shape=(28, 28), dtype=uint8)}\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.data.read_images(\"s3://anyscale-public-materials/ray-ai-libraries/mnist/50_per_index/\", shuffle=\"files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling block order\n",
    "\n",
    "- This option randomizes the **order of blocks in a dataset**. \n",
    "- Blocks are the **basic unit** of data chunk that Ray Data stores in the object store. \n",
    "- Applying this operation alone **doesn’t involve heavy computation and communication**. \n",
    "- However, it requires Ray Data to **materialize all blocks in memory** before applying the operation. \n",
    "- Only use this option when your dataset is small enough to fit into the object store memory.\n",
    "\n",
    "To perform block order shuffling, use `randomize_block_order`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 10:05:33,949\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 10:05:33,950\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> ActorPoolMapOperator[MapBatches(MNISTClassifier)] -> AllToAllOperator[RandomizeBlockOrder]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5297bfef17f649f0acba3dc8dd61bc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97c6ef0da094b0aa04611a09505a884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed1835bd1d9465ebac618e784360555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(normalize) 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329c220ebca748e2b8c65a1fef5ddbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(MNISTClassifier) 4: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9ba079cb3647fa864041dd50f246e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- RandomizeBlockOrder 5: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1597c5ba644488bad47508513f8d28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8538f462f44945578216b32ccfbecde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MaterializedDataset(\n",
       "   num_blocks=1,\n",
       "   num_rows=500,\n",
       "   schema={\n",
       "      image: numpy.ndarray(shape=(1, 28, 28), dtype=float),\n",
       "      path: string,\n",
       "      predicted_label: int64\n",
       "   }\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_randomized_blocks = ds_preds.randomize_block_order()\n",
    "ds_randomized_blocks.materialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle rows globally\n",
    "\n",
    "- To randomly **shuffle all rows globally**, call `random_shuffle()`. \n",
    "- This is the **slowest option** for shuffle, and requires **transferring data across network between workers**. \n",
    "- This option achieves the **best randomness** among all options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 10:06:32,993\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 10:06:32,993\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> ActorPoolMapOperator[MapBatches(MNISTClassifier)] -> AllToAllOperator[RandomShuffle]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf337ef31dfe487c9efdea62da612b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3333d530d743b9a14a93742dcf5017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5d2b6f604e4966bd447bf9727cbf4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(normalize) 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331a7b12c71c412885275ba0bc5953ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(MNISTClassifier) 4: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba74932e2414528b11b8cb9ace7b912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- RandomShuffle 5: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76915ea2db9a45dd863d7b6655d5ff0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 6:   0%|          | 0/1 [00:00<?, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b0db9008ee47e0ae10c2f9744bdeb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 7:   0%|          | 0/1 [00:00<?, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51db4ce6d1cb44c8821604f0153bd3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b89b64c5d704cc78586185270ade833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MaterializedDataset(\n",
       "   num_blocks=1,\n",
       "   num_rows=500,\n",
       "   schema={\n",
       "      image: numpy.ndarray(shape=(1, 28, 28), dtype=float),\n",
       "      path: string,\n",
       "      predicted_label: int64\n",
       "   }\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_randomized_rows = ds_preds.random_shuffle()\n",
    "ds_randomized_rows.materialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Persisting Data\n",
    "\n",
    "Finally, you can persist a dataset to storage using any of the \"write\" functions that Ray Data supports.\n",
    "\n",
    "Lets write our predictions to a parquet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 10:09:17,311\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 10:09:17,312\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> ActorPoolMapOperator[MapBatches(MNISTClassifier)] -> TaskPoolMapOperator[Write]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7194b8806374c608933859cadfb8889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ab2e4529ce46e09aa339f9e79121a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c93a4788d44a17b5bc092afbcdd486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(normalize) 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e659f73f788497db93b0baf0a028ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(MNISTClassifier) 4: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52dbcf73364d4befb38dfb2461d4aff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Write 5: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1eb1c886a84195a2c5475cb3b65252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_preds.write_parquet(\"/mnt/cluster_storage/mnist_preds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the [Input/Output docs](https://docs.ray.io/en/latest/data/api/input_output.html) for a comprehensive list of write functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "!rm -rf /mnt/cluster_storage/mnist_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlook:  Ray Data in Production\n",
    "\n",
    "1. Runway AI is using Ray Data to scale its ML workloads. See [this interview with Runway AI](https://siliconangle.com/2024/10/02/runway-transforming-ai-driven-filmmaking-innovative-tools-techniques-raysummit/) to learn more.\n",
    "2. Netflix is using Ray Data for multi-modal inference pipelines. See [this talk at the Ray Summit 2024](https://raysummit.anyscale.com/flow/anyscale/raysummit2024/landing/page/sessioncatalog/session/1722028596844001bCg0) to learn more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
