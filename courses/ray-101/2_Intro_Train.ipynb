{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Ray Train\n",
    "\n",
    "This notebook will walk you through the basics of distributed training with Ray Train and PyTorch.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b> Roadmap</b>\n",
    "\n",
    "<ul>\n",
    "    <li><b>Part 0:</b> Introduction</li>\n",
    "    <li><b>Part 1:</b> PyTorch introductory example</li>\n",
    "    <li><b>Part 2:</b> Overview of Distributed Training with Ray Train</li>\n",
    "    <li><b>Part 3:</b> Overview of the training loop in Ray Train</li>\n",
    "    <li><b>Part 4:</b> Migrating the model and dataset to Ray Train</li>\n",
    "    <li><b>Part 5:</b> Reporting metrics and checkpoints</li>\n",
    "    <li><b>Part 6:</b> Launching the distributed training job</li>\n",
    "    <li><b>Part 7:</b> Accessing training results</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PyTorch introductory example (single GPU)\n",
    "\n",
    "We will start by fitting a `ResNet18` model to an `MNIST` dataset.\n",
    "\n",
    "Here is a diagram visualizing the single GPU training process:\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-ai-libraries/diagrams/single_gpu_pytorch_v3.png\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a high level, here is how our training loop in PyTorch looks like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torchmetrics\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "def train_loop_torch(num_epochs: int = 2, batch_size: int = 128, local_path: str = \"./checkpoints\"):\n",
    "    # Model, Loss, Optimizer\n",
    "    loss_function = CrossEntropyLoss()\n",
    "    model = load_model_torch()  # Later\n",
    "    optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    # Initialize the metric \n",
    "    acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(\"cuda\")\n",
    "\n",
    "    # Load the data loader\n",
    "    data_loader = build_data_loader_torch(batch_size=batch_size)  # Later\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in data_loader:\n",
    "            # Move the data to the GPU\n",
    "            images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_function(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the metric\n",
    "            acc(outputs, labels)\n",
    "        \n",
    "        # Report the metrics\n",
    "        metrics = report_metrics_torch(loss=loss, accuracy=acc.compute(), epoch=epoch)  # Later\n",
    "        \n",
    "        # Reset the metric\n",
    "        acc.reset()\n",
    "\n",
    "        # Save the checkpoint and metrics\n",
    "        Path(local_path).mkdir(parents=True, exist_ok=True)\n",
    "        save_checkpoint_and_metrics_torch(metrics=metrics, model=model, local_path=local_path)  # Later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and load our model on a single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "def build_resnet18():\n",
    "    model = resnet18(num_classes=10)\n",
    "    model.conv1 = torch.nn.Conv2d(\n",
    "        in_channels=1, # grayscale (one channel) MNIST images\n",
    "        out_channels=64,\n",
    "        kernel_size=(7, 7),\n",
    "        stride=(2, 2),\n",
    "        padding=(3, 3),\n",
    "        bias=False,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_torch() -> torch.nn.Module:\n",
    "    model = build_resnet18()\n",
    "    # Move to the single GPU device\n",
    "    model.to(\"cuda\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and visualizing MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "dataset = MNIST(root=\"./data\", train=True, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the first 10 images, with the corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.11/site-packages/torchvision/datasets/mnist.py:76: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/home/ray/anaconda3/lib/python3.11/site-packages/torchvision/datasets/mnist.py:66: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 10, figsize=(20, 2))\n",
    "\n",
    "for i in range(10):\n",
    "    axs[i].imshow(dataset.train_data[i], cmap=\"gray\")\n",
    "    axs[i].axis(\"off\")\n",
    "    axs[i].set_title(dataset.train_labels[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_data_loader_torch(batch_size: int) -> DataLoader:\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    dataset = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metrics_torch(loss: torch.Tensor, accuracy: torch.Tensor, epoch: int) -> None:\n",
    "    metrics = {\"loss\": loss.item(), \"epoch\": epoch, \"accuracy\": accuracy.item()}\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a checkpoint in a local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "def save_checkpoint_and_metrics_torch(metrics: dict[str, float], model: torch.nn.Module, local_path: str) -> None:\n",
    "    # Save the metrics\n",
    "    with open(os.path.join(local_path, \"metrics.csv\"), \"a\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(metrics.values())\n",
    "\n",
    "    # Save the model\n",
    "    checkpoint_path = os.path.join(local_path, \"model.pt\")\n",
    "    torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduling the training loop on a single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2784426808357239, 'epoch': 0, 'accuracy': 0.8147535920143127}\n",
      "{'loss': 0.10893423855304718, 'epoch': 1, 'accuracy': 0.9506543874740601}\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.now(datetime.UTC).strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "local_path = f\"/mnt/local_storage/single_gpu_mnist/torch_{timestamp}/\"\n",
    "\n",
    "train_loop_torch(\n",
    "    num_epochs=2, \n",
    "    local_path=local_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the produced checkpoints and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 43732\n",
      "-rw-r--r-- 1 ray users       83 Nov 22 09:26 metrics.csv\n",
      "-rw-r--r-- 1 ray users 44773570 Nov 22 09:26 model.pt\n"
     ]
    }
   ],
   "source": [
    "!ls -l {local_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.278443</td>\n",
       "      <td>0</td>\n",
       "      <td>0.814754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108934</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  epoch  accuracy\n",
       "0  0.278443      0  0.814754\n",
       "1  0.108934      1  0.950654"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "metrics = pd.read_csv(\n",
    "    os.path.join(local_path, \"metrics.csv\"),\n",
    "    header=None,\n",
    "    names=[\"loss\", \"epoch\", \"accuracy\"],\n",
    ")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load our produced model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52702/470834418.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(os.path.join(local_path, \"model.pt\")))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = build_resnet18()\n",
    "loaded_model.load_state_dict(torch.load(os.path.join(local_path, \"model.pt\")))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can the proceed to generate predictions on the first 10 images of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.11/site-packages/torchvision/datasets/mnist.py:76: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 10, figsize=(20, 2))\n",
    "for i in range(10):\n",
    "    axs[i].imshow(dataset.train_data[i], cmap=\"gray\")\n",
    "    axs[i].axis(\"off\")\n",
    "    with torch.no_grad():\n",
    "        normalized = Normalize((0.5,), (0.5,))(ToTensor()(dataset[i][0]))\n",
    "        prediction = loaded_model(normalized.unsqueeze(0)).argmax()\n",
    "    axs[i].set_title(prediction.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distributed Data Parallel Training with Ray Train and PyTorch (multiple GPUs)\n",
    "\n",
    "- Let's now consider the case where we have a very large dataset of images that would take a long time to train on a single GPU.\n",
    "- We would now like to scale this training job to run on multiple GPUs. \n",
    "- Here is a diagram visualizing the desired distributed data-parallel training process\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-ai-libraries/diagrams/multi_gpu_pytorch_v4.png\" width=\"1000\" >\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Overview of the training loop in Ray Train\n",
    "\n",
    "Let's see how this data-parallel training loop will look like with Ray Train and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_ray_train(config: dict):  # pass in hyperparameters in config\n",
    "    loss_function = CrossEntropyLoss()\n",
    "    \n",
    "    # New: Use Ray Train to wrap the original PyTorch model\n",
    "    model = load_model_ray_train()\n",
    "\n",
    "    # Initialize Adam optimizer\n",
    "    optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "    \n",
    "    # New: Calculate the batch size for each worker (batch size / num workers)\n",
    "    batch_size = config[\"global_batch_size\"] // ray.train.get_context().get_world_size()\n",
    "    \n",
    "    # New: Use Ray Train to wrap the data loader as a distributed sampler\n",
    "    data_loader = build_data_loader_ray_train(batch_size=batch_size) \n",
    "    \n",
    "    acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(model.device)\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        # Ensure data is on the correct device for each epoch\n",
    "        data_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "        # New: images, labels are now sharded,\n",
    "        # Gradients are accumulated across the workers\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            acc(outputs, labels)\n",
    "\n",
    "        # accuracy is now aggregated across the workers\n",
    "        accuracy = acc.compute()\n",
    "\n",
    "        # Use Ray Train to report metrics\n",
    "        metrics = print_metrics_ray_train(loss, accuracy, epoch)\n",
    "\n",
    "        # Use Ray Train to save checkpoint and metrics\n",
    "        save_checkpoint_and_metrics_ray_train(model, metrics)\n",
    "        acc.reset() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure scale and GPUs\n",
    "Outside of our training function, we create a `ScalingConfig` object to configure:\n",
    "\n",
    "- `num_workers`: The number of distributed training worker processes.\n",
    "- `use_gpu`: Whether each worker should use a GPU (or CPU).\n",
    "\n",
    "\n",
    "See [docs on configuring scale and GPUs](https://docs.ray.io/en/latest/train/user-guides/using-gpus.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train import ScalingConfig\n",
    "\n",
    "scaling_config = ScalingConfig(num_workers=2, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a high-level architecture of how Ray Train works:\n",
    "\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/overview.png\" width=600>\n",
    "\n",
    "#### Key points\n",
    "- The scaling config specifies the number of training workers.\n",
    "- A trainer actor process is launched that oversees the training workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Migrating the model and dataset to Ray Train\n",
    "\n",
    "Use the `ray.train.torch.prepare_model()` utility function to:\n",
    "\n",
    "- Automatically move your model to the correct device.\n",
    "- Wrap the model in pytorch's `DistributedDataParallel`.\n",
    "\n",
    "To learn more about the `prepare_model()` function, see the [API reference](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.prepare_model.html#ray-train-torch-prepare-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def load_model_ray_train() -> torch.nn.Module:\n",
    "    model = build_resnet18()\n",
    "    # Instead of model = model.to(\"cuda\")\n",
    "    model = ray.train.torch.prepare_model(model) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `ray.train.torch.prepare_data_loader()` utility function, to:\n",
    "\n",
    "- Automatically moves the batches to the right device.\n",
    "- Wrap the data loader with pytorch's `DistributedSampler`.\n",
    "\n",
    "To learn more about the `prepare_data_loader()` function, see the [API reference](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.prepare_data_loader.html#ray-train-torch-prepare-data-loader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_loader_ray_train(batch_size: int) -> DataLoader:\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    train_data = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    # Add DistributedSampler to the DataLoader\n",
    "    train_loader = ray.train.torch.prepare_data_loader(train_loader)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Note</b> that this step isnt necessary if you are integrating your Ray Train implementaiton with Ray Data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reporting checkpoints and metrics\n",
    "\n",
    "To monitor progress, we can continue to print/log metrics as before. This time we chose to only do so for the first worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics_ray_train(\n",
    "    loss: torch.Tensor, accuracy: torch.Tensor, epoch: int\n",
    ") -> None:\n",
    "    metrics = {\"loss\": loss.item(), \"accuracy\": accuracy.item(), \"epoch\": epoch}\n",
    "    if ray.train.get_context().get_world_rank() == 0:\n",
    "        print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will report intermediate metrics and checkpoints using the `ray.train.report` utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_and_metrics_ray_train(\n",
    "    model: torch.nn.Module, metrics: dict[str, float]\n",
    ") -> None:\n",
    "    with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "        torch.save(\n",
    "            model.module.state_dict(),  # note the .module to unwrap the DistributedDataParallel\n",
    "            os.path.join(temp_checkpoint_dir, \"model.pt\"),\n",
    "        )\n",
    "        ray.train.report(  # use ray.train.report to save the metrics and checkpoint\n",
    "            metrics,  # train.report will only save worker rank 0's metrics\n",
    "            checkpoint=ray.train.Checkpoint.from_directory(temp_checkpoint_dir),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the lifecycle of a checkpoint from being created using a local path to being uploaded to persistent storage.\n",
    "\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/checkpoint_lifecycle.png\" width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given it is the same model across all workers, we can instead only build the checkpoint on worker of rank 0. Note that we will still need to call `ray.train.report` on all workers to ensure that the training loop is synchronized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import ray\n",
    "\n",
    "def save_checkpoint_and_metrics_ray_train(model: torch.nn.Module, metrics: dict[str, float]):\n",
    "    with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "        checkpoint = None\n",
    "        # On the first worker\n",
    "        if ray.train.get_context().get_world_rank() == 0:\n",
    "            # Save PyTorch checkpoints locally\n",
    "            torch.save(model.module.state_dict(), os.path.join(temp_checkpoint_dir, \"model.pt\"))\n",
    "            # Convert to Ray Train checkpoint\n",
    "            checkpoint = ray.train.Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "        # Report checkpoint\n",
    "        ray.train.report(\n",
    "            metrics,\n",
    "            checkpoint=checkpoint,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an in-depth guide on saving checkpoints and metrics, see the [docs](https://docs.ray.io/en/latest/train/user-guides/checkpoints.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Launching the distributed training job\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-ai-libraries/diagrams/multi_gpu_pytorch_annotated_v5.png\" width=\"1000\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's proceed to launch the distributed training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure persistent storage\n",
    "Create a `RunConfig` object to specify the path where results (including checkpoints and artifacts) will be saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train import RunConfig\n",
    "\n",
    "storage_path = \"/mnt/cluster_storage/ray-summit-2024-training/\"\n",
    "run_config = RunConfig(storage_path=storage_path, name=\"distributed-mnist-resnet18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching a distributed training job with a `TorchTrainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 11:46:34,891\tINFO worker.py:1596 -- Connecting to existing Ray cluster at address: 10.0.25.5:6379...\n",
      "2024-11-22 11:46:34,898\tINFO worker.py:1772 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-wun39fg7yb3g9682a8fejskwz3.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "2024-11-22 11:46:35,055\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_c0d0f875c8f886002dd044911a6c5a1d734f1c8c.zip' (63.64MiB) to Ray cluster...\n",
      "2024-11-22 11:46:35,772\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_c0d0f875c8f886002dd044911a6c5a1d734f1c8c.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +1h34m20s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_ray_train,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    train_loop_config={\"num_epochs\": 2, \"global_batch_size\": 128},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `trainer.fit()` will start the run and block until it completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 11:49:35,784\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-11-22 11:49:35 (running for 00:00:00.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 2.0/2 GPUs (0.0/2.0 anyscale/accelerator_shape:1xT4, 0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/provider:aws, 0.0/2.0 anyscale/region:us-west-2)\n",
      "Result logdir: /tmp/ray/session_2024-11-22_06-00-05_069833_2422/artifacts/2024-11-22_11-49-35/distributed-mnist-resnet18/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-11-22 11:49:40 (running for 00:00:05.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 2.0/2 GPUs (0.0/2.0 anyscale/accelerator_shape:1xT4, 0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/provider:aws, 0.0/2.0 anyscale/region:us-west-2)\n",
      "Result logdir: /tmp/ray/session_2024-11-22_06-00-05_069833_2422/artifacts/2024-11-22_11-49-35/distributed-mnist-resnet18/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-11-22 11:49:45 (running for 00:00:10.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 2.0/2 GPUs (0.0/2.0 anyscale/region:us-west-2, 0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/provider:aws, 0.0/2.0 anyscale/accelerator_shape:1xT4)\n",
      "Result logdir: /tmp/ray/session_2024-11-22_06-00-05_069833_2422/artifacts/2024-11-22_11-49-35/distributed-mnist-resnet18/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-11-22 11:49:50 (running for 00:00:15.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 2.0/2 GPUs (0.0/2.0 anyscale/region:us-west-2, 0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/provider:aws, 0.0/2.0 anyscale/accelerator_shape:1xT4)\n",
      "Result logdir: /tmp/ray/session_2024-11-22_06-00-05_069833_2422/artifacts/2024-11-22_11-49-35/distributed-mnist-resnet18/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-11-22 11:49:55 (running for 00:00:20.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 2.0/2 GPUs (0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/provider:aws, 0.0/2.0 anyscale/accelerator_shape:1xT4, 0.0/2.0 anyscale/region:us-west-2)\n",
      "Result logdir: /tmp/ray/session_2024-11-22_06-00-05_069833_2422/artifacts/2024-11-22_11-49-35/distributed-mnist-resnet18/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-11-22 11:50:01 (running for 00:00:25.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 2.0/2 GPUs (0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/provider:aws, 0.0/2.0 anyscale/accelerator_shape:1xT4, 0.0/2.0 anyscale/region:us-west-2)\n",
      "Result logdir: /tmp/ray/session_2024-11-22_06-00-05_069833_2422/artifacts/2024-11-22_11-49-35/distributed-mnist-resnet18/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-11-22 11:50:06 (running for 00:00:30.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 2.0/2 GPUs (0.0/2.0 anyscale/accelerator_shape:1xT4, 0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/region:us-west-2, 0.0/2.0 anyscale/provider:aws)\n",
      "Result logdir: /tmp/ray/session_2024-11-22_06-00-05_069833_2422/artifacts/2024-11-22_11-49-35/distributed-mnist-resnet18/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-11-22 11:50:11 (running for 00:00:35.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 2.0/2 GPUs (0.0/2.0 anyscale/accelerator_shape:1xT4, 0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/region:us-west-2, 0.0/2.0 anyscale/provider:aws)\n",
      "Result logdir: /tmp/ray/session_2024-11-22_06-00-05_069833_2422/artifacts/2024-11-22_11-49-35/distributed-mnist-resnet18/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-11-22 11:50:16 (running for 00:00:40.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 2.0/2 GPUs (0.0/2.0 anyscale/accelerator_shape:1xT4, 0.0/2.0 anyscale/provider:aws, 0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/region:us-west-2)\n",
      "Result logdir: /tmp/ray/session_2024-11-22_06-00-05_069833_2422/artifacts/2024-11-22_11-49-35/distributed-mnist-resnet18/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-11-22 11:50:21 (running for 00:00:45.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 2.0/2 GPUs (0.0/2.0 anyscale/accelerator_shape:1xT4, 0.0/2.0 anyscale/provider:aws, 0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/region:us-west-2)\n",
      "Result logdir: /tmp/ray/session_2024-11-22_06-00-05_069833_2422/artifacts/2024-11-22_11-49-35/distributed-mnist-resnet18/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-11-22 11:50:26 (running for 00:00:50.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 2.0/2 GPUs (0.0/2.0 anyscale/region:us-west-2, 0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/provider:aws, 0.0/2.0 anyscale/accelerator_shape:1xT4)\n",
      "Result logdir: /tmp/ray/session_2024-11-22_06-00-05_069833_2422/artifacts/2024-11-22_11-49-35/distributed-mnist-resnet18/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m Failed to download (trying next):\n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m HTTP Error 403: Forbidden\n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9912422 [00:00<?, ?it/s]38)\u001b[0m \n",
      "  1%|          | 98304/9912422 [00:00<00:11, 875444.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m [rank1]:[W1122 11:49:45.059424410 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "100%|| 1648877/1648877 [00:00<00:00, 4945514.39it/s]\n",
      "100%|| 1648877/1648877 [00:00<00:00, 4100558.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m Moving model to device: cuda:0\n",
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m {'loss': 0.30887049436569214, 'accuracy': 0.7834368348121643, 'epoch': 0}\n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m Failed to download (trying next):\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m HTTP Error 403: Forbidden\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/ray-summit-2024-training/distributed-mnist-resnet18/TorchTrainer_d89d0_00000_0_2024-11-22_11-49-35/checkpoint_000000)\n",
      "100%|| 4542/4542 [00:00<00:00, 3756759.76it/s]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      " 38%|      | 622592/1648877 [00:00<00:00, 2175211.11it/s]\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=30603, ip=10.0.4.138)\u001b[0m {'loss': 0.06367093324661255, 'accuracy': 0.9425080418586731, 'epoch': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=129887)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/ray-summit-2024-training/distributed-mnist-resnet18/TorchTrainer_d89d0_00000_0_2024-11-22_11-49-35/checkpoint_000001)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 11:50:29,707\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/mnt/cluster_storage/ray-summit-2024-training/distributed-mnist-resnet18' in 0.0255s.\n",
      "2024-11-22 11:50:29,709\tINFO tune.py:1041 -- Total run time: 53.92 seconds (53.89 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-11-22 11:50:29 (running for 00:00:53.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 2.0/2 GPUs (0.0/2.0 anyscale/region:us-west-2, 0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/provider:aws, 0.0/2.0 anyscale/accelerator_shape:1xT4)\n",
      "Result logdir: /tmp/ray/session_2024-11-22_06-00-05_069833_2422/artifacts/2024-11-22_11-49-35/distributed-mnist-resnet18/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Accessing the training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training completes, a `Result` object is returned which contains information about the training run, including the metrics and checkpoints reported during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'loss': 0.06367093324661255, 'accuracy': 0.9425080418586731, 'epoch': 1},\n",
       "  path='/mnt/cluster_storage/ray-summit-2024-training/distributed-mnist-resnet18/TorchTrainer_d89d0_00000_0_2024-11-22_11-49-35',\n",
       "  filesystem='local',\n",
       "  checkpoint=Checkpoint(filesystem=local, path=/mnt/cluster_storage/ray-summit-2024-training/distributed-mnist-resnet18/TorchTrainer_d89d0_00000_0_2024-11-22_11-49-35/checkpoint_000001)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the metrics produced by the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>pid</th>\n",
       "      <th>hostname</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>config/train_loop_config/num_epochs</th>\n",
       "      <th>config/train_loop_config/global_batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.308870</td>\n",
       "      <td>0.783437</td>\n",
       "      <td>0</td>\n",
       "      <td>1732276209</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>d89d0_00000</td>\n",
       "      <td>2024-11-22_11-50-09</td>\n",
       "      <td>29.641551</td>\n",
       "      <td>29.641551</td>\n",
       "      <td>30551</td>\n",
       "      <td>ip-10-0-4-138</td>\n",
       "      <td>10.0.4.138</td>\n",
       "      <td>29.641551</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.942508</td>\n",
       "      <td>1</td>\n",
       "      <td>1732276227</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>d89d0_00000</td>\n",
       "      <td>2024-11-22_11-50-27</td>\n",
       "      <td>18.365191</td>\n",
       "      <td>48.006742</td>\n",
       "      <td>30551</td>\n",
       "      <td>ip-10-0-4-138</td>\n",
       "      <td>10.0.4.138</td>\n",
       "      <td>48.006742</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  epoch   timestamp checkpoint_dir_name  \\\n",
       "0  0.308870  0.783437      0  1732276209   checkpoint_000000   \n",
       "1  0.063671  0.942508      1  1732276227   checkpoint_000001   \n",
       "\n",
       "   should_checkpoint   done  training_iteration     trial_id  \\\n",
       "0               True  False                   1  d89d0_00000   \n",
       "1               True  False                   2  d89d0_00000   \n",
       "\n",
       "                  date  time_this_iter_s  time_total_s    pid       hostname  \\\n",
       "0  2024-11-22_11-50-09         29.641551     29.641551  30551  ip-10-0-4-138   \n",
       "1  2024-11-22_11-50-27         18.365191     48.006742  30551  ip-10-0-4-138   \n",
       "\n",
       "      node_ip  time_since_restore  iterations_since_restore  \\\n",
       "0  10.0.4.138           29.641551                         1   \n",
       "1  10.0.4.138           48.006742                         2   \n",
       "\n",
       "   config/train_loop_config/num_epochs  \\\n",
       "0                                    2   \n",
       "1                                    2   \n",
       "\n",
       "   config/train_loop_config/global_batch_size  \n",
       "0                                         128  \n",
       "1                                         128  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.metrics_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take the latest checkpoint and load it to inspect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = result.checkpoint\n",
    "with ckpt.as_directory() as ckpt_dir:\n",
    "    model_path = os.path.join(ckpt_dir, \"model.pt\")\n",
    "    loaded_model_ray_train = build_resnet18()\n",
    "    state_dict = torch.load(model_path, map_location=torch.device('cpu'), weights_only=True)\n",
    "    loaded_model_ray_train.load_state_dict(state_dict)\n",
    "    loaded_model_ray_train.eval()\n",
    "\n",
    "loaded_model_ray_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the training results, see this [docs](https://docs.ray.io/en/latest/train/user-guides/results.html) on inspecting the training results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then proceed to generate predictions using the loaded model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 10, figsize=(20, 2))\n",
    "\n",
    "for i in range(10):\n",
    "    axs[i].imshow(dataset.train_data[i], cmap=\"gray\")\n",
    "    axs[i].axis(\"off\")\n",
    "    with torch.no_grad():\n",
    "        normalized = Normalize((0.5,), (0.5,))(ToTensor()(dataset[i][0]))\n",
    "        prediction = loaded_model_ray_train(normalized.unsqueeze(0)).argmax()\n",
    "    axs[i].set_title(prediction.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Activity: Update the training loop to compute the area under the curve of ROC (AUROC)\n",
    "\n",
    "1. Update the training loop `train_loop_ray_train` to compute the AUROC metric.\n",
    "2. Update the `print_metrics_ray_train` function to include the AUROC metric.\n",
    "3. Save the AUROC metric in the `save_checkpoint_and_metrics_ray_train` function.\n",
    "\n",
    "Use the following code snippets to guide you:\n",
    "\n",
    "```python\n",
    "# Hint: Update the print function to include AUROC\n",
    "def print_metrics_ray_train(...):\n",
    "    ...\n",
    "\n",
    "def train_loop_ray_train(config):\n",
    "    # Hint: Update the training loop to compute AUROC\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_ray_train,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    train_loop_config={\"num_epochs\": 2, \"global_batch_size\": 128},\n",
    ")\n",
    "result = trainer.fit()\n",
    "result.metrics_dataframe\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary> Click here to see the solution </summary>\n",
    "\n",
    "```python\n",
    "def print_metrics_ray_train(loss, accuracy, auroc):\n",
    "    metrics = {\n",
    "        \"loss\": loss.item(),\n",
    "        \"accuracy\": accuracy.item(),\n",
    "        \"auroc\": auroc.item(),\n",
    "    }\n",
    "    if ray.train.get_context().get_world_rank() == 0:\n",
    "        print(\n",
    "            f\"Loss: {loss.item()}, Accuracy: {accuracy.item()}, AUROC: {auroc.item()}\"\n",
    "        )\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train_loop_ray_train(config):\n",
    "    loss_function = CrossEntropyLoss()\n",
    "    model = load_model_ray_train()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    global_batch_size = config[\"global_batch_size\"]\n",
    "    batch_size = global_batch_size // ray.train.get_context().get_world_size()\n",
    "    data_loader = build_data_loader_ray_train(batch_size=batch_size)\n",
    "\n",
    "    acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(model.device)\n",
    "    # Add AUROC metric\n",
    "    auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=10).to(model.device)\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        data_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            acc(outputs, labels)\n",
    "            auroc(outputs, labels)\n",
    "\n",
    "        metrics = print_metrics_ray_train(\n",
    "            loss, acc.compute(), auroc.compute()\n",
    "        )\n",
    "        save_checkpoint_and_metrics_ray_train(model, metrics)\n",
    "        acc.reset()\n",
    "        auroc.reset()\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_ray_train,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    train_loop_config={\"num_epochs\": 2, \"global_batch_size\": 128},\n",
    ")\n",
    "result = trainer.fit()\n",
    "print(result.metrics_dataframe)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ray Train in Production\n",
    "\n",
    "Here are some use-cases of using Ray Train in production:\n",
    "1. Canva uses Ray Train + Ray Data to cut down Stable Diffusion training costs by 3.7x. Read this [Anyscale blog post here](https://www.anyscale.com/blog/scalable-and-cost-efficient-stable-diffusion-pre-training-with-ray) and the [Canva  case study here](https://www.anyscale.com/resources/case-study/how-canva-built-a-modern-ai-platform-using-anyscale)\n",
    "2. Anyscale uses Ray Train + Deepspeed to finetune language models. Read more [here](https://github.com/ray-project/ray/tree/master/doc/source/templates/04_finetuning_llms_with_deepspeed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell for file cleanup \n",
    "!rm -rf /mnt/cluster_storage/single_gpu_mnist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orphan": true,
  "vscode": {
   "interpreter": {
    "hash": "a8c1140d108077f4faeb76b2438f85e4ed675f93d004359552883616a1acd54c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
