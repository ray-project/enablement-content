
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Introduction to Ray Data: Industry Landscape &#8212; Course Notebooks</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/custom_hide.css?v=af9667c8" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js?v=1ae7504c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'courses/foundations/Ray_Data/00_Landscape/04a_Intro_Ray_Data_Industry_Landscape';</script>
    <script src="../../../../_static/custom_toggle.js?v=1235ef5b"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Course Notebooks</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../index.html">
                    Ray Enablement Content
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Anyscale For Admins</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_01.html">Anyscale Administrator Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_02.html">1. What is an Anyscale Cloud?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_03.html">2. Cloud Deployment Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_04.html">3. A Demonstrative Example of Resource Creation with AWS EC2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_05.html">3.1 IAM Role Definition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_06.html">4. Register Anyscale Cloud to Your Cloud Provider</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_01.html">Deployment Options: Virtual Machines vs. Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_02.html">2. Virtual Machines (VM) vs. Kubernetes (K8s)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_03.html">3. (Optional) More Kubernetes Deployments Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_01.html">Introduction: Deploy Anyscale Ray on AWS EC2 Instances</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_02.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_03.html">2. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_04.html">3. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_05.html">4. Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_06.html">5. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_01.html">Introduction: Deploy Anyscale Ray on GCP Compute Engine Instances (GCE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_03.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_04.html">2. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_05.html">3. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_06.html">4. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_07.html">5. Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_01.html">Introduction: Deploy Anyscale Ray on A New AWS EKS Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_02.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_03.html">2. Install Kubernetes Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_04.html">3. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_05.html">4. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_06.html">5. Verify the Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_07.html">6. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_08.html">7. Clean up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_09.html">8. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_01.html">Introduction: Deploy Anyscale Ray on An Existing AWS EKS Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_03.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_04.html">2. Attach Required IAM Policies to Your existing EKS‚Äôs Node Role</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_05.html">3. Install Kubernetes Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_06.html">4. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_07.html">5. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_08.html">6. Verify the Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_09.html">7. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_10.html">8. Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_11.html">9. Clean up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_12.html">10. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_01.html">Introduction: Deploy Anyscale Ray on A New Google Kubernetes Engine (GKE) Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_03.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_04.html">2. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_05.html">3. Troubleshooting GPU Availability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_06.html">4. kubectl Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_07.html">5. Install NGINX Ingress Controller</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_08.html">6. (Optional) Upgrade Anyscale Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_09.html">7. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_10.html">8. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_11.html">8. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_12.html">9. Cleanup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Anyscale Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_01_anyscale_intro_workspace_01.html">101 ‚Äî Introduction to Anyscale Workspaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_02_anyscale_development_intro_01.html">101 ‚Äì Developing Application with Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_03_anyscale_compute_runtime_intro_01.html">101 ‚Äì Compute Configs and Execution Environments in Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_04_anyscale_storage_options_01.html">101 ‚Äì Storage Options in the Anyscale Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_05_anyscale_logging_metrics_01.html">101 ‚Äì Debug and Monitor Your Anyscale Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_06_anyscale_intro_jobs_01.html">101 ‚Äì Introduction to Anyscale Jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_07_anyscale_intro_services_01.html">101 ‚Äì  Introduction to Anyscale Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_08_anyscale_collaboration_01.html">101 ‚Äì Collaboration on Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_09_anyscale_org_setup_01.html">101 - Anyscale Organization and Cloud Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_09_anyscale_org_setup_02.html">üìå Overview of Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_09_anyscale_org_setup_03.html">üß† Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_anyscale_intro_jobs_01.html">Content Used</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_anyscale_intro_jobs_02.html">Part 1. Creating and Submitting your first job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_anyscale_intro_jobs_03.html">Part 2. Automation and Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_anyscale_intro_services_01.html">Sources</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../Anyscale_Getting_Started/output/101_anyscale_intro_services_02.html">Part 1: Starting your first Anyscale Service</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Llm Serving</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/00_intro_serve_llm/output/notebook_01.html">Introduction to Ray Serve LLM: Foundations of Large Language Model Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/00_intro_serve_llm/output/notebook_02.html">What is LLM Serving?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/00_intro_serve_llm/output/notebook_03.html">Key Concepts and Optimizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/00_intro_serve_llm/output/notebook_04.html">Challenges in LLM Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/00_intro_serve_llm/output/notebook_05.html">Ray Serve LLM + Anyscale Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/00_intro_serve_llm/output/notebook_06.html">Getting Started with Ray Serve LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/00_intro_serve_llm/output/notebook_07.html">Key Takeaways</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/01_deploy_medium_llm/output/notebook_01.html">Deploy a Medium-Sized LLM with Ray Serve LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/01_deploy_medium_llm/output/notebook_02.html">Overview: Why Medium-Sized Models?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/01_deploy_medium_llm/output/notebook_03.html">Setting up Ray Serve LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/01_deploy_medium_llm/output/notebook_04.html">Local Deployment &amp; Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/01_deploy_medium_llm/output/notebook_05.html">Deploying to Anyscale Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/01_deploy_medium_llm/output/notebook_06.html">Advanced Topics: Monitoring &amp; Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/01_deploy_medium_llm/output/notebook_07.html">Summary &amp; Outlook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/02_advanced_llm_features/output/notebook_01.html">Advanced LLM Features with Ray Serve LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/02_advanced_llm_features/output/notebook_02.html">Overview: Advanced Features Preview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/02_advanced_llm_features/output/notebook_03.html">Example: Deploying LoRA Adapters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/02_advanced_llm_features/output/notebook_04.html">Example: Getting Structured JSON Output</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/02_advanced_llm_features/output/notebook_05.html">Example: Setting up Tool Calling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/02_advanced_llm_features/output/notebook_06.html">How to Choose an LLM?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_Serving/02_advanced_llm_features/output/notebook_07.html">Conclusion: Next Steps</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Observability</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Observability/01_Intro_and_setup/output/01_general_intro_and_setup_01.html">Observability Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Observability/01_Intro_and_setup/output/01_general_intro_and_setup_02.html">Observability Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Observability/01_Intro_and_setup/output/01_general_intro_and_setup_03.html">Setting Up Local Ray Observability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_01.html">Ray and Anyscale Observability Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_02.html">Ray Observability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_03.html">Anyscale Observability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_04.html">Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_01.html">Ray and Anyscale Observability in Detail</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_02.html">Data Pipeline Observability (Ray Data)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_03.html">Web Application Observability (Ray Serve)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Ai Libs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_AI_Libs/00_Overview/output/01_Intro_Ray_AI_Libs_Overview_01.html">Introduction to the Ray AI Libraries: An example of using Ray data, Ray Train, Ray Tune, Ray Serve to implement a XGBoost regression model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_AI_Libs/00_Overview/output/01_Intro_Ray_AI_Libs_Overview_02.html">1. Overview of the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_AI_Libs/00_Overview/output/01_Intro_Ray_AI_Libs_Overview_03.html">2. Quick end-to-end example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_AI_Libs/00_intro/output/README_01.html">Introduction to Ray: Developer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Core</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_01.html">Introduction to Ray Core: Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_02.html">0. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_03.html">1. Creating Remote Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_04.html">2. Executing Remote Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_05.html">4. Putting It All Together</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_01.html">Introduction to Ray Core (Advancement): Object store, Tasks, Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_02.html">1. Object store</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_03.html">2. Chaining Tasks and Passing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_04.html">3. Task retries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_05.html">4. Task Runtime Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_06.html">5. Resource allocation and management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_07.html">6. Nested Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_08.html">7. Pattern: Pipeline data processing and waiting for results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_09.html">8. Ray Actors</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="output/04a_Intro_Ray_Data_Industry_Landscape_01.html">Introduction to Ray Data: Industry Landscape</a></li>

<li class="toctree-l1"><a class="reference internal" href="output/04a_Intro_Ray_Data_Industry_Landscape_02.html">The Compute Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_Intro_Ray_Data_Industry_Landscape_03.html">The Orchestration Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_Intro_Ray_Data_Industry_Landscape_04.html">Distributed Computing Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_Intro_Ray_Data_Industry_Landscape_05.html">Data Processing with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_Intro_Ray_Data_Industry_Landscape_06.html">Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_Structured/output/04b_Intro_Ray_Data_Structured_01.html">Introduction to Ray Data: Ray Data + Structured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_Structured/output/04b_Intro_Ray_Data_Structured_02.html">0. What is Ray Data?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_Structured/output/04b_Intro_Ray_Data_Structured_03.html">2. Loading Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_Structured/output/04b_Intro_Ray_Data_Structured_04.html">3. Transforming Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_Structured/output/04b_Intro_Ray_Data_Structured_05.html">4. Writing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_Structured/output/04b_Intro_Ray_Data_Structured_06.html">5. Data Operations: Shuffling, Grouping and Aggregation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_Structured/output/04b_Intro_Ray_Data_Structured_07.html">6. When to use Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_01.html">Intro to Ray Data:  Ray Data + Unstructured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_02.html">1. When to Consider Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_03.html">2. How to work with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_04.html">3. Loading data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_05.html">3. Lazy execution mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_06.html">4. Transforming data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_07.html">5. Stateful transformations with Ray Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_08.html">6. Materializing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_09.html">7. Data Operations: grouping, aggregation, and shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_10.html">8. Persisting data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_11.html">9. Ray Data in production</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Serve</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_01.html">Introduction to Ray Serve with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_02.html">1. When to Consider Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_03.html">2. Overview of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_04.html">3. Implement an image classification service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_05.html">4. Development workflow</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Train</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_01.html">üìö 01 ¬∑ Introduction to Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_02.html">01 ¬∑ Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_03.html">04 ¬∑ Define ResNet-18 Model for MNIST</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_04.html">05 ¬∑ Define the Ray Train Loop (DDP per-worker)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_05.html">06 ¬∑ Define <code class="docutils literal notranslate"><span class="pre">train_loop_config</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_06.html">07 ¬∑ Configure Scaling with <code class="docutils literal notranslate"><span class="pre">ScalingConfig</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_07.html">08 ¬∑ Wrap the Model with <code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_08.html">09 ¬∑ Build the DataLoader with <code class="docutils literal notranslate"><span class="pre">prepare_data_loader()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_09.html">10 ¬∑ Report Training Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_10.html">11 ¬∑ Save Checkpoints and Report Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_11.html">14 ¬∑ Create the <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_12.html">16 ¬∑ Inspect the Training Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_13.html">18 ¬∑ Load a Checkpoint for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_14.html">üîÑ 02 ¬∑ Integrating Ray Train with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_15.html">01 ¬∑ Define Training Loop with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_16.html">02 ¬∑ Build DataLoader from Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_17.html">03 ¬∑ Prepare Dataset for Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_18.html">05 ¬∑ Define Image Transformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_19.html">07 ¬∑ Configure <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_20.html">üõ°Ô∏è 03 ¬∑ Fault Tolerance in Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_21.html">01 ¬∑ Modify Training Loop to Enable Checkpoint Loading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_22.html">02 ¬∑ Save Full Checkpoint with Extra State</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_23.html">04 ¬∑ Launch Fault-Tolerant Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_24.html">05 ¬∑ Manual Restoration from Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_25.html">07 ¬∑ Clean Up Cluster Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Train/output/01_02_03_intro_to_ray_train_26.html">üéâ Wrapping Up &amp; Next Steps</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Tune</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_01.html">Introduction to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_02.html">1. Loading the data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_03.html">2. Starting out with vanilla PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_04.html">3. Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_05.html">4. Ray Tune in Production</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Pytorch Lightning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_01.html">Introduction to Ray Train: Ray Train + PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_02.html">1. When to use Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_03.html">2. Single GPU Training with PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_04.html">3. Distributed Training with Ray Train and PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_05.html">4. Ray Train in Production</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Data Batch Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Batch_Inference/00_workload/00_lesson/output/lesson_01.html">Batch Inference with Ray Data¬© 2025, Anyscale. All Rights Reservedüíª <strong>Launch Locally</strong>: You can run this notebook locally.üöÄ <strong>Launch on Cloud</strong>: Think about running this notebook on a Ray Cluster (Click here to easily start a Ray cluster on Anyscale)This example shows how to do batch inference with Ray Data.Batch inference with Ray Data enables you to efficiently generate predictions from machine learning models on large datasets by processing multiple data points at once. Instead of running inference on one row at a time, which can be slow and resource-inefficient, batch inference leverages vectorized computation and parallelism to maximize throughput. This is especially useful when working with modern deep learning models, which are optimized for batch processing on CPUs, GPUs, or Apple Silicon devices.The typical workflow begins by loading your dataset‚Äîsuch as a public dataset from Hugging Face‚Äîinto a Ray Dataset. Ray Data can automatically partition the data for parallel processing, or you can repartition it explicitly to control the number of data blocks. Once the data is loaded, you define a callable class (such as a text embedding model) that loads the machine learning model in its constructor and implements a <code class="docutils literal notranslate"><span class="pre">__call__</span></code> method to process each batch. Ray Data‚Äôs <code class="docutils literal notranslate"><span class="pre">map_batches</span></code> API is then used to apply this callable to each batch of data, with options to control concurrency and resource allocation (e.g., number of GPUs).This approach allows you to spin up multiple concurrent model instances, each processing different batches of data in parallel. The result is a significant speedup in inference time, especially for large datasets. After inference, you can materialize the results, inspect the output, and shut down the Ray cluster to free up resources. Batch inference with Ray Data is scalable, flexible, and integrates seamlessly with modern ML workflows, making it a powerful tool for production and research environments alike.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_01.html">Batch Inference with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_02.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_03.html">Load a dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_04.html">Batch Inference Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_05.html">Create a batch data and call the model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_06.html">Run inference on the entire dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Batch_Inference/00_workload/01_lesson/output/lesson_01.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Batch_Inference/00_workload/02_lesson/output/lesson_01.html">Load a datasetLoad a dataset from hugging face or local and convert into Ray Dataset. A Ray cluster automatically initialized on local or on Anyscale platform. You can also use <strong>ray.init()</strong> To explicitly create or connect to an existing Ray cluster.https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html#ray.init# load a Hugging Face datasethf_dataset = load_dataset(‚Äúcardiffnlp/tweet_eval‚Äù, ‚Äúsentiment‚Äù, split=‚Äùtrain‚Äù)# Convert the Hugging Face dataset to a Ray Datasetds = ray.data.from_huggingface(hf_dataset).repartition(2) # repartition to 2 blocks for parallel processing. Not necessary if already partitioned due to the size of the dataset.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Batch_Inference/00_workload/03_lesson/output/lesson_01.html">Batch Inference ClassMany machine learning models are optimized for processing a batch of inputs at once. When working with a large dataset, there could be many batches of data. Instead of loading machine learning models repeatedly to run each batch of data, you want to spin up a number of actor processes that are <strong>initialized once</strong> with your model <strong>and reused</strong> to process multiple batches. To implement this, you can use the <code class="docutils literal notranslate"><span class="pre">map_batches</span></code> API with a ‚ÄúCallable‚Äù class method that implements:- <code class="docutils literal notranslate"><span class="pre">__init__</span></code>: Initialize any expensive state.- <code class="docutils literal notranslate"><span class="pre">__call__</span></code>: Perform the stateful transformation.In this example, a lightweight sentence transformer model, <strong>all-MiniLM-L6-v2</strong> is used to generate embeddings of text data.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Batch_Inference/00_workload/04_lesson/output/lesson_01.html">Create a batch data and call the modelDefine a Ray Data map_batches function to embed text using the SentenceTransformer model. This function will be applied to each batch of data in the Ray Data dataset. It will take a batch of sentences, encode them into embeddings, and return the batch with the embeddings added.Showcasing two options of to do batch inference based on if the ray cluster has have GPU nodes or if it has just CPU nodes. The second option also works on a local ray cluster on an Apple Silicon Mac with MPS.# setting manually so that code works on ray clusters with both CPU or GPU workers, or on a local mac with MPSworker_device = ‚Äúcpu‚Äù # or ‚Äúcuda‚Äù if you have a nvidia gpu on worker nodes# batch_size should be set based on VRAM if worker_device == ‚Äúcuda‚Äù: # if you have a nvidia gpu on worker nodes    # adjust batch_size based on the VRAM available on the GPU    ds = ds.map_batches(TextEmbedder, num_gpus=1, concurrency=2, batch_size=64) # 2 nodes with 1 GPU eachelse:    ds = ds.map_batches(TextEmbedder, concurrency=2, batch_size=64) # either cpu or mps (on a mac)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Batch_Inference/00_workload/05_lesson/output/lesson_01.html">Run inference on the entire datasetExecute and materialize this dataset into object store memory. This operation will trigger execution of the lazy transformations performed on this dataset. The embedding model ‚ÄòTextEmbedder‚Äô in map_batches() is called on the entire dataset.# Run inference on the entire dataset# Note that this does not mutate the original Dataset.materialized_ds = ds.materialize()# metadata after inferenceprint(‚Äò** Original dataset:‚Äô, ds)print(‚Äò\n** Materialized dataset:‚Äô, materialized_ds)# Show a few rows of the materialized dataset with embeddingsmaterialized_ds.show(3)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Data Processing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_01.html">Data Processing with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_02.html">Library Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_03.html">Convert to Ray Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_04.html">Filter Ray Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_05.html">Join Two Ray Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_06.html">Preprocessing with a Tokenizer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Distributed Training</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_01.html">Distributed training with Ray Train, PyTorch and Hugging Face</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_02.html">1. Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_03.html">3. Metrics Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_04.html">4. Training function per worker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_05.html">5. Main Training Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_06.html">6. Start Training</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Serve Online Serving</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Serve_Online_Serving/00_workload/00_lesson/output/lesson_01.html">Online Model Serving with Ray Serve¬© 2025, Anyscale. All Rights Reservedüíª <strong>Launch Locally</strong>: You can run this notebook locally.üöÄ <strong>Launch on Cloud</strong>: Think about running this notebook on a Ray Cluster (Click here to easily start a Ray cluster on Anyscale)Model serving is the process of deploying machine learning models to production so that they can be accessed and used by applications or users. It involves creating an API or interface that allows users to send requests to the modeland receive predictions in response. There are several libraries and frameworks available for model serving, each with its own features and capabilities. In this notebook, we showcase Ray Serve and FastAPI to deploy a sentiment analysismachine learning (ML) model.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Serve_Online_Serving/00_workload/01_lesson/output/lesson_01.html">Architecture### Import librariesIn addition to ray and serve, we also import FastAPI to create webservice and Hugging Face transformers to download ML models.# Import ray serve and FastAPI librariesimport rayfrom ray import servefrom fastapi import FastAPI# library for pre-trained modelsfrom transformers import pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Serve_Online_Serving/00_workload/02_lesson/output/lesson_01.html">FastAPI webservice and deploy a modelFastAPI is used to create a webservice ‚Äòapp‚Äô to accept HTTP requests.MySentimentModel class loads the ML model and defines <em>predict</em> function for online inference. @serve.deployment decorator defines the Ray Serve deployment.<em>@app.get()</em> is used to create a GET ‚Äò/predict‚Äô route. Similarly, @app.post() can be used POST requests. See https://docs.ray.io/en/latest/serve/http-guide.html for more details.In this example, <em>application_logic()</em> function is used to define a sample transformation or business logic that can be applied before sending the input to the ML model for inference. See inline comments for further explanation.### Scaling deployment<em>num_replicas</em> parameter sets the number of instances of the deployment. FastAPI and RayServe automatically load balances to send requests to each instance. There are more options to set the <em>accelerator_type</em> to GPU and even use fractional GPUs. See configuration options here: https://docs.ray.io/en/latest/serve/configure-serve-deployment.html .</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_01.html">Online Model Serving with Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_02.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_03.html">FastAPI webservice and deploy a model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_04.html">Simulate Client: Send test requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Serve_Online_Serving/00_workload/03_lesson/output/lesson_01.html">Deploy the modelserve.run(MySentimentModel.bind()) # Bind the deployment to the Ray Serve runtimeDeploymentHandle(deployment=‚ÄôMySentimentModel‚Äô)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Serve_Online_Serving/00_workload/03_lesson/output/lesson_02.html">Simulate Client: Send test requestsWe use <em>requests</em> library to send HTTP requests to the deployed model.Note: if you encounter any errors with serve not able to start, most likely it is due to previous instance of serve not being shutdown properly. Restart the notebook or see towards the end of notebook to see how to gracefully shutdown ray serve and the ray cluster.import requests # used to send HTTP requests to the deployed model# Query the deployed modelresponse = requests.get(‚Äùhttp://localhost:8000/predict‚Äù, params={‚Äútext‚Äù: ‚ÄúI love Ray Serve!‚Äù})print(response.json())  # Should print the sentiment analysis result{‚Äòtext‚Äô: ‚Äòi love ray serve!‚Äô, ‚Äòsentiment‚Äô: [{‚Äòlabel‚Äô: ‚ÄòPOSITIVE‚Äô, ‚Äòscore‚Äô: 0.9998507499694824}]}</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Ray_Serve_Online_Serving/00_workload/04_lesson/output/lesson_01.html">Shutdown the Ray Serve instances and Ray Cluster# stop ray serveserve.shutdown()  # Shutdown Ray Serve when done, ray cluster will still be runningray.shutdown()  # Shutdown Ray cluster</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Generative Cv</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_01.html">04-d1 Generative computer-vision pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_02.html">1. Imports and setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_03.html">8. Pixel diffusion LightningModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_04.html">9. Ray Train <code class="docutils literal notranslate"><span class="pre">train_loop</span></code> (Lightning + Ray integration)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_05.html">12. Resume from latest checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_06.html">13. Reverse diffusion sampler</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Policy Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_01.html">04-d2 Diffusion-Policy Pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_02.html">1. Imports and setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_03.html">4. DiffusionPolicy LightningModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_04.html">5. Distributed Train loop with checkpointing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_05.html">8. Reverse diffusion helper</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Rec Sys</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_01.html">04e Recommendation system pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_02.html">1. Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_03.html">7. Define matrix factorization model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_04.html">8. Define Ray Train loop (with validation, checkpointing, and Ray-managed metrics)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_05.html">11. Resume training from checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_06.html">12. Inference: recommend top-N items for a user</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Tabular</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_01.html">04b Tabular workload pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_02.html">1. Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_03.html">8. Define the Ray Train worker loop (Arrow-based, memory-efficient)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_04.html">12. Confusion matrix visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_05.html">15. Continue training from the latest checkpoint</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Time Series</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_01.html">04c Time-Series workload pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_02.html">1. Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_03.html">9. PositionalEncoding and Transformer model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_04.html">10. Ray Train training loop (with teacher forcing)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_05.html">13. Resume training from checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_06.html">14. Inference helper ‚Äî Ray Data batch predictor on GPU</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Vision Pattern</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_01.html">04a Computer-vision pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_02.html">1. Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_03.html">6. Custom <code class="docutils literal notranslate"><span class="pre">Food101Dataset</span></code> for Parquet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_04.html">10. Helper: Ray-prepared DataLoaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_05.html">11. <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_06.html">12. Launch distributed training with <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_07.html">13. Plot training and validation loss curves</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_08.html">14. Demonstrate fault-tolerant resumption</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_09.html">15. Batch inference with Ray Data</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/courses/foundations/Ray_Data/00_Landscape/04a_Intro_Ray_Data_Industry_Landscape.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Introduction to Ray Data: Industry Landscape</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Introduction to Ray Data: Industry Landscape</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#the-data-layer">The data layer</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#databases">Databases</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-warehouses">Data warehouses</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-lakes">Data lakes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#structure-of-a-data-lake">Structure of a data lake</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lakehouses">Lakehouses</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#in-memory-data-formats">In-memory data formats</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-arrow">Apache Arrow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-compute-layer">The Compute Layer</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-by-function">Compute by Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-engineering-compute">Data Engineering Compute</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-and-ai-compute">Machine Learning and AI Compute</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-orchestration-layer">The Orchestration Layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distributed-computing-frameworks">Distributed Computing Frameworks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#streaming-applications">Streaming Applications</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-processing">Batch Processing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#general-purpose-distributed-computing">General-Purpose Distributed Computing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-with-jvm">Challenges with JVM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-processing-with-ray-data">Data Processing with Ray Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-ray-data">What is Ray Data ?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-ray-data">Why Ray Data ?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#when-to-use-ray-core-over-ray-data">When to use Ray Core over Ray Data ?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#on-ray-data-vs-spark">On Ray Data vs Spark</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ray-serve">Ray Serve</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-ray-serve">What is Ray Serve ?</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-flow">Data flow</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-ray-serve">Why Ray Serve ?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ray-serve-vs-ray-data">Ray Serve vs Ray Data</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="introduction-to-ray-data-industry-landscape">
<h1>Introduction to Ray Data: Industry Landscape<a class="headerlink" href="#introduction-to-ray-data-industry-landscape" title="Link to this heading">#</a></h1>
<p>¬© 2025, Anyscale. All Rights Reserved</p>
<p>This document is meant to provide a landscape of the industry.
<b> Here is the roadmap: </b></p>
<ul> 
    <li> The Data Layer </li>
    <li> The Compute Layer </li>
    <li> The Orchestration Layer </li>
    <li> Commercial Distributed Computing Platforms </li>
    <li> Distributed Computing execution models </li>
</ul></section>
<section class="tex2jax_ignore mathjax_ignore" id="the-data-layer">
<h1>The data layer<a class="headerlink" href="#the-data-layer" title="Link to this heading">#</a></h1>
<p>This document provides an overview of the data layer, including its components and commonly used tools. The evolution of data storage patterns reflects the changing needs of businesses and advancements in technology. Below is a breakdown of these patterns and their applications.</p>
<section id="databases">
<h2>Databases<a class="headerlink" href="#databases" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Purpose</strong>: Built for handling transactional data.</p></li>
<li><p><strong>Optimization</strong>: Designed for online transaction processing (OLTP).</p></li>
<li><p><strong>Key characteristics</strong>:</p>
<ul>
<li><p>Handles frequent, small-scale, atomic transactions.</p></li>
<li><p>Ensures data consistency and integrity using <strong>ACID properties</strong>: atomicity, consistency, isolation, and durability.</p></li>
</ul>
</li>
<li><p><strong>Examples</strong>: MySQL, PostgreSQL, MongoDB.</p></li>
<li><p><strong>Specialized Databases</strong>:</p>
<ul>
<li><p><strong>Vector Databases</strong>: Databases that are optimized for storing and querying vector data.</p>
<ul>
<li><p><strong>Examples</strong>: Pinecone, Zilliz, ChromaDB, Weaviate.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="data-warehouses">
<h2>Data warehouses<a class="headerlink" href="#data-warehouses" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Purpose</strong>: Designed for analyzing large datasets.</p></li>
<li><p><strong>Optimization</strong>: Suited for online analytical processing (OLAP).</p></li>
<li><p><strong>Key characteristics</strong>:</p>
<ul>
<li><p>Stores vast amounts of structured and historical data optimized for analytics.</p></li>
<li><p>Uses indexing and sorting to accelerate query performance.</p></li>
<li><p>Often employs proprietary storage formats (e.g., Snowflake‚Äôs columnar format) for efficiency.</p></li>
<li><p>Supports SQL-based querying and analytical functions for business intelligence.</p></li>
<li><p>Relies on ETL (extract, transform, load) or ELT (extract, load, transform) pipelines to preprocess and structure data.</p></li>
</ul>
</li>
<li><p><strong>Examples</strong>: Amazon Redshift, Google BigQuery, Snowflake.</p></li>
</ul>
</section>
<section id="data-lakes">
<h2>Data lakes<a class="headerlink" href="#data-lakes" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Purpose</strong>: Store large volumes of raw, semi-structured, or unstructured data.</p></li>
<li><p><strong>Key characteristics</strong>:</p>
<ul>
<li><p>Maintains raw data in its native format without requiring prior transformation.</p></li>
<li><p>Supports diverse data types (e.g., text, images, videos, logs).</p></li>
<li><p>Ideal for machine learning, big data analytics, and scenarios requiring data exploration.</p></li>
<li><p>Lacks built-in mechanisms for enforcing data quality, transactional consistency, or indexing.</p></li>
</ul>
</li>
</ul>
<section id="structure-of-a-data-lake">
<h3>Structure of a data lake<a class="headerlink" href="#structure-of-a-data-lake" title="Link to this heading">#</a></h3>
<p>Data lakes are organized into layers that enable efficient storage and processing:</p>
<img src="https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/storage-layer.png" width="500">
<ol class="arabic simple">
<li><p><strong>Storage layer</strong>: The foundation of the data lake, implemented using scalable systems like AWS S3, Cloudflare R2, or distributed file systems such as Ceph and Lustre.</p></li>
<li><p><strong>File formats</strong>: Stores data in multiple formats, including Parquet, CSV, JSON, JPEG, and Protocol Buffers, to support varied workloads.</p></li>
<li><p><strong>Table format layer</strong>: Adds features like schema management, ACID transactions, and indexing to provide database-like capabilities within the data lake. Examples of table formats include:</p>
<ul class="simple">
<li><p><strong>Apache Iceberg</strong>: Focuses on versioning, schema evolution, and large-scale analytics.</p></li>
<li><p><strong>Delta Lake</strong>: Built with ACID transactions and data quality controls for analytics and machine learning.</p></li>
<li><p><strong>Apache Hudi</strong>: Offers incremental processing capabilities and efficient updates for data lakes.</p></li>
</ul>
</li>
</ol>
</section>
<section id="lakehouses">
<h3>Lakehouses<a class="headerlink" href="#lakehouses" title="Link to this heading">#</a></h3>
<p>Lakehouses build on the foundation of data lakes, addressing their limitations while incorporating features of data warehouses.</p>
<ul class="simple">
<li><p><strong>Purpose</strong>: Provide a unified platform for both analytical and transactional workloads.</p></li>
<li><p><strong>Key characteristics</strong>:</p>
<ul>
<li><p>Combines the scalability and flexibility of data lakes with the structure and performance of data warehouses.</p></li>
<li><p>Implements ACID transactions, indexing, and schema enforcement directly on lake-stored data.</p></li>
<li><p>Built on open table formats (e.g., Apache Iceberg, Delta Lake, Apache Hudi) for robust querying and data management.</p></li>
<li><p>Bridges the gap between data engineering and machine learning workflows, enabling seamless data sharing.</p></li>
<li><p>Eliminates the need to move data between separate lake and warehouse systems, reducing complexity and cost.</p></li>
</ul>
</li>
<li><p><strong>Examples</strong>: Databricks Lakehouse Platform, Delta Lake, and other systems leveraging modern table formats.</p></li>
</ul>
</section>
</section>
<section id="in-memory-data-formats">
<h2>In-memory data formats<a class="headerlink" href="#in-memory-data-formats" title="Link to this heading">#</a></h2>
<section id="apache-arrow">
<h3>Apache Arrow<a class="headerlink" href="#apache-arrow" title="Link to this heading">#</a></h3>
<p>Apache Arrow is a high-performance in-memory data processing framework designed to enhance analytical workflows across languages and platforms.</p>
<ul class="simple">
<li><p><strong>Purpose</strong>: Provides a standard for in-memory data that minimizes serialization costs and maximizes interoperability.</p></li>
<li><p><strong>Language bindings</strong>:</p>
<ul>
<li><p>Examples: PyArrow for Python, Arrow-rs for Rust.</p></li>
</ul>
</li>
<li><p><strong>Key capabilities</strong>:</p>
<ul>
<li><p><strong>Zero-copy data sharing</strong>: Supports efficient shared memory access and RPC-based data transfers.</p></li>
<li><p><strong>File format support</strong>: Reads and writes formats like CSV, Apache ORC, and Apache Parquet.</p></li>
<li><p><strong>In-memory analytics</strong>: Facilitates high-speed operations using the Arrow Table abstraction for query processing and computation.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="the-compute-layer">
<h2>The Compute Layer<a class="headerlink" href="#the-compute-layer" title="Link to this heading">#</a></h2>
<p>Here is one way in which compute can be categorized:</p>
<img src="https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/compute-layer-overview.png" width="500">
<section id="compute-by-function">
<h3>Compute by Function<a class="headerlink" href="#compute-by-function" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Data Engineering</strong>: Transforming a dataset (X) into a new dataset (X‚Äô) through various operations.</p></li>
<li><p><strong>Analytics</strong>: Using datasets to create visualizations, dashboards, and reports.</p></li>
<li><p><strong>Machine Learning and AI</strong>: Training models using the data to produce predictive models.</p></li>
</ul>
</section>
<section id="data-engineering-compute">
<h3>Data Engineering Compute<a class="headerlink" href="#data-engineering-compute" title="Link to this heading">#</a></h3>
<p>If we want to drill deeper, here is how the data engineering compute space is categorized:</p>
<img src="https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/compute-layer-data-eng.png" width="500">
</section>
<section id="machine-learning-and-ai-compute">
<h3>Machine Learning and AI Compute<a class="headerlink" href="#machine-learning-and-ai-compute" title="Link to this heading">#</a></h3>
<p>Similarly, here is how the machine learning and AI compute space is categorized:</p>
<img src="https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/compute-layer-data-eng-v2.png" width="500">
</section>
</section>
<section id="the-orchestration-layer">
<h2>The Orchestration Layer<a class="headerlink" href="#the-orchestration-layer" title="Link to this heading">#</a></h2>
<p>To orchestrate between different stages of compute, we usually use a workflow engine or orchestration platform.</p>
<p>Here are some of the most popular ones:</p>
<img src="https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/orchestration-layer-v2.png" width="500">
<p>Orchestration platforms usually differ in the following ways:</p>
<ul class="simple">
<li><p><strong>Language</strong>: Some are natively written in Python, others are not.</p></li>
<li><p><strong>Ease of use</strong>: Some have a rigid DAG/DSL interface, others have a more flexible API-based interface to creating tasks.</p></li>
<li><p><strong>Tilt towards ML vs Data Engineering</strong>: Some are more focused on ML, some are more focused on Data Engineering.</p>
<ul>
<li><p>Some have native dataset concepts meant for data engineering whereas others have native workflow concepts meant for ML.</p></li>
</ul>
</li>
<li><p><strong>Cost</strong>: Some are cheaper than others depending on the commercial offering.</p></li>
</ul>
</section>
<section id="distributed-computing-frameworks">
<h2>Distributed Computing Frameworks<a class="headerlink" href="#distributed-computing-frameworks" title="Link to this heading">#</a></h2>
<p>Distributed computing frameworks enable scalable data processing and analysis by dividing workloads across multiple machines. These frameworks are often categorized based on their primary use case, such as stream processing, batch processing, or general-purpose computing.</p>
<section id="streaming-applications">
<h3>Streaming Applications<a class="headerlink" href="#streaming-applications" title="Link to this heading">#</a></h3>
<p>Streaming frameworks process data as it arrives in real-time or near-real-time. They are essential for applications requiring immediate insights, such as fraud detection, monitoring, and recommendation systems.</p>
<ul class="simple">
<li><p><strong>Apache Kafka</strong> (JVM-Based):</p>
<ul>
<li><p>Distributed event streaming platform.</p></li>
<li><p>Fault-tolerant and scalable messaging.</p></li>
<li><p>Widely used for real-time data pipelines and log aggregation.</p></li>
<li><p>Python integration relies on external libraries like <code class="docutils literal notranslate"><span class="pre">confluent-kafka</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Apache Flink</strong> (JVM-Based):</p>
<ul>
<li><p>Unified engine for stream and batch processing.</p></li>
<li><p>Features low-latency, event-time processing, and stateful computation.</p></li>
<li><p>Commonly used for real-time dashboards, fraud detection, and IoT analytics.</p></li>
<li><p>PyFlink API provides Python support but has fewer features compared to Java/Scala.</p></li>
</ul>
</li>
</ul>
</section>
<section id="batch-processing">
<h3>Batch Processing<a class="headerlink" href="#batch-processing" title="Link to this heading">#</a></h3>
<p>Batch processing frameworks handle large data volumes in discrete chunks, often for ETL workflows, batch inference and last-mile data processing.</p>
<ul class="simple">
<li><p><strong>Apache Hadoop</strong> (JVM-Based):</p>
<ul>
<li><p>Pioneer in distributed storage (HDFS) and batch processing (MapReduce).</p></li>
<li><p>Reliable for large-scale, fault-tolerant data processing.</p></li>
<li><p>Historically used for batch ETL and analytics.</p></li>
</ul>
</li>
<li><p><strong>Apache Spark</strong> (JVM-Based):</p>
<ul>
<li><p>Unified engine for batch and streaming workloads.</p></li>
<li><p>Features in-memory computation, scalable processing, and rich APIs.</p></li>
<li><p>Popular for data transformation, machine learning pipelines, and analytics.</p></li>
<li><p>Python integration via PySpark can introduce overhead due to JVM interaction.</p></li>
</ul>
</li>
</ul>
</section>
<section id="general-purpose-distributed-computing">
<h3>General-Purpose Distributed Computing<a class="headerlink" href="#general-purpose-distributed-computing" title="Link to this heading">#</a></h3>
<p>These frameworks are designed for diverse tasks, including machine learning, reinforcement learning, and data processing.</p>
<ul class="simple">
<li><p><strong>Dask</strong>:</p>
<ul>
<li><p>Python-native framework for parallel and distributed computing.</p></li>
<li><p>Frequently used in scientific computing and dataframe-based workflows.</p></li>
<li><p>Scales efficiently from single machines to distributed clusters.</p></li>
</ul>
</li>
<li><p><strong>Ray</strong>:</p>
<ul>
<li><p>Flexible platform for scalable distributed applications.</p></li>
<li><p>Rich in high-level libraries for:</p>
<ul>
<li><p>Reinforcement Learning (Ray RLlib)</p></li>
<li><p>Distributed Data processing (Ray Data)</p></li>
<li><p>Distributed Training (Ray Train)</p></li>
<li><p>Distributed Hyperparameter Tuning (Ray Tune)</p></li>
<li><p>Distributed Serving (Ray Serve)</p></li>
</ul>
</li>
<li><p>Seamless integration across the Ray ecosystem to build end-to-end data pipelines.</p></li>
<li><p>Ideal for Python-centric teams needing high-performance distributed computing.</p></li>
</ul>
</li>
</ul>
</section>
<section id="challenges-with-jvm">
<h3>Challenges with JVM<a class="headerlink" href="#challenges-with-jvm" title="Link to this heading">#</a></h3>
<p>JVM-based frameworks like Spark and Flink have historically dominated the distributed computing landscape. However, they present several challenges:</p>
<p>Here is a diagram of the data flow in Spark:</p>
<img src="https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/data-flow-jvm.png" width="500">
<p>Here are the issues highlighted in the diagram:</p>
<img src="https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/data-flow-jvm-issues.png" width="500">
<ol class="arabic simple">
<li><p><strong>Painful local development UX</strong>:<br />
Getting a local development environment setup is difficult given the complexity of the dependencies.</p></li>
<li><p><strong>Inscrutable error traces between Python and JVM</strong>:<br />
Some tracebacks are not helpful in debugging given failures can occur across the language boundary (e.g. socket errors, JVM crashes vs Python application crashes).</p></li>
<li><p><strong>Data/Memory Overhead</strong>:<br />
The onus is on the user to properly type and design their UDFs and to minimize the data/memory overhead in serializing and deserializing data between Python and JVM.</p></li>
</ol>
<p>By contrast, frameworks like Ray and Dask avoid the JVM overhead entirely, offering Python-native performance and better alignment with modern data science workflows.</p>
</section>
</section>
<section id="data-processing-with-ray-data">
<h2>Data Processing with Ray Data<a class="headerlink" href="#data-processing-with-ray-data" title="Link to this heading">#</a></h2>
<section id="what-is-ray-data">
<h3>What is Ray Data ?<a class="headerlink" href="#what-is-ray-data" title="Link to this heading">#</a></h3>
<p>Ray Data is a distributed data processing library designed for high-performance workloads.</p>
<ul class="simple">
<li><p>Initially developed as a last-mile data processing solution to seamlessly integrate with model training workflows.</p></li>
<li><p>Facilitates efficient execution of GPU-intensive batch inference tasks.</p></li>
<li><p>Currently being enhanced to support structured data processing, including advanced functionalities for operations such as joins and groupby.</p></li>
</ul>
</section>
<section id="why-ray-data">
<h3>Why Ray Data ?<a class="headerlink" href="#why-ray-data" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Ray Data is natively designed to support:</p>
<ul>
<li><p>Heterogeneous computational workloads</p></li>
<li><p>Pass data dependencies via a distributed in-memory object store</p></li>
</ul>
</li>
<li><p>Ray‚Äôs support for stateful computation through Actors is a core feature. In contrast:</p>
<ul>
<li><p>Spark lacks native support for stateful computations</p></li>
<li><p>Dask documents stateful capabilities, it does not guarantee execution.</p></li>
</ul>
</li>
<li><p>Ray Data‚Äôs seamless integration with the broader Ray ecosystem (including Train, Tune, Core, and Serve) offers significant advantages in integration engineering, which often incurs higher costs and performance impacts than application engineering.</p></li>
<li><p>Ray‚Äôs advanced resource tagging, accounting, and scalability capabilities are more sophisticated than those of other tools.</p></li>
</ul>
</section>
<section id="when-to-use-ray-core-over-ray-data">
<h3>When to use Ray Core over Ray Data ?<a class="headerlink" href="#when-to-use-ray-core-over-ray-data" title="Link to this heading">#</a></h3>
<p>If a user is:</p>
<ul class="simple">
<li><p>an expert in Ray Core</p></li>
<li><p>knows their data distribution very well</p></li>
<li><p>has very complex data processing logic</p></li>
</ul>
<p>Then perhaps trying out Ray Data won‚Äôt lead to a win, given they will be able to optimize their workflow while implementing complex logic to handle object store backpressure.</p>
</section>
<section id="on-ray-data-vs-spark">
<h3>On Ray Data vs Spark<a class="headerlink" href="#on-ray-data-vs-spark" title="Link to this heading">#</a></h3>
<p>On the positive side:</p>
<ul class="simple">
<li><p>It handles running on heterogeneous compute much nicer than Spark where GPU support has been patched in.</p></li>
<li><p>Its Python-native API and integration with the end-to-end Ray and ML ecosystem is a big win.</p></li>
</ul>
<p>On the negative side:</p>
<ul class="simple">
<li><p>Still immature to claim it can compete with Spark on SQL-like operations.</p></li>
<li><p>Spark is a much more mature product with a much larger community and ecosystem.</p></li>
</ul>
</section>
</section>
<section id="ray-serve">
<h2>Ray Serve<a class="headerlink" href="#ray-serve" title="Link to this heading">#</a></h2>
<section id="what-is-ray-serve">
<h3>What is Ray Serve ?<a class="headerlink" href="#what-is-ray-serve" title="Link to this heading">#</a></h3>
<p>Ray Serve is a framework for building distributed ML inference services.</p>
<section id="data-flow">
<h4>Data flow<a class="headerlink" href="#data-flow" title="Link to this heading">#</a></h4>
<p>Here is a diagram of the request lifecycle in Ray Serve:</p>
<img src="https://anyscale-materials.s3.us-west-2.amazonaws.com/geotab/request_lifecycle.jpg" width="800">
<p>When an HTTP or gRPC request is sent to the corresponding HTTP or gRPC proxy, the following happens:</p>
<ol class="arabic simple">
<li><p>The request is received and parsed.</p></li>
<li><p>Ray Serve looks up the correct deployment associated with the HTTP URL path or application name metadata. Serve places the request in a queue.</p></li>
<li><p>For each request in a deployment‚Äôs queue, an available replica is looked up and the request is sent to it.</p></li>
<li><p>If no replicas are available (that is, more than <code class="docutils literal notranslate"><span class="pre">max_ongoing_requests</span></code> requests are outstanding at each replica), the request is left in the queue until a replica becomes available.</p></li>
<li><p>Each replica maintains a queue of requests and executes requests one at a time, possibly using asyncio to process them concurrently.</p></li>
</ol>
</section>
</section>
<section id="why-ray-serve">
<h3>Why Ray Serve ?<a class="headerlink" href="#why-ray-serve" title="Link to this heading">#</a></h3>
<p>Ray Serve enables scaling services and is a good choice given it:</p>
<ul class="simple">
<li><p>allows for an intuitive approach to autoscaling based on request load.</p></li>
<li><p>has integrations with tools like FastAPI to make it easier to develop and document APIs.</p></li>
<li><p>allows for easy composition of a complex DAG of models and data processing steps.</p></li>
<li><p>provides support for both grpc and http protocols.</p></li>
</ul>
</section>
<section id="ray-serve-vs-ray-data">
<h3>Ray Serve vs Ray Data<a class="headerlink" href="#ray-serve-vs-ray-data" title="Link to this heading">#</a></h3>
<p>Rules of thumb:</p>
<ul class="simple">
<li><p>When dealing with continuous/streaming applications where low-latency is critical, Ray Serve is a good choice.</p></li>
<li><p>Otherwise, if data can be batched, processed at longer time intervals, Ray Data is a good choice to maximize throughput.</p></li>
</ul>
<p>In terms of implementation:</p>
<ul class="simple">
<li><p>Ray Data implements complex logic to handle object store backpressure and perform dynamic resource allocation</p></li>
<li><p>whereas Ray Serve relies on simple logic to batch and queue requests and statically allocates resources.</p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./courses/foundations/Ray_Data/00_Landscape"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Introduction to Ray Data: Industry Landscape</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#the-data-layer">The data layer</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#databases">Databases</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-warehouses">Data warehouses</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-lakes">Data lakes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#structure-of-a-data-lake">Structure of a data lake</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lakehouses">Lakehouses</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#in-memory-data-formats">In-memory data formats</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-arrow">Apache Arrow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-compute-layer">The Compute Layer</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-by-function">Compute by Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-engineering-compute">Data Engineering Compute</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-and-ai-compute">Machine Learning and AI Compute</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-orchestration-layer">The Orchestration Layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distributed-computing-frameworks">Distributed Computing Frameworks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#streaming-applications">Streaming Applications</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-processing">Batch Processing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#general-purpose-distributed-computing">General-Purpose Distributed Computing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-with-jvm">Challenges with JVM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-processing-with-ray-data">Data Processing with Ray Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-ray-data">What is Ray Data ?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-ray-data">Why Ray Data ?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#when-to-use-ray-core-over-ray-data">When to use Ray Core over Ray Data ?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#on-ray-data-vs-spark">On Ray Data vs Spark</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ray-serve">Ray Serve</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-ray-serve">What is Ray Serve ?</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-flow">Data flow</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-ray-serve">Why Ray Serve ?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ray-serve-vs-ray-data">Ray Serve vs Ray Data</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book community
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>