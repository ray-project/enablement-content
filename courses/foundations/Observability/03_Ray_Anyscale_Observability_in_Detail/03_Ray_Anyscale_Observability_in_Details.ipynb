{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray and Anyscale Observability in Detail\n",
    "\n",
    "Â© 2025, Anyscale. All Rights Reserved\n",
    "\n",
    "Ray and Anyscale provide a few different dashboards to support observability. This notebook presents examples that show when and how to use Ray and Anyscale observability dashboards for monitoring and debugging.\n",
    "\n",
    "### **Prerequisites**\n",
    "\n",
    "Before beginning this course, ensure you have:\n",
    "\n",
    "- **Basic Ray Data knowledge**: Familiarity with fundamental Ray Data and Ray Serve concepts and operations\n",
    "- **Basic data engineering knowledge**: Familiarity with data engineering pipelines and web application backend concepts\n",
    "- **Anyscale platform experience**: Previous experience using the Anyscale platform is recommended\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> Here is the roadmap for this notebook:</b>\n",
    "<ul>\n",
    "    <li><b>1. </b> Data Pipeline Observability (Ray Data)\n",
    "        <ul>\n",
    "            <li>Run a simple data pipeline</li>\n",
    "            <li>Ray Data Logs</li>\n",
    "            <li>Ray Data Metrics</li>\n",
    "            <li>Ray Workloads Data Dashboard</li>\n",
    "        </ul>\n",
    "    <li><b>2. </b> Web Application Observability (Ray Serve)\n",
    "        <ul>\n",
    "            <li>Ray Serve Metrics</li>\n",
    "            <li>Ray Serve Logs</li>\n",
    "            <li>Ray Serve Tracing</li>\n",
    "            <li>Ray Serve Alerts</li>\n",
    "            <li>Anyscale Ray Serve Observability</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "All examples are runnable on the Anyscale console, and some are also compatible with local Ray clusters (clearly labeled). This course demonstrates the examples using the Anyscale console.\n",
    "\n",
    "ðŸ’» **Local environment**: This notebook can be run locally. Steps to launch a local Ray cluster are in the [Setup Guide](../01_general_intro_and_setup.ipynb).\n",
    "\n",
    "ðŸš€ **Anyscale platform**: Consider running this notebook on a Ray cluster. Register to start a cluster via the Anyscale console: [Sign up](https://console.anyscale.com/register)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline Observability (Ray Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run a simple Data Pipeline\n",
    "\n",
    "ðŸ’» Local Environment. Please modify the value of **default_cluster_storage** to your local.\n",
    "\n",
    "Let's start with an example pipeline that we will use to demonstrate Ray Data's observability tools. Please modify **default_cluster_storage** to the path in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile simple_pipeline.py\n",
    "import ray\n",
    "import time\n",
    "import pyarrow.fs as fs\n",
    "\n",
    "default_cluster_storage = \"/mnt/cluster_storage/observed_data/\"\n",
    "\n",
    "\"\"\"\n",
    "s3://anyscale-public-materials/nyc-taxi-cab/yellow_tripdata_2011-05.parquet\n",
    "\"\"\"\n",
    "s3_fs = fs.S3FileSystem(anonymous=True)\n",
    "ds = ray.data.read_parquet(\n",
    "    \"s3://anyscale-public-materials/nyc-taxi-cab/yellow_tripdata_2011-05.parquet\",\n",
    "    filesystem=s3_fs\n",
    ")\n",
    "\n",
    "def slow_adjust_total_amount(batch):\n",
    "    time.sleep(10)\n",
    "    batch[\"adjusted_total_amount\"] = batch[\"total_amount\"] - batch[\"tip_amount\"]\n",
    "    return batch\n",
    "\n",
    "ds = ds.map_batches(slow_adjust_total_amount)\n",
    "ds.write_parquet(default_cluster_storage)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now execute the pipeline from the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy and run this inside a terminal\n",
    "# !python simple_pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view job running, navigate to the Ray Dashboard tab and click on the jobs tab to see the pipeline running.\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/experian/jobs_tab_v2.png\" width=\"800\">\n",
    "\n",
    "Let's click on the job to see its overview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the Job overview page, let's click on the **Ray Data Overview** section to see our dataset.\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/experian/data_overview_collapsed_v2.png\" width=\"800\">\n",
    "\n",
    "The dataset is currently named as \"dataset_{index}\" - the auto-generated name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's expand the dataset to see the operators/stages in the pipeline.\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/experian/data_overview_expanded_v2.png\" width=\"800\">\n",
    "\n",
    "\n",
    "For each operator, you can view:\n",
    "- the number of blocks outputted \n",
    "- the state\n",
    "\n",
    "these are the two key pieces of information that you can use to monitor your pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Data Logs\n",
    "\n",
    "Next let's look at the Ray Data logs that are generated in our terminal and stored on disk.\n",
    "\n",
    "The logs can help us find the operators that are backpressured - i.e. operators that can't add more tasks to process their inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an explanation of the Ray Data logs\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/experian/progress_bar_annotated.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Data Metrics\n",
    "\n",
    "<!-- Similar to overview + logs but timeseries along with more internal metrics. -->\n",
    "\n",
    "Now let's take a look at the Ray Data Dashboard.\n",
    "\n",
    "The Ray Data Dashboard provides a more detailed view of the pipeline, including a timeseries view of the dataset operators and metrics.\n",
    "\n",
    "To navigate to the Ray Data Dashboard, click on the \"Ray Dashboard > Metrics tab\" and then click on the \"Open in Grafana\" dropdown (select the Ray Data Dashboard).\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/experian/metrics-grafana-access.png\">\n",
    "\n",
    "You should see a dashboard similar to the one below:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/experian/data-dashboard-outlook.png\" width=\"800\">\n",
    "\n",
    "Here we can get throughput metrics for each operator in the pipeline (e.g. number of blocks/rows/bytes processed per second).\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/experian/data-dashboard-througput.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Workloads Data Dashboard\n",
    "\n",
    "ðŸš€ **Anyscale Platform**: This view only exists in Anyscale \n",
    "\n",
    "From the Ray Workloads Data dashboard, view detailed Ray Data pipeline execution status (Throughputs, Resources, etc):\n",
    "\n",
    "<div style=\"display: flex; gap: 20px; margin: 20px 0;\">\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/3-Ray-Data/ray_data_1.png\" width=\"80%\" loading=\"lazy\">\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; gap: 20px; margin: 20px 0;\">\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/3-Ray-Data/ray_data_2.png\" width=\"80%\" loading=\"lazy\">\n",
    "</div>\n",
    "\n",
    "Check the details of any operator in the pipeline by viewing:\n",
    "<div style=\"display: flex; gap: 20px; margin: 20px 0;\">\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/3-Ray-Data/ray_data_3.png\" width=\"80%\" loading=\"lazy\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Application Observability (Ray Serve)\n",
    "\n",
    "#### Launching a Web Application using Ray Serve\n",
    "\n",
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import requests\n",
    "from ray import serve\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’» Local Environment. Please modify the value of **local_path** to your local path.\n",
    "\n",
    "Deploy a web application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the app with default config\n",
    "!cd scipts/ && serve run main:mnist_app --non-blocking --name app1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now send http request by running following script. It generates traffic to the Ray Serve web application, allowing you to explore its observability features in the subsequent sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "while time.time() - start < 60:\n",
    "    images = np.random.rand(2, 1, 28, 28).tolist()\n",
    "    json_request = json.dumps({\"image\": images})\n",
    "    response = requests.post(\"http://localhost:8000/\", json=json_request)\n",
    "    response.json()[\"predicted_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Serve Metrics\n",
    "\n",
    "The following metrics are Ray Serve specific:\n",
    "\n",
    "- **Throughput metrics:**\n",
    "    - Queries per second (QPS)\n",
    "    - Error QPS\n",
    "    - Error by error code QPS\n",
    "\n",
    "Shown are the throughput metrics for above web application. Click \"Metrics\" -> \"VIEW IN GRAFANA\" -> \"Dashboards\" -> \"Serve Dashboard\"\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/throughput_per_application.png\" alt=\"Ray Serve Metrics\" width=\"800\">\n",
    "\n",
    "- **Latency metrics:**\n",
    "    - P50, P90, P99 latencies\n",
    "\n",
    "Shown are the latency metrics for the MNIST application.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/latency_per_application.png\" alt=\"Ray Serve Latency Metrics\" width=\"800\">\n",
    "\n",
    "- **Latency and throughput metrics are available at different levels of granularity:**\n",
    "    - Per-application metrics\n",
    "    - Per-deployment metrics\n",
    "    - Per-replica metrics\n",
    "\n",
    "Shown are the latency metrics on the deployment level.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/latency_per_deployment.png\" alt=\"Ray Serve Latency Metrics\" width=\"800\">\n",
    "\n",
    "- **Deployment-specific metrics:**\n",
    "    - Number of replicas\n",
    "    - Queue size (TODO - explain which queue)\n",
    "\n",
    "Shown are the number of replicas and queue size for the MNIST application.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/replicas_per_deployment.png\" alt=\"Ray Serve Deployment Metrics\" width=\"400\">\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/queue_size_per_deploymnet.png\" alt=\"Ray Serve Deployment Metrics\" width=\"400\">\n",
    "\n",
    "\n",
    "For Anyscale users, the following metrics are also available:\n",
    "- **Rollout-specific metrics:**\n",
    "    - QPS per version\n",
    "    - Error QPS per version\n",
    "    - P90 latency per version\n",
    "    - Number of replicas per version\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/rollouts_per_application.png\" alt=\"Ray Serve Rollout Metrics\" width=\"800\">\n",
    "\n",
    "For details on how to setup custom dashboards and alerts, refer to this [guide in the Anyscale docs](https://docs.anyscale.com/monitoring/custom-dashboards-and-alerting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Serve Logs\n",
    "\n",
    "ðŸ’» Local Environment\n",
    "\n",
    "To understand system-level behavior and to surface application-level details during runtime, you can leverage Ray logging.\n",
    "\n",
    "**Implementation:**\n",
    "- Uses Python's standard logging module\n",
    "- Logger name is \"ray.serve\"\n",
    "\n",
    "**Log Output Locations:**\n",
    "- Logs are sent to stderr\n",
    "- Logs are written to disk at `/tmp/ray/session_latest/logs/serve/`\n",
    "\n",
    "**Types of Logs Captured:**\n",
    "- System-level logs (from Serve controller and proxy)\n",
    "- Access logs\n",
    "- Custom user logs from deployment replicas\n",
    "\n",
    "**Development Environment Behavior:**\n",
    "- Logs are streamed to the driver Ray program\n",
    "- Driver program can be either:\n",
    "    - Python script calling serve.run()\n",
    "    - serve run CLI command\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:**\n",
    "Given Ray Serve uses Python's standard logging module, aggressive logging inside your application will incur a performance penalty. Use logging levels to control the verbosity of your logs and to avoid this penalty when running in production.\n",
    "\n",
    "</div>\n",
    "\n",
    "Here is how to use logging in a deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment()\n",
    "class SayHelloDefaultLogging:\n",
    "    async def __call__(self):\n",
    "        logger = logging.getLogger(\"ray.serve\")\n",
    "        logger.info(\"hello world\")\n",
    "\n",
    "\n",
    "serve.run(SayHelloDefaultLogging.bind())\n",
    "\n",
    "resp = requests.get(\"http://localhost:8000/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging Configuration\n",
    "\n",
    "ðŸ’» Local Environment\n",
    "\n",
    "Here are the common configurations for logging.\n",
    "\n",
    "- `enable_access_log`: Access logs are injected by default into Replica and Proxy logs. By default, it is `True`.\n",
    "- `log_level`: Set the log level. By default, it is `INFO`.\n",
    "- `encoding`: Set the encoding of the log file. By default, it is `JSON`.\n",
    "\n",
    "You can set the logging configuration:\n",
    "- At the deployment level\n",
    "- At the serve instance level\n",
    "\n",
    "Both programmatically or via a configuration file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(logging_config={\"log_level\": \"DEBUG\"})\n",
    "class SayHelloDebugLogging:\n",
    "    async def __call__(self):\n",
    "        logger = logging.getLogger(\"ray.serve\")\n",
    "        logger.debug(\"hello world\")\n",
    "\n",
    "\n",
    "serve.run(\n",
    "    SayHelloDebugLogging.bind(),\n",
    "    logging_config={\n",
    "        \"encoding\": \"JSON\",\n",
    "        \"log_level\": \"INFO\",\n",
    "        \"enable_access_log\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "resp = requests.get(\"http://localhost:8000/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Serve Tracing (Anyscale Only)\n",
    "\n",
    "To perform end-to-end tracing of requests, you can use the Anyscale Tracing integration.\n",
    "\n",
    "See the [tracing guide](https://docs.anyscale.com/monitoring/tracing/) for details.\n",
    "\n",
    "After following [README.md](tracing_example/README.md) to run the example, a single request's tracing logs display the following hierarchical structure:\n",
    "\n",
    "```\n",
    "1. proxy_http_request (Root) - Duration: 245ms\n",
    "   â””â”€â”€ 2. proxy_route_to_replica (APIGateway) - Duration: 240ms\n",
    "       â””â”€â”€ 3. replica_handle_request (APIGateway) - Duration: 235ms\n",
    "           â””â”€â”€ 4. proxy_route_to_replica (UserService) - Duration: 180ms\n",
    "               â””â”€â”€ 5. replica_handle_request (UserService) - Duration: 175ms\n",
    "                   â””â”€â”€ 6. proxy_route_to_replica (DatabaseService) - Duration: 110ms\n",
    "                       â””â”€â”€ 7. replica_handle_request (DatabaseService) - Duration: 105ms\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Serve Alerts\n",
    "\n",
    "**Alert Types:**\n",
    "Grafana [can alert](https://grafana.com/docs/grafana/v7.5/alerting/) based on:\n",
    "- Metric values\n",
    "- Rate of change\n",
    "- Metric absence\n",
    "\n",
    "**Notification Options:**\n",
    "- Supports multiple [notification channels](https://grafana.com/docs/grafana/v7.5/alerting/notifications/#add-a-notification-channel) (Slack, PagerDuty, etc.)\n",
    "- Email support planned for future\n",
    "- Configurable through notification channels\n",
    "\n",
    "**Documentation:** Full setup details available in Grafana's [official documentation](https://grafana.com/docs/grafana/v7.5/alerting/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anyscale Ray Serve Observability\n",
    "\n",
    "ðŸš€ **Anyscale Platform**: This view only exists in Anyscale \n",
    "\n",
    "When deploying a web application to Anyscale, utilize Anyscale's advanced observability features to debug and manage the service.\n",
    "\n",
    "The Logs view enables viewing and filtering logs:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/4-Ray-Serve/ray_serve_log_filter.png\" width=\"80%\" loading=\"lazy\">\n",
    "\n",
    "Since each deployment has a version ID, rolling back to an older version is easy through the **Versions** view. Zero-downtime rollouts can be performed with one click:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/4-Ray-Serve/ray_serve_versions.png\" width=\"80%\" loading=\"lazy\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xing-ray-jupyter-3.11",
   "language": "python",
   "name": "xing-ray-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
