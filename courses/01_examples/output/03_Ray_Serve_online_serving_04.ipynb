{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Client: Send test requests\n",
    "\n",
    "We use *requests* library to send HTTP requests to the deployed model.\n",
    "\n",
    "Note: if you encounter any errors with serve not able to start, most likely it is due to previous instance of serve not being shutdown properly. Restart the notebook or see towards the end of notebook to see how to gracefully shutdown ray serve and the ray cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # used to send HTTP requests to the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'i love ray serve!', 'sentiment': [{'label': 'POSITIVE', 'score': 0.9998507499694824}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Query the deployed model\n",
    "response = requests.get(\"http://localhost:8000/predict\", params={\"text\": \"I love Ray Serve!\"})\n",
    "print(response.json())  # Should print the sentiment analysis result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'mars landscape is a tough place to live, but it ha', 'sentiment': [{'label': 'NEGATIVE', 'score': 0.9590334296226501}]}\n"
     ]
    }
   ],
   "source": [
    "text = \"Mars landscape is a tough place to live, but it has its own beauty. Venus is even tougher, with its extreme heat and pressure. \"\n",
    "response = requests.get(\"http://localhost:8000/predict\", params={\"text\": text})\n",
    "print(response.json())  # prints result, note the text is truncated to 50 characters in the application logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'national parks are a great way to experience natur', 'sentiment': [{'label': 'POSITIVE', 'score': 0.9996353387832642}]}\n"
     ]
    }
   ],
   "source": [
    "text = \"National Parks are a great way to experience nature and wildlife.\"\n",
    "response = requests.get(\"http://localhost:8000/predict\", params={\"text\": text})\n",
    "print(response.json())  # # prints result, note the text is truncated to 50 characters in the application logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shutdown the Ray Serve instances and Ray Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop ray serve\n",
    "serve.shutdown()  # Shutdown Ray Serve when done, ray cluster will still be running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()  # Shutdown Ray cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this notebook, we deployed a sentiment analysis model from Hugging Face using Ray Serve and FastAPI. Using *num_replicas* we scaled the number of instances of the model. There are many more options to autoscale to increase the replicas when the traffic is high and downscale to zero when there is no traffic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}