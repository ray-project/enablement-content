{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Main Training Function\n",
    "The *train_bert* function sets up the distributed training environment using Ray and starts the training process. To enable training using GPU, we only need to make the following changes:\n",
    "\n",
    "* Require an GPU for each worker in ScalingConfig\n",
    "* Set backend to \u201cnccl\u201d in TorchConfig\n",
    "\n",
    "This function is designed to train a BERT model using Ray Train. It sets up the training configuration, scaling, and starts the Ray cluster. The function initializes the Ray Train environment, configures the trainer, and starts the training process.\n",
    "* It is intended to be run in a distributed setting with multiple workers, allowing for efficient training of large models on large datasets by leveraging Ray's distributed computing capabilities.\n",
    "* The function uses the Ray Train library to manage distributed training and the TorchTrainer for PyTorch models.\n",
    "* It supports both GPU and CPU training, making it flexible for different hardware configurations. \n",
    "* Additionally, it can be easily adapted for different models and datasets by changing the model and dataset loading parts. \n",
    "* This approach provides a scalable solution for training deep learning models in a distributed manner and can be used in various environments, including local machines and cloud platforms.\n",
    "* It is a powerful tool for researchers and developers working with large-scale machine learning tasks, enabling efficient training on large datasets and easy integration into existing machine learning workflows with minimal changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train BERT model using Ray Train\n",
    "# This function sets up the training configuration, scaling, and starts the Ray cluster.\n",
    "# It initializes the Ray Train environment, configures the trainer, and starts the training process.\n",
    "def train_bert(num_workers=2):\n",
    "    global_batch_size = 8 # This is the total batch size across all workers\n",
    "\n",
    "    # Define the training configuration\n",
    "    # This configuration includes the learning rate, number of epochs, and batch size per worker\n",
    "    train_config = {\n",
    "        \"lr\": 1e-3,  # Learning rate\n",
    "        \"epochs\": 2,  # Reduced for faster testing\n",
    "        \"batch_size_per_worker\": global_batch_size // num_workers,\n",
    "    }\n",
    "\n",
    "    # Configure computation resources\n",
    "    # if using CPUs or MPS\n",
    "    scaling_config = ScalingConfig(num_workers=num_workers, resources_per_worker={\"CPU\": 1,})\n",
    "    \n",
    "    # If using GPUs, you can specify resources_per_worker={\"CPU\": 1, \"GPU\": 1}\n",
    "    # scaling_config = ScalingConfig(num_workers=num_workers, resources_per_worker={\"CPU\": 1, \"GPU\": 1})\n",
    "    # Set backend to nccl in TorchConfig\n",
    "    # torch_config = TorchConfig(backend = \"nccl\")\n",
    "    \n",
    "    # start your ray cluster\n",
    "    ray.init() \n",
    "    \n",
    "    # Initialize a Ray TorchTrainer\n",
    "    trainer = TorchTrainer(\n",
    "        train_loop_per_worker=train_func_per_worker,\n",
    "        train_loop_config=train_config,\n",
    "        # torch_config=torch_config, # Uncomment if using nccl backend\n",
    "        scaling_config=scaling_config,\n",
    "    )\n",
    "\n",
    "    result = trainer.fit() # Start the training process\n",
    "    print(f\"Training result: {result}\") # This will print the training result, which includes metrics like loss and accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}