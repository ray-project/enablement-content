
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>04a Computer-vision pattern with Ray Train &#8212; Course Notebooks</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/custom_hide.css?v=af9667c8" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js?v=1ae7504c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'courses/workloads/Train_Vision_Pattern/00_workload/04a_vision_pattern';</script>
    <script src="../../../../_static/custom_toggle.js?v=1235ef5b"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Course Notebooks</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../index.html">
                    Ray Enablement Content
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Intro to Ray</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_01.html">Introduction to Ray Core: Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_02.html">0. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_03.html">1. Creating Remote Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_04.html">2. Executing Remote Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_05.html">4. Putting It All Together</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_01.html">Introduction to Ray Core (Advancement): Object store, Tasks, Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_02.html">1. Object store</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_03.html">2. Chaining Tasks and Passing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_04.html">3. Task retries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_05.html">4. Task Runtime Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_06.html">5. Resource allocation and management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_07.html">6. Nested Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_08.html">7. Pattern: Pipeline data processing and waiting for results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_09.html">8. Ray Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_01.html">Introduction to the Ray AI Libraries: An example of using Ray data, Ray Train, Ray Tune, Ray Serve to implement a XGBoost regression model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_02.html">1. Overview of the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_03.html">2. Quick end-to-end example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_01.html">Introduction to Ray Train + PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_02.html">1. When to use Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_03.html">2. Single GPU Training with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_04.html">3. Distributed Data Parallel Training with Ray Train and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_01.html">Introduction to Ray Train: Ray Train + PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_02.html">1. When to use Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_03.html">2. Single GPU Training with PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_04.html">3. Distributed Training with Ray Train and PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_05.html">4. Ray Train in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_01.html">Introduction to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_02.html">1. Loading the data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_03.html">2. Starting out with vanilla PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_04.html">3. Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_05.html">4. Ray Tune in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_01.html">Introduction to Ray Data: Industry Landscape</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_02.html">The Compute Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_03.html">The Orchestration Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_04.html">Distributed Computing Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_05.html">Data Processing with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_06.html">Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_01.html">Introduction to Ray Data: Ray Data + Structured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_02.html">0. What is Ray Data?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_03.html">2. Loading Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_04.html">3. Transforming Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_05.html">4. Writing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_06.html">5. Data Operations: Shuffling, Grouping and Aggregation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_07.html">6. When to use Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_01.html">Intro to Ray Data:  Ray Data + Unstructured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_02.html">1. When to Consider Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_03.html">2. How to work with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_04.html">3. Loading data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_05.html">3. Lazy execution mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_06.html">4. Transforming data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_07.html">5. Stateful transformations with Ray Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_08.html">6. Materializing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_09.html">7. Data Operations: grouping, aggregation, and shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_10.html">8. Persisting data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_11.html">9. Ray Data in production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_01.html">Introduction to Ray Serve with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_02.html">1. When to Consider Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_03.html">2. Overview of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_04.html">3. Implement an image classification service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_05.html">4. Development workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/README_01.html">Introduction to Ray: Developer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Gettingstarted</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_01_anyscale_intro_workspace_01.html">101 ‚Äî Introduction to Anyscale Workspaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_02_anyscale_development_intro_01.html">101 ‚Äì Developing Application with Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_03_anyscale_compute_runtime_intro_01.html">101 ‚Äì Compute Configs and Execution Environments in Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_04_anyscale_storage_options_01.html">101 ‚Äì Storage Options in the Anyscale Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_05_anyscale_logging_metrics_01.html">101 ‚Äì Debug and Monitor Your Anyscale Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_06_anyscale_intro_jobs_01.html">101 ‚Äì Introduction to Anyscale Jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_07_anyscale_intro_services_01.html">101 ‚Äì  Introduction to Anyscale Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_08_anyscale_collaboration_01.html">101 ‚Äì Collaboration on Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_09_anyscale_org_setup_01.html">101 - Anyscale Organization and Cloud Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_09_anyscale_org_setup_02.html">üìå Overview of Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_09_anyscale_org_setup_03.html">üß† Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_anyscale_intro_jobs_01.html">Content Used</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_anyscale_intro_jobs_02.html">Part 1. Creating and Submitting your first job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_anyscale_intro_jobs_03.html">Part 2. Automation and Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_anyscale_intro_services_01.html">Sources</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_anyscale_intro_services_02.html">Part 1: Starting your first Anyscale Service</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray 101</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/1_AI_Libs_Intro_01.html">Introduction to the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/1_AI_Libs_Intro_02.html">1. Overview of the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/1_AI_Libs_Intro_03.html">2. End-to-end example: predicting taxi tips in New York</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_01.html">Introduction to Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_02.html">1. PyTorch introductory example (single GPU)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_03.html">2. Distributed Data Parallel Training with Ray Train and PyTorch (multiple GPUs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_04.html">3. Overview of the training loop in Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_05.html">4. Migrating the model and dataset to Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_06.html">5. Reporting checkpoints and metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_07.html">6. Launching the distributed training job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_08.html">7. Accessing the training results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_09.html">8. Ray Train in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/3_Intro_Tune_01.html">Intro to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/3_Intro_Tune_02.html">1. Loading and visualizing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/3_Intro_Tune_03.html">2. Setting up a PyTorch model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/3_Intro_Tune_04.html">3. Introduction to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/3_Intro_Tune_05.html">4. Diving deeper into Ray Tune concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/3_Intro_Tune_06.html">5. Hyperparameter tuning the PyTorch model using Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/4_Intro_Data_01.html">Intro to Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/4_Intro_Data_02.html">1. When to use Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/4_Intro_Data_03.html">2. Loading Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/4_Intro_Data_04.html">3. Transforming Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/4_Intro_Data_05.html">4. Data Operations: Grouping, Aggregation, and Shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/4_Intro_Data_06.html">5. Persisting Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/5_Intro_Serve_01.html">Intro to Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/5_Intro_Serve_02.html">1. Overview of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/5_Intro_Serve_03.html">2. Implement an Classifier service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/5_Intro_Serve_04.html">3. Advanced features of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/5_Intro_Serve_05.html">4. Ray Serve in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/5_Intro_Serve_06.html">Clean up</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Anyscale For Admins</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_01.html">Anyscale Administrator Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_02.html">1. What is an Anyscale Cloud?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_03.html">2. Cloud Deployment Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_04.html">3. A Demonstrative Example of Resource Creation with AWS EC2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_05.html">3.1 IAM Role Definition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_06.html">4. Register Anyscale Cloud to Your Cloud Provider</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_01.html">Deployment Options: Virtual Machines vs. Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_02.html">2. Virtual Machines (VM) vs. Kubernetes (K8s)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_03.html">3. (Optional) More Kubernetes Deployments Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_01.html">Introduction: Deploy Anyscale Ray on AWS EC2 Instances</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_02.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_03.html">2. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_04.html">3. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_05.html">4. Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_06.html">5. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_01.html">Introduction: Deploy Anyscale Ray on GCP Compute Engine Instances (GCE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_03.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_04.html">2. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_05.html">3. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_06.html">4. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_07.html">5. Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_01.html">Introduction: Deploy Anyscale Ray on A New AWS EKS Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_02.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_03.html">2. Install Kubernetes Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_04.html">3. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_05.html">4. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_06.html">5. Verify the Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_07.html">6. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_08.html">7. Clean up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_09.html">8. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_01.html">Introduction: Deploy Anyscale Ray on An Existing AWS EKS Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_03.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_04.html">2. Attach Required IAM Policies to Your existing EKS‚Äôs Node Role</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_05.html">3. Install Kubernetes Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_06.html">4. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_07.html">5. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_08.html">6. Verify the Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_09.html">7. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_10.html">8. Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_11.html">9. Clean up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_12.html">10. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_01.html">Introduction: Deploy Anyscale Ray on A New Google Kubernetes Engine (GKE) Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_03.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_04.html">2. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_05.html">3. Troubleshooting GPU Availability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_06.html">4. kubectl Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_07.html">5. Install NGINX Ingress Controller</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_08.html">6. (Optional) Upgrade Anyscale Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_09.html">7. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_10.html">8. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_11.html">8. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_12.html">9. Cleanup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Llm Serving</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_01.html">Introduction to Ray Serve LLM: Foundations of Large Language Model Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_02.html">What is LLM Serving?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_03.html">Key Concepts and Optimizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_04.html">Challenges in LLM Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_05.html">Ray Serve LLM + Anyscale Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_06.html">Getting Started with Ray Serve LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_07.html">Key Takeaways</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_01.html">Deploy a Medium-Sized LLM with Ray Serve LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_02.html">Overview: Why Medium-Sized Models?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_03.html">Setting up Ray Serve LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_04.html">Local Deployment &amp; Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_05.html">Deploying to Anyscale Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_06.html">Advanced Topics: Monitoring &amp; Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_07.html">Summary &amp; Outlook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_01.html">Advanced LLM Features with Ray Serve LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_02.html">Overview: Advanced Features Preview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_03.html">Example: Deploying LoRA Adapters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_04.html">Example: Getting Structured JSON Output</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_05.html">Example: Setting up Tool Calling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_06.html">How to Choose an LLM?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_07.html">Conclusion: Next Steps</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Observability</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/01_Intro_and_setup/output/01_general_intro_and_setup_01.html">Observability Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/01_Intro_and_setup/output/01_general_intro_and_setup_02.html">Observability Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/01_Intro_and_setup/output/01_general_intro_and_setup_03.html">Setting Up Local Ray Observability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_01.html">Ray and Anyscale Observability Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_02.html">Ray Observability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_03.html">Anyscale Observability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_04.html">Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_01.html">Ray and Anyscale Observability in Detail</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_02.html">Data Pipeline Observability (Ray Data)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_03.html">Web Application Observability (Ray Serve)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Train Foundation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_01.html">üìö 01 ¬∑ Introduction to Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_02.html">01 ¬∑ Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_03.html">04 ¬∑ Define ResNet-18 Model for MNIST</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_04.html">05 ¬∑ Define the Ray Train Loop (DDP per-worker)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_05.html">06 ¬∑ Define <code class="docutils literal notranslate"><span class="pre">train_loop_config</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_06.html">07 ¬∑ Configure Scaling with <code class="docutils literal notranslate"><span class="pre">ScalingConfig</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_07.html">08 ¬∑ Wrap the Model with <code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_08.html">09 ¬∑ Build the DataLoader with <code class="docutils literal notranslate"><span class="pre">prepare_data_loader()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_09.html">10 ¬∑ Report Training Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_10.html">11 ¬∑ Save Checkpoints and Report Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_11.html">14 ¬∑ Create the <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_12.html">16 ¬∑ Inspect the Training Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_13.html">18 ¬∑ Load a Checkpoint for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_14.html">üîÑ 02 ¬∑ Integrating Ray Train with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_15.html">01 ¬∑ Define Training Loop with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_16.html">02 ¬∑ Build DataLoader from Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_17.html">03 ¬∑ Prepare Dataset for Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_18.html">05 ¬∑ Define Image Transformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_19.html">07 ¬∑ Configure <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_20.html">üõ°Ô∏è 03 ¬∑ Fault Tolerance in Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_21.html">01 ¬∑ Modify Training Loop to Enable Checkpoint Loading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_22.html">02 ¬∑ Save Full Checkpoint with Extra State</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_23.html">04 ¬∑ Launch Fault-Tolerant Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_24.html">05 ¬∑ Manual Restoration from Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_25.html">07 ¬∑ Clean Up Cluster Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train_Foundation/output/01_02_03_intro_to_ray_train_26.html">üéâ Wrapping Up &amp; Next Steps</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Data Batch Inference/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_01.html">Batch Inference with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_02.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_03.html">Load a dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_04.html">Batch Inference Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_05.html">Create a batch data and call the model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_06.html">Run inference on the entire dataset</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Data Processing/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_01.html">Data Processing with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_02.html">Library Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_03.html">Convert to Ray Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_04.html">Filter Ray Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_05.html">Join Two Ray Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_06.html">Preprocessing with a Tokenizer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Distributed Training/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_01.html">Distributed training with Ray Train, PyTorch and Hugging Face</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_02.html">1. Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_03.html">3. Metrics Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_04.html">4. Training function per worker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_05.html">5. Main Training Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_06.html">6. Start Training</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Serve Online Serving/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_01.html">Online Model Serving with Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_02.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_03.html">FastAPI webservice and deploy a model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_04.html">Simulate Client: Send test requests</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Generative Cv/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_01.html">04-d1 Generative computer-vision pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_02.html">1. Imports and setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_03.html">8. Pixel diffusion LightningModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_04.html">9. Ray Train <code class="docutils literal notranslate"><span class="pre">train_loop</span></code> (Lightning + Ray integration)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_05.html">12. Resume from latest checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_06.html">13. Reverse diffusion sampler</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Policy Learning/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_01.html">04-d2 Diffusion-Policy Pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_02.html">1. Imports and setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_03.html">4. DiffusionPolicy LightningModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_04.html">5. Distributed Train loop with checkpointing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_05.html">8. Reverse diffusion helper</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Rec Sys/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_01.html">04e Recommendation system pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_02.html">1. Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_03.html">7. Define matrix factorization model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_04.html">8. Define Ray Train loop (with validation, checkpointing, and Ray-managed metrics)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_05.html">11. Resume training from checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_06.html">12. Inference: recommend top-N items for a user</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Tabular/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Train_Tabular/00_workload/output/04b_tabular_workload_pattern_01.html">04b Tabular workload pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Tabular/00_workload/output/04b_tabular_workload_pattern_02.html">1. Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Tabular/00_workload/output/04b_tabular_workload_pattern_03.html">8. Define the Ray Train worker loop (Arrow-based, memory-efficient)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Tabular/00_workload/output/04b_tabular_workload_pattern_04.html">12. Confusion matrix visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Tabular/00_workload/output/04b_tabular_workload_pattern_05.html">15. Continue training from the latest checkpoint</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Time Series/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_01.html">04c Time-Series workload pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_02.html">1. Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_03.html">9. PositionalEncoding and Transformer model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_04.html">10. Ray Train training loop (with teacher forcing)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_05.html">13. Resume training from checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_06.html">14. Inference helper ‚Äî Ray Data batch predictor on GPU</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Vision Pattern/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_01.html">04a Computer-vision pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_02.html">1. Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_03.html">6. Custom <code class="docutils literal notranslate"><span class="pre">Food101Dataset</span></code> for Parquet</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_04.html">10. Helper: Ray-prepared DataLoaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_05.html">11. <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_06.html">12. Launch distributed training with <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_07.html">13. Plot training and validation loss curves</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_08.html">14. Demonstrate fault-tolerant resumption</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04a_vision_pattern_09.html">15. Batch inference with Ray Data</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/courses/workloads/Train_Vision_Pattern/00_workload/04a_vision_pattern.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>04a Computer-vision pattern with Ray Train</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-you-learn-and-take-away">What you learn and take away</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-problem-are-you-solving-image-classification-with-food-101-lite">What problem are you solving? (image classification with Food-101-Lite)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inputs">Inputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#labels">Labels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-does-the-model-learn">What does the model learn?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-migrate-this-computer-vision-workload-to-a-distributed-setup-using-ray-on-anyscale">How to migrate this computer vision workload to a distributed setup using Ray on Anyscale</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">1. Imports</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-10-of-food-101">2. Load 10 % of Food-101</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resize-and-encode-images">3. Resize and encode images</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visual-sanity-check">4. Visual sanity check</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#persist-to-parquet">5. Persist to Parquet</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-food101dataset-for-parquet">6. Custom <code class="docutils literal notranslate"><span class="pre">Food101Dataset</span></code> for Parquet</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-transform">7. Image transform</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-validation-split">8. Train/validation split</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inspect-a-dataloader-batch">9. Inspect a DataLoader batch</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-ray-prepared-dataloaders">10. Helper: Ray-prepared DataLoaders</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-loop-per-worker">11. <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-distributed-training-with-torchtrainer">12. Launch distributed training with <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-training-and-validation-loss-curves">13. Plot training and validation loss curves</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstrate-fault-tolerant-resumption">14. Demonstrate fault-tolerant resumption</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-inference-with-ray-data">15. Batch inference with Ray Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-and-visualize-ray-data-inference">16. Run and visualize Ray Data inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clean-up">17. Clean up</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#wrap-up-and-next-steps">Wrap up and next steps</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#where-can-you-take-this-next">Where can you take this next?</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="a-computer-vision-pattern-with-ray-train">
<h1>04a Computer-vision pattern with Ray Train<a class="headerlink" href="#a-computer-vision-pattern-with-ray-train" title="Link to this heading">#</a></h1>
<p>This notebook is an end-to-end, <strong>real-world computer-vision workflow</strong> that runs seamlessly on an Anyscale cluster using <strong>Ray Train</strong>. You start by pulling a slice of the Food-101 dataset, push it through a lightweight preprocessing pipeline, store it efficiently in Parquet, and then fine-tune a ResNet-18 model in a fault-tolerant, distributed manner. Along the way, you lean on Ray‚Äôs helpers to prepare data loaders, coordinate workers, checkpoint automatically, and resume after failure. Afterwards, you perform inference with Ray Data, all without writing a single line of low-level distributed code.</p>
<section id="what-you-learn-and-take-away">
<h2>What you learn and take away<a class="headerlink" href="#what-you-learn-and-take-away" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Launch distributed training with <strong>Ray Train‚Äôs <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></strong> and configure it for multi-GPU, multi-node execution.</p></li>
<li><p>Use <strong>Ray Train‚Äôs built-in utilities</strong> (<code class="docutils literal notranslate"><span class="pre">prepare_model</span></code>, <code class="docutils literal notranslate"><span class="pre">prepare_data_loader</span></code>, <code class="docutils literal notranslate"><span class="pre">get_checkpoint</span></code>, <code class="docutils literal notranslate"><span class="pre">train.report</span></code>) to wrap your existing PyTorch code without modifying your modeling logic.</p></li>
<li><p>Save and resume from <strong>automatic, fault-tolerant checkpoints</strong> across epochs.</p></li>
<li><p>Offload batch <strong>inference using Ray Data</strong>. This allows you to treat inference as a scalable workload.</p></li>
<li><p>Run end-to-end training and evaluation without needing to understand the low-level mechanics of distributed systems.</p></li>
</ul>
<p>By the end of the tutorial you have a working model, clear loss curves, and a hands-on experience of how Ray Train simplifies distributed computer-vision workloads.</p>
</section>
<section id="what-problem-are-you-solving-image-classification-with-food-101-lite">
<h2>What problem are you solving? (image classification with Food-101-Lite)<a class="headerlink" href="#what-problem-are-you-solving-image-classification-with-food-101-lite" title="Link to this heading">#</a></h2>
<p>This notebook trains a neural network to <strong>classify food photos</strong> into one of <strong>10 categories</strong><br />
using the <strong>Food-101-Lite</strong> dataset‚Äîa compact, 10-class subset of the original Food-101 benchmark.</p>
<hr class="docutils" />
</section>
<section id="inputs">
<h2>Inputs<a class="headerlink" href="#inputs" title="Link to this heading">#</a></h2>
<p>Every sample is a 3-channel Red-Green-Blue (RGB) image, resized to <span class="math notranslate nohighlight">\(224 \times 224\)</span>:</p>
<div class="math notranslate nohighlight">
\[
x \;\in\; [0,1]^{3 \times 224 \times 224}\;.
\]</div>
<p>You apply standard vision transforms (normalization, random crop/flip) and batch the data with a plain <strong>PyTorch DataLoader</strong> (wrapped by <code class="docutils literal notranslate"><span class="pre">ray.train.torch.prepare_data_loader</span></code> for distributed training).</p>
<hr class="docutils" />
</section>
<section id="labels">
<h2>Labels<a class="headerlink" href="#labels" title="Link to this heading">#</a></h2>
<p>Each image belongs to one of ten classes:</p>
<p>[‚Äòpizza‚Äô, ‚Äòhamburger‚Äô, ‚Äòsushi‚Äô, ‚Äòramen‚Äô, ‚Äòfried rice‚Äô,
‚Äòsteak‚Äô, ‚Äòhot dog‚Äô, ‚Äòpancake‚Äô, ‚Äòburrito‚Äô, ‚Äòcaesar salad‚Äô]</p>
<p>The label is an integer <span class="math notranslate nohighlight">\(y \in \{0, \dots, 9\}\)</span> used for supervision.</p>
<hr class="docutils" />
</section>
<section id="what-does-the-model-learn">
<h2>What does the model learn?<a class="headerlink" href="#what-does-the-model-learn" title="Link to this heading">#</a></h2>
<p>You train a compact CNN (For example, <strong>ResNet-18</strong>) to map an image (x) to class probabilities:</p>
<div class="math notranslate nohighlight">
\[
f_\theta(x)\;=\;\hat{y}\;\in\;\mathbb{R}^{10}.
\]</div>
<p>Training minimizes the <strong>cross-entropy loss</strong>,</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(x,y)\;=\;-\log \bigl(\hat{y}_{\,y}\bigr),
\]</div>
<p>so the network assigns high likelihood to the correct class.</p>
<hr class="docutils" />
</section>
<section id="how-to-migrate-this-computer-vision-workload-to-a-distributed-setup-using-ray-on-anyscale">
<h2>How to migrate this computer vision workload to a distributed setup using Ray on Anyscale<a class="headerlink" href="#how-to-migrate-this-computer-vision-workload-to-a-distributed-setup-using-ray-on-anyscale" title="Link to this heading">#</a></h2>
<p>In this tutorial, you start with a small PyTorch-based image classification task‚Äîtraining a ResNet-18 model on a 10% slice of the Food-101 dataset, and progressively migrate it into a fully distributed, fault-tolerant training job using <strong>Ray Train on Anyscale</strong>. The goal is to show you exactly how to scale <em>your existing workflow</em> without rewriting it from scratch.</p>
<p>Use the following steps to migrate:</p>
<ol class="arabic">
<li><p><strong>Preprocess data and persist it in a distributed-friendly format</strong><br />
You take raw images from Hugging Face‚Äôs <code class="docutils literal notranslate"><span class="pre">food101</span></code> dataset, apply <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> resizing and center-cropping, and serialize them to <strong>Parquet</strong> using <code class="docutils literal notranslate"><span class="pre">pyarrow</span></code>. The system writes these Parquet files to the <strong>Anyscale cluster‚Äôs shared storage volume</strong> (<code class="docutils literal notranslate"><span class="pre">/mnt/cluster_storage</span></code>), so any node can access them, on any worker, without duplication or sync issues.</p></li>
<li><p><strong>Create a lightweight PyTorch <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> for Parquet ingestion</strong><br />
You implement a custom <code class="docutils literal notranslate"><span class="pre">Food101Dataset</span></code> that reads directly from the Parquet files. This provides control over the way the system reads rows and row groups. While this isn‚Äôt yet fully distributed, it allows you to simulate a real-world scenario where a developer starts with something simple before optimizing. <strong>Note:</strong> you use PyTorch style data loading in this tutorial to demonstrate (1) low level control in a PyTorch native environment and (2) how to move pre-existing PyTorch code into a distributed Anyscale environment. Other tutorials in this module incorporate Ray Data, so you can see how the two approaches differ.</p></li>
<li><p><strong>Integrate Ray Train into the training loop</strong><br />
You encapsulate your existing PyTorch training logic in a <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker()</span></code> function, which Ray Train executes on each worker, typically one per GPU. Inside this loop, you:</p>
<ul class="simple">
<li><p>Wrap the model with <code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code> to make it compatible with distributed data parallelism.</p></li>
<li><p>Wrap the <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> with <code class="docutils literal notranslate"><span class="pre">prepare_data_loader()</span></code> to enable device placement and Ray worker context handling.</p></li>
<li><p>Use Ray‚Äôs <code class="docutils literal notranslate"><span class="pre">Checkpoint</span></code> API to save and resume from checkpoints as needed.</p></li>
<li><p>Report training and validation metrics with <code class="docutils literal notranslate"><span class="pre">train.report()</span></code> after each epoch.</p></li>
</ul>
</li>
<li><p><strong>Launch training with <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> on an Anyscale cluster</strong><br />
You instantiate a <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> that runs:</p>
<ul class="simple">
<li><p>With <code class="docutils literal notranslate"><span class="pre">num_workers=8</span></code> and <code class="docutils literal notranslate"><span class="pre">use_gpu=True</span></code>. For example, across 8 A10 or A100 GPUs on Anyscale. Please note that this amount of compute is not necessary for the example in this tutorial, as the excess resources are for educational purposes only.</p></li>
<li><p>With <code class="docutils literal notranslate"><span class="pre">RunConfig</span></code> that sets checkpoint retention and auto-resume (with <code class="docutils literal notranslate"><span class="pre">max_failures=3</span></code>).</p></li>
<li><p>On infrastructure that‚Äôs provisioned and scheduled by Anyscale with no manual Ray cluster setup required.</p></li>
</ul>
<p>Once launched, Ray automatically handles:</p>
<ul class="simple">
<li><p>Multi-node orchestration</p></li>
<li><p>Worker assignment and device pinning</p></li>
<li><p>Failure recovery and retry logic</p></li>
<li><p>Checkpointing and logging</p></li>
</ul>
</li>
<li><p><strong>Validate fault tolerance</strong><br />
You run <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code> a second time. If manual intervention or failure interrupts the previous training, Ray picks up from the latest checkpoint. This shows <strong>real-world robustness</strong> without any manual checkpoint management or scripting.</p></li>
<li><p><strong>Launch distributed GPU inference tasks</strong><br />
At the end, you provide inference with a Ray Data pipeline that loads the best checkpoint and runs inference on a single image from the validation set. You run this task on one GPU from the cluster.</p></li>
</ol>
<p>All of this runs inside a <strong>managed Anyscale workspace</strong>. You don‚Äôt need to start or SSH into clusters, worry about node IP, or configure NCCL. The entire setup is <strong>declarative and self-contained in this notebook</strong>, and you can re-run it or scale it up by changing a single parameter (<code class="docutils literal notranslate"><span class="pre">num_workers</span></code>).</p>
<p>This tutorial mirrors how many ML teams operate in practice: starting with a working PyTorch training loop and migrating it to the cloud without rewriting core logic. With Ray Train on Anyscale, the migration is clean, incremental, and production-ready.</p>
</section>
<section id="imports">
<h2>1. Imports<a class="headerlink" href="#imports" title="Link to this heading">#</a></h2>
<p>Before you start, gather every library you‚Äôre going to rely on throughout this notebook. Pull in core Python utilities for file handling and plotting, PyTorch and TorchVision for deep-learning components, Ray Train for distributed orchestration, Hugging Face Datasets for quick data access, and PyArrow plus Pandas for fast Parquet IO. Importing everything up-front keeps the rest of the tutorial clean and predictable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 00. Runtime setup </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span><span class="o">,</span><span class="w"> </span><span class="nn">sys</span><span class="o">,</span><span class="w"> </span><span class="nn">subprocess</span>

<span class="c1"># Non-secret env var </span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;RAY_TRAIN_V2_ENABLED&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>

<span class="c1"># Install Python dependencies </span>
<span class="n">subprocess</span><span class="o">.</span><span class="n">check_call</span><span class="p">([</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="p">,</span> <span class="s2">&quot;-m&quot;</span><span class="p">,</span> <span class="s2">&quot;pip&quot;</span><span class="p">,</span> <span class="s2">&quot;install&quot;</span><span class="p">,</span> <span class="s2">&quot;--no-cache-dir&quot;</span><span class="p">,</span>
    <span class="s2">&quot;torch==2.8.0&quot;</span><span class="p">,</span>
    <span class="s2">&quot;torchvision==0.23.0&quot;</span><span class="p">,</span>
    <span class="s2">&quot;matplotlib==3.10.6&quot;</span><span class="p">,</span>
    <span class="s2">&quot;pyarrow==14.0.2&quot;</span><span class="p">,</span>
    <span class="s2">&quot;datasets==2.19.2&quot;</span><span class="p">,</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 01. Imports</span>

<span class="c1"># ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>
<span class="c1"># Standard Library Utilities</span>
<span class="c1"># ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span><span class="o">,</span><span class="w"> </span><span class="nn">io</span><span class="o">,</span><span class="w"> </span><span class="nn">tempfile</span><span class="o">,</span><span class="w"> </span><span class="nn">shutil</span>  <span class="c1"># file I/O and temp dirs</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>                      <span class="c1"># reading/writing configs</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span><span class="o">,</span><span class="w"> </span><span class="nn">uuid</span>              <span class="c1"># randomness and unique IDs</span>

<span class="c1"># ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>
<span class="c1"># Core Data &amp; Storage Libraries</span>
<span class="c1"># ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>              <span class="c1"># tabular data handling</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>               <span class="c1"># numerical ops</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pa</span>             <span class="c1"># in-memory columnar format</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow.parquet</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pq</span>     <span class="c1"># reading/writing Parquet files</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>            <span class="c1"># progress bars</span>

<span class="c1"># ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>
<span class="c1"># Image Handling &amp; Visualization</span>
<span class="c1"># ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>  <span class="c1"># plotting loss curves, images</span>

<span class="c1"># ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>
<span class="c1"># PyTorch + TorchVision Core</span>
<span class="c1"># ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span> <span class="k">as</span> <span class="n">T</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">resnet18</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">Compose</span><span class="p">,</span> <span class="n">Resize</span><span class="p">,</span> <span class="n">CenterCrop</span>

<span class="c1"># ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>
<span class="c1"># Ray Train: Distributed Training Primitives</span>
<span class="c1"># ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ray.train</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">train</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.train.torch</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">prepare_model</span><span class="p">,</span>
    <span class="n">prepare_data_loader</span><span class="p">,</span>
    <span class="n">TorchTrainer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.train</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ScalingConfig</span><span class="p">,</span>
    <span class="n">RunConfig</span><span class="p">,</span>
    <span class="n">FailureConfig</span><span class="p">,</span>
    <span class="n">CheckpointConfig</span><span class="p">,</span>
    <span class="n">Checkpoint</span><span class="p">,</span>
    <span class="n">get_checkpoint</span><span class="p">,</span>
    <span class="n">get_context</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>
<span class="c1"># Dataset Access</span>
<span class="c1"># ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>  <span class="c1"># Hugging Face Datasets</span>
</pre></div>
</div>
</div>
</div>
<section id="load-10-of-food-101">
<h3>2. Load 10 % of Food-101<a class="headerlink" href="#load-10-of-food-101" title="Link to this heading">#</a></h3>
<p>Next, get roughly 7,500 images, exactly 10% of Food-101‚Äîusing a single call to <code class="docutils literal notranslate"><span class="pre">load_dataset</span></code>. This trimmed subset trains quickly while still being large enough to demonstrate Ray‚Äôs scaling behavior.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 02. Load 10% of food101 (~7,500 images)</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;food101&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train[:10%]&quot;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</section>
<section id="resize-and-encode-images">
<h3>3. Resize and encode images<a class="headerlink" href="#resize-and-encode-images" title="Link to this heading">#</a></h3>
<p>Preprocess each image: resize to 256 pixels, center-crop to 224 pixels (the size expected by most ImageNet models), and then convert the result to raw Joint Photographic Experts Group (JPEG) bytes. By storing bytes instead of full Python Imaging Library (PIL) objects, you keep the dataset compact and Parquet-friendly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 03. Resize and encode as JPEG bytes</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">([</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span> <span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">)])</span>
<span class="n">records</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Preprocessing images&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;img&quot;</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
        <span class="n">buf</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
        <span class="n">img</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;JPEG&quot;</span><span class="p">)</span>
        <span class="n">records</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;image_bytes&quot;</span><span class="p">:</span> <span class="n">buf</span><span class="o">.</span><span class="n">getvalue</span><span class="p">(),</span>
            <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="n">example</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>
        <span class="p">})</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">continue</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visual-sanity-check">
<h3>4. Visual sanity check<a class="headerlink" href="#visual-sanity-check" title="Link to this heading">#</a></h3>
<p>Before committing to hours of training, take nine random samples and plot them with their class names. This quick inspection lets you properly align labels and confirm that images are correctly resized.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 04. Visualize the dataset</span>

<span class="n">label_names</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span>  <span class="c1"># maps int ‚Üí string</span>

<span class="n">samples</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">records</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Sample Resized Images from food101-lite&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">rec</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">samples</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">rec</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">]))</span>
    <span class="n">label_name</span> <span class="o">=</span> <span class="n">label_names</span><span class="p">[</span><span class="n">rec</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label_name</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="persist-to-parquet">
<h3>5. Persist to Parquet<a class="headerlink" href="#persist-to-parquet" title="Link to this heading">#</a></h3>
<p>Write the images and labels to a Parquet file. Because Parquet is columnar, you can read just the columns you need during training, which speeds up IO‚Äîespecially when multiple workers are reading in parallel under Ray.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 05. Write Dataset to Parquet</span>

<span class="n">output_dir</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite/parquet_256&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">table</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="o">.</span><span class="n">from_pydict</span><span class="p">({</span>
    <span class="s2">&quot;image_bytes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">records</span><span class="p">],</span>
    <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">records</span><span class="p">]</span>
<span class="p">})</span>
<span class="n">pq</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;shard_0.parquet&quot;</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Wrote </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">records</span><span class="p">)</span><span class="si">}</span><span class="s2"> records to </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="custom-food101dataset-for-parquet">
<h2>6. Custom <code class="docutils literal notranslate"><span class="pre">Food101Dataset</span></code> for Parquet<a class="headerlink" href="#custom-food101dataset-for-parquet" title="Link to this heading">#</a></h2>
<p>To feed data into PyTorch, define a custom <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>. You cache Parquet metadata, map global indices to specific row groups, and pull only the row you need. Each <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> returns an <code class="docutils literal notranslate"><span class="pre">(image,</span> <span class="pre">label)</span></code> pair that‚Äôs immediately ready for further transforms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 06. Define PyTorch Dataset that loads from Parquet</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Food101Dataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parquet_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parquet_file</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">ParquetFile</span><span class="p">(</span><span class="n">parquet_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

        <span class="c1"># Precompute a global row index to (row_group_idx, local_idx) map</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">row_group_map</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">rg_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parquet_file</span><span class="o">.</span><span class="n">num_row_groups</span><span class="p">):</span>
            <span class="n">rg_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parquet_file</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">row_group</span><span class="p">(</span><span class="n">rg_idx</span><span class="p">)</span>
            <span class="n">num_rows</span> <span class="o">=</span> <span class="n">rg_meta</span><span class="o">.</span><span class="n">num_rows</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">row_group_map</span><span class="o">.</span><span class="n">extend</span><span class="p">([(</span><span class="n">rg_idx</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_rows</span><span class="p">)])</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_group_map</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">row_group_idx</span><span class="p">,</span> <span class="n">local_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_group_map</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="c1"># Read only the relevant row group (in memory-efficient batch---for scalability)</span>
        <span class="n">table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parquet_file</span><span class="o">.</span><span class="n">read_row_group</span><span class="p">(</span><span class="n">row_group_idx</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">])</span>
        <span class="n">row</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">local_idx</span><span class="p">]</span>

        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">]))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<section id="image-transform">
<h3>7. Image transform<a class="headerlink" href="#image-transform" title="Link to this heading">#</a></h3>
<p>Create a transform pipeline: <code class="docutils literal notranslate"><span class="pre">ToTensor()</span></code> followed by ImageNet mean and standard-deviation normalisation. By applying the transform inside the dataset, you make sure every worker, no matter where it runs, processes images in exactly the same way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 07. Define data preprocessing transform</span>
<span class="n">IMAGENET_MEAN</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">]</span>
<span class="n">IMAGENET_STD</span>  <span class="o">=</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">T</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">IMAGENET_MEAN</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">IMAGENET_STD</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-validation-split">
<h3>8. Train/validation split<a class="headerlink" href="#train-validation-split" title="Link to this heading">#</a></h3>
<p>Shuffle the full Parquet table once (seeded for reproducibility) and then slice off the last 500 rows to construct the validation set. Write the train and validation partitions to their own Parquet files so you can load them independently later.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 08. Create train/val Parquet splits </span>
<span class="n">full_path</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite/parquet_256/shard_0.parquet&quot;</span>

<span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">pq</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">full_path</span><span class="p">)</span>
    <span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>
    <span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># shuffle for reproducibility</span>
<span class="p">)</span>

<span class="n">df</span><span class="p">[:</span><span class="o">-</span><span class="mi">500</span><span class="p">]</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s2">&quot;/mnt/cluster_storage/food101_lite/train.parquet&quot;</span><span class="p">)</span>   <span class="c1"># training</span>
<span class="n">df</span><span class="p">[</span><span class="o">-</span><span class="mi">500</span><span class="p">:]</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s2">&quot;/mnt/cluster_storage/food101_lite/val.parquet&quot;</span><span class="p">)</span>     <span class="c1"># validation</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="inspect-a-dataloader-batch">
<h3>9. Inspect a DataLoader batch<a class="headerlink" href="#inspect-a-dataloader-batch" title="Link to this heading">#</a></h3>
<p>Before you scale out, build a regular single-process <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>, pull one batch, and print its shape. This tiny test reassures you that batching, multiprocessing, and transforms work correctly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 09. Observe data shape</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">Food101Dataset</span><span class="p">(</span><span class="s2">&quot;/mnt/cluster_storage/food101_lite/train.parquet&quot;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="helper-ray-prepared-dataloaders">
<h2>10. Helper: Ray-prepared DataLoaders<a class="headerlink" href="#helper-ray-prepared-dataloaders" title="Link to this heading">#</a></h2>
<p>Wrap the DataLoader with <code class="docutils literal notranslate"><span class="pre">prepare_data_loader</span></code>.<br />
Ray automatically injects a <code class="docutils literal notranslate"><span class="pre">DistributedSampler</span></code>, pins the loader to the correct GPU, and manages all worker-rank bookkeeping. This means you don‚Äôt need to manually construct a <code class="docutils literal notranslate"><span class="pre">DistributedSampler</span></code>, as it‚Äôs handled internally by Ray.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 10. Define helper to create prepared DataLoader</span>
<span class="k">def</span><span class="w"> </span><span class="nf">build_dataloader</span><span class="p">(</span><span class="n">parquet_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">Food101Dataset</span><span class="p">(</span><span class="n">parquet_path</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

    <span class="c1"># Let Ray handle DistributedSampler and device placement via prepare_data_loader.</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">prepare_data_loader</span><span class="p">(</span><span class="n">loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-loop-per-worker">
<h2>11. <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code><a class="headerlink" href="#train-loop-per-worker" title="Link to this heading">#</a></h2>
<p>This function defines the <strong>per-worker training logic</strong> that Ray Train executes on each distributed worker.</p>
<p>Each worker builds its own model, optimizer, and dataloaders; resumes automatically from the most recent Ray-managed checkpoint (if available); and then trains and validates the model across epochs.</p>
<p>Key behaviors to note:</p>
<ul class="simple">
<li><p><strong>Checkpoints</strong> are first written to a fast <strong>temporary local directory</strong> on each worker, then safely persisted to the run‚Äôs configured <code class="docutils literal notranslate"><span class="pre">storage_path</span></code> by <code class="docutils literal notranslate"><span class="pre">train.report()</span></code>‚Äîensuring reliability and retry support even under transient node failures.</p></li>
<li><p><strong>Metrics</strong> (train and validation loss) are automatically collected and stored by Ray Train‚Äîno need for manual file writes or JSON logging.</p></li>
<li><p><strong>Fault tolerance</strong> is fully handled by Ray Train‚Äôs checkpointing and retry mechanism via <code class="docutils literal notranslate"><span class="pre">RunConfig</span></code> and <code class="docutils literal notranslate"><span class="pre">FailureConfig</span></code>.</p></li>
<li><p><strong>Final accuracy</strong> is computed using <code class="docutils literal notranslate"><span class="pre">torchmetrics.MulticlassAccuracy</span></code>, which performs synchronized, <strong>distributed accuracy aggregation</strong> across all workers, ensuring a correct global metric instead of rank-0-only evaluation.</p></li>
</ul>
<p>This design keeps the training loop clean, fault-tolerant, and fully aligned with Ray Train‚Äôs built-in distributed orchestration.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 11. Define Ray Train train_loop_per_worker (tempdir checkpoints + Ray-managed metrics)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_loop_per_worker</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>

    <span class="n">rank</span> <span class="o">=</span> <span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_world_rank</span><span class="p">()</span>

    <span class="c1"># === Model ===</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">prepare_model</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

    <span class="c1"># === Optimizer / Loss ===</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">])</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="c1"># === Resume from Checkpoint ===</span>
    <span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">ckpt</span> <span class="o">=</span> <span class="n">get_checkpoint</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">ckpt</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">ckpt</span><span class="o">.</span><span class="n">as_directory</span><span class="p">()</span> <span class="k">as</span> <span class="n">ckpt_dir</span><span class="p">:</span>
            <span class="c1"># Map to CPU is fine; prepare_model will handle device placement.</span>
            <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">),</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
            <span class="n">opt_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;optimizer.pt&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">opt_path</span><span class="p">):</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">opt_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
            <span class="n">meta_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;meta.pt&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">meta_path</span><span class="p">):</span>
                <span class="c1"># Continue from the next epoch after the saved one</span>
                <span class="n">start_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">meta_path</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">] Resumed from checkpoint at epoch </span><span class="si">{</span><span class="n">start_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># === DataLoaders ===</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">build_dataloader</span><span class="p">(</span>
        <span class="s2">&quot;/mnt/cluster_storage/food101_lite/train.parquet&quot;</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">build_dataloader</span><span class="p">(</span>
        <span class="s2">&quot;/mnt/cluster_storage/food101_lite/val.parquet&quot;</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>

    <span class="c1"># === Training Loop ===</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">]):</span>
        <span class="c1"># Required when using DistributedSampler</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="s2">&quot;sampler&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">sampler</span><span class="p">,</span> <span class="s2">&quot;set_epoch&quot;</span><span class="p">):</span>
            <span class="n">train_loader</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">set_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">train_loss_total</span><span class="p">,</span> <span class="n">train_batches</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">train_loss_total</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">train_batches</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_loss_total</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_batches</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># === Validation Loop ===</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">val_loss_total</span><span class="p">,</span> <span class="n">val_batches</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">val_xb</span><span class="p">,</span> <span class="n">val_yb</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
                <span class="n">val_loss_total</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">val_xb</span><span class="p">),</span> <span class="n">val_yb</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">val_batches</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">val_loss_total</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">val_batches</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span> <span class="s2">&quot;train_loss&quot;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">,</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>

        <span class="c1"># ---- Save checkpoint to fast local temp dir; Ray persists it via report() ----</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdir</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">))</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">,</span> <span class="s2">&quot;optimizer.pt&quot;</span><span class="p">))</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">},</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">,</span> <span class="s2">&quot;meta.pt&quot;</span><span class="p">))</span>
                <span class="n">ckpt_out</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_directory</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">)</span>
                <span class="n">train</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="n">ckpt_out</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Non-zero ranks report metrics only (no checkpoint attachment)</span>
            <span class="n">train</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>

    <span class="c1"># === Final validation accuracy (distributed via TorchMetrics) ===</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">torchmetrics.classification</span><span class="w"> </span><span class="kn">import</span> <span class="n">MulticlassAccuracy</span>

    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
    <span class="c1"># Sync across DDP workers when computing the final value</span>
    <span class="n">acc_metric</span> <span class="o">=</span> <span class="n">MulticlassAccuracy</span><span class="p">(</span>
        <span class="n">num_classes</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="n">sync_on_compute</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">acc_metric</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>

    <span class="n">dist_val_acc</span> <span class="o">=</span> <span class="n">acc_metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Val Accuracy (distributed): </span><span class="si">{</span><span class="n">dist_val_acc</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="launch-distributed-training-with-torchtrainer">
<h2>12. Launch distributed training with <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code><a class="headerlink" href="#launch-distributed-training-with-torchtrainer" title="Link to this heading">#</a></h2>
<p>Instantiate a <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code>. Ask for eight GPU workers, enable up to three automatic retries, and tell Ray to keep the five checkpoints with the lowest validation loss. One call to <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code> kicks off a fault-tolerant job on your Anyscale cluster.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 12. Run Training with Ray Train </span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
    <span class="n">train_loop_per_worker</span><span class="o">=</span><span class="n">train_loop_per_worker</span><span class="p">,</span>
    <span class="n">train_loop_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span> <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">},</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">run_config</span><span class="o">=</span><span class="n">RunConfig</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;food101_ft_resume&quot;</span><span class="p">,</span>
        <span class="n">storage_path</span><span class="o">=</span><span class="s2">&quot;/mnt/cluster_storage/food101_lite/results&quot;</span><span class="p">,</span>
        <span class="n">checkpoint_config</span><span class="o">=</span><span class="n">CheckpointConfig</span><span class="p">(</span>
            <span class="n">num_to_keep</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
            <span class="n">checkpoint_frequency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">checkpoint_score_attribute</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
            <span class="n">checkpoint_score_order</span><span class="o">=</span><span class="s2">&quot;min&quot;</span>
        <span class="p">),</span>
        <span class="n">failure_config</span><span class="o">=</span><span class="n">FailureConfig</span><span class="p">(</span><span class="n">max_failures</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
    <span class="p">),</span>
<span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final metrics:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
<span class="n">best_ckpt</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span>  <span class="c1"># this is the one with lowest val_loss</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-training-and-validation-loss-curves">
<h2>13. Plot training and validation loss curves<a class="headerlink" href="#plot-training-and-validation-loss-curves" title="Link to this heading">#</a></h2>
<p>After training completes, visualize the recorded metrics directly from Ray Train‚Äôs results object. No manual CSV handling is required.<br />
<code class="docutils literal notranslate"><span class="pre">result.metrics_dataframe</span></code> automatically contains every metric reported during training, including per-epoch loss values from all workers.</p>
<p>This plot extracts the training and validation losses, groups them by epoch, and displays the most recent report for each.<br />
By comparing these two curves, you quickly assess convergence behavior and detect overfitting (for example, when training loss continues to decrease while validation loss rises).</p>
<p>Because Ray Train automatically stores all metrics and checkpoints, this visualization reflects the same information used to select the <strong>best checkpoint</strong> based on validation loss in your <code class="docutils literal notranslate"><span class="pre">RunConfig</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 13. Plot training / validation loss curves </span>

<span class="c1"># Pull the full metrics history Ray stored for this run</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">metrics_dataframe</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Keep only the columns we need (guard against extra columns)</span>
<span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="c1"># If multiple rows per epoch exist, keep the last report per epoch</span>
<span class="k">if</span> <span class="s2">&quot;epoch&quot;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="n">as_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">last</span><span class="p">()</span>

<span class="c1"># Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">if</span> <span class="s2">&quot;train_loss&quot;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Train Loss&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="s2">&quot;val_loss&quot;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Val Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Train/Val Loss across Epochs&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="demonstrate-fault-tolerant-resumption">
<h2>14. Demonstrate fault-tolerant resumption<a class="headerlink" href="#demonstrate-fault-tolerant-resumption" title="Link to this heading">#</a></h2>
<p>To prove that checkpointing works, run <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code> a second time without changing anything. If the earlier run crashed mid-epoch, Ray automatically picks up the latest checkpoint and continue. If it already finished, Ray simply starts a clean new experiment.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 14. Run the trainer again to demonstrate resuming from latest checkpoint  </span>

<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final metrics:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="batch-inference-with-ray-data">
<h2>15. Batch inference with Ray Data<a class="headerlink" href="#batch-inference-with-ray-data" title="Link to this heading">#</a></h2>
<p>Define a <strong>stateful, GPU-backed batch inference pipeline</strong> using Ray Data.<br />
Each actor loads the model <strong>once per GPU</strong>, keeps it in memory, and performs inference on incoming batches in parallel.<br />
This pattern scales efficiently across multiple GPUs and avoids redundant model loading for every prediction.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 15. Batch inference with Ray Data (force GPU actors if available on the cluster)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">ray.data</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">rdata</span>

<span class="k">class</span><span class="w"> </span><span class="nc">ImageBatchPredictor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Stateful per-actor batch predictor that keeps the model in memory.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="c1"># Pick the best available device on the ACTOR (worker), not the driver.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="c1"># === Load model &amp; weights once per actor ===</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_directory</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">as_directory</span><span class="p">()</span> <span class="k">as</span> <span class="n">ckpt_dir</span><span class="p">:</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">),</span>
                <span class="n">map_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Strip DDP &quot;module.&quot; prefix if present</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;module.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">T</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">IMAGENET_MEAN</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">IMAGENET_STD</span><span class="p">),</span>
        <span class="p">])</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;batch: Pandas DataFrame with columns [&#39;image_bytes&#39;, &#39;label&#39;]&quot;&quot;&quot;</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">]:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">b</span><span class="p">))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
            <span class="n">imgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>  <span class="c1"># (C,H,W) as numpy</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># (N,C,H,W)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">out</span><span class="p">[</span><span class="s2">&quot;predicted_label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">[[</span><span class="s2">&quot;predicted_label&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">]]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">build_inference_dataset</span><span class="p">(</span>
    <span class="n">checkpoint_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">parquet_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">num_actors</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
    <span class="n">use_gpu_actors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>   <span class="c1"># &lt;‚Äî default to GPU actors on the cluster</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a Ray Dataset pipeline that performs batch inference using</span>
<span class="sd">    stateful per-actor model loading. By default, requests 1 GPU per actor</span>
<span class="sd">    so each actor runs on a GPU worker (driver may have no GPU).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">rdata</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">parquet_path</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image_bytes&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">])</span>

    <span class="n">pred_ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span>
        <span class="n">ImageBatchPredictor</span><span class="p">,</span>                     <span class="c1"># pass the CLASS (stateful actors)</span>
        <span class="n">fn_constructor_args</span><span class="o">=</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,),</span>  <span class="c1"># ctor args for each actor</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="o">=</span><span class="n">num_actors</span><span class="p">,</span>                  <span class="c1"># number of actor workers</span>
        <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="n">use_gpu_actors</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>     <span class="c1"># &lt;‚Äî force GPU placement on workers</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">pred_ds</span>
</pre></div>
</div>
</div>
</div>
<section id="run-and-visualize-ray-data-inference">
<h3>16. Run and visualize Ray Data inference<a class="headerlink" href="#run-and-visualize-ray-data-inference" title="Link to this heading">#</a></h3>
<p>Use the best checkpoint to run <strong>Ray Data Inference</strong> on a validation sample.<br />
The model loads once per GPU actor, predictions are batched and parallelized, and the result is visualized alongside the ground-truth label for quick qualitative evaluation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 16. Perform inference with Ray Data using the best checkpoint</span>

<span class="n">checkpoint_root</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite/results/food101_ft_resume&quot;</span>

<span class="n">checkpoint_dirs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">checkpoint_root</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">d</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;checkpoint_&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_root</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
    <span class="p">],</span>
    <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">checkpoint_dirs</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="s2">&quot;No checkpoint directories found.&quot;</span><span class="p">)</span>

<span class="c1"># Use the best checkpoint from the training result</span>
<span class="k">with</span> <span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">as_directory</span><span class="p">()</span> <span class="k">as</span> <span class="n">ckpt_dir</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best checkpoint contents:&quot;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">))</span>
    <span class="n">best_ckpt_path</span> <span class="o">=</span> <span class="n">ckpt_dir</span>

<span class="n">parquet_path</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite/val.parquet&quot;</span>

<span class="c1"># Which item to visualize</span>
<span class="n">idx</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Build a Ray Data inference pipeline (model is loaded once per GPU actor)</span>
<span class="n">pred_ds</span> <span class="o">=</span> <span class="n">build_inference_dataset</span><span class="p">(</span>
    <span class="n">checkpoint_path</span><span class="o">=</span><span class="n">best_ckpt_path</span><span class="p">,</span>
    <span class="n">parquet_path</span><span class="o">=</span><span class="n">parquet_path</span><span class="p">,</span>
    <span class="n">num_actors</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>       <span class="c1"># adjust to scale out</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>      <span class="c1"># adjust for throughput</span>
<span class="p">)</span>

<span class="c1"># Materialize predictions up to the desired index and grab the row</span>
<span class="n">pred_rows</span> <span class="o">=</span> <span class="n">pred_ds</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">inference_row</span> <span class="o">=</span> <span class="n">pred_rows</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># {&quot;predicted_label&quot;: ..., &quot;label&quot;: ...}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inference_row</span><span class="p">)</span>

<span class="c1"># Load label map from Hugging Face (for pretty titles)</span>
<span class="n">ds_tmp</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;food101&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train[:1%]&quot;</span><span class="p">)</span>  <span class="c1"># just to get label names</span>
<span class="n">label_names</span> <span class="o">=</span> <span class="n">ds_tmp</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span>

<span class="c1"># Load the raw image locally for visualization</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">Food101Dataset</span><span class="p">(</span><span class="n">parquet_path</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">img</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="c1"># Plot the image with predicted and true labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Pred: </span><span class="si">{</span><span class="n">label_names</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">inference_row</span><span class="p">[</span><span class="s1">&#39;predicted_label&#39;</span><span class="p">])]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="sa">f</span><span class="s2">&quot;True: </span><span class="si">{</span><span class="n">label_names</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">inference_row</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])]</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="clean-up">
<h3>17. Clean up<a class="headerlink" href="#clean-up" title="Link to this heading">#</a></h3>
<p>Finally, tidy up by deleting temporary checkpoint folders, the metrics CSV, and any intermediate result directories. Clearing out old artifacts frees disk space and leaves your workspace clean for whatever comes next.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 17. Cleanup---delete checkpoints and metrics from model training</span>

<span class="c1"># Base directory</span>
<span class="n">BASE_DIR</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/food101_lite&quot;</span>

<span class="c1"># Paths to clean</span>
<span class="n">paths_to_delete</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s2">&quot;tmp_checkpoints&quot;</span><span class="p">),</span>           <span class="c1"># custom checkpoints</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s2">&quot;results&quot;</span><span class="p">,</span> <span class="s2">&quot;history.csv&quot;</span><span class="p">),</span>    <span class="c1"># metrics history file</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s2">&quot;results&quot;</span><span class="p">,</span> <span class="s2">&quot;food101_ft_resume&quot;</span><span class="p">),</span>  <span class="c1"># ray trainer run dir</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s2">&quot;results&quot;</span><span class="p">,</span> <span class="s2">&quot;food101_ft_run&quot;</span><span class="p">),</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s2">&quot;results&quot;</span><span class="p">,</span> <span class="s2">&quot;food101_single_run&quot;</span><span class="p">),</span>
<span class="p">]</span>

<span class="c1"># Delete each path if it exists</span>
<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths_to_delete</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Deleted file: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Deleted directory: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Not found (skipped): </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="wrap-up-and-next-steps">
<h3>Wrap up and next steps<a class="headerlink" href="#wrap-up-and-next-steps" title="Link to this heading">#</a></h3>
<p>You‚Äôve taken a realistic computer-vision workload, from raw images all the way to distributed training and GPU inference, and run it on Ray Train with zero boilerplate around GPUs, data parallelism, or fault-tolerance. You should now feel comfortable:</p>
<ul class="simple">
<li><p>Using <strong>Ray Train‚Äôs TorchTrainer</strong> to scale PyTorch training across multiple GPUs and nodes with minimal code changes</p></li>
<li><p>Wrapping models and data loaders with <strong><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></strong> and <strong><code class="docutils literal notranslate"><span class="pre">prepare_data_loader()</span></code></strong> to enable Ray-managed device placement and distributed execution</p></li>
<li><p>Sharding data across workers using and coordinating training epochs across Ray workers</p></li>
<li><p>Configuring <strong>automatic checkpointing and failure recovery</strong> using Ray Train‚Äôs built-in <code class="docutils literal notranslate"><span class="pre">Checkpoint</span></code>, <code class="docutils literal notranslate"><span class="pre">RunConfig</span></code>, and <code class="docutils literal notranslate"><span class="pre">FailureConfig</span></code> APIs</p></li>
<li><p>Running <strong>Ray Data based Inference</strong> for distributed inference, showing how to serve and scale model predictions across a Ray cluster</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="where-can-you-take-this-next">
<h3>Where can you take this next?<a class="headerlink" href="#where-can-you-take-this-next" title="Link to this heading">#</a></h3>
<p>Below are a few directions you might explore to adapt or extend the pattern:</p>
<ol class="arabic simple">
<li><p><strong>Larger or custom datasets</strong></p>
<ul class="simple">
<li><p>Swap in the full 75 k-image Food-101 split‚Äîor your own dataset in any storage backend (S3, GCS, Azure Blob).</p></li>
<li><p>Add multi-file Parquet sharding and let each worker read a different shard.</p></li>
</ul>
</li>
<li><p><strong>Model architectures</strong></p>
<ul class="simple">
<li><p>Drop in Vision Transformers (<code class="docutils literal notranslate"><span class="pre">vit_b_16</span></code>, <code class="docutils literal notranslate"><span class="pre">vit_l_32</span></code>) or ConvNeXt; the prepare helpers work exactly the same.</p></li>
<li><p>Experiment with transfer learning versus training from scratch.</p></li>
</ul>
</li>
<li><p><strong>Mixed precision and performance tuning</strong></p>
<ul class="simple">
<li><p>Enable automatic mixed precision (<code class="docutils literal notranslate"><span class="pre">torch.cuda.amp</span></code>) or bfloat16 to speed up training and save memory.</p></li>
<li><p>Profile data-loading throughput and play with <code class="docutils literal notranslate"><span class="pre">num_workers</span></code>, prefetching, and caching.</p></li>
</ul>
</li>
<li><p><strong>Hyperparameter sweeps</strong></p>
<ul class="simple">
<li><p>Wrap the training loop in <strong>Ray Tune</strong> to search over learning rates, augmentations, or optimizers.</p></li>
<li><p>Use Ray‚Äôs integrated reporting to schedule early stopping.</p></li>
</ul>
</li>
<li><p><strong>Data augmentation pipelines</strong></p>
<ul class="simple">
<li><p>Integrate additional transforms inside the dataset class for image augmentation.</p></li>
<li><p>Compare CPU versus GPU-side augmentations for throughput.</p></li>
</ul>
</li>
<li><p><strong>Distributed validation and metrics</strong></p>
<ul class="simple">
<li><p>Replace your simple accuracy printout with more advanced metrics (F1, top-5 accuracy, confusion matrices).</p></li>
</ul>
</li>
<li><p><strong>Model serving</strong></p>
<ul class="simple">
<li><p>Convert the remote inference helper into a <strong>Ray Serve</strong> deployment for low-latency online predictions.</p></li>
<li><p>Auto-scale replicas based on request volume.</p></li>
</ul>
</li>
<li><p><strong>End-to-end MLOps</strong></p>
<ul class="simple">
<li><p>Register checkpoints in a model registry (for example, MLflow, Weights &amp; Biases, or Ray‚Äôs built-in MLflow integration).</p></li>
<li><p>Schedule the notebook as a Ray Job or CI/CD pipeline for regular retraining runs.</p></li>
</ul>
</li>
</ol>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./courses/workloads/Train_Vision_Pattern/00_workload"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-you-learn-and-take-away">What you learn and take away</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-problem-are-you-solving-image-classification-with-food-101-lite">What problem are you solving? (image classification with Food-101-Lite)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inputs">Inputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#labels">Labels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-does-the-model-learn">What does the model learn?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-migrate-this-computer-vision-workload-to-a-distributed-setup-using-ray-on-anyscale">How to migrate this computer vision workload to a distributed setup using Ray on Anyscale</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">1. Imports</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-10-of-food-101">2. Load 10 % of Food-101</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resize-and-encode-images">3. Resize and encode images</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visual-sanity-check">4. Visual sanity check</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#persist-to-parquet">5. Persist to Parquet</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-food101dataset-for-parquet">6. Custom <code class="docutils literal notranslate"><span class="pre">Food101Dataset</span></code> for Parquet</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-transform">7. Image transform</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-validation-split">8. Train/validation split</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inspect-a-dataloader-batch">9. Inspect a DataLoader batch</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-ray-prepared-dataloaders">10. Helper: Ray-prepared DataLoaders</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-loop-per-worker">11. <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-distributed-training-with-torchtrainer">12. Launch distributed training with <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-training-and-validation-loss-curves">13. Plot training and validation loss curves</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstrate-fault-tolerant-resumption">14. Demonstrate fault-tolerant resumption</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-inference-with-ray-data">15. Batch inference with Ray Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-and-visualize-ray-data-inference">16. Run and visualize Ray Data inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clean-up">17. Clean up</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#wrap-up-and-next-steps">Wrap up and next steps</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#where-can-you-take-this-next">Where can you take this next?</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book community
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>