
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>04e Recommendation system pattern with Ray Train &#8212; Course Notebooks</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/custom_hide.css?v=af9667c8" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js?v=1ae7504c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'courses/workloads/Train_Rec_sys/00_workload/04e_rec_sys_workload_pattern';</script>
    <script src="../../../../_static/custom_toggle.js?v=1235ef5b"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Course Notebooks</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../index.html">
                    Ray Enablement Content
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Intro to Ray</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_01.html">Introduction to Ray Core: Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_02.html">0. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_03.html">1. Creating Remote Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_04.html">2. Executing Remote Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_05.html">4. Putting It All Together</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_01.html">Introduction to Ray Core (Advancement): Object store, Tasks, Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_02.html">1. Object store</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_03.html">2. Chaining Tasks and Passing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_04.html">3. Task retries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_05.html">4. Task Runtime Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_06.html">5. Resource allocation and management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_07.html">6. Nested Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_08.html">7. Pattern: Pipeline data processing and waiting for results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_09.html">8. Ray Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_01.html">Introduction to the Ray AI Libraries: An example of using Ray data, Ray Train, Ray Tune, Ray Serve to implement a XGBoost regression model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_02.html">1. Overview of the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_03.html">2. Quick end-to-end example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_01.html">Introduction to Ray Train + PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_02.html">1. When to use Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_03.html">2. Single GPU Training with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_04.html">3. Distributed Data Parallel Training with Ray Train and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_01.html">Introduction to Ray Train: Ray Train + PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_02.html">1. When to use Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_03.html">2. Single GPU Training with PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_04.html">3. Distributed Training with Ray Train and PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_05.html">4. Ray Train in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_01.html">Introduction to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_02.html">1. Loading the data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_03.html">2. Starting out with vanilla PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_04.html">3. Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_05.html">4. Ray Tune in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_01.html">Introduction to Ray Data: Industry Landscape</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_02.html">The Compute Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_03.html">The Orchestration Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_04.html">Distributed Computing Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_05.html">Data Processing with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_06.html">Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_01.html">Introduction to Ray Data: Ray Data + Structured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_02.html">0. What is Ray Data?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_03.html">2. Loading Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_04.html">3. Transforming Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_05.html">4. Writing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_06.html">5. Data Operations: Shuffling, Grouping and Aggregation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_07.html">6. When to use Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_01.html">Intro to Ray Data:  Ray Data + Unstructured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_02.html">1. When to Consider Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_03.html">2. How to work with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_04.html">3. Loading data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_05.html">3. Lazy execution mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_06.html">4. Transforming data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_07.html">5. Stateful transformations with Ray Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_08.html">6. Materializing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_09.html">7. Data Operations: grouping, aggregation, and shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_10.html">8. Persisting data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_11.html">9. Ray Data in production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_01.html">Introduction to Ray Serve with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_02.html">1. When to Consider Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_03.html">2. Overview of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_04.html">3. Implement an image classification service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_05.html">4. Development workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../00_Developer_Intro_to_Ray/output/README_01.html">Introduction to Ray: Developer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Gettingstarted</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_01_anyscale_intro_workspace_01.html">101 â€” Introduction to Anyscale Workspaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_02_anyscale_development_intro_01.html">101 â€“ Developing Application with Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_03_anyscale_compute_runtime_intro_01.html">101 â€“ Compute Configs and Execution Environments in Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_04_anyscale_storage_options_01.html">101 â€“ Storage Options in the Anyscale Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_05_anyscale_logging_metrics_01.html">101 â€“ Debug and Monitor Your Anyscale Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_06_anyscale_intro_jobs_01.html">101 â€“ Introduction to Anyscale Jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_07_anyscale_intro_services_01.html">101 â€“  Introduction to Anyscale Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_08_anyscale_collaboration_01.html">101 â€“ Collaboration on Anyscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_09_anyscale_org_setup_01.html">101 - Anyscale Organization and Cloud Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_09_anyscale_org_setup_02.html">ðŸ“Œ Overview of Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_09_anyscale_org_setup_03.html">ðŸ§  Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_anyscale_intro_jobs_01.html">Content Used</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_anyscale_intro_jobs_02.html">Part 1. Creating and Submitting your first job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_anyscale_intro_jobs_03.html">Part 2. Automation and Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_anyscale_intro_services_01.html">Sources</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../GettingStarted/output/101_anyscale_intro_services_02.html">Part 1: Starting your first Anyscale Service</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray 101</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/1_AI_Libs_Intro_01.html">Introduction to the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/1_AI_Libs_Intro_02.html">1. Overview of the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/1_AI_Libs_Intro_03.html">2. End-to-end example: predicting taxi tips in New York</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_01.html">Introduction to Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_02.html">1. PyTorch introductory example (single GPU)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_03.html">2. Distributed Data Parallel Training with Ray Train and PyTorch (multiple GPUs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_04.html">3. Overview of the training loop in Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_05.html">4. Migrating the model and dataset to Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_06.html">5. Reporting checkpoints and metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_07.html">6. Launching the distributed training job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_08.html">7. Accessing the training results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/2_Intro_Train_09.html">8. Ray Train in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/3_Intro_Tune_01.html">Intro to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/3_Intro_Tune_02.html">1. Loading and visualizing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/3_Intro_Tune_03.html">2. Setting up a PyTorch model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/3_Intro_Tune_04.html">3. Introduction to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/3_Intro_Tune_05.html">4. Diving deeper into Ray Tune concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/3_Intro_Tune_06.html">5. Hyperparameter tuning the PyTorch model using Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/4_Intro_Data_01.html">Intro to Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/4_Intro_Data_02.html">1. When to use Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/4_Intro_Data_03.html">2. Loading Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/4_Intro_Data_04.html">3. Transforming Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/4_Intro_Data_05.html">4. Data Operations: Grouping, Aggregation, and Shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/4_Intro_Data_06.html">5. Persisting Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/5_Intro_Serve_01.html">Intro to Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/5_Intro_Serve_02.html">1. Overview of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/5_Intro_Serve_03.html">2. Implement an Classifier service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/5_Intro_Serve_04.html">3. Advanced features of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/5_Intro_Serve_05.html">4. Ray Serve in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-101/output/5_Intro_Serve_06.html">Clean up</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Anyscale For Admins</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_01.html">Anyscale Administrator Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_02.html">1. What is an Anyscale Cloud?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_03.html">2. Cloud Deployment Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_04.html">3. A Demonstrative Example of Resource Creation with AWS EC2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_05.html">3.1 IAM Role Definition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_06.html">4. Register Anyscale Cloud to Your Cloud Provider</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_01.html">Deployment Options: Virtual Machines vs. Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_02.html">2. Virtual Machines (VM) vs. Kubernetes (K8s)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_03.html">3. (Optional) More Kubernetes Deployments Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_01.html">Introduction: Deploy Anyscale Ray on AWS EC2 Instances</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_02.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_03.html">2. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_04.html">3. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_05.html">4. Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_06.html">5. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_01.html">Introduction: Deploy Anyscale Ray on GCP Compute Engine Instances (GCE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_03.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_04.html">2. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_05.html">3. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_06.html">4. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_07.html">5. Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_01.html">Introduction: Deploy Anyscale Ray on A New AWS EKS Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_02.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_03.html">2. Install Kubernetes Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_04.html">3. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_05.html">4. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_06.html">5. Verify the Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_07.html">6. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_08.html">7. Clean up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_09.html">8. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_01.html">Introduction: Deploy Anyscale Ray on An Existing AWS EKS Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_03.html">1. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_04.html">2. Attach Required IAM Policies to Your existing EKSâ€™s Node Role</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_05.html">3. Install Kubernetes Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_06.html">4. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_07.html">5. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_08.html">6. Verify the Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_09.html">7. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_10.html">8. Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_11.html">9. Clean up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_12.html">10. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_01.html">Introduction: Deploy Anyscale Ray on A New Google Kubernetes Engine (GKE) Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_02.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_03.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_04.html">2. Create Anyscale Resources with Terraform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_05.html">3. Troubleshooting GPU Availability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_06.html">4. kubectl Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_07.html">5. Install NGINX Ingress Controller</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_08.html">6. (Optional) Upgrade Anyscale Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_09.html">7. Register the Anyscale Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_10.html">8. Install the Anyscale Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_11.html">8. Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_12.html">9. Cleanup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Llm Serving</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_01.html">Introduction to Ray Serve LLM: Foundations of Large Language Model Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_02.html">What is LLM Serving?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_03.html">Key Concepts and Optimizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_04.html">Challenges in LLM Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_05.html">Ray Serve LLM + Anyscale Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_06.html">Getting Started with Ray Serve LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/00_intro_serve_llm/output/notebook_07.html">Key Takeaways</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_01.html">Deploy a Medium-Sized LLM with Ray Serve LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_02.html">Overview: Why Medium-Sized Models?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_03.html">Setting up Ray Serve LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_04.html">Local Deployment &amp; Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_05.html">Deploying to Anyscale Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_06.html">Advanced Topics: Monitoring &amp; Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_07.html">Summary &amp; Outlook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_01.html">Advanced LLM Features with Ray Serve LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_02.html">Overview: Advanced Features Preview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_03.html">Example: Deploying LoRA Adapters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_04.html">Example: Getting Structured JSON Output</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_05.html">Example: Setting up Tool Calling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_06.html">How to Choose an LLM?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/LLM_Serving/02_advanced_llm_features/output/notebook_07.html">Conclusion: Next Steps</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Observability</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/01_Intro_and_setup/output/01_general_intro_and_setup_01.html">Observability Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/01_Intro_and_setup/output/01_general_intro_and_setup_02.html">Observability Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/01_Intro_and_setup/output/01_general_intro_and_setup_03.html">Setting Up Local Ray Observability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_01.html">Ray and Anyscale Observability Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_02.html">Ray Observability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_03.html">Anyscale Observability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_04.html">Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_01.html">Ray and Anyscale Observability in Detail</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_02.html">Data Pipeline Observability (Ray Data)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_03.html">Web Application Observability (Ray Serve)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Ai Libs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_AI_Libs/00_Overview/output/01_Intro_Ray_AI_Libs_Overview_01.html">Introduction to the Ray AI Libraries: An example of using Ray data, Ray Train, Ray Tune, Ray Serve to implement a XGBoost regression model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_AI_Libs/00_Overview/output/01_Intro_Ray_AI_Libs_Overview_02.html">1. Overview of the Ray AI Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_AI_Libs/00_Overview/output/01_Intro_Ray_AI_Libs_Overview_03.html">2. Quick end-to-end example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_AI_Libs/00_intro/output/README_01.html">Introduction to Ray: Developer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Core</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_01.html">Introduction to Ray Core: Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_02.html">0. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_03.html">1. Creating Remote Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_04.html">2. Executing Remote Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_05.html">4. Putting It All Together</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_01.html">Introduction to Ray Core (Advancement): Object store, Tasks, Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_02.html">1. Object store</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_03.html">2. Chaining Tasks and Passing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_04.html">3. Task retries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_05.html">4. Task Runtime Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_06.html">5. Resource allocation and management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_07.html">6. Nested Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_08.html">7. Pattern: Pipeline data processing and waiting for results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_09.html">8. Ray Actors</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_01.html">Introduction to Ray Data: Industry Landscape</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_02.html">The Compute Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_03.html">The Orchestration Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_04.html">Distributed Computing Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_05.html">Data Processing with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_06.html">Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_01.html">Introduction to Ray Data: Ray Data + Structured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_02.html">0. What is Ray Data?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_03.html">2. Loading Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_04.html">3. Transforming Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_05.html">4. Writing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_06.html">5. Data Operations: Shuffling, Grouping and Aggregation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_07.html">6. When to use Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_01.html">Intro to Ray Data:  Ray Data + Unstructured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_02.html">1. When to Consider Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_03.html">2. How to work with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_04.html">3. Loading data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_05.html">3. Lazy execution mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_06.html">4. Transforming data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_07.html">5. Stateful transformations with Ray Actors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_08.html">6. Materializing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_09.html">7. Data Operations: grouping, aggregation, and shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_10.html">8. Persisting data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_11.html">9. Ray Data in production</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Serve/00 Serve</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_01.html">Introduction to Ray Serve with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_02.html">1. When to Consider Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_03.html">2. Overview of Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_04.html">3. Implement an image classification service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_05.html">4. Development workflow</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Train</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_01.html">ðŸ“š 01 Â· Introduction to Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_02.html">01 Â· Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_03.html">04 Â· Define ResNet-18 Model for MNIST</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_04.html">05 Â· Define the Ray Train Loop (DDP per-worker)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_05.html">06 Â· Define <code class="docutils literal notranslate"><span class="pre">train_loop_config</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_06.html">07 Â· Configure Scaling with <code class="docutils literal notranslate"><span class="pre">ScalingConfig</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_07.html">08 Â· Wrap the Model with <code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_08.html">09 Â· Build the DataLoader with <code class="docutils literal notranslate"><span class="pre">prepare_data_loader()</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_09.html">10 Â· Report Training Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_10.html">11 Â· Save Checkpoints and Report Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_11.html">14 Â· Create the <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_12.html">16 Â· Inspect the Training Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_13.html">18 Â· Load a Checkpoint for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_14.html">ðŸ”„ 02 Â· Integrating Ray Train with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_15.html">01 Â· Define Training Loop with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_16.html">02 Â· Build DataLoader from Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_17.html">03 Â· Prepare Dataset for Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_18.html">05 Â· Define Image Transformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_19.html">07 Â· Configure <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_20.html">ðŸ›¡ï¸ 03 Â· Fault Tolerance in Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_21.html">01 Â· Modify Training Loop to Enable Checkpoint Loading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_22.html">02 Â· Save Full Checkpoint with Extra State</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_23.html">04 Â· Launch Fault-Tolerant Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_24.html">05 Â· Manual Restoration from Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_25.html">07 Â· Clean Up Cluster Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Train/output/01_02_03_intro_to_ray_train_26.html">ðŸŽ‰ Wrapping Up &amp; Next Steps</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Tune/00 Tune</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_01.html">Introduction to Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_02.html">1. Loading the data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_03.html">2. Starting out with vanilla PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_04.html">3. Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_05.html">4. Ray Tune in Production</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Pytorch Lightning/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_01.html">Introduction to Ray Train: Ray Train + PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_02.html">1. When to use Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_03.html">2. Single GPU Training with PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_04.html">3. Distributed Training with Ray Train and PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_05.html">4. Ray Train in Production</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Data Batch Inference/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_01.html">Batch Inference with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_02.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_03.html">Load a dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_04.html">Batch Inference Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_05.html">Create a batch data and call the model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_06.html">Run inference on the entire dataset</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Data Processing/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_01.html">Data Processing with Ray Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_02.html">Library Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_03.html">Convert to Ray Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_04.html">Filter Ray Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_05.html">Join Two Ray Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_06.html">Preprocessing with a Tokenizer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Distributed Training/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_01.html">Distributed training with Ray Train, PyTorch and Hugging Face</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_02.html">1. Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_03.html">3. Metrics Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_04.html">4. Training function per worker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_05.html">5. Main Training Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_06.html">6. Start Training</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ray Serve Online Serving/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_01.html">Online Model Serving with Ray Serve</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_02.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_03.html">FastAPI webservice and deploy a model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_04.html">Simulate Client: Send test requests</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Generative Cv/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_01.html">04-d1 Generative computer-vision pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_02.html">1. Imports and setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_03.html">8. Pixel diffusion LightningModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_04.html">9. Ray Train <code class="docutils literal notranslate"><span class="pre">train_loop</span></code> (Lightning + Ray integration)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_05.html">12. Resume from latest checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_06.html">13. Reverse diffusion sampler</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Policy Learning/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_01.html">04-d2 Diffusion-Policy Pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_02.html">1. Imports and setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_03.html">4. DiffusionPolicy LightningModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_04.html">5. Distributed Train loop with checkpointing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_05.html">8. Reverse diffusion helper</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Rec Sys/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="output/04e_rec_sys_workload_pattern_01.html">04e Recommendation system pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04e_rec_sys_workload_pattern_02.html">1. Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04e_rec_sys_workload_pattern_03.html">7. Define matrix factorization model</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04e_rec_sys_workload_pattern_04.html">8. Define Ray Train loop (with validation, checkpointing, and Ray-managed metrics)</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04e_rec_sys_workload_pattern_05.html">11. Resume training from checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="output/04e_rec_sys_workload_pattern_06.html">12. Inference: recommend top-N items for a user</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Tabular/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Train_Tabular/00_workload/output/04b_tabular_workload_pattern_01.html">04b Tabular workload pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Tabular/00_workload/output/04b_tabular_workload_pattern_02.html">1. Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Tabular/00_workload/output/04b_tabular_workload_pattern_03.html">8. Define the Ray Train worker loop (Arrow-based, memory-efficient)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Tabular/00_workload/output/04b_tabular_workload_pattern_04.html">12. Confusion matrix visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Tabular/00_workload/output/04b_tabular_workload_pattern_05.html">15. Continue training from the latest checkpoint</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Time Series/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_01.html">04c Time-Series workload pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_02.html">1. Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_03.html">9. PositionalEncoding and Transformer model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_04.html">10. Ray Train training loop (with teacher forcing)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_05.html">13. Resume training from checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_06.html">14. Inference helper â€” Ray Data batch predictor on GPU</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Train Vision Pattern/00 Workload</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Train_Vision_Pattern/00_workload/output/04a_vision_pattern_01.html">04a Computer-vision pattern with Ray Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Vision_Pattern/00_workload/output/04a_vision_pattern_02.html">1. Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Vision_Pattern/00_workload/output/04a_vision_pattern_03.html">6. Custom <code class="docutils literal notranslate"><span class="pre">Food101Dataset</span></code> for Parquet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Vision_Pattern/00_workload/output/04a_vision_pattern_04.html">10. Helper: Ray-prepared DataLoaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Vision_Pattern/00_workload/output/04a_vision_pattern_05.html">11. <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Vision_Pattern/00_workload/output/04a_vision_pattern_06.html">12. Launch distributed training with <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Vision_Pattern/00_workload/output/04a_vision_pattern_07.html">13. Plot training and validation loss curves</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Vision_Pattern/00_workload/output/04a_vision_pattern_08.html">14. Demonstrate fault-tolerant resumption</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Train_Vision_Pattern/00_workload/output/04a_vision_pattern_09.html">15. Batch inference with Ray Data</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/courses/workloads/Train_Rec_sys/00_workload/04e_rec_sys_workload_pattern.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>04e Recommendation system pattern with Ray Train</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-you-learn-and-take-away">What you learn and take away</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-problem-are-you-solving-matrix-factorization-for-recommendations">What problem are you solving? (matrix factorization for recommendations)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input-useritemrating-triples">Input: userâ€“itemâ€“rating triples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-embedding-based-matrix-factorization">Model: embedding-based matrix factorization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-objective">Training objective</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-ranking-items-per-user">Inference: ranking items per user</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-migrate-this-recommendation-system-workload-to-a-distributed-setup-using-ray-on-anyscale">How to migrate this recommendation system workload to a distributed setup using Ray on Anyscale</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">1. Imports</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-movielens-100k-dataset">2. Load MovieLens 100K dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#point-to-parquet-dataset-uri">3. Point to Parquet dataset URI</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-dataset-ratings-users-and-items">4. Visualize dataset: ratings, users, and items</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#create-ray-dataset-from-parquet-and-encode-ids">5. Create Ray Dataset from Parquet and encode IDs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-validation-split-using-ray-data">6. Train/validation split using Ray Data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-matrix-factorization-model">7. Define matrix factorization model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-ray-train-loop-with-validation-checkpointing-and-ray-managed-metrics">8. Define Ray Train loop (with validation, checkpointing, and Ray-managed metrics)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-distributed-training-with-ray-train">9. Launch distributed training with Ray Train</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-train-and-validation-loss-curves">10. Plot train and validation loss curves</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resume-training-from-checkpoint">11. Resume training from checkpoint</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-recommend-top-n-items-for-a-user">12. Inference: recommend top-N items for a user</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#join-top-n-item-ids-with-movie-titles">13. Join top-N item IDs with movie titles</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clean-up-shared-storage">14. Clean up shared storage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#wrap-up-and-next-steps">Wrap up and next steps</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#where-can-you-take-this-next">Where can you take this next?</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="e-recommendation-system-pattern-with-ray-train">
<h1>04e Recommendation system pattern with Ray Train<a class="headerlink" href="#e-recommendation-system-pattern-with-ray-train" title="Link to this heading">#</a></h1>
<p>This notebook builds a <strong>scalable matrix factorization recommendation system</strong> using the <strong>MovieLens 100K</strong> dataset, fully distributed on an Anyscale cluster with <strong>Ray Train V2</strong> and <strong>Ray Data</strong>. For larger scale recommendation use-cases we additionally have an integration with TorchRec. An example can be found <a class="reference external" href="https://github.com/ray-project/ray/tree/d84d0fd0e88f116302c3fa22ed80fbc3d358c4a3/release/train_tests/benchmark/recsys">here</a>.</p>
<section id="what-you-learn-and-take-away">
<h2>What you learn and take away<a class="headerlink" href="#what-you-learn-and-take-away" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>How to use <strong>Ray Data</strong> to load, encode, and shard tabular datasets across many workers</p></li>
<li><p>How to <strong>stream training data</strong> directly into PyTorch using <code class="docutils literal notranslate"><span class="pre">iter_torch_batches()</span></code></p></li>
<li><p>How to build a <strong>custom training loop with validation and checkpointing</strong> using <code class="docutils literal notranslate"><span class="pre">ray.train.report()</span></code></p></li>
<li><p>How to use <strong>Ray Train V2â€™s fault-tolerant trainer</strong> to resume training from the latest checkpoint with no extra logic</p></li>
<li><p>How to separate <strong>training, evaluation, and inference</strong> while keeping all code modular and distributed-ready</p></li>
<li><p>How to run real-world recommendation workloads with <strong>no changes to your model code</strong>, using Rayâ€™s orchestration</p></li>
</ul>
</section>
<section id="what-problem-are-you-solving-matrix-factorization-for-recommendations">
<h2>What problem are you solving? (matrix factorization for recommendations)<a class="headerlink" href="#what-problem-are-you-solving-matrix-factorization-for-recommendations" title="Link to this heading">#</a></h2>
<p>Build a <strong>collaborative filtering recommendation system</strong> that predicts how much a user likes an item<br />
based on <strong>historical interaction data</strong>â€”in this case, user ratings from the MovieLens 100K dataset.</p>
<p>Use <strong>matrix factorization</strong>, a classic yet scalable approach where you embed each user and item in a latent space.<br />
The model learns to represent users and items as vectors and predicts ratings by computing their dot product.</p>
<hr class="docutils" />
</section>
<section id="input-useritemrating-triples">
<h2>Input: userâ€“itemâ€“rating triples<a class="headerlink" href="#input-useritemrating-triples" title="Link to this heading">#</a></h2>
<p>Each row in the dataset represents a userâ€™s explicit rating of a movie:</p>
<div class="math notranslate nohighlight">
\[
(u, {i}, r) \in \{\text{users}\} \times \{\text{items}\} \times \{1, 2, 3, 4, 5\}
\]</div>
<p>Encode these using contiguous integer indices (<code class="docutils literal notranslate"><span class="pre">user_idx</span></code>, <code class="docutils literal notranslate"><span class="pre">item_idx</span></code>)<br />
and normalize them for efficient embedding lookup and training.</p>
<hr class="docutils" />
</section>
<section id="model-embedding-based-matrix-factorization">
<h2>Model: embedding-based matrix factorization<a class="headerlink" href="#model-embedding-based-matrix-factorization" title="Link to this heading">#</a></h2>
<p>Learn an embedding vector for each user and each item:</p>
<div class="math notranslate nohighlight">
\[
U_{u} \in \mathbb{R}^d, \quad V_{i} \in \mathbb{R}^d
\]</div>
<p>The predicted rating is the dot product of these vectors:</p>
<div class="math notranslate nohighlight">
\[
\hat{r}_{u,{i}} = U_{u}^\top V_{i}
\]</div>
<p>The embedding dimension <span class="math notranslate nohighlight">\(d\)</span> controls model capacity.</p>
<hr class="docutils" />
</section>
<section id="training-objective">
<h2>Training objective<a class="headerlink" href="#training-objective" title="Link to this heading">#</a></h2>
<p>Minimize <strong>Mean Squared Error (MSE)</strong> between predicted and actual ratings:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L} = \mathbb{E}_{(u, {i}, r)}\ \big(\hat{r}_{u,{i}} - r\big)^2
\]</div>
<p>This encourages the model to assign higher scores to userâ€“item pairs that historically received high ratings.</p>
<hr class="docutils" />
</section>
<section id="inference-ranking-items-per-user">
<h2>Inference: ranking items per user<a class="headerlink" href="#inference-ranking-items-per-user" title="Link to this heading">#</a></h2>
<p>Once the model is trained, you can recommend items by computing predicted scores for a target user<br />
against <strong>all items in the catalog</strong> (approximate methods can later be applied at scale):</p>
<div class="math notranslate nohighlight">
\[
\hat{r}_{u, *} = U_{u}^\top V^\top
\]</div>
<p>Sort these scores and return the top-N items as personalized recommendations.</p>
<hr class="docutils" />
</section>
<section id="how-to-migrate-this-recommendation-system-workload-to-a-distributed-setup-using-ray-on-anyscale">
<h2>How to migrate this recommendation system workload to a distributed setup using Ray on Anyscale<a class="headerlink" href="#how-to-migrate-this-recommendation-system-workload-to-a-distributed-setup-using-ray-on-anyscale" title="Link to this heading">#</a></h2>
<p>This tutorial <strong>migrates a local matrix factorization pipeline for recommendation into a distributed, fault-tolerant training loop using Ray Train and Ray Data on Anyscale</strong>.</p>
<p>Approach the transition with the following steps:</p>
<ol class="arabic simple">
<li><p><strong>Convert parquet files to sharded Ray Dataset</strong><br />
Load MovieLens 100K to parquet, encode the IDs to create a <strong>multi-block Ray Dataset</strong>. Each block is a training shard that Ray can distribute across workers.</p></li>
<li><p><strong>Stream Torch data loaders</strong><br />
Instead of manually writing PyTorch <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> logic, use <code class="docutils literal notranslate"><span class="pre">iter_torch_batches()</span></code> from <strong>Ray Data</strong> to stream batches directly into each worker. Ray handles all the parallelism and sharding behind the scenes.</p></li>
<li><p><strong>Convert a single-node PyTorch process to a multi-GPU distributed training</strong><br />
Write a minimal <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code> that runs on each Ray worker. Using <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> and <code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code>, scale this loop across 8 GPU workers automatically, where each works on its own data shard.</p></li>
<li><p><strong>Configure structured epoch logging and checkpoints</strong><br />
Each epoch logs <code class="docutils literal notranslate"><span class="pre">train_loss</span></code> and <code class="docutils literal notranslate"><span class="pre">val_loss</span></code> and report checkpoints with <code class="docutils literal notranslate"><span class="pre">ray.train.report(checkpoint=...)</span></code>. This enables <strong>automatic recovery and metric tracking</strong> without any additional code.</p></li>
<li><p><strong>Declaratively configure tolerance, checkpointing and scaling</strong><br />
Configure fault tolerance, checkpointing, and scaling using <code class="docutils literal notranslate"><span class="pre">ScalingConfig</span></code>, <code class="docutils literal notranslate"><span class="pre">CheckpointConfig</span></code>, and <code class="docutils literal notranslate"><span class="pre">FailureConfig</span></code>. This lets Ray and Anyscale handle retries, recovery, and GPU orchestration.</p></li>
<li><p><strong>Write lightweight Python functions for post- inferfence</strong><br />
After training, load the latest checkpoint and generate top-N recommendations for any user with a simple forward pass. No retraining, no re-initialization, just pure PyTorch inference.</p></li>
</ol>
<p>With just a few changes to your core code, scale a traditional recommendation pipeline across a Ray cluster with <strong>distributed data loading, checkpointing, fault tolerance, and parallel training</strong>, all fully managed by Anyscale.</p>
</section>
<section id="imports">
<h2>1. Imports<a class="headerlink" href="#imports" title="Link to this heading">#</a></h2>
<p>Start by importing all the libraries you need for the rest of the notebook. These include standard utilities like <code class="docutils literal notranslate"><span class="pre">os</span></code>, <code class="docutils literal notranslate"><span class="pre">json</span></code>, and <code class="docutils literal notranslate"><span class="pre">pandas</span></code>, as well as deep learning libraries like PyTorch and visualization tools like <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>.</p>
<p>Also, import everything needed for <strong>distributed training and data processing with Ray</strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ray</span></code> and <code class="docutils literal notranslate"><span class="pre">ray.data</span></code> provide the high-level distributed data API.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ray.train</span></code> gives you <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code>, <code class="docutils literal notranslate"><span class="pre">ScalingConfig</span></code>, checkpointing, and metrics reporting.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prepare_model</span></code> wraps your PyTorch model for multi-worker training with Distributed Data Parallel (DDP).</p></li>
</ul>
<p>A few extra helpers like <code class="docutils literal notranslate"><span class="pre">tqdm</span></code> and <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> round out the list for progress bars and quick offline preprocessing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 00. Runtime setup</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span><span class="o">,</span><span class="w"> </span><span class="nn">sys</span><span class="o">,</span><span class="w"> </span><span class="nn">subprocess</span>

<span class="c1"># Non-secret env var </span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;RAY_TRAIN_V2_ENABLED&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>

<span class="c1"># Install Python dependencies </span>
<span class="n">subprocess</span><span class="o">.</span><span class="n">check_call</span><span class="p">([</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="p">,</span> <span class="s2">&quot;-m&quot;</span><span class="p">,</span> <span class="s2">&quot;pip&quot;</span><span class="p">,</span> <span class="s2">&quot;install&quot;</span><span class="p">,</span> <span class="s2">&quot;--no-cache-dir&quot;</span><span class="p">,</span>
    <span class="s2">&quot;torch==2.8.0&quot;</span><span class="p">,</span>
    <span class="s2">&quot;matplotlib==3.10.6&quot;</span><span class="p">,</span>
    <span class="s2">&quot;pyarrow==14.0.2&quot;</span><span class="p">,</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 01. Imports</span>

<span class="c1"># Standard libraries</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">uuid</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">zipfile</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">shutil</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>

<span class="c1"># PyTorch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="c1"># Ray</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ray.data</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.train</span><span class="w"> </span><span class="kn">import</span> <span class="n">ScalingConfig</span><span class="p">,</span> <span class="n">RunConfig</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">FailureConfig</span><span class="p">,</span> <span class="n">Checkpoint</span><span class="p">,</span> <span class="n">get_checkpoint</span><span class="p">,</span> <span class="n">get_context</span><span class="p">,</span>  <span class="n">get_dataset_shard</span><span class="p">,</span> <span class="n">report</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.train.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">TorchTrainer</span><span class="p">,</span> <span class="n">prepare_model</span>

<span class="c1"># Other</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
</pre></div>
</div>
</div>
</div>
<section id="load-movielens-100k-dataset">
<h3>2. Load MovieLens 100K dataset<a class="headerlink" href="#load-movielens-100k-dataset" title="Link to this heading">#</a></h3>
<p>Download and extract the <a class="reference external" href="https://grouplens.org/datasets/movielens/100k/">MovieLens 100K</a> dataset, then persist a cleaned copy under <code class="docutils literal notranslate"><span class="pre">/mnt/cluster_storage/rec_sys_tutorial/raw/</span></code> in <strong>two formats</strong>:</p>
<ul class="simple">
<li><p><strong>CSV:</strong> <code class="docutils literal notranslate"><span class="pre">ratings.csv</span></code> (kept for later inference cells).</p></li>
<li><p><strong>Parquet dataset:</strong> <code class="docutils literal notranslate"><span class="pre">ratings_parquet/</span></code> as multiple shards (production-style blob store layout) so Ray Data can <strong>stream</strong> reads in parallel without materializing the full dataset.</p></li>
</ul>
<p>The output has four columns: <code class="docutils literal notranslate"><span class="pre">user_id</span></code>, <code class="docutils literal notranslate"><span class="pre">item_id</span></code>, <code class="docutils literal notranslate"><span class="pre">rating</span></code>, and <code class="docutils literal notranslate"><span class="pre">timestamp</span></code>.</p>
<p>The MovieLens 100K dataset contains <strong>100,000 ratings</strong> across <strong>943 users</strong> and <strong>1,682 movies</strong> â€” small enough for quick iteration, yet realistic for demonstrating distributed streaming and training with <strong>Ray Data + Ray Train</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 02. Load MovieLens 100K Dataset and store in /mnt/cluster_storage/ as CSV + Parquet</span>

<span class="c1"># Define clean working paths</span>
<span class="n">DATA_URL</span> <span class="o">=</span> <span class="s2">&quot;http://files.grouplens.org/datasets/movielens/ml-100k.zip&quot;</span>
<span class="n">LOCAL_ZIP</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/rec_sys_tutorial/ml-100k.zip&quot;</span>
<span class="n">EXTRACT_DIR</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/rec_sys_tutorial/ml-100k&quot;</span>
<span class="n">OUTPUT_CSV</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/rec_sys_tutorial/raw/ratings.csv&quot;</span>
<span class="n">PARQUET_DIR</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/rec_sys_tutorial/raw/ratings_parquet&quot;</span>

<span class="c1"># Ensure target directories exist</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;/mnt/cluster_storage/rec_sys_tutorial/raw&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Download only if not already done</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">LOCAL_ZIP</span><span class="p">):</span>
    <span class="o">!</span>wget<span class="w"> </span>-q<span class="w"> </span><span class="nv">$DATA_URL</span><span class="w"> </span>-O<span class="w"> </span><span class="nv">$LOCAL_ZIP</span>

<span class="c1"># Extract cleanly</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">EXTRACT_DIR</span><span class="p">):</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">zipfile</span>
    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">LOCAL_ZIP</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
        <span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s2">&quot;/mnt/cluster_storage/rec_sys_tutorial&quot;</span><span class="p">)</span>

<span class="c1"># Load raw file</span>
<span class="n">raw_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">EXTRACT_DIR</span><span class="p">,</span> <span class="s2">&quot;u.data&quot;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">raw_path</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;user_id&quot;</span><span class="p">,</span> <span class="s2">&quot;item_id&quot;</span><span class="p">,</span> <span class="s2">&quot;rating&quot;</span><span class="p">,</span> <span class="s2">&quot;timestamp&quot;</span><span class="p">])</span>

<span class="c1"># Persist CSV (kept for later inference cell that expects CSV)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">OUTPUT_CSV</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Persist a Parquet *dataset* (multiple files) to simulate blob storage layout</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">PARQUET_DIR</span><span class="p">):</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">PARQUET_DIR</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">PARQUET_DIR</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">NUM_PARQUET_SHARDS</span> <span class="o">=</span> <span class="mi">8</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">shard</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">NUM_PARQUET_SHARDS</span><span class="p">)):</span>
    <span class="n">shard</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">PARQUET_DIR</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;part-</span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">.parquet&quot;</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Loaded </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> ratings â†’ CSV: </span><span class="si">{</span><span class="n">OUTPUT_CSV</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Wrote Parquet dataset with </span><span class="si">{</span><span class="n">NUM_PARQUET_SHARDS</span><span class="si">}</span><span class="s2"> shards â†’ </span><span class="si">{</span><span class="n">PARQUET_DIR</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="point-to-parquet-dataset-uri">
<h3>3. Point to Parquet dataset URI<a class="headerlink" href="#point-to-parquet-dataset-uri" title="Link to this heading">#</a></h3>
<p>Instead of creating a Ray Dataset from in-memory pandas objects, this tutorial now reads data directly from a <strong>Parquet dataset</strong> stored in persistent cluster storage.</p>
<p>This URI will be used by Ray Data to <strong>stream</strong> Parquet shards efficiently across workers without loading the full dataset into memory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 03. Point to Parquet dataset URI </span>
<span class="n">DATASET_URI</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
    <span class="s2">&quot;RATINGS_PARQUET_URI&quot;</span><span class="p">,</span>
    <span class="s2">&quot;/mnt/cluster_storage/rec_sys_tutorial/raw/ratings_parquet&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Parquet dataset URI:&quot;</span><span class="p">,</span> <span class="n">DATASET_URI</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-dataset-ratings-users-and-items">
<h3>4. Visualize dataset: ratings, users, and items<a class="headerlink" href="#visualize-dataset-ratings-users-and-items" title="Link to this heading">#</a></h3>
<p>Before training, visualize the distribution of ratings, user activity, and item popularity.<br />
These plots serve as a quick sanity check to confirm the dataset loaded correctly and to highlight patterns in userâ€“item interactions:</p>
<ul class="simple">
<li><p><strong>Rating distribution:</strong> shows how often each rating (1â€“5 stars) occurs, typically skewed toward higher scores.</p></li>
<li><p><strong>Ratings per user:</strong> reveals the long-tail behavior where a few users rate many items, while most rate only a few.</p></li>
<li><p><strong>Ratings per item:</strong> similarly shows that a handful of popular items receive most of the ratings.</p></li>
</ul>
<p>This visualization works with either raw IDs (<code class="docutils literal notranslate"><span class="pre">user_id</span></code>, <code class="docutils literal notranslate"><span class="pre">item_id</span></code>) or encoded indices (<code class="docutils literal notranslate"><span class="pre">user_idx</span></code>, <code class="docutils literal notranslate"><span class="pre">item_idx</span></code>), depending on whatâ€™s available in the current DataFrame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 04. Visualize dataset: ratings, user and item activity</span>

<span class="c1"># Use encoded indices if present; otherwise fall back to raw IDs</span>
<span class="n">user_col</span> <span class="o">=</span> <span class="s2">&quot;user_idx&quot;</span> <span class="k">if</span> <span class="s2">&quot;user_idx&quot;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">else</span> <span class="s2">&quot;user_id&quot;</span>
<span class="n">item_col</span> <span class="o">=</span> <span class="s2">&quot;item_idx&quot;</span> <span class="k">if</span> <span class="s2">&quot;item_idx&quot;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">else</span> <span class="s2">&quot;item_id&quot;</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="c1"># Rating distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;rating&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">,</span><span class="mf">5.5</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Rating Distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Rating&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Frequency&quot;</span><span class="p">)</span>

<span class="c1"># Number of ratings per user</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="n">user_col</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Ratings per User&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;# Ratings&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Users&quot;</span><span class="p">)</span>

<span class="c1"># Number of ratings per item</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="n">item_col</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Ratings per Item&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;# Ratings&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Items&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="create-ray-dataset-from-parquet-and-encode-ids">
<h3>5. Create Ray Dataset from Parquet and encode IDs<a class="headerlink" href="#create-ray-dataset-from-parquet-and-encode-ids" title="Link to this heading">#</a></h3>
<p>Read the MovieLens ratings directly from the <strong>Parquet dataset</strong> using <code class="docutils literal notranslate"><span class="pre">ray.data.read_parquet()</span></code>. This keeps data in a <strong>streaming, non-materialized</strong> form suitable for large-scale distributed processing.</p>
<p>Next, build lightweight <strong>global ID mappings</strong> for users and items on the driver to convert raw <code class="docutils literal notranslate"><span class="pre">user_id</span></code> and <code class="docutils literal notranslate"><span class="pre">item_id</span></code> values into contiguous integer indices (<code class="docutils literal notranslate"><span class="pre">user_idx</span></code>, <code class="docutils literal notranslate"><span class="pre">item_idx</span></code>) required for embedding layers.<br />
This mapping step materializes only the distinct IDs (a small subset of the data) while keeping the main dataset lazy and scalable.</p>
<p>Finally, apply a <code class="docutils literal notranslate"><span class="pre">map_batches()</span></code> transformation to encode each batch of rows in parallel across the cluster.<br />
The resulting <strong>Ray Dataset</strong> remains distributed and ready for streaming batches directly into the Ray Train workers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 05. Create Ray Dataset by reading Parquet, then encode IDs via Ray</span>

<span class="c1"># Read Parquet dataset directly</span>
<span class="n">ratings_ds</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">DATASET_URI</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ… Parquet dataset loaded (streaming, non-materialized)&quot;</span><span class="p">)</span>
<span class="n">ratings_ds</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># ---- Build global ID mappings on the driver ----</span>
<span class="n">user_ids</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;user_id&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">ratings_ds</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;user_id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">take_all</span><span class="p">()])</span>
<span class="n">item_ids</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;item_id&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">ratings_ds</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;item_id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">take_all</span><span class="p">()])</span>

<span class="n">user2idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">uid</span><span class="p">:</span> <span class="n">j</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">uid</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">user_ids</span><span class="p">)}</span>
<span class="n">item2idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">iid</span><span class="p">:</span> <span class="n">j</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">iid</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">item_ids</span><span class="p">)}</span>

<span class="n">NUM_USERS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">user2idx</span><span class="p">)</span>
<span class="n">NUM_ITEMS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">item2idx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Users: </span><span class="si">{</span><span class="n">NUM_USERS</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> | Items: </span><span class="si">{</span><span class="n">NUM_ITEMS</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># ---- Encode to contiguous indices within Ray (keeps everything distributed) ----</span>
<span class="k">def</span><span class="w"> </span><span class="nf">encode_batch</span><span class="p">(</span><span class="n">pdf</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="n">pdf</span><span class="p">[</span><span class="s2">&quot;user_idx&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[</span><span class="s2">&quot;user_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">user2idx</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;int64&quot;</span><span class="p">)</span>
    <span class="n">pdf</span><span class="p">[</span><span class="s2">&quot;item_idx&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[</span><span class="s2">&quot;item_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">item2idx</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;int64&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pdf</span><span class="p">[[</span><span class="s2">&quot;user_idx&quot;</span><span class="p">,</span> <span class="s2">&quot;item_idx&quot;</span><span class="p">,</span> <span class="s2">&quot;rating&quot;</span><span class="p">,</span> <span class="s2">&quot;timestamp&quot;</span><span class="p">]]</span>

<span class="n">ratings_ds</span> <span class="o">=</span> <span class="n">ratings_ds</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span><span class="n">encode_batch</span><span class="p">,</span> <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ… Encoded Ray Dataset schema:&quot;</span><span class="p">,</span> <span class="n">ratings_ds</span><span class="o">.</span><span class="n">schema</span><span class="p">())</span>
<span class="n">ratings_ds</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-validation-split-using-ray-data">
<h3>6. Train/validation split using Ray Data<a class="headerlink" href="#train-validation-split-using-ray-data" title="Link to this heading">#</a></h3>
<p>Next, split the dataset into training and validation sets. First, shuffle the entire Ray Dataset to ensure randomization, then split by row index, using 80% for training and 20% for validation.</p>
<p>This approach is simple and scalable: Ray handles the shuffling and slicing in parallel across blocks. Also, set a fixed seed to ensure the split is reproducible. After you split it, each dataset remains a fully distributed Ray Dataset, ready to stream into workers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 06. Train/val split using Ray Data (lazy, avoids materialization)</span>

<span class="n">TRAIN_FRAC</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span>  <span class="c1"># for reproducibility</span>

<span class="c1"># Block-level shuffle + proportional split (approximate by block, lazy)</span>
<span class="n">train_ds</span><span class="p">,</span> <span class="n">val_ds</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ratings_ds</span>
    <span class="o">.</span><span class="n">randomize_block_order</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>   <span class="c1"># lightweight; no row-level materialization</span>
    <span class="o">.</span><span class="n">split_proportionately</span><span class="p">([</span><span class="n">TRAIN_FRAC</span><span class="p">])</span>  <span class="c1"># returns [train, remainder]</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ… Train/Val Split:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Train â†’ </span><span class="si">{</span><span class="n">train_ds</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> rows&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Val   â†’ </span><span class="si">{</span><span class="n">val_ds</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> rows&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="define-matrix-factorization-model">
<h2>7. Define matrix factorization model<a class="headerlink" href="#define-matrix-factorization-model" title="Link to this heading">#</a></h2>
<p>Define a simple but effective matrix factorization model using PyTorch. A learned embedding vector represents each user and item. The model predicts a rating by taking the dot product of the corresponding user and item embeddings.</p>
<p>This architecture is commonly used in collaborative filtering and serves as a strong baseline for recommendation tasks. Itâ€™s also well-suited for scaling with Ray Train and DistributedDataParallel (DDP).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 07. Define matrix factorization model</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MatrixFactorizationModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_users</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_items</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_users</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_items</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_idx</span><span class="p">,</span> <span class="n">item_idx</span><span class="p">):</span>
        <span class="n">user_vecs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_embedding</span><span class="p">(</span><span class="n">user_idx</span><span class="p">)</span>
        <span class="n">item_vecs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embedding</span><span class="p">(</span><span class="n">item_idx</span><span class="p">)</span>
        <span class="n">dot_product</span> <span class="o">=</span> <span class="p">(</span><span class="n">user_vecs</span> <span class="o">*</span> <span class="n">item_vecs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dot_product</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-ray-train-loop-with-validation-checkpointing-and-ray-managed-metrics">
<h2>8. Define Ray Train loop (with validation, checkpointing, and Ray-managed metrics)<a class="headerlink" href="#define-ray-train-loop-with-validation-checkpointing-and-ray-managed-metrics" title="Link to this heading">#</a></h2>
<p>Define the <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code>, the core function executed by each Ray Train worker.<br />
This loop handles distributed training, validation, and checkpointing with Ray-managed metrics.</p>
<p>Each worker receives its own shard of the training and validation datasets using <code class="docutils literal notranslate"><span class="pre">get_dataset_shard()</span></code>.<br />
Batches are streamed directly into PyTorch via <code class="docutils literal notranslate"><span class="pre">iter_torch_batches()</span></code>, ensuring efficient, fully distributed data loading.</p>
<p>During each epoch:</p>
<ul class="simple">
<li><p>Compute average <strong>training</strong> and <strong>validation</strong> MSE losses.</p></li>
<li><p>On <strong>rank 0</strong> only, save a temporary checkpoint (model weights + epoch metadata) using <code class="docutils literal notranslate"><span class="pre">tempfile.TemporaryDirectory()</span></code>.</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">ray.train.report()</span></code> to report metrics and attach the checkpoint; other workers report metrics only.</p></li>
</ul>
<p>All metrics are automatically captured by Ray and made available in <code class="docutils literal notranslate"><span class="pre">result.metrics_dataframe</span></code>, enabling progress tracking and fault-tolerant recovery without extra logging logic.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 08. Define Ray Train loop (with val loss, checkpointing, and Ray-managed metrics)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train_loop_per_worker</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>
    <span class="c1"># ---------------- Dataset shards -&gt; PyTorch-style iterators ---------------- #</span>
    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="n">val_ds</span>   <span class="o">=</span> <span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">iter_torch_batches</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">val_loader</span>   <span class="o">=</span> <span class="n">val_ds</span><span class="o">.</span><span class="n">iter_torch_batches</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># ---------------- Model / Optimizer ---------------- #</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">MatrixFactorizationModel</span><span class="p">(</span>
        <span class="n">num_users</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_users&quot;</span><span class="p">],</span>
        <span class="n">num_items</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_items&quot;</span><span class="p">],</span>
        <span class="n">embedding_dim</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;embedding_dim&quot;</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">))</span>

    <span class="c1"># ---------------- Checkpointing setup ---------------- #</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_world_rank</span><span class="p">()</span>
    <span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># If a checkpoint exists (auto-resume), load it</span>
    <span class="n">ckpt</span> <span class="o">=</span> <span class="n">get_checkpoint</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">ckpt</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">ckpt</span><span class="o">.</span><span class="n">as_directory</span><span class="p">()</span> <span class="k">as</span> <span class="n">ckpt_dir</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">),</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">start_epoch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;meta.pt&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">] âœ… Resumed from checkpoint at epoch </span><span class="si">{</span><span class="n">start_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># ---------------- Training loop ---------------- #</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epochs&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)):</span>
        <span class="c1"># ---- Train ----</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">user</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;user_idx&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="n">item</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;item_idx&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="n">rating</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;rating&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">user</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">rating</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="n">avg_train_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">train_losses</span><span class="p">)</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_losses</span><span class="p">))</span>

        <span class="c1"># ---- Validate ----</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
                <span class="n">user</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;user_idx&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                <span class="n">item</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;item_idx&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                <span class="n">rating</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;rating&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

                <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">user</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">rating</span><span class="p">)</span>
                <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="n">avg_val_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">val_losses</span><span class="p">)</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_losses</span><span class="p">))</span>

        <span class="c1"># Console log (optional)</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">] Train MSE: </span><span class="si">{</span><span class="n">avg_train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | Val MSE: </span><span class="si">{</span><span class="n">avg_val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="s2">&quot;train_loss&quot;</span><span class="p">:</span> <span class="n">avg_train_loss</span><span class="p">,</span>
            <span class="s2">&quot;val_loss&quot;</span><span class="p">:</span> <span class="n">avg_val_loss</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># ---- Save checkpoint &amp; report (rank 0 attaches checkpoint; others report metrics only) ----</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdir</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">))</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">},</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">,</span> <span class="s2">&quot;meta.pt&quot;</span><span class="p">))</span>
                <span class="n">ckpt_out</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_directory</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">)</span>
                <span class="n">report</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="n">ckpt_out</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">report</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="launch-distributed-training-with-ray-train">
<h3>9. Launch distributed training with Ray Train<a class="headerlink" href="#launch-distributed-training-with-ray-train" title="Link to this heading">#</a></h3>
<p>Now, launch distributed training using <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code>, Ray Trainâ€™s high-level orchestration interface. Provide it with:</p>
<ul class="simple">
<li><p>Your custom <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code> function</p></li>
<li><p>A <code class="docutils literal notranslate"><span class="pre">train_config</span></code> dictionary that specifies model dimensions, learning rate, and number of epochs</p></li>
<li><p>The sharded <code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">val</span></code> Ray Datasets</p></li>
<li><p>A <code class="docutils literal notranslate"><span class="pre">ScalingConfig</span></code> that sets the number of workers and GPU usage</p></li>
</ul>
<p>Also, configure checkpointing and fault tolerance:</p>
<ul class="simple">
<li><p>Ray keeps all checkpoints checkpoints for later plotting</p></li>
<li><p>Failed workers retry up to two times</p></li>
</ul>
<p>Calling <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code> kicks off training across the cluster. If any workers fail or disconnect, Ray restarts them and resume from the latest checkpoint.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 09. Launch distributed training with Ray TorchTrainer</span>

<span class="c1"># Define config params (use Ray-derived counts)</span>
<span class="n">train_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;num_users&quot;</span><span class="p">:</span> <span class="n">NUM_USERS</span><span class="p">,</span>
    <span class="s2">&quot;num_items&quot;</span><span class="p">:</span> <span class="n">NUM_ITEMS</span><span class="p">,</span>
    <span class="s2">&quot;embedding_dim&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
    <span class="n">train_loop_per_worker</span><span class="o">=</span><span class="n">train_loop_per_worker</span><span class="p">,</span>
    <span class="n">train_loop_config</span><span class="o">=</span><span class="n">train_config</span><span class="p">,</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>       <span class="c1"># Increase as needed</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span>         <span class="c1"># Set to True if training on GPUs</span>
    <span class="p">),</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_ds</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">:</span> <span class="n">val_ds</span><span class="p">},</span>
    <span class="n">run_config</span><span class="o">=</span><span class="n">RunConfig</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mf_ray_train&quot;</span><span class="p">,</span>
        <span class="n">storage_path</span><span class="o">=</span><span class="s2">&quot;/mnt/cluster_storage/rec_sys_tutorial/results&quot;</span><span class="p">,</span>
        <span class="n">checkpoint_config</span><span class="o">=</span><span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">num_to_keep</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span>
        <span class="n">failure_config</span><span class="o">=</span><span class="n">FailureConfig</span><span class="p">(</span><span class="n">max_failures</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Run distributed training</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-train-and-validation-loss-curves">
<h3>10. Plot train and validation loss curves<a class="headerlink" href="#plot-train-and-validation-loss-curves" title="Link to this heading">#</a></h3>
<p>After training, retrieve the full metrics history directly from <strong>Ray Trainâ€™s internal tracking</strong> via <code class="docutils literal notranslate"><span class="pre">result.metrics_dataframe</span></code>.</p>
<p>This DataFrame automatically includes all reported metrics across epochs (e.g., <code class="docutils literal notranslate"><span class="pre">train_loss</span></code>, <code class="docutils literal notranslate"><span class="pre">val_loss</span></code>) for every call to <code class="docutils literal notranslate"><span class="pre">ray.train.report()</span></code>.<br />
You use it to visualize model convergence and ensure the training loop, checkpointing, and reporting worked correctly.</p>
<p>The plotted curves show how the <strong>training</strong> and <strong>validation</strong> MSE losses evolve over timeâ€”confirming whether the model is learning effectively and when it begins to stabilize.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 10. Plot train/val loss curves (from Ray Train results)</span>

<span class="c1"># Pull the full metrics history Ray stored for this run</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">metrics_dataframe</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Keep only the columns we need (guard against extra columns)</span>
<span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="c1"># If multiple rows per epoch exist, keep the last report per epoch</span>
<span class="k">if</span> <span class="s2">&quot;epoch&quot;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="n">as_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">last</span><span class="p">()</span>

<span class="c1"># Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">if</span> <span class="s2">&quot;train_loss&quot;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Train&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="s2">&quot;val_loss&quot;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Val&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;MSE Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matrix Factorization - Loss per Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="resume-training-from-checkpoint">
<h2>11. Resume training from checkpoint<a class="headerlink" href="#resume-training-from-checkpoint" title="Link to this heading">#</a></h2>
<p>Run <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code> again to resume training from the most recent checkpoint. Since <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> was originally configured with <code class="docutils literal notranslate"><span class="pre">resume_from_checkpoint=True</span></code> and a persistent <code class="docutils literal notranslate"><span class="pre">storage_path</span></code>, Ray automatically restores the latest saved model state and continues training from the correct epoch.</p>
<p>This demonstrates Ray Trainâ€™s built-in support for fault tolerance and iterative experimentation, allowing training to pick up exactly where it left off without manual intervention.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 11. Run trainer.fit() again to resume from last checkpoint</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="inference-recommend-top-n-items-for-a-user">
<h2>12. Inference: recommend top-N items for a user<a class="headerlink" href="#inference-recommend-top-n-items-for-a-user" title="Link to this heading">#</a></h2>
<p>To demonstrate inference, generate top-10 item recommendations for a randomly selected user. Please note that the following method is meant for this small example, and <strong>Ray Data</strong> should be used for inference at scale.</p>
<p>First, reload the original <code class="docutils literal notranslate"><span class="pre">ratings.csv</span></code> and rebuild the user and item ID mappings used during training. Then, load the latest model checkpoint and restore the trained embedding weights. If you trained the model with DDP, strip the <code class="docutils literal notranslate"><span class="pre">'module.'</span></code> prefix from checkpoint keys.</p>
<p>Next, select a user, compute their embedding, and take the dot product against all item embeddings to produce predicted scores. Finally, extract the top-N items with the highest scores and print their IDs and associated scores.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 12. Inference: recommend top-N items for a user</span>

<span class="c1"># ---------------------------------------------</span>
<span class="c1"># Step 1: Reload original ratings CSV and mappings</span>
<span class="c1"># ---------------------------------------------</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;/mnt/cluster_storage/rec_sys_tutorial/raw/ratings.csv&quot;</span><span class="p">)</span>

<span class="c1"># Recompute ID mappings (same as during preprocessing)</span>
<span class="n">unique_users</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;user_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="n">unique_items</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;item_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>

<span class="n">user2idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">uid</span><span class="p">:</span> <span class="n">j</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">uid</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_users</span><span class="p">)}</span>
<span class="n">item2idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">iid</span><span class="p">:</span> <span class="n">j</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">iid</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_items</span><span class="p">)}</span>
<span class="n">idx2item</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">item2idx</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="c1"># ---------------------------------------------</span>
<span class="c1"># Step 2: Load model from checkpoint</span>
<span class="c1"># ---------------------------------------------</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MatrixFactorizationModel</span><span class="p">(</span>
    <span class="n">num_users</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">user2idx</span><span class="p">),</span>
    <span class="n">num_items</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">item2idx</span><span class="p">),</span>
    <span class="n">embedding_dim</span><span class="o">=</span><span class="n">train_config</span><span class="p">[</span><span class="s2">&quot;embedding_dim&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="k">with</span> <span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">as_directory</span><span class="p">()</span> <span class="k">as</span> <span class="n">ckpt_dir</span><span class="p">:</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">),</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="c1"># Remove &#39;module.&#39; prefix if using DDP-trained model</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;module.&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">):</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;module.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">):</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># ---------------------------------------------</span>
<span class="c1"># Step 3: Select a user and generate recommendations</span>
<span class="c1"># ---------------------------------------------</span>
<span class="c1"># Choose a random user from the original dataset</span>
<span class="n">original_user_id</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;user_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">user_idx</span> <span class="o">=</span> <span class="n">user2idx</span><span class="p">[</span><span class="n">original_user_id</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generating recommendations for user_id=</span><span class="si">{</span><span class="n">original_user_id</span><span class="si">}</span><span class="s2"> (internal idx=</span><span class="si">{</span><span class="n">user_idx</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="c1"># Compute scores for all items for this user</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">user_vector</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">user_embedding</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">user_idx</span><span class="p">]))</span>           <span class="c1"># [1, D]</span>
    <span class="n">item_vectors</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">item_embedding</span><span class="o">.</span><span class="n">weight</span>                             <span class="c1"># [num_items, D]</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">user_vector</span><span class="p">,</span> <span class="n">item_vectors</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>          <span class="c1"># [num_items]</span>

    <span class="n">topk</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">top_item_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx2item</span><span class="p">[</span><span class="n">j</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">topk</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>
    <span class="n">top_scores</span> <span class="o">=</span> <span class="n">topk</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="c1"># ---------------------------------------------</span>
<span class="c1"># Step 4: Print top-N recommendations</span>
<span class="c1"># ---------------------------------------------</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Top 10 Recommended Item IDs:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">item_id</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">top_item_ids</span><span class="p">,</span> <span class="n">top_scores</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">. Item ID: </span><span class="si">{</span><span class="n">item_id</span><span class="si">}</span><span class="s2"> | Score: </span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="join-top-n-item-ids-with-movie-titles">
<h3>13. Join top-N item IDs with movie titles<a class="headerlink" href="#join-top-n-item-ids-with-movie-titles" title="Link to this heading">#</a></h3>
<p>To make your recommendations more interpretable, join the top-10 recommended <code class="docutils literal notranslate"><span class="pre">item_id</span></code>s with movie titles from the original <code class="docutils literal notranslate"><span class="pre">u.item</span></code> metadata file.</p>
<p>Load only the relevant columnsâ€”<code class="docutils literal notranslate"><span class="pre">item_id</span></code> and <code class="docutils literal notranslate"><span class="pre">title</span></code>â€”from <code class="docutils literal notranslate"><span class="pre">u.item</span></code>, then merge them with the top-N predictions you computed in the previous step. The result is a user-friendly list of movie titles with associated predicted scores, rather than raw item IDs.</p>
<p>This small addition makes the model outputs easier to understand and more useful for downstream applications.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 13. Join top-N item IDs with movie titles from u.item</span>

<span class="n">item_metadata</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;/mnt/cluster_storage/rec_sys_tutorial/ml-100k/u.item&quot;</span><span class="p">,</span>
    <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;|&quot;</span><span class="p">,</span>
    <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;latin-1&quot;</span><span class="p">,</span>
    <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>  <span class="c1"># Only item_id and title</span>
    <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;item_id&quot;</span><span class="p">,</span> <span class="s2">&quot;title&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Join with top-N items</span>
<span class="n">top_items_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;item_id&quot;</span><span class="p">:</span> <span class="n">top_item_ids</span><span class="p">,</span>
    <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">top_scores</span>
<span class="p">})</span>

<span class="n">merged</span> <span class="o">=</span> <span class="n">top_items_df</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">item_metadata</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;item_id&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Top 10 Recommended Movies:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">merged</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> | Score: </span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="clean-up-shared-storage">
<h3>14. Clean up shared storage<a class="headerlink" href="#clean-up-shared-storage" title="Link to this heading">#</a></h3>
<p>Reclaim cluster disk space by deleting the entire tutorial output directory.<br />
Run this only when youâ€™re <strong>sure</strong> you donâ€™t need the checkpoints or metrics anymore.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 14. Cleanup -- delete checkpoints and metrics from model training</span>

<span class="n">TARGET_PATH</span> <span class="o">=</span> <span class="s2">&quot;/mnt/cluster_storage/rec_sys_tutorial&quot;</span>  <span class="c1"># please note, that /mnt/cluster_storage/ only exists on Anyscale</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">TARGET_PATH</span><span class="p">):</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">TARGET_PATH</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Deleted everything under </span><span class="si">{</span><span class="n">TARGET_PATH</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âš ï¸ Path does not exist: </span><span class="si">{</span><span class="n">TARGET_PATH</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="wrap-up-and-next-steps">
<h3>Wrap up and next steps<a class="headerlink" href="#wrap-up-and-next-steps" title="Link to this heading">#</a></h3>
<p>In this tutorial, you used <strong>Ray Train and Ray Data on Anyscale</strong> to scale a full matrix factorization recommendation system, end-to-end, from a raw CSV to multi-GPU distributed training and personalized top-N item recommendations.</p>
<p>You should now feel confident:</p>
<ul class="simple">
<li><p>Using <strong>Ray Data</strong> to preprocess, encode, and shard large tabular datasets</p></li>
<li><p>Streaming data into PyTorch with <code class="docutils literal notranslate"><span class="pre">iter_torch_batches()</span></code> for efficient training</p></li>
<li><p>Scaling matrix factorization across multiple GPUs with <strong>Ray Trainâ€™s <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code></strong></p></li>
<li><p>Saving and resuming training with <strong>Ray Checkpoints</strong></p></li>
<li><p>Running multi-node, fault-tolerant jobs without touching orchestration code</p></li>
<li><p>Performing post-training inference using Ray-restored model checkpoints and learned user and item embeddings</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="where-can-you-take-this-next">
<h3>Where can you take this next?<a class="headerlink" href="#where-can-you-take-this-next" title="Link to this heading">#</a></h3>
<p>The following are a few directions you can explore to extend or adapt this workload:</p>
<ol class="arabic simple">
<li><p><strong>Ranking metrics and evaluation</strong></p>
<ul class="simple">
<li><p>Add metrics like <strong>Root Mean Squared Error (RMSE)</strong>, <strong>Normalized Discounted Cumulative Gain (NDCG)</strong>, or <strong>Hit&#64;K</strong> to evaluate recommendation quality.</p></li>
<li><p>Filter out already-rated items during inference to measure novelty.</p></li>
</ul>
</li>
<li><p><strong>Two-tower and deep models</strong></p>
<ul class="simple">
<li><p>Replace dot product with a <strong>two-tower neural model</strong> or a <strong>deep MLP</strong>.</p></li>
<li><p>Add side features (for example, timestamp, genre) into each tower for better personalization.</p></li>
</ul>
</li>
<li><p><strong>Recommendation personalization</strong></p>
<ul class="simple">
<li><p>Store and cache user embeddings after training.</p></li>
<li><p>Run lightweight inference tasks to generate recommendations in real-time.</p></li>
</ul>
</li>
<li><p><strong>Content-based or hybrid models</strong></p>
<ul class="simple">
<li><p>Join movie metadata (genres, tags) and build a hybrid collaborativeâ€“content model.</p></li>
<li><p>Embed titles or genres using pre-trained language models.</p></li>
</ul>
</li>
<li><p><strong>Hyperparameter optimization</strong></p>
<ul class="simple">
<li><p>Use <strong>Ray Tune</strong> to sweep embedding sizes, learning rates, or regularization.</p></li>
<li><p>Track performance over epochs and checkpoint the best models automatically.</p></li>
</ul>
</li>
<li><p><strong>Data scaling</strong></p>
<ul class="simple">
<li><p>Switch from MovieLens 100K to 1M or 10M as Ray Data handles it seamlessly.</p></li>
<li><p>Save and load from cloud object storage (S3, GCS) for real-world deployments.</p></li>
</ul>
</li>
<li><p><strong>Production inference</strong></p>
<ul class="simple">
<li><p>Wrap the recommendation system into a <strong>Ray Serve</strong> endpoint for serving top-N results using <strong>Ray Data</strong> based inference.</p></li>
<li><p>Build a simple demo that recommends movies to live users.</p></li>
</ul>
</li>
<li><p><strong>End-to-end MLOps</strong></p>
<ul class="simple">
<li><p>Register the best model with MLflow or Weights &amp; Biases.</p></li>
<li><p>Package the training job as a Ray job and schedule it with Anyscale.</p></li>
</ul>
</li>
<li><p><strong>Multi-tenant recommendation systems</strong></p>
<ul class="simple">
<li><p>Extend this to support <strong>multiple audiences</strong> or contexts (for example, multi-country, A/B groups).</p></li>
<li><p>Train and serve context-aware models in parallel using Ray.</p></li>
</ul>
</li>
</ol>
<p>This pattern gives you a solid foundation for scaling recommendation workloads across real datasets and real infrastructureâ€”without rewriting your model or managing your cluster.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./courses/workloads/Train_Rec_sys/00_workload"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-you-learn-and-take-away">What you learn and take away</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-problem-are-you-solving-matrix-factorization-for-recommendations">What problem are you solving? (matrix factorization for recommendations)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input-useritemrating-triples">Input: userâ€“itemâ€“rating triples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-embedding-based-matrix-factorization">Model: embedding-based matrix factorization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-objective">Training objective</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-ranking-items-per-user">Inference: ranking items per user</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-migrate-this-recommendation-system-workload-to-a-distributed-setup-using-ray-on-anyscale">How to migrate this recommendation system workload to a distributed setup using Ray on Anyscale</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">1. Imports</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-movielens-100k-dataset">2. Load MovieLens 100K dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#point-to-parquet-dataset-uri">3. Point to Parquet dataset URI</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-dataset-ratings-users-and-items">4. Visualize dataset: ratings, users, and items</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#create-ray-dataset-from-parquet-and-encode-ids">5. Create Ray Dataset from Parquet and encode IDs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-validation-split-using-ray-data">6. Train/validation split using Ray Data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-matrix-factorization-model">7. Define matrix factorization model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-ray-train-loop-with-validation-checkpointing-and-ray-managed-metrics">8. Define Ray Train loop (with validation, checkpointing, and Ray-managed metrics)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-distributed-training-with-ray-train">9. Launch distributed training with Ray Train</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-train-and-validation-loss-curves">10. Plot train and validation loss curves</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resume-training-from-checkpoint">11. Resume training from checkpoint</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-recommend-top-n-items-for-a-user">12. Inference: recommend top-N items for a user</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#join-top-n-item-ids-with-movie-titles">13. Join top-N item IDs with movie titles</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clean-up-shared-storage">14. Clean up shared storage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#wrap-up-and-next-steps">Wrap up and next steps</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#where-can-you-take-this-next">Where can you take this next?</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book community
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>