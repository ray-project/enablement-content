{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08 \u00b7 Pixel Diffusion LightningModule  \n",
    "A minimal **de-noising diffusion** policy:  \n",
    "* Input = noisy image + scalar timestep (packed as a 4-channel tensor)  \n",
    "* Output = predicted noise \u03f5  \n",
    "Log per-epoch losses and save them to a shared JSON so every worker can later plot global curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08. Pixel De-noising Diffusion Model\n",
    "\n",
    "class PixelDiffusion(pl.LightningModule):\n",
    "    \"\"\"Tiny CNN that predicts noise \u03f5 given noisy image + timestep.\"\"\"\n",
    "\n",
    "    def __init__(self, max_t=1000, log_path=None):\n",
    "        super().__init__()\n",
    "        self.max_t = max_t\n",
    "        self.log_path = log_path or \"/mnt/cluster_storage/generative_cv/epoch_metrics.json\"\n",
    "\n",
    "        # Network: (3\u202f+\u202f1)\u2011channel input \u2192 3\u2011channel noise prediction\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, 3, padding=1),\n",
    "        )\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self._train_losses, self._val_losses = [], []\n",
    "\n",
    "    # ---------- forward ----------\n",
    "    def forward(self, noisy_img, t):\n",
    "        \"\"\"noisy_img: Bx3xHxW,  t: B (int) or Bx1 scalar\"\"\"\n",
    "        b, _, h, w = noisy_img.shape\n",
    "        t_scaled = (t / self.max_t).view(-1, 1, 1, 1).float().to(noisy_img.device)\n",
    "        t_img = t_scaled.expand(-1, 1, h, w)\n",
    "        x = torch.cat([noisy_img, t_img], dim=1)  # 4 channels\n",
    "        return self.net(x)\n",
    "    \n",
    "    # ---------- training / validation steps ----------\n",
    "    def _shared_step(self, batch):\n",
    "        clean = batch[\"image\"].to(self.device)             # Bx3xHxW, \u20111\u20261\n",
    "        noise = torch.randn_like(clean)                    # \u03f5 ~ N(0,\u202f1)\n",
    "        t = torch.randint(0, self.max_t, (clean.size(0),), device=self.device)\n",
    "        noisy = clean + noise                              # x_t = x_0 + \u03f5\n",
    "        pred_noise = self(noisy, t)\n",
    "        return self.loss_fn(pred_noise, noise)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._shared_step(batch)\n",
    "        self._train_losses.append(loss.item())\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._shared_step(batch)\n",
    "        self._val_losses.append(loss.item())\n",
    "        return loss\n",
    "\n",
    "    # ---------- epoch end logging ----------\n",
    "    def on_train_epoch_end(self):\n",
    "        rank = get_context().get_world_rank()\n",
    "        if rank == 0:\n",
    "            train_avg = np.mean(self._train_losses)\n",
    "            val_avg   = np.mean(self._val_losses) if self._val_losses else None\n",
    "            if val_avg is not None:\n",
    "                print(f\"[Epoch {self.current_epoch}] train={train_avg:.4f}  val={val_avg:.4f}\")\n",
    "            else:\n",
    "                print(f\"[Epoch {self.current_epoch}] train={train_avg:.4f}  val=N/A\")\n",
    "\n",
    "            # Append to shared JSON so you can plot later\n",
    "            if os.path.exists(self.log_path):\n",
    "                with open(self.log_path, \"r\") as f: logs = json.load(f)\n",
    "            else:\n",
    "                logs = []\n",
    "            logs.append({\"epoch\": self.current_epoch+1, \"train_loss\": train_avg, \"val_loss\": val_avg})\n",
    "            with open(self.log_path, \"w\") as f: json.dump(logs, f)\n",
    "\n",
    "        # Clear per\u2011epoch trackers\n",
    "        self._train_losses.clear(); self._val_losses.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=2e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}