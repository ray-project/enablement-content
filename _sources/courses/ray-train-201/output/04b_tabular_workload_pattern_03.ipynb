{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 \u00b7 Custom per-worker training loop  \n",
    "Ray Train launches one copy of `train_func` on every worker (16 CPUs in your case).  \n",
    "Inside the loop you:  \n",
    "1. Pull the local shard of both the training and validation Ray datasets.  \n",
    "2. Convert each pandas shard into an XGBoost `DMatrix` (efficient Certificate Signing Request (CSR) format).  \n",
    "3. Resume from an existing checkpoint if Ray passed one in with `get_checkpoint()`.  \n",
    "4. Call `xgb.train`, handing it a `RayTrainReportCallback` so that **every boosting round automatically reports metrics**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08. Custom Ray Train loop for XGBoost (CPU)\n",
    "\n",
    "def train_func(config):\n",
    "    \"\"\"Per-worker training loop executed by Ray Train.\"\"\"\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1. Pull this worker\u2019s data shard from Ray Datasets\n",
    "    # --------------------------------------------------------\n",
    "    label_col   = config[\"label_column\"]\n",
    "    train_df    = get_dataset_shard(\"train\").materialize().to_pandas()\n",
    "    eval_df     = get_dataset_shard(\"evaluation\").materialize().to_pandas()\n",
    "    feature_cols = [c for c in train_df.columns if c != label_col]\n",
    "\n",
    "    # Convert pandas \u2192 DMatrix (fast CSR format used by XGBoost)\n",
    "    dtrain = xgb.DMatrix(train_df[feature_cols], label=train_df[label_col])\n",
    "    deval  = xgb.DMatrix(eval_df[feature_cols],  label=eval_df[label_col])\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 2. Train booster \u2014 RayTrainReportCallback handles:\n",
    "    #       \u2022 per-round ray.train.report(...)\n",
    "    #       \u2022 checkpoint upload to Ray storage\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    # Optional resume from checkpoint (Ray sets this automatically if resuming)\n",
    "    ckpt = get_checkpoint()\n",
    "    if ckpt:\n",
    "        with ckpt.as_directory() as d:\n",
    "            model_path = os.path.join(d, RayTrainReportCallback.CHECKPOINT_NAME)\n",
    "            booster = xgb.Booster()\n",
    "            booster.load_model(model_path)\n",
    "            print(f\"[Rank {get_context().get_world_rank()}] Resumed from checkpoint\")\n",
    "    else:\n",
    "        booster = None\n",
    "    \n",
    "    evals_result = {}  # <- XGBoost fills this with per-iteration metrics\n",
    "\n",
    "    xgb.train(\n",
    "        params          = config[\"params\"],\n",
    "        dtrain          = dtrain,\n",
    "        evals           = [(dtrain, \"train\"), (deval, \"validation\")],  # \u2190 CHANGED label only\n",
    "        num_boost_round = config[\"num_boost_round\"],\n",
    "        xgb_model       = booster,  # <- resumes if booster is not None\n",
    "        evals_result    = evals_result,  # <- NEW: capture metrics per round\n",
    "        callbacks=[\n",
    "            RayTrainReportCallback()  # \u2190 CHANGED: let it auto-collect metrics\n",
    "        ],\n",
    "    )\n",
    "    # --------------------------------------------------------\n",
    "    # 3. Rank-0 writes metrics JSON to the shared path\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    if get_context().get_world_rank() == 0:\n",
    "        out_json_path = config[\"out_json_path\"]\n",
    "\n",
    "        # Optionally add a quick \u201cbest\u201d summary for convenience\n",
    "        v_hist = evals_result.get(\"validation\", {}).get(\"mlogloss\", [])\n",
    "        best_idx = int(np.argmin(v_hist)) if len(v_hist) else None\n",
    "        payload = {\n",
    "            \"evals_result\": evals_result,\n",
    "            \"best\": {\n",
    "                \"iteration\": (best_idx + 1) if best_idx is not None else None,\n",
    "                \"validation-mlogloss\": (float(v_hist[best_idx]) if best_idx is not None else None),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        os.makedirs(os.path.dirname(out_json_path), exist_ok=True)\n",
    "        with open(out_json_path, \"w\") as f:\n",
    "            json.dump(payload, f)\n",
    "        print(f\"[Rank 0] Wrote metrics JSON \u2192 {out_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 \u00b7 Configure XGBoost and build the Trainer  \n",
    "Here you define all model hyper-parameters (objective, number of classes, CPU tree method, etc.) and wrap `train_func` inside an `XGBoostTrainer`.  \n",
    "* `ScalingConfig(num_workers=16, use_gpu=False)` allocates one CPU per worker.  \n",
    "* `CheckpointConfig(checkpoint_frequency=10, num_to_keep=3)` keeps the three most recent checkpoints.  \n",
    "* `FailureConfig(max_failures=1)` tells Ray to retry training up to one time if a worker crashes.  \n",
    "Because you pass the Ray Datasets directly, Ray takes care of sharding them evenly across workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 09. XGBoost config + Trainer (uses train_func above)\n",
    "xgb_params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"num_class\": 7,\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"tree_method\": \"hist\",  # CPU histogram algorithm \n",
    "    \"eta\": 0.3,\n",
    "    \"max_depth\": 8,\n",
    "}\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "    train_func,                \n",
    "    scaling_config   = ScalingConfig(num_workers=16, use_gpu=False),\n",
    "    datasets         = {\"train\": train_ds, \"evaluation\": val_ds},\n",
    "    train_loop_config={\n",
    "        \"label_column\": \"label\",\n",
    "        \"params\": xgb_params,\n",
    "        \"num_boost_round\": 50,  # Increase or decrease to adjust training iterations\n",
    "        \"out_json_path\": \"/mnt/cluster_storage/covtype/results/covtype_xgb_cpu/metrics.json\",\n",
    "    },\n",
    "    run_config       = RunConfig(\n",
    "        name=\"covtype_xgb_cpu\",\n",
    "        storage_path=\"/mnt/cluster_storage/covtype/results\",\n",
    "        checkpoint_config=CheckpointConfig(checkpoint_frequency=10, num_to_keep=1),\n",
    "        failure_config=FailureConfig(max_failures=1),  # resume up to 3 times\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 \u00b7 Start distributed training  \n",
    "`trainer.fit()` blocks until all boosting rounds finish (or until Ray exhausts retries).  The result object contains the last reported metrics and the best checkpoint found so far. Print the final validation log-loss and keep a handle to the checkpoint for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Fit the trainer (reports eval metrics every boosting round)\n",
    "result = trainer.fit()\n",
    "best_ckpt = result.checkpoint            # saved automatically by Trainer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 \u00b7 Plot log-loss over boosting rounds  \n",
    "During training you captured the full per-round evaluation history using XGBoost\u2019s built-in `evals_result` and saved it to JSON. Reloading that JSON now gives you both training and validation log-loss values for each boosting round. Plotting these lists against their round index shows how the model converges: training loss decrease steadily, while validation loss follows, maintaining a small gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Plot evaluation history from saved JSON\n",
    "\n",
    "with open(\"/mnt/cluster_storage/covtype/results/covtype_xgb_cpu/metrics.json\") as f:\n",
    "    payload = json.load(f)\n",
    "\n",
    "hist = payload[\"evals_result\"]\n",
    "train = hist[\"train\"][\"mlogloss\"]\n",
    "val   = hist[\"validation\"][\"mlogloss\"]\n",
    "\n",
    "xs = np.arange(1, len(val) + 1)\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(xs, train, label=\"Train\")\n",
    "plt.plot(xs, val,   label=\"Val\")\n",
    "plt.xlabel(\"Boosting round\"); plt.ylabel(\"Log-loss\"); plt.title(\"XGBoost log-loss\")\n",
    "plt.grid(True); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "best = payload[\"best\"][\"validation-mlogloss\"]\n",
    "print(\"Best validation log-loss:\", best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}