{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 \u00b7 PositionalEncoding + Transformer model  \n",
    "This is the neural architecture that you train. It consists of a standard PyTorch Transformer with encoder-decoder structure and sinusoidal positional encodings. The model accepts a sequence of past observations (and optionally decoder inputs during training) and returns predictions for the future window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 09. PositionalEncoding + Transformer model (univariate)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.2, max_len=1024):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float32) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(x + self.pe[:, : x.size(1)])\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_window, horizon, d_model=64, nhead=8, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.horizon  = horizon\n",
    "        self.d_model  = d_model\n",
    "\n",
    "        self.in_proj  = nn.Linear(1, d_model)\n",
    "        self.pos_enc  = PositionalEncoding(d_model)\n",
    "        self.tr_model = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.out_proj = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, past, decoder_input=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            past           : (B, T, 1)    \u2014 encoder input\n",
    "            decoder_input  : (B, F, 1)    \u2014 optional decoder input (teacher forcing)\n",
    "        Returns:\n",
    "            preds          : (B, F)       \u2014 predicted future values\n",
    "        \"\"\"\n",
    "        B = past.size(0)\n",
    "\n",
    "        # Encoder input\n",
    "        src = self.in_proj(past) * math.sqrt(self.d_model)\n",
    "        src = self.pos_enc(src)\n",
    "\n",
    "        # Decoder input\n",
    "        if decoder_input is None:\n",
    "            decoder_input = past[:, -1:, :].repeat(1, self.horizon, 1)\n",
    "\n",
    "        tgt = self.in_proj(decoder_input) * math.sqrt(self.d_model)\n",
    "        tgt = self.pos_enc(tgt)\n",
    "\n",
    "        # Transformer forward\n",
    "        output = self.tr_model(src, tgt)  # shape: (B, F, d_model)\n",
    "        return self.out_proj(output).squeeze(-1)  # shape: (B, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 \u00b7 Ray Train training loop (with teacher forcing)  \n",
    "This is the heart of Ray Train. Each worker executes this loop independently, but Ray orchestrates everything from checkpointing to failure recovery. Include teacher forcing, feeding the shifted ground-truth to the decoder, which allows the model to learn more quickly than starting from zero. Also log training and validation loss per epoch and save checkpoints to the shared filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Ray Train train_loop_per_worker with checkpointing, teacher forcing, and clean structure\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    # 1. Instantiate and prepare the model\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    model = TimeSeriesTransformer(\n",
    "        input_window=INPUT_WINDOW,\n",
    "        horizon=HORIZON,\n",
    "        d_model=config[\"d_model\"],\n",
    "        nhead=config[\"nhead\"],\n",
    "        num_layers=config[\"num_layers\"],\n",
    "    )\n",
    "    model = train.torch.prepare_model(model)  # wrap in DDP if needed\n",
    "\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    # 2. Define optimizer and loss\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    loss_fn  = nn.SmoothL1Loss()\n",
    "\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    # 3. Restore checkpoint if available\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    start_epoch = 0\n",
    "    checkpoint = get_checkpoint()\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as ckpt_dir:\n",
    "            model.load_state_dict(torch.load(os.path.join(ckpt_dir, \"model.pt\")))\n",
    "            optimizer.load_state_dict(torch.load(os.path.join(ckpt_dir, \"optim.pt\")))\n",
    "            start_epoch = torch.load(os.path.join(ckpt_dir, \"extra.pt\"))[\"epoch\"] + 1\n",
    "        print(f\"[Rank {get_context().get_world_rank()}] Resumed @ epoch {start_epoch}\")\n",
    "\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    # 4. Load data for this worker\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    train_loader = build_dataloader(\n",
    "        os.path.join(PARQUET_DIR, \"train.parquet\"),\n",
    "        batch_size=config[\"bs\"],\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_loader = build_dataloader(\n",
    "        os.path.join(PARQUET_DIR, \"val.parquet\"),\n",
    "        batch_size=config[\"bs\"],\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    # 5. Epoch loop\n",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    for epoch in range(start_epoch, config[\"epochs\"]):\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "\n",
    "        # \u2500\u2500\u2500\u2500\u2500 Training step \u2500\u2500\u2500\u2500\u2500\n",
    "        for past, future in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Teacher forcing: shift future targets to use as decoder input\n",
    "            future = future.unsqueeze(-1)                          # (B, F, 1)\n",
    "            start_token = torch.zeros_like(future[:, :1])         # (B, 1, 1)\n",
    "            decoder_input = torch.cat([start_token, future[:, :-1]], dim=1)  # (B, F, 1)\n",
    "\n",
    "            # Forward + loss\n",
    "            pred = model(past, decoder_input)                     # (B, F)\n",
    "            loss = loss_fn(pred, future.squeeze(-1))             # (B, F) vs (B, F)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_sum += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss_sum / len(train_loader)\n",
    "\n",
    "        # \u2500\u2500\u2500\u2500\u2500 Validation step \u2500\u2500\u2500\u2500\u2500\n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for past, future in val_loader:\n",
    "                pred = model(past)                               # model inference (zeros as decoder input)\n",
    "                loss = loss_fn(pred, future)\n",
    "                val_loss_sum += loss.item()\n",
    "        avg_val_loss = val_loss_sum / len(val_loader)\n",
    "\n",
    "        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        # 6. Report metrics + optionally save checkpoint (rank 0 only)\n",
    "        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        metrics = {\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"val_loss\": avg_val_loss,\n",
    "        }\n",
    "\n",
    "        if get_context().get_world_rank() == 0:\n",
    "            print(metrics)\n",
    "\n",
    "            # Save checkpoint\n",
    "            ckpt_dir = f\"{DATA_DIR}/tmp_ckpts/epoch_{epoch}_{uuid.uuid4().hex}\"\n",
    "            os.makedirs(ckpt_dir, exist_ok=True)\n",
    "            torch.save(model.state_dict(), os.path.join(ckpt_dir, \"model.pt\"))\n",
    "            torch.save(optimizer.state_dict(), os.path.join(ckpt_dir, \"optim.pt\"))\n",
    "            torch.save({\"epoch\": epoch}, os.path.join(ckpt_dir, \"extra.pt\"))\n",
    "            checkpoint_out = Checkpoint.from_directory(ckpt_dir)\n",
    "\n",
    "            # Save loss history\n",
    "            hist_path = os.path.join(DATA_DIR, \"results\", \"history.csv\")\n",
    "            with open(hist_path, \"a\") as f:\n",
    "                f.write(f\"{epoch},{avg_train_loss:.6f},{avg_val_loss:.6f}\\n\")\n",
    "        else:\n",
    "            checkpoint_out = None\n",
    "\n",
    "        train.report(metrics, checkpoint=checkpoint_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}