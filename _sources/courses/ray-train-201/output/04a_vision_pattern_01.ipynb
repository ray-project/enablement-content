{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\uddbc\ufe0f 04a \u00b7 Computer-Vision Pattern with Ray Train\n",
    "\n",
    "This notebook walks through an end-to-end, **real-world computer-vision workflow** that runs seamlessly on an Anyscale cluster using **Ray Train**. You start by pulling a slice of the Food-101 dataset, push it through a lightweight preprocessing pipeline, store it efficiently in Parquet, and then fine-tune a ResNet-18 in a fault-tolerant, distributed manner. Along the way, you  lean on Ray\u2019s helpers to prepare data loaders, coordinate workers, checkpoint automatically, resume after failure, and even launch GPU inference jobs\u2014all without writing a single line of low-level distributed code.\n",
    "\n",
    "### What you\u2019ll learn & take away\n",
    "\n",
    "- Launch distributed training with **Ray Train\u2019s `TorchTrainer`** and configure it for multi-GPU, multi-node execution.  \n",
    "- Use **Ray Train\u2019s built-in utilities** (`prepare_model`, `prepare_data_loader`, `get_checkpoint`, `train.report`) to wrap your existing PyTorch code without modifying your modeling logic.  \n",
    "- Save and resume from **automatic, fault-tolerant checkpoints** across epochs.  \n",
    "- Offload batch **inference as a Ray remote task**, allowing you to treat inference as a scalable workload.  \n",
    "- Run end-to-end training and evaluation without needing to understand the low-level mechanics of distributed systems.\n",
    "\n",
    "By the end of the tutorial you have a working model, clear loss curves, and a hands-on feel for how Ray Train simplifies distributed computer-vision workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udd22 What problem are you solving? (Image classification with Food-101-Lite)\n",
    "\n",
    "In this notebook you train a neural network to **classify food photos** into one of **10 categories**  \n",
    "using the **Food-101-Lite** dataset\u2014a compact, 10-class subset of the original Food-101 benchmark.\n",
    "\n",
    "---\n",
    "\n",
    "### Inputs  \n",
    "\n",
    "Every sample is a 3-channel Red-Green-Blue (RGB) image, resized to $224 \\times 224$:\n",
    "\n",
    "$$\n",
    "x \\;\\in\\; [0,1]^{3 \\times 224 \\times 224}\\;.\n",
    "$$\n",
    "\n",
    "You apply standard vision transforms (normalization, random crop/flip) and batch the data with plain **PyTorch DataLoader** (wrapped by `ray.train.torch.prepare_data_loader` for distributed training).\n",
    "\n",
    "---\n",
    "\n",
    "### Labels  \n",
    "\n",
    "Each image belongs to one of ten classes:\n",
    "\n",
    "['pizza', 'hamburger', 'sushi', 'ramen', 'fried rice',\n",
    "'steak', 'hot dog', 'pancake', 'burrito', 'caesar salad']\n",
    "\n",
    "\n",
    "The label is an integer $y \\in \\{0, \\dots, 9\\}$ used for supervision.\n",
    "\n",
    "---\n",
    "\n",
    "### What does the model learn?\n",
    "\n",
    "You train a compact CNN (For example, **ResNet-18**) to map an image \\(x\\) to class probabilities:\n",
    "\n",
    "$$\n",
    "f_\\theta(x)\\;=\\;\\hat{y}\\;\\in\\;\\mathbb{R}^{10}.\n",
    "$$\n",
    "\n",
    "Training minimizes the **cross-entropy loss**\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(x,y)\\;=\\;-\\log \\bigl(\\hat{y}_{\\,y}\\bigr),\n",
    "$$\n",
    "\n",
    "so the network assigns high likelihood to the correct class.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83e\udded How you migrate this computer vision workload to a distributed setup using Ray on Anyscale\n",
    "In this tutorial, you start with a small PyTorch-based image classification task---training a ResNet-18 on a 10% slice of the Food-101 dataset, and progressively migrate it into a fully distributed, fault-tolerant training job using **Ray Train on Anyscale**. Your goal is to show you exactly how to scale *your existing workflow* without rewriting it from scratch.\n",
    "\n",
    "Here\u2019s how you do it':\n",
    "\n",
    "1. **Preprocess data and persist it in a distributed-friendly format**  \n",
    "   You take raw images from Hugging Face\u2019s `food101` dataset, apply `torchvision` resizing and center-cropping, and serialize them to **Parquet** using `pyarrow`. The system writes these Parquet files to the **Anyscale cluster\u2019s shared storage volume** (`/mnt/cluster_storage`), so any node can access them, on any worker, without duplication or sync issues.\n",
    "\n",
    "2. **Create a lightweight PyTorch `Dataset` for Parquet ingestion**  \n",
    "   Instead of using Ray Data or Hugging Face `Dataset`, you implement a custom `Food101Dataset` that reads directly from the Parquet files. This provides control over the way the system reads rows and row groups. While this isn\u2019t yet fully distributed, it allows you to simulate a real-world scenario where a developer starts with something simple before optimizing. **Note:** you use Pytorch style data loading in this tutorial to demonstrate (1) low level control in a pytorch native environment and (2) how to move pre-existing pytorch code into a distributed Anyscale environment. Other tutorials in this module incorporate Ray Data, so you can see how the two approaches differ.\n",
    "\n",
    "3. **Integrate Ray Train into the training loop**  \n",
    "   You encapsulate your existing PyTorch training logic in a `train_loop_per_worker()` function, which Ray Train executes on each worker (typically one per GPU). Inside this loop, you:\n",
    "\n",
    "   - Wrap the model with `prepare_model()` to make it compatible with distributed data parallelism.  \n",
    "   - Wrap the `DataLoader` with `prepare_data_loader()` to enable device placement and Ray worker context handling.  \n",
    "   - Add a `torch.utils.data.DistributedSampler` to each `DataLoader`, so that **data is correctly sharded across workers**\u2014each worker only processes a unique subset of the training and validation datasets.  \n",
    "   - As required by the `DistributedSampler`, all `sampler.set_epoch(epoch)` at the start of each epoch to reshuffle the data correctly.\n",
    "   - Use Ray\u2019s `Checkpoint` API to save and resume from checkpoints as needed.  \n",
    "   - Report training and validation metrics with `train.report()` after each epoch.\n",
    "\n",
    "4. **Launch training with `TorchTrainer` on an Anyscale cluster**  \n",
    "   You instantiate a `TorchTrainer` that runs:\n",
    "   - With `num_workers=8` and `use_gpu=True` (For example, across 8 A10 or A100 GPUs on Anyscale).  \n",
    "   - With `RunConfig` that sets checkpoint retention and auto-resume (with `max_failures=3`).  \n",
    "   - On infrastructure that's provisioned and scheduled by Anyscale with no manual Ray cluster setup required.  \n",
    "\n",
    "   Once launched, Ray automatically handles:\n",
    "   - Multi-node orchestration  \n",
    "   - Worker assignment and device pinning  \n",
    "   - Failure recovery and retry logic  \n",
    "   - Checkpointing and logging\n",
    "\n",
    "5. **Validate fault tolerance**  \n",
    "   You run `trainer.fit()` a second time. If manual intervention or failure interrupts the previous training, Ray picks up from the latest checkpoint. This shows **real-world robustness** without any manual checkpoint management or scripting.\n",
    "\n",
    "6. **Launch distributed GPU inference tasks**  \n",
    "   At the end, you define a Ray remote function (`@ray.remote(num_gpus=1)`) that loads the best checkpoint and runs inference on a single image from the validation set. You run this task on one GPU from the cluster.\n",
    "\n",
    "All of this runs inside a **managed Anyscale workspace**. You don\u2019t need to start or SSH into clusters, worry about node IP, or configure NCCL. The entire setup is **declarative and self-contained in this notebook**, and can be re-run or scaled up by changing a single parameter (`num_workers`).\n",
    "\n",
    "This tutorial mirrors how many ML teams operate in practice: starting with a working PyTorch training loop and migrating it to the cloud without rewriting core logic. With Ray Train on Anyscale, the migration is clean, incremental, and production-ready."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}