{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 \u00b7 Prepare Dataset for Ray Data  \n",
    "\n",
    "Ray Data works best with data in **tabular formats** such as Parquet.  \n",
    "In this step we:  \n",
    "\n",
    "- Convert the MNIST dataset into a **pandas DataFrame** with two columns:  \n",
    "  * `\"image\"` \u2192 raw image arrays  \n",
    "  * `\"label\"` \u2192 digit class (0\u20139)  \n",
    "- Write the DataFrame to disk in **Parquet format** under `/mnt/cluster_storage/`.  \n",
    "\n",
    "Parquet is efficient for both reading and distributed processing, making it a good fit for Ray Data pipelines.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03. Convert MNIST dataset into Parquet for Ray Data\n",
    "\n",
    "# Build a DataFrame with image arrays and labels\n",
    "df = pd.DataFrame({\n",
    "    \"image\": dataset.data.tolist(),   # raw image pixels (as lists)\n",
    "    \"label\": dataset.targets          # digit labels 0\u20139\n",
    "})\n",
    "\n",
    "# Persist the dataset in Parquet format (columnar, efficient for Ray Data)\n",
    "df.to_parquet(\"/mnt/cluster_storage/cifar10.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 \u00b7 Load Dataset into Ray Data  \n",
    "\n",
    "Now that the training data is stored as Parquet, we can load it back into a **Ray Dataset**:  \n",
    "\n",
    "- Use `ray.data.read_parquet()` to create a distributed Ray Dataset from the Parquet file.  \n",
    "- Each row has two columns: `\"image\"` (raw pixel array) and `\"label\"` (digit class).  \n",
    "- The dataset is automatically **sharded across the Ray cluster**, so multiple workers can read and process it in parallel.  \n",
    "\n",
    "This Ray Dataset will later be passed to the `TorchTrainer` for distributed training.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04. Load the Parquet dataset into a Ray Dataset\n",
    "\n",
    "# Read the Parquet file \u2192 creates a distributed Ray Dataset\n",
    "train_ds = ray.data.read_parquet(\"/mnt/cluster_storage/cifar10.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orphan": true,
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}