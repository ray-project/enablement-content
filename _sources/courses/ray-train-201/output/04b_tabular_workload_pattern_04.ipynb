{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 \u00b7 Evaluate the trained model  \n",
    "Pull the XGBoost `Booster` back from the checkpoint, run predictions on the entire validation set, and compute overall accuracy. Converting the Ray Dataset to pandas keeps the example short; in production you could stream batches instead of materialising the whole frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Retrieve Booster object from Ray Checkpoint\n",
    "booster = RayTrainReportCallback.get_model(best_ckpt)\n",
    "\n",
    "# Convert Ray Dataset \u2192 pandas for quick local scoring\n",
    "val_pd = val_ds.to_pandas()\n",
    "dmatrix = xgb.DMatrix(val_pd[feature_columns])\n",
    "pred_prob = booster.predict(dmatrix)\n",
    "pred_labels = np.argmax(pred_prob, axis=1)\n",
    "\n",
    "acc = accuracy_score(val_pd.label, pred_labels)\n",
    "print(f\"Validation accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13 \u00b7 Confusion matrix visualisation  \n",
    "Raw counts and row-normalised ratios highlight which cover types the model confuses most often. Diagonal dominance indicates good performance; off-diagonal hot spots may suggest a need for more data or feature engineering for those specific classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Confusion matrix\n",
    "\n",
    "cm = confusion_matrix(val_pd.label, pred_labels)  # or sample_batch.label if used\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"viridis\")\n",
    "plt.title(\"Confusion Matrix with Counts\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap=\"viridis\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14 \u00b7 CPU batch inference with Ray remote tasks  \n",
    "To demonstrate scalable inference, send a 1024-row pandas batch to a **single CPU worker**.  The remote function loads the model once per task, converts the batch to `DMatrix`, and returns class indices. Measure accuracy on the fly to confirm that out-of-process inference matches earlier results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Example: Run batch inference using Ray remote task on a CPU worker\n",
    "\n",
    "# This remote function is scheduled on a CPU-enabled Ray worker.\n",
    "# It loads a trained XGBoost model from a Ray checkpoint and runs predictions on a pandas DataFrame.\n",
    "@ray.remote(num_cpus=1)\n",
    "def predict_batch(ckpt, batch_pd):\n",
    "    # Load the trained XGBoost Booster model from the checkpoint.\n",
    "    model = RayTrainReportCallback.get_model(ckpt)\n",
    "\n",
    "    # Convert the input batch (pandas DataFrame) to DMatrix, required by XGBoost for inference.\n",
    "    dmatrix = xgb.DMatrix(batch_pd[feature_columns])\n",
    "\n",
    "    # Predict class probabilities for each row in the batch.\n",
    "    preds = model.predict(dmatrix)\n",
    "\n",
    "    # Select the class with highest predicted probability for each row.\n",
    "    return np.argmax(preds, axis=1)\n",
    "\n",
    "# Take a random sample of 1024 rows from the validation set to use as input.\n",
    "sample_batch = val_pd.sample(1024, random_state=0)\n",
    "\n",
    "# Submit the batch inference task to a Ray worker and block until it finishes.\n",
    "preds = ray.get(predict_batch.remote(best_ckpt, sample_batch))\n",
    "\n",
    "# Compute and print classification accuracy by comparing predictions to true labels.\n",
    "print(\"Sample batch accuracy:\", accuracy_score(sample_batch.label, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 \u00b7 Feature-importance diagnostics  \n",
    "XGBoost\u2019s built-in `get_score(importance_type=\"gain\")` ranks each feature by its average gain across all splits. Visualising the top-15 helps connect model behaviour back to domain knowledge. For example, elevation, and soil-type often dominate forest-cover prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Gain\u2011based feature importance\n",
    "importances = booster.get_score(importance_type=\"gain\")\n",
    "keys, gains = zip(*sorted(importances.items(), key=lambda kv: kv[1], reverse=True)[:15])\n",
    "\n",
    "plt.barh(range(len(gains)), gains)\n",
    "plt.yticks(range(len(gains)), keys)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top-15 Feature Importances (gain)\"); plt.xlabel(\"Average gain\"); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}