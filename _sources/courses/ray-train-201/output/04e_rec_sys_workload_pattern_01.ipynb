{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\udde0 04e \u00b7 Recommendation System Pattern with Ray Train \n",
    "In this notebook you build a **scalable matrix factorization recommendation system** using the **MovieLens 100K** dataset, fully distributed on an Anyscale cluster with **Ray Train V2** and **Ray Data**.\n",
    "\n",
    "### What you\u2019ll learn & take away  \n",
    "* How to use **Ray Data** to load, encode, and shard tabular datasets across many workers  \n",
    "* How to **stream training data** directly into PyTorch using `iter_torch_batches()`  \n",
    "* How to build a **custom training loop with validation and checkpointing** using `ray.train.report()`  \n",
    "* How to use **Ray Train V2's fault-tolerant trainer** to resume training from the latest checkpoint with no extra logic  \n",
    "* How to separate **training, evaluation, and inference** while keeping all code modular and distributed-ready  \n",
    "* How to run real-world recommendation workloads with **no changes to your model code**, thanks to Ray\u2019s orchestration  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udd22 What problem are you solving? (Matrix factorization for recommendations)\n",
    "\n",
    "You\u2019re building a **collaborative filtering recommendation system** that predicts how much a user likes an item  \n",
    "based on **historical interaction data** \u2014 in this case, user ratings from the MovieLens 100K dataset.\n",
    "\n",
    "Use **matrix factorization**, a classic yet scalable approach where you embed each user and item in a latent space.  \n",
    "The model learns to represent users and items as vectors and predicts ratings by computing their dot product.\n",
    "\n",
    "---\n",
    "\n",
    "### Input: User\u2013Item\u2013Rating triples\n",
    "\n",
    "Each row in the dataset represents a user\u2019s explicit rating of a movie:\n",
    "\n",
    "$$\n",
    "(u, {i}, r) \\in \\{\\text{users}\\} \\times \\{\\text{items}\\} \\times \\{1, 2, 3, 4, 5\\}\n",
    "$$\n",
    "\n",
    "Encode these using contiguous integer indices (`user_idx`, `item_idx`)  \n",
    "and normalize them for efficient embedding lookup and training.\n",
    "\n",
    "---\n",
    "\n",
    "### Model: Embedding-based matrix factorization\n",
    "\n",
    "Learn an embedding vector for each user and each item:\n",
    "\n",
    "$$\n",
    "U_{u} \\in \\mathbb{R}^d, \\quad V_{i} \\in \\mathbb{R}^d\n",
    "$$\n",
    "\n",
    "The predicted rating is the dot product of these vectors:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{u,{i}} = U_{u}^\\top V_{i}\n",
    "$$\n",
    "\n",
    "The embedding dimension $d$ controls model capacity.\n",
    "\n",
    "---\n",
    "\n",
    "### Training objective\n",
    "\n",
    "Minimize **Mean Squared Error (MSE)** between predicted and actual ratings:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\mathbb{E}_{(u, {i}, r)}\\ \\big(\\hat{r}_{u,{i}} - r\\big)^2\n",
    "$$\n",
    "\n",
    "This encourages the model to assign higher scores to user\u2013item pairs that historically received high ratings.\n",
    "\n",
    "---\n",
    "\n",
    "### Inference: ranking items per user\n",
    "\n",
    "Once trained, you can recommend items by computing predicted scores for a target user  \n",
    "against **all items in the catalog**:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{u, *} = U_{u}^\\top V^\\top\n",
    "$$\n",
    "\n",
    "Sort these scores and return the top-N items as personalized recommendations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83e\udded How you\u2019ll migrate this recommendation system workload to a distributed setup using Ray on Anyscale\n",
    "\n",
    "This tutorial walks through how to **migrate a local matrix factorization pipeline for recommendation into a distributed, fault-tolerant training loop using Ray Train and Ray Data on Anyscale**.\n",
    "\n",
    "Here\u2019s how you approach the transition:\n",
    "\n",
    "1. **Pandas DataFrame \u2192 Sharded Ray Dataset**  \n",
    "   Load MovieLens 100K as a pandas DataFrame, encode the IDs, and use `ray.data.from_pandas_refs()` to create a **multi-block Ray Dataset**. Each block is a training shard that Ray can distribute across workers.\n",
    "\n",
    "2. **Manual Batching \u2192 Streaming Torch Data loaders**  \n",
    "   Instead of manually writing PyTorch `Dataset` logic, use `iter_torch_batches()` from **Ray Data** to stream batches directly into each worker. Ray handles all the parallelism and sharding behind the scenes.\n",
    "\n",
    "3. **Single-node PyTorch \u2192 Multi-GPU Distributed Training**  \n",
    "   Write a minimal `train_loop_per_worker` that runs on each Ray worker. Using `TorchTrainer` and `prepare_model()`, scale this loop across 8 GPU workers automatically, where each working on its own data shard.\n",
    "\n",
    "4. **Ad-hoc Logging \u2192 Structured Epoch Logging and Checkpoints**  \n",
    "   Each epoch logs `train_loss` and `val_loss` to a shared JSON file, and report checkpoints with `ray.train.report(checkpoint=...)`. This enables **automatic recovery and metric tracking** without any additional code.\n",
    "\n",
    "5. **Resume and Scaling \u2192 Declarative Configuration**  \n",
    "   Configure fault tolerance, checkpointing, and scaling using `ScalingConfig`, `CheckpointConfig`, and `FailureConfig`. This lets Ray + Anyscale handle retries, recovery, and GPU orchestration.\n",
    "\n",
    "6. **Post-training Inference \u2192 Lightweight Python Function**  \n",
    "   After training, load the latest checkpoint and generate top-N recommendations for any user with a simple forward pass. No retraining, no re-initialization, just pure PyTorch inference.\n",
    "\n",
    "With just a few changes to your core code, scale a traditional recommendation pipeline across a Ray cluster with **distributed data loading, checkpointing, fault tolerance, and parallel training**, all fully managed by Anyscale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}