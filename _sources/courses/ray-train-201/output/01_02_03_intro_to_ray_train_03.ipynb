{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 \u00b7 Define ResNet-18 Model for MNIST  \n",
    "\n",
    "Now let\u2019s define the **ResNet-18** architecture we\u2019ll use for classification.  \n",
    "\n",
    "- `torchvision.models.resnet18` is preconfigured for **3-channel RGB input** and **ImageNet classes**.  \n",
    "- Since MNIST digits are **1-channel grayscale** images with **10 output classes**, we need two adjustments:  \n",
    "  1. Override the first convolution layer (`conv1`) to accept **`in_channels=1`**.  \n",
    "  2. Set the final layer to output **10 logits**, one per digit class (handled by `num_classes=10`).  \n",
    "\n",
    "This gives us a ResNet-18 tailored for MNIST while preserving the rest of the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04. Define ResNet-18 Model for MNIST\n",
    "\n",
    "def build_resnet18():\n",
    "    # Start with a torchvision ResNet-18 backbone\n",
    "    # Set num_classes=10 since MNIST has digits 0\u20139\n",
    "    model = resnet18(num_classes=10)\n",
    "\n",
    "    # Override the first convolution layer:\n",
    "    # - Default expects 3 channels (RGB images)\n",
    "    # - MNIST is grayscale \u2192 only 1 channel\n",
    "    # - Keep kernel size/stride/padding consistent with original ResNet\n",
    "    model.conv1 = torch.nn.Conv2d(\n",
    "        in_channels=1,   # input = grayscale\n",
    "        out_channels=64, # number of filters remains the same as original ResNet\n",
    "        kernel_size=(7, 7),\n",
    "        stride=(2, 2),\n",
    "        padding=(3, 3),\n",
    "        bias=False,\n",
    "    )\n",
    "\n",
    "    # Return the customized ResNet-18\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Migration roadmap: from standalone PyTorch to PyTorch with Ray Train</b>  \n",
    "\n",
    "The following are the steps to take a **regular PyTorch training loop** and run it in a **fully distributed setup with Ray Train**.  \n",
    "\n",
    "<ol>\n",
    "    <li><b>Configure scale and GPUs</b> \u2014 decide how many workers and whether each should use a GPU.</li>\n",
    "    <li><b>Wrap the model with Ray Train</b> \u2014 use <code>prepare_model()</code> to move the ResNet to the right device and wrap it in DDP automatically.</li>\n",
    "    <li><b>Wrap the dataset with Ray Train</b> \u2014 use <code>prepare_data_loader()</code> so each worker gets a distinct shard of MNIST, moved to the correct device.</li>\n",
    "    <li><b>Add metrics & checkpointing</b> \u2014 report training loss and save checkpoints with <code>ray.train.report()</code> from rank-0.</li>\n",
    "    <li><b>Configure persistent storage</b> \u2014 store outputs under <code>/mnt/cluster_storage/</code> so that results and checkpoints are available across the cluster.</li>\n",
    "</ol>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ray Train is built around [four key concepts](https://docs.ray.io/en/latest/train/overview.html):\n",
    "1. **Training function**: (implemented above `train_loop_ray_train`): A Python function that contains your model training logic.\n",
    "1. **Worker**: A process that runs the training function.\n",
    "1. **Scaling config**: specifices number of workers and compute resources (CPUs or GPUs, TPUs).\n",
    "1. **Trainer**: A Python class (Ray Actor) that ties together the training function, workers, and scaling configuration to execute a distributed training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|<img src=\"https://docs.ray.io/en/latest/_images/overview.png\" width=\"60%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|High-level architecture of how Ray Train|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orphan": true,
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}