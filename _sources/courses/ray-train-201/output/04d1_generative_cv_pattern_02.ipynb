{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 \u00b7 Imports & Setup  \n",
    "Pull in standard Python utilities, Ray (core, Data, Train, Lightning), and PyTorch Lightning.  \n",
    "Make sure you set the Anyscale cluster to Ray \u2265 2.48, so you get Ray Train V2 semantics automatically enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. Imports\n",
    "\n",
    "# Standard libraries\n",
    "import os, io, json, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Ray\n",
    "import ray, ray.data\n",
    "from ray.train import ScalingConfig, get_context, RunConfig, FailureConfig, CheckpointConfig, Checkpoint, get_checkpoint\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train.lightning import RayLightningEnvironment\n",
    "\n",
    "# PyTorch / Lightning\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Dataset\n",
    "from datasets import load_dataset\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm  \n",
    "from torchvision.transforms import Compose, Resize, CenterCrop\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 \u00b7 Load 10 % of Food-101  \n",
    "Next, grab roughly 7 500 images, exactly 10 % of Food-101\u2014using a single call to `load_dataset`. This trimmed subset trains quickly while still being large enough to demonstrate Ray\u2019s scaling behaviour.\n",
    "\n",
    "NOTE: skip cells 02-05 if the dataset is already downloaded, as this is the same dataset as in tutorial 04a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02. Load 10% of food101 (~7,500 images)\n",
    "ds = load_dataset(\"food101\", split=\"train[:10%]\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 \u00b7 Resize and Encode Images  \n",
    "Preprocess each image: resize to 256 pixel, center-crop to 224 pixel (the size expected by most ImageNet models), and then convert the result to raw JPEG bytes. By storing bytes instead of full Python Imaging Library (PIL) objects, you keep the dataset compact and Parquet-friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03. Resize + encode as JPEG bytes\n",
    "transform = Compose([Resize(256), CenterCrop(224)])\n",
    "records = []\n",
    "\n",
    "for example in tqdm(ds, desc=\"Preprocessing images\", unit=\"img\"):\n",
    "    try:\n",
    "        img = transform(example[\"image\"])\n",
    "        buf = io.BytesIO()\n",
    "        img.save(buf, format=\"JPEG\")\n",
    "        records.append({\n",
    "            \"image_bytes\": buf.getvalue(),\n",
    "            \"label\": example[\"label\"]\n",
    "        })\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 \u00b7 Visual Sanity Check  \n",
    "Before committing to hours of training, take nine random samples and plot them with their class names. This quick inspection lets you confirm that images are correctly resized and preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04. Visualize the dataset\n",
    "\n",
    "label_names = ds.features[\"label\"].names  # maps int \u2192 string\n",
    "\n",
    "samples = random.sample(records, 9)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(8, 8))\n",
    "fig.suptitle(\"Sample Resized Images from food101-lite\", fontsize=16)\n",
    "\n",
    "for ax, rec in zip(axs.flatten(), samples):\n",
    "    img = Image.open(io.BytesIO(rec[\"image_bytes\"]))\n",
    "    label_name = label_names[rec[\"label\"]]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(label_name)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 \u00b7 Persist to Parquet  \n",
    "Now, write the images and labels to a Parquet file. Because Parquet is columnar, you can read just the columns you need during training, which speeds up IO---especially when multiple workers are reading in parallel under Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05. Write Dataset to Parquet\n",
    "\n",
    "output_dir = \"/mnt/cluster_storage/food101_lite/parquet_256\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "table = pa.Table.from_pydict({\n",
    "    \"image_bytes\": [r[\"image_bytes\"] for r in records],\n",
    "    \"label\": [r[\"label\"] for r in records]\n",
    "})\n",
    "pq.write_table(table, os.path.join(output_dir, \"shard_0.parquet\"))\n",
    "\n",
    "print(f\"Wrote {len(records)} records to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06 \u00b7 Load & Decode with Ray Data  \n",
    "Read the Parquet shard into a **Ray Dataset**, decode the JPEG bytes to ** Channel-Height-Width (CHW) float32 tensors**, scale to \\[-1, 1\\], and drop the original byte column.  \n",
    "Because `decode_and_normalize` is stateless, the default **task-based** execution is perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06. Load & Decode Food-101-Lite\n",
    "\n",
    "# Path to Parquet shards written earlier\n",
    "PARQUET_PATH = \"/mnt/cluster_storage/food101_lite/parquet_256\"\n",
    "\n",
    "# Read the Parquet files (\u22487\u202f500 rows with JPEG bytes + label)\n",
    "ds = ray.data.read_parquet(PARQUET_PATH)\n",
    "print(\"Raw rows:\", ds.count())\n",
    "\n",
    "# Decode JPEG \u2192 CHW float32 in [\u20111,\u202f1]\n",
    "\n",
    "def decode_and_normalize(batch_df):\n",
    "    \"\"\"Decode JPEG bytes and scale to [-1, 1].\"\"\"\n",
    "    images = []\n",
    "    for b in batch_df[\"image_bytes\"]:\n",
    "        img = Image.open(io.BytesIO(b)).convert(\"RGB\")\n",
    "        arr = np.asarray(img, dtype=np.float32) / 255.0       # H\u202f\u00d7\u202fW\u202f\u00d7\u202f3, 0\u20111\n",
    "        arr = (arr - 0.5) / 0.5                               # \u20111\u202f\u2026\u202f1\n",
    "        arr = arr.transpose(2, 0, 1)                          # 3\u202f\u00d7\u202fH\u202f\u00d7\u202fW (CHW)\n",
    "        images.append(arr)\n",
    "    return {\"image\": images}\n",
    "\n",
    "# Apply in parallel\n",
    "#   batch_format=\"pandas\" \u2192 batch_df is a DataFrame, return dict of lists.\n",
    "#   default task\u2011based compute is sufficient for a stateless function.\n",
    "\n",
    "ds = ds.map_batches(\n",
    "    decode_and_normalize,\n",
    "    batch_format=\"pandas\",\n",
    "    # Use the default (task\u2011based) compute strategy since `decode_and_normalize` is a plain function.\n",
    "    num_cpus=1,\n",
    ")\n",
    "\n",
    "# Drop the original JPEG column to save memory\n",
    "if \"image_bytes\" in ds.schema().names:\n",
    "    ds = ds.drop_columns([\"image_bytes\", \"label\"])\n",
    "\n",
    "print(\"Decoded rows:\", ds.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07 \u00b7 Shuffle & Train/Val Split  \n",
    "Perform a reproducible shuffle, then split 80 % / 20 % into `train_ds` and `val_ds`.  \n",
    "Each split remains a first-class Ray Dataset, enabling distributed, sharded DataLoaders later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07. Shuffle & Train/Val Split\n",
    "\n",
    "# Typical 80\u202f/\u202f20 split\n",
    "TOTAL = ds.count()\n",
    "train_count = int(TOTAL * 0.8)\n",
    "ds = ds.random_shuffle()\n",
    "train_ds, val_ds = ds.split_at_indices([train_count])\n",
    "print(\"Train rows:\", train_ds.count())\n",
    "print(\"Val rows:\",   val_ds.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}