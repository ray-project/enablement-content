{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. Reverse Diffusion Helper\n",
    "\n",
    "Iteratively de-noise a random action vector **50 steps** back to a feasible Pendulum command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08. Reverse diffusion sampling for 1-D action\n",
    "\n",
    "# Function to simulate reverse diffusion process\n",
    "def sample_action(model, obs, n_steps=50, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Runs reverse diffusion starting from noise to generate a Pendulum action.\n",
    "    obs: torch.Tensor of shape (3,)\n",
    "    returns: torch.Tensor of shape (1,)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        obs = obs.unsqueeze(0).to(device)      # [1, 3]\n",
    "        obs = obs / np.pi                      # same normalization used in training\n",
    "\n",
    "        x = torch.randn(1, 1).to(device)       # start from noise in action space\n",
    "\n",
    "        for step in reversed(range(n_steps)):\n",
    "            t = torch.tensor([step], device=device)\n",
    "            pred_noise = model(obs, x, t)\n",
    "            x = x - pred_noise * 0.1\n",
    "\n",
    "        return x.squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 09. Sample an Action from the Trained Policy\n",
    "\n",
    "Finally, load the **latest epoch checkpoint**, supply a sample state  \n",
    "`[cos \u03b8 = 1, sin \u03b8 = 0, \u03b8\u0307 = 0]`, and generate a 1-D torque command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 09. In-notebook sampling from trained model\n",
    "\n",
    "# A plausible pendulum state: [cos(theta), sin(theta), theta_dot]\n",
    "obs_sample = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float32)   # shape (3,)\n",
    "\n",
    "# Load the most recent model checkpoint from the checkpoint directory\n",
    "CKPT_DIR = \"/mnt/cluster_storage/pendulum_diffusion/pendulum_diffusion_ckpts\"\n",
    "\n",
    "# Pick latest by sorted creation time (or filename if using uuid naming)\n",
    "latest = sorted(os.listdir(CKPT_DIR))[-1]\n",
    "model_path = os.path.join(CKPT_DIR, latest, \"model.pt\")\n",
    "\n",
    "model = DiffusionPolicy(obs_dim=3, act_dim=1)\n",
    "model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Run reverse diffusion sampling\n",
    "action = sample_action(model, obs_sample, n_steps=50, device=\"cpu\")\n",
    "print(\"Sampled action:\", action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Cleanup -- delete checkpoints and metrics from model training\n",
    "\n",
    "TARGET_PATH = \"/mnt/cluster_storage/pendulum_diffusion\"\n",
    "\n",
    "if os.path.exists(TARGET_PATH):\n",
    "    shutil.rmtree(TARGET_PATH)\n",
    "    print(f\"\u2705 Deleted everything under {TARGET_PATH}\")\n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f Path does not exist: {TARGET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83c\udf89 Wrapping Up & Next Steps  \n",
    "\n",
    "Great job reaching the finish line. You\u2019ve transformed a synthetic control demo into a **Ray-native, real-data pipeline**, training a diffusion policy across multiple GPUs, surviving worker restarts, and sampling feasible actions, all within a distributed Ray environment.\n",
    "\n",
    "You should now feel confident:\n",
    "\n",
    "* Logging continuous-control trajectories directly into a **Ray Dataset** for scalable preprocessing  \n",
    "* Streaming data into a **Ray Train** workload using Ray Data + Lightning with minimal integration overhead  \n",
    "* Saving structured checkpoints with `ray.train.report()` and leveraging **Ray\u2019s fault-tolerant recovery**  \n",
    "* Running reverse diffusion sampling directly in-notebook\u2014or scaling it up as **Ray remote tasks**  \n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\ude80 Where can you take this next?\n",
    "\n",
    "1. **Evaluate in the Environment**  \n",
    "   * Load the best checkpoint, deploy the policy in Gym\u2019s `Pendulum-v1`, and log episode returns.  \n",
    "   * Compare against baseline behavior cloning or TD3/TD3+BC.\n",
    "\n",
    "2. **Larger & Richer Datasets**  \n",
    "   * Generate 100 k+ steps with a scripted controller or collect data from a learned agent.  \n",
    "   * Swap in other classic-control tasks like `CartPole` or `MountainCar`.\n",
    "\n",
    "3. **Model & Loss Upgrades**  \n",
    "   * Add timestep embeddings or a small transformer for better temporal reasoning.  \n",
    "   * Experiment with different noise schedules or auxiliary consistency losses.\n",
    "\n",
    "4. **Hyperparameter Sweeps**  \n",
    "   * Wrap the training loop in **Ray Tune** and grid-search learning rate, hidden size, or diffusion steps.  \n",
    "   * Use Tune\u2019s automatic checkpoint pruning to keep only the top-N runs.\n",
    "\n",
    "5. **Mixed Precision & Performance**  \n",
    "   * Enable `torch.set_float32_matmul_precision('high')` to leverage A10G Tensor Cores.  \n",
    "   * Profile GPU utilization across workers and tune batch size accordingly.\n",
    "\n",
    "6. **Real Robotics Logs**  \n",
    "   * Replace Pendulum with logs from a real robotic apparatus stored in Parquet; Ray Data shards them just the same.\n",
    "\n",
    "7. **Serving the Policy**  \n",
    "   * Export the trained MLP to TorchScript and deploy with **Ray Serve** for low-latency inference.  \n",
    "   * Hook it to a real-time simulator or a web dashboard.\n",
    "\n",
    "8. **End-to-End MLOps**  \n",
    "   * Track checkpoints and metrics with MLflow or Weights & Biases.  \n",
    "   * Schedule nightly Ray Jobs on Anyscale to retrain as new data arrives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}