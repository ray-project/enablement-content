{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial concludes by evaluating the trained model on the test dataset. Evaluation is essentially the same as the batch inference workload where you apply the model on batches of data and then calculate metrics using the predictions versus true labels. Ray Data is hyper optimized for throughput so preserving order isn't a priority. But for evaluation, this approach is crucial. Achieve this approach by preserving the entire row and adding the predicted label as another column to each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchPredictor:\n",
    "    def __init__(self, preprocessor, model):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def __call__(self, batch, device=\"cuda\"):\n",
    "        self.model.to(device)\n",
    "        batch[\"prediction\"] = self.model.predict(collate_fn(batch))\n",
    "        return batch\n",
    "\n",
    "    def predict_probabilities(self, batch, device=\"cuda\"):\n",
    "        self.model.to(device)\n",
    "        predicted_probabilities = self.model.predict_probabilities(collate_fn(batch))\n",
    "        batch[\"probabilities\"] = [\n",
    "            {\n",
    "                self.preprocessor.label_to_class[i]: float(prob)\n",
    "                for i, prob in enumerate(probabilities)\n",
    "            }\n",
    "            for probabilities in predicted_probabilities\n",
    "        ]\n",
    "        return batch\n",
    "\n",
    "    @classmethod\n",
    "    def from_artifacts_dir(cls, artifacts_dir):\n",
    "        with open(os.path.join(artifacts_dir, \"class_to_label.json\"), \"r\") as fp:\n",
    "            class_to_label = json.load(fp)\n",
    "        preprocessor = Preprocessor(class_to_label=class_to_label)\n",
    "        model = ClassificationModel.load(\n",
    "            args_fp=os.path.join(artifacts_dir, \"args.json\"),\n",
    "            state_dict_fp=os.path.join(artifacts_dir, \"model.pt\"),\n",
    "        )\n",
    "        return cls(preprocessor=preprocessor, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preproces eval dataset.\n",
    "artifacts_dir = urlparse(best_run.artifact_uri).path\n",
    "predictor = TorchPredictor.from_artifacts_dir(artifacts_dir=artifacts_dir)\n",
    "test_ds = ray.data.read_images(\"s3://doggos-dataset/test\", include_paths=True)\n",
    "test_ds = test_ds.map(add_class)\n",
    "test_ds = predictor.preprocessor.transform(ds=test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 00:34:12,802\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_96_0\n",
      "2025-08-22 00:34:12,814\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_96_0. Full logs are in /tmp/ray/session_2025-08-21_18-48-13_464408_2298/logs/ray-data\n",
      "2025-08-22 00:34:12,815\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_96_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[Map(add_class)->Map(convert_to_label)] -> ActorPoolMapOperator[MapBatches(EmbedImages)] -> TaskPoolMapOperator[MapBatches(drop_columns)] -> TaskPoolMapOperator[MapBatches(TorchPredictor)] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d1c62a744146a398da57614e787e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d9b9453d0f40928a76a188f7a30eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ListFiles 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b1f60100d8451995792b7da3f8ac83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f46bc81e674ba38e39f807dae62551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Map(add_class)->Map(convert_to_label) 3: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9133c6ae847f4d52955482803d33c67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(EmbedImages) 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ecc392709b442f4b123fcad7fc7e60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(drop_columns) 5: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df8844d4afa424f8e750c4b362e3667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(TorchPredictor) 6: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2838a72543d43f4a41520dc98f9dd57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 7: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=18066, ip=10.0.4.102)\u001b[0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +8m20s)\u001b[0m [autoscaler] [1xT4:8CPU-32GB] Attempting to add 1 node to the cluster (increasing from 0 to 1).\n",
      "\u001b[36m(autoscaler +8m25s)\u001b[0m [autoscaler] [1xT4:8CPU-32GB|g4dn.2xlarge] [us-west-2a] [on-demand] Launched 1 instance.\n",
      "\u001b[36m(autoscaler +8m25s)\u001b[0m [autoscaler] [4xT4:48CPU-192GB] Attempting to add 1 node to the cluster (increasing from 1 to 2).\n",
      "\u001b[36m(autoscaler +8m30s)\u001b[0m [autoscaler] [4xT4:48CPU-192GB|g4dn.12xlarge] [us-west-2a] [on-demand] Launched 1 instance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MapBatches(TorchPredictor) pid=19185, ip=10.0.4.102)\u001b[0m /tmp/ipykernel_120810/417303983.py:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "\u001b[36m(_MapWorker pid=18062, ip=10.0.4.102)\u001b[0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "2025-08-22 00:34:50,050\tINFO streaming_executor.py:231 -- \u2714\ufe0f  Dataset dataset_96_0 execution finished in 37.23 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'path': 'doggos-dataset/test/basset/basset_10005.jpg',\n",
       "  'class': 'basset',\n",
       "  'label': 2,\n",
       "  'embedding': array([ 8.86104554e-02, -5.89382686e-02,  1.15464866e-01,  2.15815112e-01,\n",
       "         -3.43266308e-01, -3.35150540e-01,  1.48883224e-01, -1.02369718e-01,\n",
       "         -1.69915810e-01,  4.34856862e-03,  2.41593361e-01,  1.79200619e-01,\n",
       "          4.34402555e-01,  4.59785998e-01,  1.59284808e-02,  4.16959971e-01,\n",
       "          5.20779848e-01,  1.86366066e-01, -3.43496174e-01, -4.00813907e-01,\n",
       "         -1.15213782e-01, -3.04853529e-01,  1.77998394e-01,  1.82090014e-01,\n",
       "         -3.56360346e-01, -2.30711952e-01,  1.69025257e-01,  3.78455579e-01,\n",
       "          8.37044120e-02, -4.81875241e-02,  3.17967087e-01, -1.40099749e-01,\n",
       "         -2.15949178e-01, -4.72761095e-01, -3.01893711e-01,  7.59940967e-02,\n",
       "         -2.64865339e-01,  5.89084566e-01, -3.75831634e-01,  3.11807573e-01,\n",
       "         -3.82964134e-01, -1.86417520e-01,  1.07007243e-01,  4.81416702e-01,\n",
       "         -3.70819569e-01,  9.12090182e-01,  3.13470632e-01, -3.69494259e-02,\n",
       "         -2.21142501e-01,  3.32214013e-02,  8.51379186e-02,  3.64337176e-01,\n",
       "         -3.90754700e-01,  4.39904258e-02,  5.39945886e-02, -5.02359867e-01,\n",
       "         -4.76054996e-02,  3.87604594e-01, -3.71239424e-01, -8.79095644e-02,\n",
       "          5.62141061e-01,  1.96927994e-01,  3.54419112e-01, -6.80974126e-03,\n",
       "          2.86425143e-01, -3.24660867e-01, -4.56204057e-01,  6.41017914e-01,\n",
       "         -1.67037442e-01, -2.29641497e-01,  4.71122622e-01,  5.03865302e-01,\n",
       "         -9.06585157e-03, -1.23926058e-01, -3.32888782e-01,  1.59683321e-02,\n",
       "         -5.00816345e-01, -3.53796408e-02, -1.60535276e-01, -2.88702995e-01,\n",
       "          5.51706925e-02, -3.47863048e-01, -3.01085338e-02, -6.00592375e-01,\n",
       "          2.04530790e-01, -1.17298350e-01,  8.88321698e-01, -3.18641007e-01,\n",
       "          2.02193573e-01, -1.50856599e-01, -2.96603352e-01, -5.45758486e-01,\n",
       "         -7.55531311e+00, -3.07271361e-01, -7.33374238e-01,  2.76708573e-01,\n",
       "         -3.76666151e-02, -4.25825119e-01, -5.56892097e-01,  7.15545475e-01,\n",
       "          1.02834240e-01, -1.19939610e-01,  1.94998607e-01, -2.46950224e-01,\n",
       "          2.61530429e-01, -4.19263542e-01,  1.31001920e-01, -2.49398082e-01,\n",
       "         -3.26750994e-01, -3.92482489e-01,  3.30219358e-01, -5.78646958e-01,\n",
       "          1.53134540e-01, -3.10127169e-01, -3.67199332e-01, -7.94161111e-02,\n",
       "         -2.93402106e-01,  2.62198240e-01,  2.91103810e-01,  1.32868871e-01,\n",
       "         -5.78317158e-02, -4.26885992e-01,  2.99195677e-01,  4.23972368e-01,\n",
       "          2.30407149e-01, -2.98300147e-01, -1.55886114e-01, -1.24661736e-01,\n",
       "         -1.17139973e-01, -4.21351314e-01, -1.45010501e-02, -3.06388348e-01,\n",
       "          2.89572328e-01,  9.73405361e-01, -5.52814901e-01,  2.36222595e-01,\n",
       "         -2.13898420e-01, -1.00043082e+00, -3.57041806e-01, -1.50843680e-01,\n",
       "          4.69288528e-02,  2.08646134e-01, -2.70194232e-01,  2.63797104e-01,\n",
       "          1.31332219e-01,  2.82329589e-01,  2.69341841e-02, -1.21627375e-01,\n",
       "          3.80910456e-01,  2.65330970e-01, -3.01948935e-01, -6.39178753e-02,\n",
       "         -3.13922286e-01, -4.14075851e-01, -2.19056532e-01,  2.22424790e-01,\n",
       "          8.13730657e-02, -3.03519934e-01,  9.32400897e-02, -3.76873404e-01,\n",
       "          8.34950879e-02,  1.01878762e-01,  2.87054926e-01,  2.09415853e-02,\n",
       "         -1.22204229e-01,  1.64302550e-02, -2.41174936e-01,  1.78844824e-01,\n",
       "          9.15416703e-03,  1.66462481e-01, -1.45732313e-01, -5.85511327e-04,\n",
       "          2.25536823e-01,  3.30472469e-01, -1.25101686e-01,  1.13093004e-01,\n",
       "          1.52094781e-01,  4.37459409e-01,  3.22061956e-01,  1.37893021e-01,\n",
       "         -2.53650725e-01, -1.94988877e-01, -2.72130489e-01, -2.57504702e-01,\n",
       "          1.92389667e-01, -2.07393348e-01,  1.73574477e-01,  2.59756446e-02,\n",
       "          2.20320046e-01,  6.48344308e-02,  3.96853566e-01,  1.11773282e-01,\n",
       "         -4.38930988e-01, -5.10937572e-02,  5.92644155e-01,  6.10140711e-03,\n",
       "         -3.97206768e-02,  7.65584633e-02, -7.68468618e-01,  1.23042464e-01,\n",
       "          3.48037392e-01,  1.49242997e-01,  2.86662281e-02,  2.79642552e-01,\n",
       "         -2.26151049e-01, -6.73239648e-01, -8.07924390e-01,  8.62701386e-02,\n",
       "          4.94999364e-02,  1.61207989e-02, -1.30242959e-01,  1.77768275e-01,\n",
       "          3.62961054e-01, -3.20745975e-01,  3.67820978e-01, -9.77848917e-02,\n",
       "         -2.64019221e-01,  6.74475431e-01,  9.26629007e-01, -4.54470068e-02,\n",
       "          9.59405363e-01,  3.02993000e-01, -5.81385851e-01,  3.98850322e-01,\n",
       "          7.40434751e-02,  1.79926023e-01,  9.12196040e-02,  2.77938917e-02,\n",
       "         -2.20950916e-02, -1.98561847e-01, -4.33019698e-01,  1.35872006e-01,\n",
       "         -3.84440348e-02,  1.63487554e-01,  5.38927615e-02,  8.52212310e-01,\n",
       "         -8.64772916e-01, -3.00439209e-01,  1.66039094e-02, -4.84181255e-01,\n",
       "         -2.57156193e-01,  4.46582437e-01,  3.71635705e-02, -7.58354291e-02,\n",
       "         -1.38248950e-02,  1.01295078e+00,  2.14489758e-01, -1.17217854e-01,\n",
       "         -2.82662451e-01,  7.08411038e-01,  2.08262652e-01, -1.69240460e-02,\n",
       "          1.02334268e-01,  4.20059741e-01,  1.07706316e-01, -3.89203757e-01,\n",
       "         -5.91410846e-02, -1.77690476e-01, -1.26772380e+00,  1.75859511e-01,\n",
       "         -2.49499828e-01,  1.60166726e-01,  8.72884393e-02, -4.53421593e-01,\n",
       "          1.96858853e-01, -2.25365251e-01, -1.31235719e-02, -4.58204031e-01,\n",
       "         -1.54087022e-01, -1.87472761e-01,  2.73187131e-01,  4.14693624e-01,\n",
       "          6.00348413e-01,  5.16499318e-02, -2.52319247e-01, -2.08351701e-01,\n",
       "         -3.85643661e-01, -6.44139796e-02, -2.70672083e-01, -5.09124994e-02,\n",
       "         -1.17392734e-01, -1.16136428e-02, -1.69710606e-01,  2.30101690e-01,\n",
       "         -6.31506741e-02,  2.20495850e-01,  4.81231391e-01,  3.76428038e-01,\n",
       "         -2.14597031e-01, -4.70009223e-02,  4.38644290e-01,  2.72557199e-01,\n",
       "         -1.89499091e-02,  6.36664629e-02, -4.86765429e-02, -6.02428794e-01,\n",
       "          5.40002957e-02, -9.60005671e-02,  4.63560931e-02, -3.55034113e-01,\n",
       "          2.27724269e-01, -1.30642965e-01, -5.17771959e-01,  7.08835796e-02,\n",
       "         -2.57462114e-01, -4.82860744e-01,  1.13421358e-01,  9.88648832e-02,\n",
       "          6.21988237e-01,  2.64641732e-01, -9.67874378e-03,  1.94528699e-01,\n",
       "          9.72453296e-01, -4.36969042e-01, -5.50681949e-02,  1.42934144e-01,\n",
       "          1.37221038e-01,  5.63952804e-01, -3.20022464e-01, -5.56031644e-01,\n",
       "          9.09894407e-01,  1.02216589e+00, -2.79887915e-01,  1.69066399e-01,\n",
       "          6.48921371e-01,  1.68456510e-02, -2.58911937e-01,  4.62736428e-01,\n",
       "          8.00172612e-03,  1.66315883e-01, -5.30062854e-01, -3.96020412e-01,\n",
       "          4.43380117e-01, -4.35658276e-01, -1.11912012e-01, -5.91614306e-01,\n",
       "         -7.02220649e-02,  1.41544282e-01, -5.65246567e-02, -1.19229007e+00,\n",
       "         -1.00026041e-01,  1.35173336e-01, -1.37986809e-01,  4.58395988e-01,\n",
       "          2.99769610e-01,  1.13845997e-01, -3.23149785e-02,  4.82394725e-01,\n",
       "         -6.13934547e-03,  3.68614852e-01, -4.91497517e-01, -4.97332066e-01,\n",
       "          8.73729736e-02,  3.60586494e-01, -2.91166097e-01,  1.89481646e-01,\n",
       "          2.87948608e-01,  1.90306157e-01,  4.15048778e-01,  3.93784940e-01,\n",
       "          6.75817132e-02,  1.18251920e-01,  2.03508779e-01,  3.09830695e-01,\n",
       "         -1.03927016e+00,  1.00612268e-01, -3.46988708e-01, -7.09752440e-01,\n",
       "          2.20241398e-01, -3.74946982e-01, -1.48783788e-01, -1.31232068e-01,\n",
       "          3.87498319e-01,  1.67044029e-01, -2.79640555e-01,  3.40543866e-01,\n",
       "          1.28378880e+00,  4.47215438e-01, -5.00054121e-01,  6.85076341e-02,\n",
       "          1.93691164e-01, -4.66935217e-01, -3.24348718e-01,  4.53348368e-01,\n",
       "          6.36629641e-01, -5.52294970e-01, -3.59640062e-01,  2.45728597e-01,\n",
       "          4.48195577e-01, -1.36022663e+00, -6.26060665e-01, -4.96963590e-01,\n",
       "         -2.55071461e-01, -2.31453001e-01, -4.22013104e-01,  5.81141561e-02,\n",
       "          1.66424632e-01, -1.81557357e-01, -2.85358205e-02, -1.10628068e+00,\n",
       "         -2.42026821e-01, -4.49676067e-03,  5.53836450e-02,  4.92810488e-01,\n",
       "          5.83105981e-01,  6.97781667e-02, -1.33217961e-01, -1.25093237e-01,\n",
       "          1.17499933e-01, -5.19634366e-01,  1.42042309e-01,  2.34404474e-01,\n",
       "         -2.55929470e-01,  3.23758684e-02, -2.34450802e-01, -7.54091814e-02,\n",
       "          1.83672294e-01, -2.25883007e-01, -4.76478487e-02, -4.84889567e-01,\n",
       "          1.12959743e-03,  1.80705532e-01, -5.87785244e-02,  4.82457250e-01,\n",
       "         -1.88920692e-01,  1.47517592e-01,  1.10182568e-01, -2.28278339e-02,\n",
       "          8.62778306e-01,  4.46689427e-02,  4.16403189e-02, -1.07179873e-01,\n",
       "         -1.42522454e+00, -2.31161788e-02,  3.05959303e-02, -6.58722073e-02,\n",
       "         -3.69132429e-01,  3.49290550e-01, -1.39178723e-01, -3.51127565e-01,\n",
       "          5.00785351e-01,  2.31236637e-01,  6.77590072e-02, -3.59323025e-02,\n",
       "          2.69076526e-01, -3.60533416e-01,  1.48107335e-01, -1.11518174e-01,\n",
       "          1.65307403e-01, -1.74086124e-01,  6.01880312e-01, -5.95235109e-01,\n",
       "          5.29538319e-02,  3.12422097e-01, -1.14403330e-01,  2.30422497e-01,\n",
       "         -9.48345065e-02,  3.76421027e-02,  4.77573276e-02,  3.89954895e-01,\n",
       "         -1.91829026e-01, -6.26232028e-01,  1.29549801e-01, -2.84714490e-01,\n",
       "          2.88834363e-01,  6.25569642e-01, -2.44193405e-01,  3.08956832e-01,\n",
       "         -4.79587227e-01,  1.59115836e-01, -1.07442781e-01,  1.57203451e-01,\n",
       "         -8.51369202e-02, -1.20136715e-01, -2.91232206e-02,  1.08408488e-01,\n",
       "         -5.97195402e-02, -1.21715315e-01, -5.79822421e-01,  3.90639007e-01,\n",
       "         -2.83878148e-01, -2.72939146e-01,  3.87672335e-04, -2.62640566e-01,\n",
       "         -1.67415068e-01,  1.97720259e-01,  3.60535234e-01, -1.85247302e-01,\n",
       "         -2.80813038e-01,  3.32875013e-01, -3.98125350e-01, -3.53022516e-02,\n",
       "          5.48863769e-01, -1.35882646e-01,  2.50048220e-01, -1.27448589e-01,\n",
       "         -3.03174406e-01,  3.85489166e-02, -7.27320850e-01,  5.22592783e-01,\n",
       "         -1.97360516e-01, -1.98229402e-01, -1.42074719e-01,  4.11824808e-02,\n",
       "         -2.92105675e-01,  2.07964912e-01,  4.97746691e-02,  1.48062438e-01,\n",
       "         -2.94304550e-01,  7.31720269e-01,  1.14105418e-02,  5.50758056e-02],\n",
       "        dtype=float32),\n",
       "  'prediction': 8}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred (batch inference).\n",
    "pred_ds = test_ds.map_batches(\n",
    "    predictor,\n",
    "    concurrency=4,\n",
    "    batch_size=64,\n",
    "    num_gpus=1,\n",
    "    accelerator_type=\"T4\",\n",
    ")\n",
    "pred_ds.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_metric(batch):\n",
    "    labels = batch[\"label\"]\n",
    "    preds = batch[\"prediction\"]\n",
    "    mcm = multilabel_confusion_matrix(labels, preds)\n",
    "    tn, fp, fn, tp = [], [], [], []\n",
    "    for i in range(mcm.shape[0]):\n",
    "        tn.append(mcm[i, 0, 0])  # True negatives\n",
    "        fp.append(mcm[i, 0, 1])  # False positives\n",
    "        fn.append(mcm[i, 1, 0])  # False negatives\n",
    "        tp.append(mcm[i, 1, 1])  # True positives\n",
    "    return {\"TN\": tn, \"FP\": fp, \"FN\": fn, \"TP\": tp}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 00:34:50,290\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_99_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 00:34:50,303\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_99_0. Full logs are in /tmp/ray/session_2025-08-21_18-48-13_464408_2298/logs/ray-data\n",
      "2025-08-22 00:34:50,304\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_99_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[Map(add_class)->Map(convert_to_label)] -> ActorPoolMapOperator[MapBatches(EmbedImages)] -> TaskPoolMapOperator[MapBatches(drop_columns)] -> TaskPoolMapOperator[MapBatches(TorchPredictor)] -> TaskPoolMapOperator[MapBatches(batch_metric)] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf87bfd70924161a7f4f956a92eb23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2114df52a7ac4646aabfda7f7802a648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ListFiles 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d889fe01be0545939617a037455180df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b23a2321514f21a50825b660f670bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Map(add_class)->Map(convert_to_label) 3: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627c443e2450449c8683775fc89d7a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(EmbedImages) 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d41291adfbf4c86817b203dc9e6f181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(drop_columns) 5: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2831719e1324270a3662420aff4c1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(TorchPredictor) 6: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120a18eec3a64dfda631fa6dbff06232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(batch_metric) 7: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18834b310df94e338ad7ad76aaf77ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 8: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898fc65b6d6e491f9bd6dd33572f0d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 9:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7712b3872448c49f04dd6ed1af48f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 10:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970b96aca5db4f1aab1e487105e61cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 11:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecfe233dbf249b7ab34fc9d26184bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 12: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=19193, ip=10.0.4.102)\u001b[0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "\u001b[36m(_MapWorker pid=25926, ip=10.0.4.102)\u001b[0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +9m10s)\u001b[0m [autoscaler] Cluster upscaled to {120 CPU, 9 GPU}.\n",
      "\u001b[36m(autoscaler +9m15s)\u001b[0m [autoscaler] Cluster upscaled to {168 CPU, 13 GPU}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MapBatches(TorchPredictor) pid=2582, ip=10.0.31.199)\u001b[0m /tmp/ipykernel_120810/417303983.py:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "\u001b[36m(_MapWorker pid=27577, ip=10.0.4.102)\u001b[0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "\u001b[36m(MapBatches(TorchPredictor) pid=2578, ip=10.0.31.199)\u001b[0m /tmp/ipykernel_120810/417303983.py:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(MapBatches(TorchPredictor) pid=2576, ip=10.0.31.199)\u001b[0m /tmp/ipykernel_120810/417303983.py:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(MapBatches(TorchPredictor) pid=3977, ip=10.0.60.138)\u001b[0m /tmp/ipykernel_120810/417303983.py:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(MapBatches(TorchPredictor) pid=4229, ip=10.0.60.138)\u001b[0m /tmp/ipykernel_120810/417303983.py:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(MapBatches(TorchPredictor) pid=2579, ip=10.0.31.199)\u001b[0m /tmp/ipykernel_120810/417303983.py:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(MapBatches(TorchPredictor) pid=2581, ip=10.0.31.199)\u001b[0m /tmp/ipykernel_120810/417303983.py:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(MapBatches(TorchPredictor) pid=5094, ip=10.0.60.138)\u001b[0m /tmp/ipykernel_120810/417303983.py:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(MapBatches(TorchPredictor) pid=5289, ip=10.0.60.138)\u001b[0m /tmp/ipykernel_120810/417303983.py:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(MapBatches(TorchPredictor) pid=5548, ip=10.0.60.138)\u001b[0m /tmp/ipykernel_120810/417303983.py:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(MapBatches(TorchPredictor) pid=5816, ip=10.0.60.138)\u001b[0m /tmp/ipykernel_120810/417303983.py:6: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "2025-08-22 00:38:03,968\tINFO streaming_executor.py:231 -- \u2714\ufe0f  Dataset dataset_99_0 execution finished in 193.66 seconds\n"
     ]
    }
   ],
   "source": [
    "# Aggregated metrics after processing all batches.\n",
    "metrics_ds = pred_ds.map_batches(batch_metric)\n",
    "aggregate_metrics = metrics_ds.sum([\"TN\", \"FP\", \"FN\", \"TP\"])\n",
    "\n",
    "# Aggregate the confusion matrix components across all batches.\n",
    "tn = aggregate_metrics[\"sum(TN)\"]\n",
    "fp = aggregate_metrics[\"sum(FP)\"]\n",
    "fn = aggregate_metrics[\"sum(FN)\"]\n",
    "tp = aggregate_metrics[\"sum(TP)\"]\n",
    "\n",
    "# Calculate metrics.\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "F1: 0.84\n",
      "Accuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +13m0s)\u001b[0m [autoscaler] Downscaling node i-0ffe5abae6e899f5a (node IP: 10.0.60.138) due to node idle termination.\n",
      "\u001b[36m(autoscaler +13m5s)\u001b[0m [autoscaler] Cluster resized to {120 CPU, 9 GPU}.\n",
      "\u001b[36m(autoscaler +16m0s)\u001b[0m [autoscaler] Downscaling node i-0aa72cef9b8921af5 (node IP: 10.0.31.199) due to node idle termination.\n",
      "\u001b[36m(autoscaler +16m5s)\u001b[0m [autoscaler] Cluster resized to {112 CPU, 8 GPU}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Using CPython 3.12.11 interpreter at: /home/ray/anaconda3/bin/python3.12\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Creating virtual environment at: .venv\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m    Building doggos @ file:///tmp/ray/session_2025-08-21_18-48-13_464408_2298/runtime_resources/working_dir_files/_ray_pkg_f79228c33bd2a431/doggos\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading pillow (6.3MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading grpcio (5.9MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading sqlalchemy (3.2MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading pydantic-core (1.9MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading jedi (1.5MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading virtualenv (5.7MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading pandas (11.4MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading setuptools (1.1MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading uvloop (4.5MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading sympy (6.0MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading numpy (15.9MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading kiwisolver (1.4MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading tokenizers (3.0MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading pyarrow (38.2MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading botocore (13.3MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading fonttools (4.7MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading widgetsnbextension (2.1MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading mlflow-skinny (5.6MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading aiohttp (1.6MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading networkx (1.9MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading pygments (1.2MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading debugpy (4.0MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading py-spy (2.6MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading scikit-learn (12.5MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading hf-xet (3.0MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading matplotlib (8.2MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading torch (783.0MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading transformers (10.0MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading scipy (33.5MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading polars (36.7MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading mlflow (26.1MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Downloading triton (148.5MiB)\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m       Built doggos @ file:///tmp/ray/session_2025-08-21_18-48-13_464408_2298/runtime_resources/working_dir_files/_ray_pkg_f79228c33bd2a431/doggos\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading pillow\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading grpcio\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading sqlalchemy\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading pydantic-core\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading jedi\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading virtualenv\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading setuptools\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading uvloop\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading nvidia-cuda-cupti-cu12\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading sympy\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading kiwisolver\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading tokenizers\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading fonttools\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading widgetsnbextension\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading mlflow-skinny\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading aiohttp\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading networkx\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading pygments\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading debugpy\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading py-spy\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading hf-xet\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading matplotlib\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading transformers\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading scikit-learn\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading numpy\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading botocore\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading pandas\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading polars\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading nvidia-cuda-nvrtc-cu12\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading scipy\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading mlflow\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading pyarrow\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading nvidia-curand-cu12\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading nvidia-cusparselt-cu12\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading triton\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading nvidia-cublas-cu12\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading torch\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m warning: Failed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m          If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m          If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m  Downloading nvidia-cudnn-cu12\n",
      "\u001b[33m(raylet, ip=10.0.4.102)\u001b[0m Installed 172 packages in 1.96s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\ud83d\udea8 Note**: Reset this notebook using the **\"\ud83d\udd04 Restart\"** button location at the notebook's menu bar. This way we can free up all the variables, utils, etc. used in this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}