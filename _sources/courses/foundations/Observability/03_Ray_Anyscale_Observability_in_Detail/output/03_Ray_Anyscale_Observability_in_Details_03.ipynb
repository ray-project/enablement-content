{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Application Observability (Ray Serve)\n",
    "\n",
    "#### Launching a Web Application using Ray Serve\n",
    "\n",
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import requests\n",
    "from ray import serve\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\ud83d\udcbb Local Environment. Please modify the value of **local_path** to your local path.\n",
    "\n",
    "Deploy a web application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the app with default config\n",
    "!cd scipts/ && serve run main:mnist_app --non-blocking --name app1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now send http request by running following script. It generates traffic to the Ray Serve web application, allowing you to explore its observability features in the subsequent sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "while time.time() - start < 60:\n",
    "    images = np.random.rand(2, 1, 28, 28).tolist()\n",
    "    json_request = json.dumps({\"image\": images})\n",
    "    response = requests.post(\"http://localhost:8000/\", json=json_request)\n",
    "    response.json()[\"predicted_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Serve Metrics\n",
    "\n",
    "The following metrics are Ray Serve specific:\n",
    "\n",
    "- **Throughput metrics:**\n",
    "    - Queries per second (QPS)\n",
    "    - Error QPS\n",
    "    - Error by error code QPS\n",
    "\n",
    "Shown are the throughput metrics for above web application. Click \"Metrics\" -> \"VIEW IN GRAFANA\" -> \"Dashboards\" -> \"Serve Dashboard\"\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/throughput_per_application.png\" alt=\"Ray Serve Metrics\" width=\"800\">\n",
    "\n",
    "- **Latency metrics:**\n",
    "    - P50, P90, P99 latencies\n",
    "\n",
    "Shown are the latency metrics for the MNIST application.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/latency_per_application.png\" alt=\"Ray Serve Latency Metrics\" width=\"800\">\n",
    "\n",
    "- **Latency and throughput metrics are available at different levels of granularity:**\n",
    "    - Per-application metrics\n",
    "    - Per-deployment metrics\n",
    "    - Per-replica metrics\n",
    "\n",
    "Shown are the latency metrics on the deployment level.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/latency_per_deployment.png\" alt=\"Ray Serve Latency Metrics\" width=\"800\">\n",
    "\n",
    "- **Deployment-specific metrics:**\n",
    "    - Number of replicas\n",
    "    - Queue size (TODO - explain which queue)\n",
    "\n",
    "Shown are the number of replicas and queue size for the MNIST application.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/replicas_per_deployment.png\" alt=\"Ray Serve Deployment Metrics\" width=\"400\">\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/queue_size_per_deploymnet.png\" alt=\"Ray Serve Deployment Metrics\" width=\"400\">\n",
    "\n",
    "\n",
    "For Anyscale users, the following metrics are also available:\n",
    "- **Rollout-specific metrics:**\n",
    "    - QPS per version\n",
    "    - Error QPS per version\n",
    "    - P90 latency per version\n",
    "    - Number of replicas per version\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/rollouts_per_application.png\" alt=\"Ray Serve Rollout Metrics\" width=\"800\">\n",
    "\n",
    "For details on how to setup custom dashboards and alerts, refer to this [guide in the Anyscale docs](https://docs.anyscale.com/monitoring/custom-dashboards-and-alerting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Serve Logs\n",
    "\n",
    "\ud83d\udcbb Local Environment\n",
    "\n",
    "To understand system-level behavior and to surface application-level details during runtime, you can leverage Ray logging.\n",
    "\n",
    "**Implementation:**\n",
    "- Uses Python's standard logging module\n",
    "- Logger name is \"ray.serve\"\n",
    "\n",
    "**Log Output Locations:**\n",
    "- Logs are sent to stderr\n",
    "- Logs are written to disk at `/tmp/ray/session_latest/logs/serve/`\n",
    "\n",
    "**Types of Logs Captured:**\n",
    "- System-level logs (from Serve controller and proxy)\n",
    "- Access logs\n",
    "- Custom user logs from deployment replicas\n",
    "\n",
    "**Development Environment Behavior:**\n",
    "- Logs are streamed to the driver Ray program\n",
    "- Driver program can be either:\n",
    "    - Python script calling serve.run()\n",
    "    - serve run CLI command\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:**\n",
    "Given Ray Serve uses Python's standard logging module, aggressive logging inside your application will incur a performance penalty. Use logging levels to control the verbosity of your logs and to avoid this penalty when running in production.\n",
    "\n",
    "</div>\n",
    "\n",
    "Here is how to use logging in a deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment()\n",
    "class SayHelloDefaultLogging:\n",
    "    async def __call__(self):\n",
    "        logger = logging.getLogger(\"ray.serve\")\n",
    "        logger.info(\"hello world\")\n",
    "\n",
    "\n",
    "serve.run(SayHelloDefaultLogging.bind())\n",
    "\n",
    "resp = requests.get(\"http://localhost:8000/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging Configuration\n",
    "\n",
    "\ud83d\udcbb Local Environment\n",
    "\n",
    "Here are the common configurations for logging.\n",
    "\n",
    "- `enable_access_log`: Access logs are injected by default into Replica and Proxy logs. By default, it is `True`.\n",
    "- `log_level`: Set the log level. By default, it is `INFO`.\n",
    "- `encoding`: Set the encoding of the log file. By default, it is `JSON`.\n",
    "\n",
    "You can set the logging configuration:\n",
    "- At the deployment level\n",
    "- At the serve instance level\n",
    "\n",
    "Both programmatically or via a configuration file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(logging_config={\"log_level\": \"DEBUG\"})\n",
    "class SayHelloDebugLogging:\n",
    "    async def __call__(self):\n",
    "        logger = logging.getLogger(\"ray.serve\")\n",
    "        logger.debug(\"hello world\")\n",
    "\n",
    "\n",
    "serve.run(\n",
    "    SayHelloDebugLogging.bind(),\n",
    "    logging_config={\n",
    "        \"encoding\": \"JSON\",\n",
    "        \"log_level\": \"INFO\",\n",
    "        \"enable_access_log\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "resp = requests.get(\"http://localhost:8000/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Serve Tracing (Anyscale Only)\n",
    "\n",
    "To perform end-to-end tracing of requests, you can use the Anyscale Tracing integration.\n",
    "\n",
    "See the [tracing guide](https://docs.anyscale.com/monitoring/tracing/) for details.\n",
    "\n",
    "After following [README.md](tracing_example/README.md) to run the example, a single request's tracing logs display the following hierarchical structure:\n",
    "\n",
    "```\n",
    "1. proxy_http_request (Root) - Duration: 245ms\n",
    "   \u2514\u2500\u2500 2. proxy_route_to_replica (APIGateway) - Duration: 240ms\n",
    "       \u2514\u2500\u2500 3. replica_handle_request (APIGateway) - Duration: 235ms\n",
    "           \u2514\u2500\u2500 4. proxy_route_to_replica (UserService) - Duration: 180ms\n",
    "               \u2514\u2500\u2500 5. replica_handle_request (UserService) - Duration: 175ms\n",
    "                   \u2514\u2500\u2500 6. proxy_route_to_replica (DatabaseService) - Duration: 110ms\n",
    "                       \u2514\u2500\u2500 7. replica_handle_request (DatabaseService) - Duration: 105ms\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Serve Alerts\n",
    "\n",
    "**Alert Types:**\n",
    "Grafana [can alert](https://grafana.com/docs/grafana/v7.5/alerting/) based on:\n",
    "- Metric values\n",
    "- Rate of change\n",
    "- Metric absence\n",
    "\n",
    "**Notification Options:**\n",
    "- Supports multiple [notification channels](https://grafana.com/docs/grafana/v7.5/alerting/notifications/#add-a-notification-channel) (Slack, PagerDuty, etc.)\n",
    "- Email support planned for future\n",
    "- Configurable through notification channels\n",
    "\n",
    "**Documentation:** Full setup details available in Grafana's [official documentation](https://grafana.com/docs/grafana/v7.5/alerting/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anyscale Ray Serve Observability\n",
    "\n",
    "\ud83d\ude80 **Anyscale Platform**: This view only exists in Anyscale \n",
    "\n",
    "When deploying a web application to Anyscale, utilize Anyscale's advanced observability features to debug and manage the service.\n",
    "\n",
    "The Logs view enables viewing and filtering logs:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/4-Ray-Serve/ray_serve_log_filter.png\" width=\"80%\" loading=\"lazy\">\n",
    "\n",
    "Since each deployment has a version ID, rolling back to an older version is easy through the **Versions** view. Zero-downtime rollouts can be performed with one click:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/4-Ray-Serve/ray_serve_versions.png\" width=\"80%\" loading=\"lazy\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xing-ray-jupyter-3.11",
   "language": "python",
   "name": "xing-ray-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}