{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Contextualized observability is observability that a user easily understands based on the context they already have. Because Anyscale:\n",
    "\n",
    "- **Knows what user\u2019s workloads are**: Workload observability can be highly contextualized.\n",
    "- **Controls the full stack from telemetry to visualization**: The tools can be deeply integrated and native to Ray and its libraries.\n",
    "- **Handles running workloads at extremely large scale**: This itself has a strong need for good observability.\n",
    "\n",
    "\n",
    "Anyscale contextualizes observability to enhance what is available from Ray OSS Observability. Here is an example of how easy it is to debug a job that uses more than 1000 nodes with Anyscale observability.\n",
    "\n",
    "The following script creates 1 billion (10**9) synthetic images and writes them to Parquet files (see `example/main.py` for the full code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from typing import Dict, Any\n",
    "\n",
    "\"\"\"\n",
    "Each image is about 1MB. (HxWxC = 580x580x3 = 1MB)\n",
    "So 1 billion images would be 1 PB. (10^9 * 1MB = 1PB)\n",
    "\"\"\"\n",
    "NUM_IMAGES = 10**9\n",
    "IMAGE_WIDTH = 580\n",
    "IMAGE_HEIGHT = 580\n",
    "CHANNELS = 3\n",
    "\n",
    "\n",
    "def generate_synthetic_image(image_id: int, width: int = 580, height: int = 580, channels: int = 3) -> Dict[str, Any]:\n",
    "    image_array = np.random.randint(0, 256, size=(height, width, channels), dtype=np.uint8)\n",
    "    return {\n",
    "        \"image_id\": image_id,\n",
    "        \"image_array\": image_array,\n",
    "        \"metadata\": {\n",
    "            \"dtype\": str(image_array.dtype),\n",
    "            \"shape\": image_array.shape,\n",
    "            \"generated_by\": \"ray_data_synthetic\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_ids = list(range(NUM_IMAGES))\n",
    "    output_path = os.path.join(os.environ[\"ANYSCALE_ARTIFACT_STORAGE\"], \"rkn/synthetic_image_output\")\n",
    "\n",
    "    ds = ray.data.from_items(image_ids)\n",
    "    ds = ds.repartition(target_num_rows_per_block=1000)\n",
    "    ds = ds.map(lambda x: generate_synthetic_image(x[\"item\"], IMAGE_WIDTH, IMAGE_HEIGHT, CHANNELS))\n",
    "    ds.write_parquet(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following is the job configuration file to start this job (see `example/job.yaml` for the full code). Replace cloud name if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "xml"
    }
   },
   "outputs": [],
   "source": [
    "name: synthetic-image-generator\n",
    "\n",
    "image_uri: anyscale/ray:2.48.0-py312-cu128\n",
    "\n",
    "compute_config:\n",
    "  worker_nodes:\n",
    "    - instance_type: m5.12xlarge\n",
    "      max_nodes: 500\n",
    "      market_type: PREFER_SPOT # (Optional) Defaults to ON_DEMAND\n",
    "    - instance_type: m5.16xlarge\n",
    "      max_nodes: 500\n",
    "      market_type: PREFER_SPOT # (Optional) Defaults to ON_DEMAND\n",
    "    - instance_type: m5.24xlarge\n",
    "      max_nodes: 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When add the correct **Anyscale Cloud ID** and run this job with following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd example/ && anyscale job submit -f job.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the job starts, memory usage will increase gradually across all workers until some workers' memory usage hits 90%+. As it continues running, the first OOM failure occurs on smaller instances. As more and more workers fail, the remaining workers become overloaded.\n",
    "\n",
    "This job causes:\n",
    "\n",
    "- **Memory pressure**: Some workers experience OOM failures\n",
    "- **Storage I/O bottlenecks**: 1000+ workers writing simultaneously\n",
    "- **Network saturation**: Data transfer between workers\n",
    "- **Cost explosion**: 1000+ instances running for hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the Ray Dashboard provides only raw metrics and logs for this job, the overwhelming volume of data makes it difficult for users to identify actionable insights,\n",
    "\n",
    "<div style=\"display: flex; gap: 20px; margin: 20px 0;\">\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/1-Overview/1000_node_raydash_metrics.png\" width=\"45%\" loading=\"lazy\">\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/1-Overview/1000_node_raydash_logs.png\" width=\"45%\" loading=\"lazy\">\n",
    "</div>\n",
    "\n",
    "Additionally, the dashboard becomes completely inaccessible when the head node fails due to out-of-memory (OOM) errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Ray workers continuously send metrics and logs to Anyscale's backend infrastructure, Anyscale observability remains accessible even after the Ray head node fails. \n",
    "\n",
    "Anyscale contextualizes these metrics and logs, enabling users to easily monitor these issues:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/1-Overview/OOM_1.png\" width=\"70%\" loading=\"lazy\">\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/1-Overview/OOM_2.png\" width=\"70%\" loading=\"lazy\">\n",
    "\n",
    "With Ray Workload view, users can detect at which step does OOM happen in this data pipeline:\n",
    "\n",
    "<div style=\"display: flex; gap: 20px; margin: 20px 0;\">\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/1-Overview/ray_dashboard_1.png\" width=\"45%\" loading=\"lazy\">\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/1-Overview/ray_dashboard_2.png\" width=\"45%\" loading=\"lazy\">\n",
    "</div>\n",
    "\n",
    "From the above graph, it is easy to see that the data pipeline was stuck at writing images into the Parquet files (materializing images).\n",
    "\n",
    "Logs are also available for querying in the logs view:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-observability/1-Overview/log_err.png\" width=\"70%\" loading=\"lazy\">\n",
    "\n",
    "This example demonstrates that while the Ray Dashboard provides raw metrics, status, and logs of workloads, Anyscale observability remains available even after jobs complete or fail, and contextualizes this information to deliver a much more user-friendly observability experience. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}