{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Single GPU Training with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by fitting a `ResNet18` model to an `MNIST` dataset. Conceptually we will follow the below recipe presented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-ai-libraries/diagrams/single_gpu_pytorch_v3.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|An overview of the single GPU training process. At a high level, here is how training loop in PyTorch looks like. The key stages include loading the dataset; run the training on mini-batches on a single GPU; saving the model checkpoint to the persistent storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "def train_loop_torch(num_epochs: int = 2, batch_size: int = 128, local_path: str = \"./checkpoints\"):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    criterion = CrossEntropyLoss()\n",
    "    model = load_model_torch().to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "    data_loader = build_data_loader_torch(batch_size=batch_size)\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for images, labels in tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(data_loader)\n",
    "\n",
    "        metrics = report_metrics_torch(loss=avg_loss, epoch=epoch)\n",
    "        Path(local_path).mkdir(parents=True, exist_ok=True)\n",
    "        save_checkpoint_and_metrics_torch(metrics=metrics, model=model, local_path=local_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Quick notes:\n",
    "\n",
    "<ul>\n",
    "    <li><code>report_metrics_torch</code> and <code>save_checkpoint_and_metrics_torch</code> are defined below,</li>\n",
    "    <li><code>local_path</code> is used for checkpointing. (default) Current working directory simply points to the notebook location (check <code>pwd</code> below).</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Build model and load it on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build [Resnet18](https://pytorch.org/vision/main/models/resnet.html#resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_resnet18():\n",
    "    model = resnet18(num_classes=10)\n",
    "    model.conv1 = torch.nn.Conv2d(\n",
    "        in_channels=1, # grayscale MNIST images\n",
    "        out_channels=64,\n",
    "        kernel_size=(7, 7),\n",
    "        stride=(2, 2),\n",
    "        padding=(3, 3),\n",
    "        bias=False,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "resnet18's <code>model.conv1</code> has <code>in_channels=3</code> by default. Here, we work with the <a href=\"https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html#mnist\" target=\"_blank\">MNIST</a> grayscale images, thus <code>in_channels=1</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Load the model on a single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model_torch() -> torch.nn.Module:\n",
    "    model = build_resnet18()\n",
    "\n",
    "    # Move to the GPU device if available, otherwise use CPU\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = MNIST(root=\"./data\", train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tree ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display 9 example (image, target) pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = np.random.randint(0, len(dataset.data))\n",
    "    img, label = dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a DataLoader to apply transformations and load data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_data_loader_torch(batch_size: int) -> torch.utils.data.DataLoader:\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    dataset = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Create metrics and checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and report the metrics using a simple print statement, and also save them to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def report_metrics_torch(loss: torch.Tensor, epoch: int) -> None:\n",
    "    metrics = {\"loss\": loss, \"epoch\": epoch}\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the checkpoint in a previously defined local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_checkpoint_and_metrics_torch(metrics: dict[str, float], model: torch.nn.Module, local_path: str) -> None:\n",
    "\n",
    "    # Save the metrics\n",
    "    with open(os.path.join(local_path, \"metrics.csv\"), \"a\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(metrics.values())\n",
    "\n",
    "    # Save the model\n",
    "    checkpoint_path = os.path.join(local_path, \"model.pt\")\n",
    "    torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Run the training loop\n",
    "Schedule the training loop on a single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "storage_folder = \"/mnt/cluster_storage\"  # Modify this path to your local folder if it runs on your local environment\n",
    "local_path = f\"{storage_folder}/torch_{timestamp}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Note about Anyscale storage options</b>\n",
    "\n",
    "In this example <code>local_path</code> points to the Anyscale's <a href=\"https://docs.anyscale.com/configuration/storage/#local-storage-for-a-node\" target=\"_blank\">local storage</a>. It's a convenient and quick access location for this basic example.\n",
    "\n",
    "* Anyscale provides each node with its own volume and disk and doesn't share them with other nodes.\n",
    "* Local storage is very fast - Anyscale supports the Non-Volatile Memory Express (NVMe) interface.\n",
    "* This is not a persistent storage, Anyscale deletes data in the local storage after instances are terminated. \n",
    "\n",
    "Read more about available <a href=\"https://docs.anyscale.com/configuration/storage\" target=\"_blank\">storage</a> options.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training:\n",
    "If you run it on your local, it can take up to 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loop_torch(\n",
    "    num_epochs=3,\n",
    "    local_path=local_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the produced checkpoints and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -l {local_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(\n",
    "    os.path.join(local_path, \"metrics.csv\"),\n",
    "    header=None,\n",
    "    names=[\"loss\", \"epoch\"],\n",
    ")\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Use checkpointed model to generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model checkpoint to the device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate predictions on randomly selected 9 images from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "loaded_model = build_resnet18()\n",
    "loaded_model.load_state_dict(torch.load(os.path.join(local_path, \"model.pt\")))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = np.random.randint(0, len(dataset.data))\n",
    "    img, label = dataset[sample_idx]\n",
    "    normalized_img = Normalize((0.5,), (0.5,))(ToTensor()(img))\n",
    "    normalized_img = normalized_img.to(device)\n",
    "\n",
    "    # use loaded model to generate preds\n",
    "    with torch.no_grad():        \n",
    "        prediction = loaded_model(normalized_img.unsqueeze(0)).argmax().cpu()\n",
    "\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f\"label: {label}; pred: {int(prediction)}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray-jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orphan": true,
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}