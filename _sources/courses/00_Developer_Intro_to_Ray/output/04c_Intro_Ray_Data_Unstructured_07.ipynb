{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stateful transformations with Ray Actors\n",
    "\n",
    "In cases like batch inference, you want to spin up a number of actor processes that are **initialized once** with your model **and reused** to process multiple batches.\n",
    "\n",
    "To implement this, you can use the `map_batches` API with a \"Callable\" class method that implements:\n",
    "\n",
    "- `__init__`: Initialize any expensive state.\n",
    "- `__call__`: Perform the stateful transformation.\n",
    "\n",
    "For example, we can implement a `MNISTClassifier` that:\n",
    "- loads a pre-trained model from a local file\n",
    "- accepts a batch of images and generates the predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MNISTClassifier:\n",
    "    def __init__(self, remote_path: str, local_path: str):\n",
    "        subprocess.run(f\"aws s3 cp --no-sign-request {remote_path} {local_path}\", shell=True, check=True)\n",
    "\n",
    "        self.model = torch.jit.load(local_path).to(\"cuda\").eval()\n",
    "\n",
    "\n",
    "    def __call__(self, batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "        images = torch.tensor(batch[\"image\"]).float().to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(images).cpu().numpy()\n",
    "\n",
    "        batch[\"predicted_label\"] = np.argmax(logits, axis=1)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `map_batches` API to apply the transformation to each batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_path = \"/mnt/cluster_storage/model.pt\" # Change this to your local path if needed\n",
    "\n",
    "mnist_classifier_args = {\n",
    "    \"remote_path\": \"s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt\",\n",
    "    \"local_path\": local_path,\n",
    "}\n",
    "\n",
    "ds_preds = ds_normalized.map_batches(\n",
    "    MNISTClassifier,\n",
    "    fn_constructor_kwargs=mnist_classifier_args,\n",
    "    num_gpus=1,\n",
    "    concurrency=3,\n",
    "    batch_size=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Resource specification for stateful transformations\n",
    "\n",
    "It is common when you have varying hardware types in your cluster to want to further specify which accelerators to use for each stage of your pipeline.\n",
    "\n",
    "Let's show how to achieve this with the `resources` parameter.\n",
    "\n",
    "Since GPU is required for following examples, we suggest to run them on Anyscale Ray Cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_preds = ds_normalized.map_batches(\n",
    "    MNISTClassifier,\n",
    "    fn_constructor_kwargs=mnist_classifier_args,\n",
    "    num_gpus=1,\n",
    "    concurrency=3,\n",
    "    batch_size=100,\n",
    "    resources={\"accelerator_type:T4\": 0.0001},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Note:</b> Pass in the Callable class uninitialized. Your driver will not execute the class constructor. Ray will pass in the arguments to the class constructor when the class is actually used in a transformation.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Note on autoscaling for stateful transformations\n",
    "\n",
    "For stateless transformations, Ray Data will automatically scale up the number of tasks to match the number of input blocks.\n",
    "\n",
    "For stateful transformations, Ray Data will schedule tasks proportional to the number of actors (workers) in the pool. \n",
    "\n",
    "To specify an autoscaling pool, use a tuple of `(min_size, max_size)` for the `concurrency` parameter.\n",
    "\n",
    "Ray Data will start with `min_size` actors and automatically scale up to `max_size` as needed.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_preds = ds_normalized.map_batches(\n",
    "    MNISTClassifier,\n",
    "    fn_constructor_kwargs=mnist_classifier_args,\n",
    "    num_gpus=1,\n",
    "    concurrency=(1, 4),  # Autoscale pool based on blocks, resources and limits\n",
    "    batch_size=100,\n",
    "    resources={\"accelerator_type:T4\": 0.0001}, # Optional if you run it locally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_preds = ds_preds.take_batch(100)\n",
    "batch_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xing-ray-jupyter-3.11",
   "language": "python",
   "name": "xing-ray-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}