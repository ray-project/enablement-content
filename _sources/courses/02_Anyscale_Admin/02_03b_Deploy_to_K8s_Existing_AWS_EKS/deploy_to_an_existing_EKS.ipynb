{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Introduction: Deploy Anyscale Ray on An Existing AWS EKS Cluster\n",
        "\n",
        "© 2025, Anyscale. All Rights Reserved\n",
        "\n",
        "This notebook serves as a guide for deploying an **Anyscale Cloud** on an existing AWS EKS cluster using the custom **`anyscale cloud register`** method. It walks through the necessary steps from prerequisites to Ray installation with Anyscale Operator.\n",
        "\n",
        "Use it as a starting point and replace all placeholders (e.g.&nbsp;`{ANYSCALE_CLOUD_NAME}`) with values from your environment.\n",
        "\n",
        "It is based on this [example](https://github.com/anyscale/terraform-kubernetes-anyscale-foundation-modules/tree/main/examples/aws/eks-existing), please refer to it for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before we begin, ensure you have the following tools installed:\n",
        "\n",
        "```bash\n",
        "# Install AWS CLI (version 2.15.0+)\n",
        "# https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\n",
        "\n",
        "# Configure AWS credentials\n",
        "# https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html\n",
        "\n",
        "# Install kubectl (version 1.25+)\n",
        "# https://kubernetes.io/docs/tasks/tools/\n",
        "\n",
        "# Install helm (version 3.10+)\n",
        "# https://helm.sh/docs/intro/install/\n",
        "\n",
        "# Install Anyscale CLI (version 0.5.86+)\n",
        "# https://docs.anyscale.com/reference/quickstart-cli/\n",
        "\n",
        "# Install Terraform (version 1.9+)\n",
        "# https://developer.hashicorp.com/terraform/install\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Alternative Terraform Installation:</b> If you are not able to install <b>Terraform 1.9+</b> with homebrew, you can try to install it with <code>tfenv</code>.\n",
        "\n",
        "<details>\n",
        "<summary>Click to expand installation steps</summary>\n",
        "\n",
        "```bash\n",
        "brew install tfenv\n",
        "tfenv install 1.9.0\n",
        "tfenv use 1.9.0\n",
        "terraform version\n",
        "```\n",
        "\n",
        "</details>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You also need:\n",
        "- An existing AWS Account\n",
        "- An existing AWS VPC\n",
        "- An existing AWS EKS Cluster running in the VPC (version 1.25+)\n",
        "- Proper IAM permissions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Create Anyscale Resources with Terraform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set up the necessary Terraform variables and apply the configuration:\n",
        "\n",
        "Steps for deploying Anyscale resources via Terraform:\n",
        "\n",
        "* Review and modify [variables.tf](variables.tf) with your configurations for the EKS cluster where you want to deploy Anyscale\n",
        "* (Optional) Create a `terraform.tfvars` file to override any defaults\n",
        "* View [main.tf](main.tf) to see how the resources are created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Set the global variables for the deployment, which are the same as in the variables.tf file.\n",
        "\"\"\"\n",
        "\n",
        "EKS_CLUSTER_NAME = \"anyscale-eks-private-xxx\"  # Replace with your actual EKS cluster name\n",
        "AWS_REGION = \"us-west-2\"  # Replace with your actual AWS region\n",
        "ANYSCALE_CLOUD_NAME = \"anyscale-cloud-eks-private-xxx\" # Replace with your actual Anyscale cloud name\n",
        "ANYSCALE_S3_BUCKET_NAME = EKS_CLUSTER_NAME + \"-\" + AWS_REGION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run Terraform commands\n",
        "\n",
        "# Initialize Terraform\n",
        "!terraform init\n",
        "\n",
        "# Preview the changes\n",
        "!terraform plan\n",
        "\n",
        "# Apply the changes. (this may take 10-15 minutes)\n",
        "!terraform apply"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>Sometimes, your AWS account may have too many existing resources consuming capacity, causing you to hit service limits. In such cases, it's a good idea to release unused resources—such as unassociated Elastic IPs (EIPs) or idle NAT gateways.\n",
        "</summary>\n",
        "During you installing, you may need to release the unused EIPs and deleted unused NAT.\n",
        "\n",
        "To find the unattached EIPs:\n",
        "```bash\n",
        "aws ec2 describe-addresses | jq '.Addresses[] | select(.InstanceId == null and .NetworkInterfaceId == null)'\n",
        "```\n",
        "You will see a list of unattached EIPs.\n",
        "\n",
        "To release one:\n",
        "\n",
        "```bash\n",
        "aws ec2 release-address --allocation-id eipalloc-xxxxxx\n",
        "```\n",
        "\n",
        "To find the unused NAT in your region, for example us-west-2:\n",
        "```bash\n",
        "aws ec2 describe-nat-gateways --region us-west-2 --filter \"Name=state,Values=available\" | jq '.NatGateways | length'\n",
        "```\n",
        "\n",
        "To delete one:\n",
        "\n",
        "```bash\n",
        "aws ec2 delete-nat-gateway --nat-gateway-id nat-xxxxxxxx\n",
        "```\n",
        "\n",
        "To identify VPCs that look like they might be safe to delete (test/development ones):\n",
        "```bash\n",
        "aws ec2 describe-vpcs --query 'Vpcs[*].[VpcId,Tags[?Key==`Name`].Value|[0]]' --output table | grep -E \"(test|temp|dev|scratch|derp|floral|scrumptious)\"\n",
        "```\n",
        "\n",
        "to delete one:\n",
        "```bash\n",
        "aws ec2 delete-vpc --vpc-id vpc-0f8bb12ddf9a451e9  # You can delete more\n",
        "```\n",
        "\n",
        "You may need to delete more depends on your scenario.\n",
        "\n",
        "</detail>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Take a note to the output of terraform apply! </b>You will need it when you register the Anyscale cloud to your cloud provider.\n",
        "</div>\n",
        "\n",
        "<details>\n",
        "<summary>Sample output</summary>\n",
        "```\n",
        "Outputs:\n",
        "\n",
        "anyscale_registration_command = <<EOT\n",
        "anyscale cloud register \\\n",
        "        --name <anyscale_cloud_name> \\\n",
        "        --region xxxxxxx \\\n",
        "        --provider aws \\\n",
        "        --compute-stack k8s \\\n",
        "        --kubernetes-zones us-west-2a,us-west-2b \\\n",
        "        --s3-bucket-id xxxxxxx \\\n",
        "        --anyscale-operator-iam-identity arn:aws:iam::xxxxxx:role/default-eks-node-group-xxxxxxxxxxxx\n",
        "EOT\n",
        "aws_region = \"xxxxxxxx\"\n",
        "eks_cluster_name = \"xxxxxxx\"\n",
        "helm_upgrade_command = <<EOT\n",
        "helm upgrade anyscale-operator anyscale/anyscale-operator \\\n",
        "        --set-string cloudDeploymentId=<cloud-deployment-id> \\\n",
        "        --set-string cloudProvider=aws \\\n",
        "        --set-string region=us-west-2 \\\n",
        "        --set-string workloadServiceAccountName=anyscale-operator \\\n",
        "        --namespace anyscale-operator \\\n",
        "        --create-namespace \\\n",
        "        -i\n",
        "EOT\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Attach Required IAM Policies to Your existing EKS's Node Role\n",
        "\n",
        "After running Terraform to create the resources, you need to attach the IAM policies to your EKS node role."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!aws eks list-nodegroups --cluster-name {EKS_CLUSTER_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "to get a list of node groups in your cluster. Pick the **Anyscale related node group name** you are looking for."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Second, find your node role name by running:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!aws eks describe-nodegroup --cluster-name {EKS_CLUSTER_NAME} --nodegroup-name {Anyscale related node group name} --query 'nodegroup.nodeRole' --output text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This will give you the ARN of the role, from which you can extract the **Node Role Name** (the part after the last \"/\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Third, to get the S3 policy ARN from Terraform output:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!terraform output -raw module.anyscale_iam_roles.anyscale_iam_s3_policy_arn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then you will attach both policies to your node role (replace **{Node Role Name}** with your existing EKS node role name):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Attach the S3 policy\n",
        "!aws iam attach-role-policy \\\n",
        "  --role-name {NODE ROLE NAME} \\\n",
        "  --policy-arn $(terraform output -raw module.anyscale_iam_roles.anyscale_iam_s3_policy_arn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Attach the EFS policy\n",
        "!aws iam attach-role-policy \\\n",
        "  --role-name {NODE ROLE NAM} \\\n",
        "  --policy-arn arn:aws:iam::aws:policy/AmazonElasticFileSystemClientReadWriteAccess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Install Kubernetes Components\n",
        "\n",
        "The Anyscale Operator requires the following components:\n",
        "- Cluster autoscaler\n",
        "- AWS Load Balancer Controller (LBC)\n",
        "- Nginx Ingress Controller\n",
        "- (Optional) Nvidia device plugin (for GPU nodes)\n",
        "\n",
        "Let's set up each of these components:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Install the Cluster Autoscaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set your EKS cluster name and AWS region\n",
        "\n",
        "# Update kubectl to connect to your new EKS cluster\n",
        "!aws eks update-kubeconfig --region {AWS_REGION} --name {EKS_CLUSTER_NAME}\n",
        "\n",
        "!helm repo add autoscaler https://kubernetes.github.io/autoscaler\n",
        "!helm upgrade cluster-autoscaler autoscaler/cluster-autoscaler \\\n",
        "  --version 9.46.0 \\\n",
        "  --namespace kube-system \\\n",
        "  --set awsRegion={AWS_REGION} \\\n",
        "  --set 'autoDiscovery.clusterName'={EKS_CLUSTER_NAME} \\\n",
        "  --install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 3.2 Install the AWS Load Balancer Controller\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!helm repo add eks https://aws.github.io/eks-charts\n",
        "!helm upgrade aws-load-balancer-controller eks/aws-load-balancer-controller \\\n",
        "  --version 1.13.2 \\\n",
        "  --namespace kube-system \\\n",
        "  --set clusterName={EKS_CLUSTER_NAME} \\\n",
        "  --install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 3.3 Install the Nginx Ingress Controller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We already have a sample-values_nginx.yaml file in the current directory\n",
        "!helm repo add nginx https://kubernetes.github.io/ingress-nginx\n",
        "!helm upgrade ingress-nginx nginx/ingress-nginx \\\n",
        "  --version 4.12.1 \\\n",
        "  --namespace ingress-nginx \\\n",
        "  --values sample-values_nginx.yaml \\\n",
        "  --create-namespace \\\n",
        "  --install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 3.4 (Optional) Install the Nvidia Device Plugin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We already have a sample-values_nvdp.yaml file in the current directory\n",
        "\n",
        "# Uncomment and run these commands when you're ready\n",
        "!helm repo add nvdp https://nvidia.github.io/k8s-device-plugin\n",
        "!helm upgrade nvdp nvdp/nvidia-device-plugin \\\n",
        "  --namespace nvidia-device-plugin \\\n",
        "  --version 0.17.1 \\\n",
        "  --values sample-values_nvdp.yaml \\\n",
        "  --create-namespace \\\n",
        "  --install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Register the Anyscale Cloud\n",
        "\n",
        "First, ensure you're logged into Anyscale. if you cannot run it in console, please run it in your local terminal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!anyscale login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then use the output of `terraform apply` to register Anyscale cloud. You only need to replace the `--name` parameter with your preferred `ANYSCALE_CLOUD_NAME`. The command looks like:\n",
        "\n",
        "```bash\n",
        "anyscale cloud register ...\n",
        "```\n",
        "\n",
        "You will get output like:\n",
        "\n",
        "```text\n",
        "Output\n",
        "(anyscale +17.9s) For registering this cloud's Kubernetes Manager, use cloud deployment ID 'cldrsrc_12345abcdefgh67890ijklmnop'.\n",
        "(anyscale +18.0s) Successfully created cloud anyscale-cloud-eks-private-xxxxx, and it's ready to use.\n",
        "```\n",
        "\n",
        "After running the command, note the Cloud Deployment ID from the output. It will look something like: \n",
        "```\n",
        "cldrsrc_12345abcdefgh67890ijklmnop\n",
        "```\n",
        "You'll need this for the next step\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Install the Anyscale Operator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the cloud deployment ID from the previous step\n",
        "CLOUD_DEPLOYMENT_ID = \"cldrsrc_12345abcdefgh67890ijklmnop\"  # Replace with your actual cloud deployment ID\n",
        "\n",
        "!helm repo add anyscale https://anyscale.github.io/helm-charts\n",
        "!helm upgrade anyscale-operator anyscale/anyscale-operator \\\n",
        "  --set-string cloudDeploymentId={CLOUD_DEPLOYMENT_ID} \\\n",
        "  --set-string cloudProvider=aws \\\n",
        "  --set-string region={AWS_REGION} \\\n",
        "  --set-string workloadServiceAccountName=anyscale-operator \\\n",
        "  --namespace anyscale-operator \\\n",
        "  --create-namespace \\\n",
        "  --install\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Verify the Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Check if Anyscale operator pods are running\n",
        "!kubectl get pods --all-namespaces | grep -E \"(anyscale|ray)\" | grep -v \"cluster-autoscaler\"\n",
        "\n",
        "\n",
        "# Check if the Anyscale cloud is registered\n",
        "!anyscale cloud list\n",
        "\n",
        "# Check if Anyscale operator pods are running\n",
        "!kubectl get pods --all-namespaces | grep -E \"(anyscale|ray)\" | grep -v \"cluster-autoscaler\"\n",
        "\n",
        "# Check if ray cluster is running\n",
        "!kubectl get pods --all-namespaces | grep ray\n",
        "\n",
        "# Check if the Anyscale cloud is registered\n",
        "!anyscale cloud list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test\n",
        "\n",
        "Once the cluster is created, you can test it by submitting a job from your terminal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "A_RANDOM_JOB_NAME = \"A random job name\"  # Replace with a random job name you like\n",
        "\n",
        "!cd ../test && python test_job.py  --cloud-name {ANYSCALE_CLOUD_NAME}  --stack-type k8s\n",
        "\n",
        "# You can check the job status by running:\n",
        "!anyscale job list --cloud {ANYSCALE_CLOUD_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "You just start a job and you can see the logs from your Anyscale Console. You can view the running results from Anyscale console in \"Jobs\".\n",
        "\n",
        "You can also run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!kubectl get pods --all-namespaces | grep -E \"(anyscale|ray)\" | grep -v \"cluster-autoscaler\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "to see new anyscale nodes are scaled up after this job starts; and after it is completed, those nodes will be terminated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you examine the [test job](../test/test_job.py#L30-L50), you'll see that we define a Ray cluster by configuring head nodes and worker nodes with appropriate instance types. When this job is submitted, the Ray cluster is created and the job executes on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute Configuration Defines Cluster Resources:\n",
        "\n",
        "compute_config = ComputeConfig(\n",
        "    cloud=cloud_name,\n",
        "    head_node=HeadNodeConfig(\n",
        "        instance_type=\"2CPU-8GB\",        # Ray head node\n",
        "    ),\n",
        "    worker_nodes=[\n",
        "        WorkerNodeGroupConfig(\n",
        "            instance_type=\"2CPU-8GB\",    # Ray worker nodes\n",
        "            min_nodes=1,                 # Minimum workers\n",
        "            max_nodes=1,                 # Maximum workers  \n",
        "        )\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. Troubleshooting\n",
        "\n",
        "Here are some common issues and how to resolve them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Troubleshooting</b> \n",
        "\n",
        "<details>\n",
        "<summary>Click to expand</summary>\n",
        "\n",
        "\n",
        "1. **IAM Permissions**: Ensure that the Node IAM role has the necessary policies attached:\n",
        "   - AmazonElasticFileSystemClientReadWriteAccess\n",
        "   - The Anyscale IAM S3 policy\n",
        "\n",
        "2. **Networking Issues**: Verify that the security groups allow the necessary traffic between nodes and for external access.\n",
        "\n",
        "3. **Cluster Autoscaler**: If nodes aren't scaling, check the cluster autoscaler logs:\n",
        "\n",
        "\n",
        "kubectl logs -n kube-system -l app=cluster-autoscaler\n",
        "\n",
        "4. **Anyscale Operator**: If the Anyscale operator isn't functioning correctly, check its logs:\n",
        "\n",
        "kubectl logs -n anyscale-operator -l app=anyscale-operator\n",
        "\n",
        "</details>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**View job logs from Anyscale Console**:\n",
        "\n",
        "<details>\n",
        "<summary> You may find you are not able to see full logs of a job, which is because you need to add Cross-origin permission to the S3 bucket you use for the deployment.\n",
        "</summary>\n",
        "   You can:\n",
        "\n",
        "   1. Log in to your AWS console, choose S3 service, and find the bucket you are using for this deployment\n",
        "   2. Click \"Permissions\", and scroll down to \"Cross-origin resource sharing (CORS)\"\n",
        "   3. Add the following:\n",
        "   ```\n",
        "   [\n",
        "      {\n",
        "        \"AllowedHeaders\": [\n",
        "            \"*\"\n",
        "        ],\n",
        "        \"AllowedMethods\": [\n",
        "            \"GET\"\n",
        "        ],\n",
        "        \"AllowedOrigins\": [\n",
        "            \"https://console.anyscale.com\"\n",
        "        ],\n",
        "        \"ExposeHeaders\": []\n",
        "      }\n",
        "   ]\n",
        "   ```\n",
        "   Save this change and you should be able to view full job logs now.\n",
        "   </details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Clean up\n",
        "\n",
        "Run these 3 commands in your terminal, updating the placeholder values to match your setup:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unregister the cloud\n",
        "!anyscale cloud delete {ANYSCALE_CLOUD_NAME}\n",
        "\n",
        "# Verify it is deleted\n",
        "!anyscale cloud list\n",
        "\n",
        "# Empty ANYSCALE S3 bucket if it contains data, if it throws error, please try it in your local terminal\n",
        "!aws s3 rm s3://{ANYSCALE_S3_BUCKET_NAME} --recursive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you can run following block to clean up the rest of the resources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uninstall the Anyscale operator\n",
        "!helm uninstall anyscale-operator --namespace anyscale-operator\n",
        "\n",
        "# Delete the namespace\n",
        "!kubectl delete namespace anyscale-operator\n",
        "\n",
        "# (Optional if you add it because you installed AnyscaleRay) Remove Nginx Ingress Controller\n",
        "!helm uninstall ingress-nginx --namespace ingress-nginx\n",
        "!kubectl delete namespace ingress-nginx\n",
        "\n",
        "# (Optional if you add it because you installed Anyscale) Remove AWS Load Balancer Controller\n",
        "!helm uninstall aws-load-balancer-controller --namespace kube-system\n",
        "\n",
        "# (Optional if you add it because you installed Anyscale) Remove Cluster Autoscaler\n",
        "!helm uninstall cluster-autoscaler --namespace kube-system\n",
        "\n",
        "# (Optional if you add it because you installed Anyscale) Remove Nvidia Device Plugin\n",
        "!helm uninstall nvdp --namespace nvidia-device-plugin\n",
        "!kubectl delete namespace nvidia-device-plugin\n",
        "\n",
        "# Empty ANYSCALE S3 bucket if it contains data, if it throws error, please try it in your local terminal\n",
        "!aws s3 rm s3://{ANYSCALE_S3_BUCKET_NAME} --recursive\n",
        "\n",
        "# Destroy Terraform-managed resources\n",
        "!terraform plan -destroy\n",
        "!terraform destroy --auto-approve\n",
        "\n",
        "# Verify no Anyscale-related pods are running\n",
        "!kubectl get pods --all-namespaces | grep -E \"(anyscale|ray)\"\n",
        "\n",
        "# Verify Helm releases are removed\n",
        "!helm list --all-namespaces\n",
        "\n",
        "# Verify Terraform resources are destroyed\n",
        "!terraform show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 10. Conclusion\n",
        "\n",
        "You have now successfully set up the Anyscale environment on an existing AWS EKS cluster. This includes:\n",
        "\n",
        "1. Creating the necessary AWS resources using Terraform\n",
        "2. Installing the required Kubernetes components:\n",
        "   - Cluster Autoscaler\n",
        "   - AWS Load Balancer Controller\n",
        "   - Nginx Ingress Controller\n",
        "   - (Optional) Nvidia Device Plugin\n",
        "3. Registering the Anyscale Cloud\n",
        "4. Installing the Anyscale Operator\n",
        "\n",
        "You can now use this environment to run Ray workloads on Anyscale.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Xing-ray-jupyter-3.11",
      "language": "python",
      "name": "xing-ray-jupyter"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
