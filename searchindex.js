Search.setIndex({"alltitles": {"0. Overview": [[1, "overview"], [13, null], [101, "overview"], [102, "overview"], [209, "overview"], [211, null]], "0. What is Ray Data?": [[8, "what-is-ray-data"], [50, null], [232, "what-is-ray-data"], [234, null]], "01 \u00b7 Define Training Loop with Ray Data": [[258, "define-training-loop-with-ray-data"], [273, null]], "01 \u00b7 Imports": [[258, "imports"], [260, null]], "01 \u00b7 Modify Training Loop to Enable Checkpoint Loading": [[258, "modify-training-loop-to-enable-checkpoint-loading"], [279, null]], "02 \u00b7 Build DataLoader from Ray Data": [[258, "build-dataloader-from-ray-data"], [274, null]], "02 \u00b7 Download MNIST Dataset": [[258, "download-mnist-dataset"], [260, "download-mnist-dataset"]], "02 \u00b7 Save Full Checkpoint with Extra State": [[258, "save-full-checkpoint-with-extra-state"], [280, null]], "03 \u00b7 Configure Automatic Retries with FailureConfig": [[258, "configure-automatic-retries-with-failureconfig"], [280, "configure-automatic-retries-with-failureconfig"]], "03 \u00b7 Prepare Dataset for Ray Data": [[258, "prepare-dataset-for-ray-data"], [275, null]], "03 \u00b7 Visualize Sample Digits": [[258, "visualize-sample-digits"], [260, "visualize-sample-digits"]], "04 \u00b7 Define ResNet-18 Model for MNIST": [[258, "define-resnet-18-model-for-mnist"], [261, null]], "04 \u00b7 Launch Fault-Tolerant Training": [[258, "launch-fault-tolerant-training"], [281, null]], "04 \u00b7 Load Dataset into Ray Data": [[258, "load-dataset-into-ray-data"], [275, "load-dataset-into-ray-data"]], "04-d1 Generative computer-vision pattern with Ray Train": [[362, null], [363, null]], "04-d2 Diffusion-Policy Pattern with Ray Train": [[369, null], [370, null]], "04a Computer-vision pattern with Ray Train": [[395, null], [396, null]], "04b Tabular workload pattern with Ray Train": [[382, null], [383, null]], "04c Time-Series workload pattern with Ray Train": [[388, null], [389, null]], "04e Recommendation system pattern with Ray Train": [[375, null], [376, null]], "05 \u00b7 Define Image Transformation": [[258, "define-image-transformation"], [276, null]], "05 \u00b7 Define the Ray Train Loop (DDP per-worker)": [[258, "define-the-ray-train-loop-ddp-per-worker"], [262, null]], "05 \u00b7 Manual Restoration from Checkpoints": [[258, "manual-restoration-from-checkpoints"], [282, null]], "06 \u00b7 Apply Transformations with Ray Data": [[258, "apply-transformations-with-ray-data"], [276, "apply-transformations-with-ray-data"]], "06 \u00b7 Define train_loop_config": [[258, "define-train-loop-config"], [263, null]], "06 \u00b7 Resume Training from the Last Checkpoint": [[258, "resume-training-from-the-last-checkpoint"], [282, "resume-training-from-the-last-checkpoint"]], "07 \u00b7 Clean Up Cluster Storage": [[258, "clean-up-cluster-storage"], [283, null]], "07 \u00b7 Configure Scaling with ScalingConfig": [[258, "configure-scaling-with-scalingconfig"], [264, null]], "07 \u00b7 Configure TorchTrainer with Ray Data": [[258, "configure-torchtrainer-with-ray-data"], [277, null]], "08 \u00b7 Launch Training with Ray Data": [[258, "launch-training-with-ray-data"], [277, "launch-training-with-ray-data"]], "08 \u00b7 Wrap the Model with prepare_model()": [[258, "wrap-the-model-with-prepare-model"], [265, null]], "09 \u00b7 Build the DataLoader with prepare_data_loader()": [[258, "build-the-dataloader-with-prepare-data-loader"], [266, null]], "1. Architecture": [[348, "architecture"], [351, null]], "1. Cloud Object Store": [[76, "cloud-object-store"], [88, "cloud-object-store"]], "1. Create Anyscale Resources with Terraform": [[112, "create-anyscale-resources-with-terraform"], [114, null], [127, "create-anyscale-resources-with-terraform"], [129, null], [137, "create-anyscale-resources-with-terraform"], [140, null]], "1. Creating Remote Functions": [[1, "creating-remote-functions"], [14, null], [209, "creating-remote-functions"], [212, null]], "1. Dataset tuples": [[369, "dataset-tuples"], [370, "dataset-tuples"]], "1. Deploy to Kubernetes with Anyscale Operator": [[108, "deploy-to-kubernetes-with-anyscale-operator"], [109, "deploy-to-kubernetes-with-anyscale-operator"]], "1. How to Use Ray Data?": [[8, "how-to-use-ray-data"], [50, "how-to-use-ray-data"], [232, "how-to-use-ray-data"], [234, "how-to-use-ray-data"]], "1. Imports": [[375, "imports"], [377, null], [382, "imports"], [384, null], [388, "imports"], [390, null], [395, "imports"], [397, null]], "1. Imports and setup": [[362, "imports-and-setup"], [364, null], [369, "imports-and-setup"], [371, null]], "1. In the Anyscale Console, open (or create) a Workspace.": [[82, "in-the-anyscale-console-open-or-create-a-workspace"], [97, "in-the-anyscale-console-open-or-create-a-workspace"]], "1. Installation": [[119, "installation"], [122, null], [150, "installation"], [153, null]], "1. Key-Value (KV) Caching": [[164, "key-value-kv-caching"], [165, "key-value-kv-caching"], [168, "key-value-kv-caching"]], "1. Loading and visualizing data": [[293, "loading-and-visualizing-data"], [309, null]], "1. Loading the data": [[6, "loading-the-data"], [39, null], [285, "loading-the-data"], [287, null]], "1. Memory Management": [[164, "memory-management"], [165, "memory-management"], [169, "memory-management"]], "1. Model Quality Benchmarks": [[181, "model-quality-benchmarks"], [187, "model-quality-benchmarks"]], "1. Object store": [[2, "object-store"], [18, null], [215, "object-store"], [217, null]], "1. Overview of Ray Serve": [[295, "overview-of-ray-serve"], [321, null]], "1. Overview of the Ray AI Libraries": [[3, "overview-of-the-ray-ai-libraries"], [27, null], [203, "overview-of-the-ray-ai-libraries"], [205, null], [291, "overview-of-the-ray-ai-libraries"], [297, null]], "1. PyTorch introductory example (single GPU)": [[292, "pytorch-introductory-example-single-gpu"], [300, null]], "1. Ray Serve for Orchestration": [[164, "ray-serve-for-orchestration"], [165, "ray-serve-for-orchestration"], [170, "ray-serve-for-orchestration"]], "1. Reduce max_model_len": [[173, "reduce-max-model-len"], [179, "reduce-max-model-len"]], "1. Sign Up for Anyscale": [[84, "sign-up-for-anyscale"]], "1. Spin up a Anyscale Workspace, we will use this as the environment to develop and publish the Anyscale Service. Give this workspace a name, check the Auto-Select Worker Nodes and leave everything else as default.": [[83, "spin-up-a-anyscale-workspace-we-will-use-this-as-the-environment-to-develop-and-publish-the-anyscale-service-give-this-workspace-a-name-check-the-auto-select-worker-nodes-and-leave-everything-else-as-default"], [100, "spin-up-a-anyscale-workspace-we-will-use-this-as-the-environment-to-develop-and-publish-the-anyscale-service-give-this-workspace-a-name-check-the-auto-select-worker-nodes-and-leave-everything-else-as-default"]], "1. Split Notebooks and Generate Navigation": [[0, "split-notebooks-and-generate-navigation"]], "1. User Profile Retrieval": [[202, "user-profile-retrieval"]], "1. Using the same workspace, create a notebook folder": [[82, "using-the-same-workspace-create-a-notebook-folder"], [98, "using-the-same-workspace-create-a-notebook-folder"]], "1. What is an Anyscale Cloud?": [[101, "what-is-an-anyscale-cloud"], [103, null]], "1. When to Consider Ray Data": [[9, "when-to-consider-ray-data"], [57, null], [240, "when-to-consider-ray-data"], [242, null]], "1. When to Consider Ray Serve": [[10, "when-to-consider-ray-serve"], [68, null], [252, "when-to-consider-ray-serve"], [254, null]], "1. When to use Ray Data": [[294, "when-to-use-ray-data"], [315, null]], "1. When to use Ray Train": [[4, "when-to-use-ray-train"], [5, "when-to-use-ray-train"], [30, null], [34, null], [326, "when-to-use-ray-train"], [328, null]], "1.1 Configure Google Cloud Authentication": [[119, "configure-google-cloud-authentication"], [122, "configure-google-cloud-authentication"]], "1.1. Configure Google Cloud Authentication": [[150, "configure-google-cloud-authentication"], [153, "configure-google-cloud-authentication"]], "1.1. Pattern: pass an object as a top-level argument": [[2, "pattern-pass-an-object-as-a-top-level-argument"], [18, "pattern-pass-an-object-as-a-top-level-argument"], [215, "pattern-pass-an-object-as-a-top-level-argument"], [217, "pattern-pass-an-object-as-a-top-level-argument"]], "1.2 Enable Required APIs": [[119, "enable-required-apis"], [122, "enable-required-apis"]], "1.2: Enable Required APIs": [[150, "enable-required-apis"], [153, "enable-required-apis"]], "10 \u00b7 Report Training Metrics": [[258, "report-training-metrics"], [267, null]], "10. Clean up": [[369, "clean-up"], [374, "clean-up"]], "10. Conclusion": [[137, "conclusion"], [149, null]], "10. Helper: Ray-prepared DataLoaders": [[395, "helper-ray-prepared-dataloaders"], [399, null]], "10. Launch distributed Training with TorchTrainer": [[362, "launch-distributed-training-with-torchtrainer"], [366, "launch-distributed-training-with-torchtrainer"]], "10. Plot train and validation loss curves": [[375, "plot-train-and-validation-loss-curves"], [379, "plot-train-and-validation-loss-curves"]], "10. Ray Train training loop (with teacher forcing)": [[388, "ray-train-training-loop-with-teacher-forcing"], [392, null]], "10. Start distributed training": [[382, "start-distributed-training"], [385, "start-distributed-training"]], "101 - Anyscale Organization and Cloud Setup": [[81, null], [93, null]], "101 Introduction to Anyscale Services": [[82, "introduction-to-anyscale-services"], [83, "introduction-to-anyscale-services"], [96, "introduction-to-anyscale-services"], [99, "introduction-to-anyscale-services"]], "101 \u2013  Introduction to Anyscale Services": [[79, null], [91, null]], "101 \u2013 Collaboration on Anyscale": [[80, null], [92, null]], "101 \u2013 Compute Configs and Execution Environments in Anyscale": [[75, null], [87, null]], "101 \u2013 Debug and Monitor Your Anyscale Application": [[77, null], [89, null]], "101 \u2013 Developing Application with Anyscale": [[74, null], [86, null]], "101 \u2013 Introduction to Anyscale Jobs": [[78, null], [90, null]], "101 \u2013 Storage Options in the Anyscale Platform": [[76, null], [88, null]], "101 \u2014 Introduction to Anyscale Workspaces": [[73, null], [85, null]], "11 \u00b7 Save Checkpoints and Report Metrics": [[258, "save-checkpoints-and-report-metrics"], [268, null]], "11. Evaluate the trained model": [[382, "evaluate-the-trained-model"], [385, "evaluate-the-trained-model"]], "11. Launch training on 8 GPUs": [[388, "launch-training-on-8-gpus"], [392, "launch-training-on-8-gpus"]], "11. Plot loss curves": [[362, "plot-loss-curves"], [366, "plot-loss-curves"]], "11. Resume training from checkpoint": [[375, "resume-training-from-checkpoint"], [380, null]], "11. train_loop_per_worker": [[395, "train-loop-per-worker"], [400, null]], "12 \u00b7 Save Checkpoints on Rank-0 Only": [[258, "save-checkpoints-on-rank-0-only"], [268, "save-checkpoints-on-rank-0-only"]], "12. Confusion matrix visualization": [[382, "confusion-matrix-visualization"], [386, null]], "12. Inference: recommend top-N items for a user": [[375, "inference-recommend-top-n-items-for-a-user"], [381, null]], "12. Launch distributed training with TorchTrainer": [[395, "launch-distributed-training-with-torchtrainer"], [401, null]], "12. Plot training and validation loss": [[388, "plot-training-and-validation-loss"], [392, "plot-training-and-validation-loss"]], "12. Resume from latest checkpoint": [[362, "resume-from-latest-checkpoint"], [367, null]], "13 \u00b7 Configure Persistent Storage with RunConfig": [[258, "configure-persistent-storage-with-runconfig"], [268, "configure-persistent-storage-with-runconfig"]], "13. CPU batch inference with Ray Data": [[382, "cpu-batch-inference-with-ray-data"], [386, "cpu-batch-inference-with-ray-data"]], "13. Join top-N item IDs with movie titles": [[375, "join-top-n-item-ids-with-movie-titles"], [381, "join-top-n-item-ids-with-movie-titles"]], "13. Plot training and validation loss curves": [[395, "plot-training-and-validation-loss-curves"], [402, null]], "13. Resume training from checkpoint": [[388, "resume-training-from-checkpoint"], [393, null]], "13. Reverse diffusion sampler": [[362, "reverse-diffusion-sampler"], [368, null]], "14 \u00b7 Create the TorchTrainer": [[258, "create-the-torchtrainer"], [269, null]], "14. Clean up shared storage": [[375, "clean-up-shared-storage"], [381, "clean-up-shared-storage"]], "14. Demonstrate fault-tolerant resumption": [[395, "demonstrate-fault-tolerant-resumption"], [403, null]], "14. Feature-importance diagnostics": [[382, "feature-importance-diagnostics"], [386, "feature-importance-diagnostics"]], "14. Generate and display samples from the best checkpoint": [[362, "generate-and-display-samples-from-the-best-checkpoint"], [368, "generate-and-display-samples-from-the-best-checkpoint"]], "14. Inference helper \u2014 Ray Data batch predictor on GPU": [[388, "inference-helper-ray-data-batch-predictor-on-gpu"], [394, null]], "15 \u00b7 Launch Training with trainer.fit()": [[258, "launch-training-with-trainer-fit"], [269, "launch-training-with-trainer-fit"]], "15. Batch inference with Ray Data": [[395, "batch-inference-with-ray-data"], [404, null]], "15. Clean up shared storage": [[362, "clean-up-shared-storage"], [368, "clean-up-shared-storage"]], "15. Continue training from the latest checkpoint": [[382, "continue-training-from-the-latest-checkpoint"], [387, null]], "15. Run distributed inference and visualize results": [[388, "run-distributed-inference-and-visualize-results"], [394, "run-distributed-inference-and-visualize-results"]], "16 \u00b7 Inspect the Training Results": [[258, "inspect-the-training-results"], [270, null]], "16. Cleanup: remove all training artifacts": [[388, "cleanup-remove-all-training-artifacts"], [394, "cleanup-remove-all-training-artifacts"]], "16. Run and visualize Ray Data inference": [[395, "run-and-visualize-ray-data-inference"], [404, "run-and-visualize-ray-data-inference"]], "16. Verify post-training inference": [[382, "verify-post-training-inference"], [387, "verify-post-training-inference"]], "17 \u00b7 View Metrics as a DataFrame": [[258, "view-metrics-as-a-dataframe"], [270, "view-metrics-as-a-dataframe"]], "17. Clean up": [[382, "clean-up"], [387, "clean-up"], [395, "clean-up"], [404, "clean-up"]], "18 \u00b7 Load a Checkpoint for Inference": [[258, "load-a-checkpoint-for-inference"], [271, null]], "19 \u00b7 Run Inference and Visualize Predictions": [[258, "run-inference-and-visualize-predictions"], [271, "run-inference-and-visualize-predictions"]], "2. Attach Required IAM Policies to Your existing EKS\u2019s Node Role": [[137, "attach-required-iam-policies-to-your-existing-eks-s-node-role"], [141, null]], "2. Build the Book": [[0, "build-the-book"]], "2. Chaining Tasks and Passing Data": [[2, "chaining-tasks-and-passing-data"], [19, null], [215, "chaining-tasks-and-passing-data"], [218, null]], "2. Clone the Repository (Optional)": [[84, "clone-the-repository-optional"]], "2. Cloud Deployment Types": [[101, "cloud-deployment-types"], [104, null]], "2. Continuous Batching": [[164, "continuous-batching"], [165, "continuous-batching"], [168, "continuous-batching"]], "2. Create Anyscale Resources with Terraform": [[119, "create-anyscale-resources-with-terraform"], [123, null], [150, "create-anyscale-resources-with-terraform"], [154, null]], "2. Distributed Data Parallel Training with Ray Train and PyTorch (multiple GPUs)": [[292, "distributed-data-parallel-training-with-ray-train-and-pytorch-multiple-gpus"], [301, null]], "2. End-to-end example: predicting taxi tips in New York": [[291, "end-to-end-example-predicting-taxi-tips-in-new-york"], [298, null]], "2. Executing Remote Functions": [[1, "executing-remote-functions"], [15, null], [209, "executing-remote-functions"], [213, null]], "2. Generate a real pendulum dataset": [[369, "generate-a-real-pendulum-dataset"], [371, "generate-a-real-pendulum-dataset"]], "2. How to work with Ray Data": [[9, "how-to-work-with-ray-data"], [58, null], [240, "how-to-work-with-ray-data"], [243, null]], "2. Implement an Classifier service": [[295, "implement-an-classifier-service"], [322, null]], "2. Install Kubernetes Components": [[127, "install-kubernetes-components"], [130, null]], "2. Latency Requirements": [[164, "latency-requirements"], [165, "latency-requirements"], [169, "latency-requirements"]], "2. Library Imports": [[348, "library-imports"], [351, "library-imports"]], "2. Load 10 % of Food-101": [[362, "load-10-of-food-101"], [364, "load-10-of-food-101"], [395, "load-10-of-food-101"], [397, "load-10-of-food-101"]], "2. Load MovieLens 100K dataset": [[375, "load-movielens-100k-dataset"], [377, "load-movielens-100k-dataset"]], "2. Load NYC taxi passenger counts (30-min)": [[388, "load-nyc-taxi-passenger-counts-30-min"], [390, "load-nyc-taxi-passenger-counts-30-min"]], "2. Load the University of California, Irvine (UCI) Cover type dataset": [[382, "load-the-university-of-california-irvine-uci-cover-type-dataset"], [384, "load-the-university-of-california-irvine-uci-cover-type-dataset"]], "2. Loading Data": [[8, "loading-data"], [51, null], [232, "loading-data"], [235, null], [294, "loading-data"], [316, null]], "2. Once in the workspace, navigate to the VS Code Editor": [[82, "once-in-the-workspace-navigate-to-the-vs-code-editor"], [97, "once-in-the-workspace-navigate-to-the-vs-code-editor"]], "2. Overview of Ray Serve": [[10, "overview-of-ray-serve"], [69, null], [252, "overview-of-ray-serve"], [255, null]], "2. Quick end-to-end example": [[3, "quick-end-to-end-example"], [28, null], [203, "quick-end-to-end-example"], [206, null]], "2. Register the Anyscale Cloud": [[112, "register-the-anyscale-cloud"], [115, null]], "2. Setting up a PyTorch model": [[293, "setting-up-a-pytorch-model"], [310, null]], "2. Shared File Storage": [[76, "shared-file-storage"], [88, "shared-file-storage"]], "2. Single GPU Training with PyTorch": [[4, "single-gpu-training-with-pytorch"], [31, null]], "2. Single GPU Training with PyTorch Lightning": [[5, "single-gpu-training-with-pytorch-lightning"], [35, null], [326, "single-gpu-training-with-pytorch-lightning"], [329, null]], "2. Starting out with vanilla PyTorch": [[6, "starting-out-with-vanilla-pytorch"], [40, null], [285, "starting-out-with-vanilla-pytorch"], [288, null]], "2. Task and Domain Alignment": [[181, "task-and-domain-alignment"], [187, "task-and-domain-alignment"]], "2. Training objective": [[369, "training-objective"], [370, "training-objective"]], "2. Use Quantized Models": [[173, "use-quantized-models"], [179, "use-quantized-models"]], "2. Use the Anyscale CLI to submit the Anyscale Job. For a full list of all available arguments, check out the Anyscale Job CLI documentation.": [[82, "use-the-anyscale-cli-to-submit-the-anyscale-job-for-a-full-list-of-all-available-arguments-check-out-the-anyscale-job-cli-documentation"], [98, "use-the-anyscale-cli-to-submit-the-anyscale-job-for-a-full-list-of-all-available-arguments-check-out-the-anyscale-job-cli-documentation"]], "2. User Registration": [[202, "user-registration"]], "2. Virtual Machines (VM) vs. Kubernetes (K8s)": [[108, "virtual-machines-vm-vs-kubernetes-k8s"], [110, null]], "2. vLLM as the inference engine": [[164, "vllm-as-the-inference-engine"], [165, "vllm-as-the-inference-engine"], [170, "vllm-as-the-inference-engine"]], "2.1 Control Layer: What Anyscale Manages or Needs Access To": [[108, "control-layer-what-anyscale-manages-or-needs-access-to"], [110, "control-layer-what-anyscale-manages-or-needs-access-to"]], "2.1 Create terraform.tfvars": [[119, "create-terraform-tfvars"], [123, "create-terraform-tfvars"]], "2.1 Install the Cluster Autoscaler": [[127, "install-the-cluster-autoscaler"], [130, "install-the-cluster-autoscaler"]], "2.1 Overview": [[5, "overview"], [35, "overview"], [326, "overview"], [329, "overview"]], "2.1 Vanilla XGboost code": [[3, "vanilla-xgboost-code"], [28, "vanilla-xgboost-code"], [203, "vanilla-xgboost-code"], [206, "vanilla-xgboost-code"]], "2.1. Overview": [[4, "overview"], [31, "overview"]], "2.1: Create terraform.tfvars": [[150, "create-terraform-tfvars"], [154, "create-terraform-tfvars"]], "2.2 Data Layer: Storage, Object Stores, and External Dependencies": [[108, "data-layer-storage-object-stores-and-external-dependencies"], [110, "data-layer-storage-object-stores-and-external-dependencies"]], "2.2 Hyperparameter tuning with Ray Tune": [[3, "hyperparameter-tuning-with-ray-tune"], [28, "hyperparameter-tuning-with-ray-tune"], [203, "hyperparameter-tuning-with-ray-tune"], [206, "hyperparameter-tuning-with-ray-tune"]], "2.2 Install the AWS Load Balancer Controller": [[127, "install-the-aws-load-balancer-controller"], [130, "install-the-aws-load-balancer-controller"]], "2.2 Note on blocks": [[9, "note-on-blocks"], [59, "note-on-blocks"], [240, "note-on-blocks"], [244, "note-on-blocks"]], "2.2 Run Terraform Commands": [[119, "run-terraform-commands"], [123, "run-terraform-commands"]], "2.2. Build model and load it on the GPU": [[4, "build-model-and-load-it-on-the-gpu"], [31, "build-model-and-load-it-on-the-gpu"]], "2.2. Create a torch dataloader": [[5, "create-a-torch-dataloader"], [35, "create-a-torch-dataloader"], [326, "create-a-torch-dataloader"], [329, "create-a-torch-dataloader"]], "2.2: Deploy Infrastructure": [[150, "deploy-infrastructure"], [154, "deploy-infrastructure"]], "2.3 Define a stable diffusion model": [[5, "define-a-stable-diffusion-model"], [35, "define-a-stable-diffusion-model"], [326, "define-a-stable-diffusion-model"], [329, "define-a-stable-diffusion-model"]], "2.3 Install the Nginx Ingress Controller": [[127, "install-the-nginx-ingress-controller"], [130, "install-the-nginx-ingress-controller"]], "2.3 Workload Execution Layer: How Ray Runs on Each Backend": [[108, "workload-execution-layer-how-ray-runs-on-each-backend"], [110, "workload-execution-layer-how-ray-runs-on-each-backend"]], "2.3. Create Dataset and DataLoader": [[4, "create-dataset-and-dataloader"], [31, "create-dataset-and-dataloader"]], "2.3. Distributed training with Ray Train": [[3, "distributed-training-with-ray-train"], [28, "distributed-training-with-ray-train"], [203, "distributed-training-with-ray-train"], [206, "distributed-training-with-ray-train"]], "2.4 (Optional) Install the Nvidia Device Plugin": [[127, "optional-install-the-nvidia-device-plugin"], [130, "optional-install-the-nvidia-device-plugin"]], "2.4 Serving an ensemble model with Ray Serve": [[3, "serving-an-ensemble-model-with-ray-serve"], [28, "serving-an-ensemble-model-with-ray-serve"], [203, "serving-an-ensemble-model-with-ray-serve"], [206, "serving-an-ensemble-model-with-ray-serve"]], "2.4 When to use which": [[108, "when-to-use-which"], [110, "when-to-use-which"]], "2.4. Create metrics and checkpointing": [[4, "create-metrics-and-checkpointing"], [31, "create-metrics-and-checkpointing"]], "2.4. Define a PyTorch Lightning training loop": [[5, "define-a-pytorch-lightning-training-loop"], [35, "define-a-pytorch-lightning-training-loop"], [326, "define-a-pytorch-lightning-training-loop"], [329, "define-a-pytorch-lightning-training-loop"]], "2.5 Batch inference with Ray Data": [[3, "batch-inference-with-ray-data"], [28, "batch-inference-with-ray-data"], [203, "batch-inference-with-ray-data"], [206, "batch-inference-with-ray-data"]], "2.5. Run the training loop": [[4, "run-the-training-loop"], [31, "run-the-training-loop"]], "2.6 Clean up": [[3, "clean-up"], [28, "clean-up"], [203, "clean-up"], [206, "clean-up"]], "2.6. Use checkpointed model to generate predictions": [[4, "use-checkpointed-model-to-generate-predictions"], [31, "use-checkpointed-model-to-generate-predictions"]], "2.Download starter template. Clone a github repository containing the files needed to deploy a Anyscale Service. Head over to the VSCode Tab (In Anyscale Workspace) and enter the following command into the terminal.": [[83, "download-starter-template-clone-a-github-repository-containing-the-files-needed-to-deploy-a-anyscale-service-head-over-to-the-vscode-tab-in-anyscale-workspace-and-enter-the-following-command-into-the-terminal"], [100, "download-starter-template-clone-a-github-repository-containing-the-files-needed-to-deploy-a-anyscale-service-head-over-to-the-vscode-tab-in-anyscale-workspace-and-enter-the-following-command-into-the-terminal"]], "20 \u00b7 Clean Up the Ray Actor": [[258, "clean-up-the-ray-actor"], [271, "clean-up-the-ray-actor"]], "3. (Optional) More Kubernetes Deployments Components": [[108, "optional-more-kubernetes-deployments-components"], [111, null]], "3. A Demonstrative Example of Resource Creation with AWS EC2": [[101, "a-demonstrative-example-of-resource-creation-with-aws-ec2"], [105, null]], "3. Advanced features of Ray Serve": [[295, "advanced-features-of-ray-serve"], [323, null]], "3. Anyscale for Infrastructure": [[164, "anyscale-for-infrastructure"], [165, "anyscale-for-infrastructure"], [170, "anyscale-for-infrastructure"]], "3. Context Window Requirements": [[181, "context-window-requirements"], [187, "context-window-requirements"]], "3. Distributed Data Parallel Training with Ray Train and PyTorch": [[4, "distributed-data-parallel-training-with-ray-train-and-pytorch"], [32, null]], "3. Distributed Training with Ray Train and PyTorch Lightning": [[5, "distributed-training-with-ray-train-and-pytorch-lightning"], [36, null], [326, "distributed-training-with-ray-train-and-pytorch-lightning"], [330, null]], "3. Enable Pipeline Parallelism": [[173, "enable-pipeline-parallelism"], [179, "enable-pipeline-parallelism"]], "3. Getting Results": [[1, "getting-results"], [15, "getting-results"], [209, "getting-results"], [213, "getting-results"]], "3. Hyperparameter tuning with Ray Tune": [[6, "hyperparameter-tuning-with-ray-tune"], [41, null], [285, "hyperparameter-tuning-with-ray-tune"], [289, null]], "3. Implement an image classification service": [[10, "implement-an-image-classification-service"], [70, null], [252, "implement-an-image-classification-service"], [256, null]], "3. Inspect the code for the Service Endpoint (./examples/02_service_hello_world/main.py)": [[83, "inspect-the-code-for-the-service-endpoint-examples-02-service-hello-world-main-py"], [100, "inspect-the-code-for-the-service-endpoint-examples-02-service-hello-world-main-py"]], "3. Install Kubernetes Components": [[137, "install-kubernetes-components"], [142, null]], "3. Install Ray and the Anyscale CLI (Recommended)": [[84, "install-ray-and-the-anyscale-cli-recommended"]], "3. Introduction to Ray Tune": [[293, "introduction-to-ray-tune"], [311, null]], "3. Lazy execution mode": [[9, "lazy-execution-mode"], [60, null], [240, "lazy-execution-mode"], [245, null]], "3. Loading data": [[9, "loading-data"], [59, null], [240, "loading-data"], [244, null]], "3. Local Cluster Storage": [[76, "local-cluster-storage"], [88, "local-cluster-storage"]], "3. Metrics Setup": [[348, "metrics-setup"], [352, null]], "3. Model parallelization or alternatives": [[164, "model-parallelization-or-alternatives"], [165, "model-parallelization-or-alternatives"], [168, "model-parallelization-or-alternatives"]], "3. Next, create a new file. You can name it hello_world.py": [[82, "next-create-a-new-file-you-can-name-it-hello-world-py"], [97, "next-create-a-new-file-you-can-name-it-hello-world-py"]], "3. Normalize and split": [[369, "normalize-and-split"], [371, "normalize-and-split"]], "3. Overview of the training loop in Ray Train": [[292, "overview-of-the-training-loop-in-ray-train"], [302, null]], "3. Point to Parquet dataset URI": [[375, "point-to-parquet-dataset-uri"], [377, "point-to-parquet-dataset-uri"]], "3. Register the Anyscale Cloud": [[119, "register-the-anyscale-cloud"], [124, null], [127, "register-the-anyscale-cloud"], [131, null]], "3. Resample to hourly, then normalize": [[388, "resample-to-hourly-then-normalize"], [390, "resample-to-hourly-then-normalize"]], "3. Resize and encode images": [[362, "resize-and-encode-images"], [364, "resize-and-encode-images"], [395, "resize-and-encode-images"], [397, "resize-and-encode-images"]], "3. Reverse diffusion (sampling)": [[369, "reverse-diffusion-sampling"], [370, "reverse-diffusion-sampling"]], "3. Running an experiment with Ray AI libraries": [[291, "running-an-experiment-with-ray-ai-libraries"], [298, "running-an-experiment-with-ray-ai-libraries"]], "3. Scalability Demands": [[164, "scalability-demands"], [165, "scalability-demands"], [169, "scalability-demands"]], "3. Serve Locally for Testing": [[0, "serve-locally-for-testing"]], "3. Submit the job again using the Anyscale Python SDK": [[82, "submit-the-job-again-using-the-anyscale-python-sdk"], [98, "submit-the-job-again-using-the-anyscale-python-sdk"]], "3. Task retries": [[2, "task-retries"], [20, null], [215, "task-retries"], [219, null]], "3. Test": [[112, "test"], [116, null]], "3. Transforming Data": [[8, "transforming-data"], [52, null], [232, "transforming-data"], [236, null], [294, "transforming-data"], [317, null]], "3. Troubleshooting GPU Availability": [[150, "troubleshooting-gpu-availability"], [155, null]], "3. Visualize class balance": [[382, "visualize-class-balance"], [384, "visualize-class-balance"]], "3.1 Distributed Data Parallel Training": [[5, "distributed-data-parallel-training"], [36, "distributed-data-parallel-training"], [326, "distributed-data-parallel-training"], [330, "distributed-data-parallel-training"]], "3.1 IAM Role Definition": [[101, "iam-role-definition"], [106, null]], "3.1 Install the Cluster Autoscaler": [[137, "install-the-cluster-autoscaler"], [142, "install-the-cluster-autoscaler"]], "3.1. Overview of the training loop in Ray Train": [[4, "overview-of-the-training-loop-in-ray-train"], [32, "overview-of-the-training-loop-in-ray-train"]], "3.1.1\u202f\u202fAnyscale Control Plane Role (anyscale-iam-role-id)": [[101, "anyscale-control-plane-role-anyscale-iam-role-id"], [106, "anyscale-control-plane-role-anyscale-iam-role-id"]], "3.1.2\u202f\u202fInstance Role (instance-iam-role-id)": [[101, "instance-role-instance-iam-role-id"], [106, "instance-role-instance-iam-role-id"]], "3.10. Activity: Run the distributed training with more workers": [[4, "activity-run-the-distributed-training-with-more-workers"], [32, "activity-run-the-distributed-training-with-more-workers"]], "3.2 Install the AWS Load Balancer Controller": [[137, "install-the-aws-load-balancer-controller"], [142, "install-the-aws-load-balancer-controller"]], "3.2 Ray Train Migration": [[5, "ray-train-migration"], [36, "ray-train-migration"], [326, "ray-train-migration"], [330, "ray-train-migration"]], "3.2. Configure scale and GPUs": [[4, "configure-scale-and-gpus"], [32, "configure-scale-and-gpus"]], "3.2.1. Note on Ray Train key concepts": [[4, "note-on-ray-train-key-concepts"], [32, "note-on-ray-train-key-concepts"]], "3.2\u202fVPC": [[101, "vpc"], [106, "vpc"]], "3.3 Install the Nginx Ingress Controller": [[137, "install-the-nginx-ingress-controller"], [142, "install-the-nginx-ingress-controller"]], "3.3 Subnets": [[101, "subnets"], [106, "subnets"]], "3.3. Configure scale and GPUs": [[5, "configure-scale-and-gpus"], [36, "configure-scale-and-gpus"], [326, "configure-scale-and-gpus"], [330, "configure-scale-and-gpus"]], "3.3. Migrating the model to Ray Train": [[4, "migrating-the-model-to-ray-train"], [32, "migrating-the-model-to-ray-train"]], "3.3.1. Note on Ray Train key concepts": [[5, "note-on-ray-train-key-concepts"], [36, "note-on-ray-train-key-concepts"], [326, "note-on-ray-train-key-concepts"], [330, "note-on-ray-train-key-concepts"]], "3.4 (Optional) Install the Nvidia Device Plugin": [[137, "optional-install-the-nvidia-device-plugin"], [142, "optional-install-the-nvidia-device-plugin"]], "3.4 Create and fit a Ray Train TorchTrainer": [[5, "create-and-fit-a-ray-train-torchtrainer"], [36, "create-and-fit-a-ray-train-torchtrainer"], [326, "create-and-fit-a-ray-train-torchtrainer"], [330, "create-and-fit-a-ray-train-torchtrainer"]], "3.4. Migrating the dataset to Ray Train": [[4, "migrating-the-dataset-to-ray-train"], [32, "migrating-the-dataset-to-ray-train"]], "3.4\u202fSecurity Groups": [[101, "security-groups"], [106, "security-groups"]], "3.5. Access the training results": [[5, "access-the-training-results"], [36, "access-the-training-results"], [326, "access-the-training-results"], [330, "access-the-training-results"]], "3.5. Reporting checkpoints and metrics": [[4, "reporting-checkpoints-and-metrics"], [32, "reporting-checkpoints-and-metrics"]], "3.5.1. Note on the checkpoint lifecycle": [[4, "note-on-the-checkpoint-lifecycle"], [32, "note-on-the-checkpoint-lifecycle"]], "3.5\u202fS3": [[101, "s3"], [106, "s3"]], "3.6. Configure remote storage": [[4, "configure-remote-storage"], [32, "configure-remote-storage"]], "3.6. Load the checkpointed model to generate predictions": [[5, "load-the-checkpointed-model-to-generate-predictions"], [36, "load-the-checkpointed-model-to-generate-predictions"], [326, "load-the-checkpointed-model-to-generate-predictions"], [330, "load-the-checkpointed-model-to-generate-predictions"]], "3.6\u202fEFS (Optional)": [[101, "efs-optional"], [106, "efs-optional"]], "3.7. Activity: Run the distributed training with more workers": [[5, "activity-run-the-distributed-training-with-more-workers"], [36, "activity-run-the-distributed-training-with-more-workers"], [326, "activity-run-the-distributed-training-with-more-workers"], [330, "activity-run-the-distributed-training-with-more-workers"]], "3.7. Launching the distributed training job": [[4, "launching-the-distributed-training-job"], [32, "launching-the-distributed-training-job"]], "3.7\u202fMemoryDB (Optional)": [[101, "memorydb-optional"], [106, "memorydb-optional"]], "3.8 Summary": [[101, "summary"], [106, "summary"]], "3.8. Access the training results": [[4, "access-the-training-results"], [32, "access-the-training-results"]], "3.9. Use checkpointed model to generate predictions": [[4, "id1"], [32, "use-checkpointed-model-to-generate-predictions"]], "4. Checkout the service.yaml file.": [[83, "checkout-the-service-yaml-file"], [100, "checkout-the-service-yaml-file"]], "4. Cleanup": [[112, "cleanup"], [117, null]], "4. Context Window Considerations": [[164, "context-window-considerations"], [165, "context-window-considerations"], [168, "context-window-considerations"]], "4. Cost Optimization": [[164, "cost-optimization"], [165, "cost-optimization"], [169, "cost-optimization"]], "4. Data Operations: Grouping, Aggregation, and Shuffling": [[294, "data-operations-grouping-aggregation-and-shuffling"], [318, null]], "4. Development workflow": [[10, "development-workflow"], [71, null], [252, "development-workflow"], [257, null]], "4. DiffusionPolicy LightningModule": [[369, "diffusionpolicy-lightningmodule"], [372, null]], "4. Diving deeper into Ray Tune concepts": [[293, "diving-deeper-into-ray-tune-concepts"], [312, null]], "4. Examples Outlook: Deploying to Your Infrastructure": [[108, "examples-outlook-deploying-to-your-infrastructure"], [111, "examples-outlook-deploying-to-your-infrastructure"]], "4. Hardware and Cost Considerations": [[181, "hardware-and-cost-considerations"], [187, "hardware-and-cost-considerations"]], "4. Install the Anyscale Operator": [[127, "install-the-anyscale-operator"], [132, null]], "4. Local File Store": [[76, "local-file-store"], [88, "local-file-store"]], "4. Migrating the model and dataset to Ray Train": [[292, "migrating-the-model-and-dataset-to-ray-train"], [303, null]], "4. Paste the basic Ray example below into the file.": [[82, "paste-the-basic-ray-example-below-into-the-file"], [97, "paste-the-basic-ray-example-below-into-the-file"]], "4. Putting It All Together": [[1, "putting-it-all-together"], [16, null], [209, "putting-it-all-together"], [214, null]], "4. Quick visual sanity-check": [[388, "quick-visual-sanity-check"], [390, "quick-visual-sanity-check"]], "4. Ray Serve in Production": [[295, "ray-serve-in-production"], [324, null]], "4. Ray Train in Production": [[4, "ray-train-in-production"], [5, "ray-train-in-production"], [32, "ray-train-in-production"], [37, null], [326, "ray-train-in-production"], [331, null]], "4. Ray Tune in Production": [[6, "ray-tune-in-production"], [42, null], [285, "ray-tune-in-production"], [290, null]], "4. Register Anyscale Cloud to Your Cloud Provider": [[101, "register-anyscale-cloud-to-your-cloud-provider"], [107, null]], "4. Register the Anyscale Cloud": [[137, "register-the-anyscale-cloud"], [143, null]], "4. Scale with More Replicas": [[173, "scale-with-more-replicas"], [179, "scale-with-more-replicas"]], "4. Task Runtime Environments": [[2, "task-runtime-environments"], [21, null], [215, "task-runtime-environments"], [220, null]], "4. Test": [[119, "test"], [125, null]], "4. Training function per worker": [[348, "training-function-per-worker"], [353, null]], "4. Transforming data": [[9, "transforming-data"], [61, null], [240, "transforming-data"], [246, null]], "4. Visual sanity check": [[362, "visual-sanity-check"], [364, "visual-sanity-check"], [395, "visual-sanity-check"], [397, "visual-sanity-check"]], "4. Visualize dataset: ratings, users, and items": [[375, "visualize-dataset-ratings-users-and-items"], [377, "visualize-dataset-ratings-users-and-items"]], "4. Write train / validation Parquet files": [[382, "write-train-validation-parquet-files"], [384, "write-train-validation-parquet-files"]], "4. Writing Data": [[8, "writing-data"], [53, null], [232, "writing-data"], [237, null]], "4. kubectl Configuration": [[150, "kubectl-configuration"], [156, null]], "4.1 On resource specification": [[9, "on-resource-specification"], [61, "on-resource-specification"], [240, "on-resource-specification"], [246, "on-resource-specification"]], "4.1. Note about Ray ID Specification": [[1, "note-about-ray-id-specification"], [16, "note-about-ray-id-specification"], [209, "note-about-ray-id-specification"], [214, "note-about-ray-id-specification"]], "4.1. Note about pip dependencies": [[2, "note-about-pip-dependencies"], [21, "note-about-pip-dependencies"], [215, "note-about-pip-dependencies"], [220, "note-about-pip-dependencies"]], "4.2 On concurrency limiting": [[9, "on-concurrency-limiting"], [61, "on-concurrency-limiting"], [240, "on-concurrency-limiting"], [246, "on-concurrency-limiting"]], "4.2. Anti-pattern: Calling ray.get in a loop harms parallelism": [[1, "anti-pattern-calling-ray-get-in-a-loop-harms-parallelism"], [16, "anti-pattern-calling-ray-get-in-a-loop-harms-parallelism"], [209, "anti-pattern-calling-ray-get-in-a-loop-harms-parallelism"], [214, "anti-pattern-calling-ray-get-in-a-loop-harms-parallelism"]], "5. Cleanup": [[119, "cleanup"], [126, null]], "5. Conclusion": [[112, "conclusion"], [118, null]], "5. Create Ray Dataset from Parquet and encode IDs": [[375, "create-ray-dataset-from-parquet-and-encode-ids"], [377, "create-ray-dataset-from-parquet-and-encode-ids"]], "5. Data Operations: Shuffling, Grouping and Aggregation": [[8, "data-operations-shuffling-grouping-and-aggregation"], [54, null], [232, "data-operations-shuffling-grouping-and-aggregation"], [238, null]], "5. Deploy the Anyscale Service by running the command below in the terminal and passing in the service configuration yaml file.": [[83, "deploy-the-anyscale-service-by-running-the-command-below-in-the-terminal-and-passing-in-the-service-configuration-yaml-file"], [100, "deploy-the-anyscale-service-by-running-the-command-below-in-the-terminal-and-passing-in-the-service-configuration-yaml-file"]], "5. Distributed Train loop with checkpointing": [[369, "distributed-train-loop-with-checkpointing"], [373, null]], "5. Hyperparameter tuning the PyTorch model using Ray Tune": [[293, "hyperparameter-tuning-the-pytorch-model-using-ray-tune"], [313, null]], "5. Install NGINX Ingress Controller": [[150, "install-nginx-ingress-controller"], [157, null]], "5. Install the Anyscale Operator": [[137, "install-the-anyscale-operator"], [144, null]], "5. Load the train and validation splits as Ray Datasets": [[382, "load-the-train-and-validation-splits-as-ray-datasets"], [384, "load-the-train-and-validation-splits-as-ray-datasets"]], "5. Main Training Function": [[348, "main-training-function"], [354, null]], "5. Open the terminal and run the following command to submit the Ray workflow as an Anyscale Job.": [[82, "open-the-terminal-and-run-the-following-command-to-submit-the-ray-workflow-as-an-anyscale-job"], [97, "open-the-terminal-and-run-the-following-command-to-submit-the-ray-workflow-as-an-anyscale-job"]], "5. Persist to Parquet": [[362, "persist-to-parquet"], [364, "persist-to-parquet"], [395, "persist-to-parquet"], [397, "persist-to-parquet"]], "5. Persisting Data": [[294, "persisting-data"], [319, null]], "5. Reporting checkpoints and metrics": [[292, "reporting-checkpoints-and-metrics"], [304, null]], "5. Resource allocation and management": [[2, "resource-allocation-and-management"], [22, null], [215, "resource-allocation-and-management"], [221, null]], "5. Sliding-window dataset to Parquet": [[388, "sliding-window-dataset-to-parquet"], [390, "sliding-window-dataset-to-parquet"]], "5. Stateful transformations with Ray Actors": [[9, "stateful-transformations-with-ray-actors"], [62, null], [240, "stateful-transformations-with-ray-actors"], [247, null]], "5. Upgrade Hardware": [[173, "upgrade-hardware"], [179, "upgrade-hardware"]], "5. Verify the Installation": [[127, "verify-the-installation"], [133, null]], "5.1 Resource specification for stateful transformations": [[9, "resource-specification-for-stateful-transformations"], [62, "resource-specification-for-stateful-transformations"], [240, "resource-specification-for-stateful-transformations"], [247, "resource-specification-for-stateful-transformations"]], "5.1. Note on resources requests, available resources, configuring large clusters": [[2, "note-on-resources-requests-available-resources-configuring-large-clusters"], [22, "note-on-resources-requests-available-resources-configuring-large-clusters"], [215, "note-on-resources-requests-available-resources-configuring-large-clusters"], [221, "note-on-resources-requests-available-resources-configuring-large-clusters"]], "5.2 Note on autoscaling for stateful transformations": [[9, "note-on-autoscaling-for-stateful-transformations"], [62, "note-on-autoscaling-for-stateful-transformations"], [240, "note-on-autoscaling-for-stateful-transformations"], [247, "note-on-autoscaling-for-stateful-transformations"]], "5.2. Fractional resources": [[2, "fractional-resources"], [22, "fractional-resources"], [215, "fractional-resources"], [221, "fractional-resources"]], "5.3. IO bound tasks and fractional resources": [[2, "io-bound-tasks-and-fractional-resources"], [22, "io-bound-tasks-and-fractional-resources"], [215, "io-bound-tasks-and-fractional-resources"], [221, "io-bound-tasks-and-fractional-resources"]], "6. (Optional) Upgrade Anyscale Dependencies": [[150, "optional-upgrade-anyscale-dependencies"], [158, null]], "6. Custom Food101Dataset for Parquet": [[395, "custom-food101dataset-for-parquet"], [398, null]], "6. Inspect dataset sizes (optional)": [[382, "inspect-dataset-sizes-optional"], [384, "inspect-dataset-sizes-optional"]], "6. Launch Ray TorchTrainer": [[369, "launch-ray-torchtrainer"], [373, "launch-ray-torchtrainer"]], "6. Launching the distributed training job": [[292, "launching-the-distributed-training-job"], [305, null]], "6. Load and decode with Ray Data": [[362, "load-and-decode-with-ray-data"], [364, "load-and-decode-with-ray-data"]], "6. Materializing data": [[9, "materializing-data"], [63, null], [240, "materializing-data"], [248, null]], "6. Nested Tasks": [[2, "nested-tasks"], [23, null], [215, "nested-tasks"], [222, null]], "6. PyTorch Dataset over Parquet": [[388, "pytorch-dataset-over-parquet"], [390, "pytorch-dataset-over-parquet"]], "6. Start Training": [[348, "start-training"], [355, null]], "6. Test": [[127, "test"], [134, null]], "6. Track the status of the job, head over to the Jobs tab and find the submitted Anyscale Job. The url is also displayed in the terminal.": [[82, "track-the-status-of-the-job-head-over-to-the-jobs-tab-and-find-the-submitted-anyscale-job-the-url-is-also-displayed-in-the-terminal"], [97, "track-the-status-of-the-job-head-over-to-the-jobs-tab-and-find-the-submitted-anyscale-job-the-url-is-also-displayed-in-the-terminal"]], "6. Train/validation split using Ray Data": [[375, "train-validation-split-using-ray-data"], [377, "train-validation-split-using-ray-data"]], "6. Verify the Installation": [[137, "verify-the-installation"], [145, null]], "6. When to use Ray Data": [[8, "when-to-use-ray-data"], [55, null], [232, "when-to-use-ray-data"], [239, null]], "7. Accessing the training results": [[292, "accessing-the-training-results"], [306, null]], "7. Clean up": [[127, "clean-up"], [135, null]], "7. Data Operations: grouping, aggregation, and shuffling": [[9, "data-operations-grouping-aggregation-and-shuffling"], [64, null], [240, "data-operations-grouping-aggregation-and-shuffling"], [249, null]], "7. Define matrix factorization model": [[375, "define-matrix-factorization-model"], [378, null]], "7. Image transform": [[395, "image-transform"], [398, "image-transform"]], "7. In the Anyscale Jobs console, we can check out the status of the submitted job. From the logs, we can verify that our job was successfully executed and Anyscale will now handle the cleanup.": [[82, "in-the-anyscale-jobs-console-we-can-check-out-the-status-of-the-submitted-job-from-the-logs-we-can-verify-that-our-job-was-successfully-executed-and-anyscale-will-now-handle-the-cleanup"], [97, "in-the-anyscale-jobs-console-we-can-check-out-the-status-of-the-submitted-job-from-the-logs-we-can-verify-that-our-job-was-successfully-executed-and-anyscale-will-now-handle-the-cleanup"]], "7. Inspect a mini-batch": [[382, "inspect-a-mini-batch"], [384, "inspect-a-mini-batch"]], "7. Inspect one random batch": [[388, "inspect-one-random-batch"], [390, "inspect-one-random-batch"]], "7. Pattern: Pipeline data processing and waiting for results": [[2, "pattern-pipeline-data-processing-and-waiting-for-results"], [24, null], [215, "pattern-pipeline-data-processing-and-waiting-for-results"], [223, null]], "7. Plot train / val loss": [[369, "plot-train-val-loss"], [373, "plot-train-val-loss"]], "7. Ray Data in Production": [[8, "ray-data-in-production"], [55, "ray-data-in-production"], [232, "ray-data-in-production"], [239, "ray-data-in-production"]], "7. Register the Anyscale Cloud": [[150, "register-the-anyscale-cloud"], [159, null]], "7. Shuffle and Train/Val split": [[362, "shuffle-and-train-val-split"], [364, "shuffle-and-train-val-split"]], "7. Shutdown Ray Cluster": [[348, "shutdown-ray-cluster"], [355, "shutdown-ray-cluster"]], "7. Test": [[137, "test"], [146, null]], "7.1 Batch Processing Pattern": [[2, "batch-processing-pattern"], [24, "batch-processing-pattern"], [215, "batch-processing-pattern"], [223, "batch-processing-pattern"]], "7.1. Custom batching using groupby.": [[9, "custom-batching-using-groupby"], [64, "custom-batching-using-groupby"], [240, "custom-batching-using-groupby"], [249, "custom-batching-using-groupby"]], "7.2 Note on fetching too many objects at once with ray.get causes failure": [[2, "note-on-fetching-too-many-objects-at-once-with-ray-get-causes-failure"], [24, "note-on-fetching-too-many-objects-at-once-with-ray-get-causes-failure"], [215, "note-on-fetching-too-many-objects-at-once-with-ray-get-causes-failure"], [223, "note-on-fetching-too-many-objects-at-once-with-ray-get-causes-failure"]], "7.2. Aggregations": [[9, "aggregations"], [64, "aggregations"], [240, "aggregations"], [249, "aggregations"]], "7.3. Shuffling data": [[9, "shuffling-data"], [64, "shuffling-data"], [240, "shuffling-data"], [249, "shuffling-data"]], "7.3.1. File based shuffle on read": [[9, "file-based-shuffle-on-read"], [64, "file-based-shuffle-on-read"], [240, "file-based-shuffle-on-read"], [249, "file-based-shuffle-on-read"]], "7.3.2. Shuffling block order": [[9, "shuffling-block-order"], [64, "shuffling-block-order"], [240, "shuffling-block-order"], [249, "shuffling-block-order"]], "7.3.3. Shuffle all rows globally": [[9, "shuffle-all-rows-globally"], [64, "shuffle-all-rows-globally"], [240, "shuffle-all-rows-globally"], [249, "shuffle-all-rows-globally"]], "8. Conclusion": [[127, "conclusion"], [136, null]], "8. Define Ray Train loop (with validation, checkpointing, and Ray-managed metrics)": [[375, "define-ray-train-loop-with-validation-checkpointing-and-ray-managed-metrics"], [379, null]], "8. Define the Ray Train worker loop (Arrow-based, memory-efficient)": [[382, "define-the-ray-train-worker-loop-arrow-based-memory-efficient"], [385, null]], "8. Install the Anyscale Operator": [[150, "install-the-anyscale-operator"], [160, null]], "8. Persisting data": [[9, "persisting-data"], [65, null], [240, "persisting-data"], [250, null]], "8. Pixel diffusion LightningModule": [[362, "pixel-diffusion-lightningmodule"], [365, null]], "8. Ray Actors": [[2, "ray-actors"], [25, null], [215, "ray-actors"], [224, null]], "8. Ray Train in Production": [[292, "ray-train-in-production"], [307, null]], "8. Ray-prepared DataLoader": [[388, "ray-prepared-dataloader"], [390, "ray-prepared-dataloader"]], "8. Reverse diffusion helper": [[369, "reverse-diffusion-helper"], [374, null]], "8. Summary": [[348, "summary"], [355, "summary"]], "8. Test": [[150, "test"], [161, null]], "8. Train/validation split": [[395, "train-validation-split"], [398, "train-validation-split"]], "8. Troubleshooting": [[137, "troubleshooting"], [147, null]], "8. Upcoming Features in Ray Data": [[8, "upcoming-features-in-ray-data"], [55, "upcoming-features-in-ray-data"], [232, "upcoming-features-in-ray-data"], [239, "upcoming-features-in-ray-data"]], "9. Clean up": [[137, "clean-up"], [148, null]], "9. Cleanup": [[150, "cleanup"], [162, null]], "9. Configure XGBoost and build the Trainer": [[382, "configure-xgboost-and-build-the-trainer"], [385, "configure-xgboost-and-build-the-trainer"]], "9. Inspect a DataLoader batch": [[395, "inspect-a-dataloader-batch"], [398, "inspect-a-dataloader-batch"]], "9. Launch distributed training with Ray Train": [[375, "launch-distributed-training-with-ray-train"], [379, "launch-distributed-training-with-ray-train"]], "9. PositionalEncoding and Transformer model": [[388, "positionalencoding-and-transformer-model"], [391, null]], "9. Ray Data in production": [[9, "ray-data-in-production"], [66, null], [240, "ray-data-in-production"], [251, null]], "9. Ray Train train_loop (Lightning + Ray integration)": [[362, "ray-train-train-loop-lightning-ray-integration"], [366, null]], "9. Sample an action from the trained policy": [[369, "sample-an-action-from-the-trained-policy"], [374, "sample-an-action-from-the-trained-policy"]], "API Endpoints": [[202, "api-endpoints"]], "Activity: Update the training loop to compute the area under the curve of ROC (AUROC)": [[292, "activity-update-the-training-loop-to-compute-the-area-under-the-curve-of-roc-auroc"], [306, "activity-update-the-training-loop-to-compute-the-area-under-the-curve-of-roc-auroc"]], "Adding New Notebooks or Courses": [[0, "adding-new-notebooks-or-courses"]], "Additional Setup (Optional)": [[189, "additional-setup-optional"], [192, "additional-setup-optional"]], "Advanced LLM Features with Ray Serve LLM": [[181, null], [182, null]], "Advanced Topics: Monitoring & Optimization": [[173, "advanced-topics-monitoring-optimization"], [179, null]], "After navigating to a specific Anyscale Workspace, you can submit your main python script as a Anyscale Job.": [[82, "after-navigating-to-a-specific-anyscale-workspace-you-can-submit-your-main-python-script-as-a-anyscale-job"], [97, "after-navigating-to-a-specific-anyscale-workspace-you-can-submit-your-main-python-script-as-a-anyscale-job"]], "Aggregations": [[294, "aggregations"], [318, "aggregations"]], "Annotated experiment table": [[293, "annotated-experiment-table"], [312, "annotated-experiment-table"]], "Anyscale 101 Learning Path": [[84, "anyscale-101-learning-path"]], "Anyscale Administrator Overview": [[101, null], [102, null]], "Anyscale For Admins": [[405, "anyscale-for-admins"]], "Anyscale Observability": [[193, "anyscale-observability"], [196, null]], "Anyscale Projects": [[80, "anyscale-projects"], [92, "anyscale-projects"]], "Anyscale Ray Serve Observability": [[198, "anyscale-ray-serve-observability"], [201, "anyscale-ray-serve-observability"]], "Anyscale Service Lifecycle": [[83, "anyscale-service-lifecycle"], [99, "anyscale-service-lifecycle"]], "Apache Arrow": [[7, "apache-arrow"], [43, "apache-arrow"], [225, "apache-arrow"], [226, "apache-arrow"]], "Applications": [[10, "applications"], [69, "applications"], [252, "applications"], [255, "applications"]], "Architecture": [[202, "architecture"], [332, "architecture"], [335, null], [356, "architecture"], [359, null]], "Available Endpoints": [[202, "available-endpoints"]], "Batch Inference Class": [[332, "batch-inference-class"], [337, null]], "Batch Inference with Ray Data": [[332, null], [334, null]], "Batch Processing": [[7, "batch-processing"], [46, "batch-processing"], [225, "batch-processing"], [229, "batch-processing"]], "Benefits of using Anyscale Services": [[83, "benefits-of-using-anyscale-services"], [99, "benefits-of-using-anyscale-services"]], "Build and load our model on a single GPU": [[292, "build-and-load-our-model-on-a-single-gpu"], [300, "build-and-load-our-model-on-a-single-gpu"]], "Challenges in LLM Serving": [[164, "challenges-in-llm-serving"], [165, "challenges-in-llm-serving"], [169, null]], "Challenges with JVM": [[7, "challenges-with-jvm"], [46, "challenges-with-jvm"], [225, "challenges-with-jvm"], [229, "challenges-with-jvm"]], "Clean Up": [[77, "clean-up"], [78, "clean-up"], [79, "clean-up"], [89, "clean-up"], [90, "clean-up"], [91, "clean-up"]], "Clean up": [[295, "clean-up"], [325, null]], "Cloning/Duplicating Resources": [[80, "cloning-duplicating-resources"], [92, "cloning-duplicating-resources"]], "Cloud": [[81, "cloud"], [94, "cloud"]], "Collaborating with Your Team": [[84, "collaborating-with-your-team"]], "Composing Deployments": [[295, "composing-deployments"], [323, "composing-deployments"]], "Compute by Function": [[7, "compute-by-function"], [44, "compute-by-function"], [225, "compute-by-function"], [227, "compute-by-function"]], "Conclusion: Next Steps": [[181, "conclusion-next-steps"], [188, null]], "Concurrency Optimization Strategies": [[173, "concurrency-optimization-strategies"], [179, "concurrency-optimization-strategies"]], "Configuration Breakdown": [[173, "configuration-breakdown"], [176, "configuration-breakdown"]], "Configuration for Medium-Sized Models": [[173, "configuration-for-medium-sized-models"], [176, "configuration-for-medium-sized-models"]], "Configure Ray Serve LLM with LoRA": [[181, "configure-ray-serve-llm-with-lora"], [184, "configure-ray-serve-llm-with-lora"]], "Configure persistent storage": [[292, "configure-persistent-storage"], [305, "configure-persistent-storage"]], "Configure scale and GPUs": [[292, "configure-scale-and-gpus"], [302, "configure-scale-and-gpus"]], "Configure the Worker Node(s)": [[75, "configure-the-worker-node-s"], [87, "configure-the-worker-node-s"]], "Content Used": [[82, null], [96, null]], "Convert to Pandas DataFrame": [[340, "convert-to-pandas-dataframe"], [347, "convert-to-pandas-dataframe"]], "Convert to Ray Dataset": [[340, "convert-to-ray-dataset"], [344, null]], "Course Welcome and Overview": [[11, "course-welcome-and-overview"], [72, "course-welcome-and-overview"], [207, "course-welcome-and-overview"], [208, "course-welcome-and-overview"]], "Create a Second Dataset": [[340, "create-a-second-dataset"], [344, "create-a-second-dataset"]], "Create a batch data and call the model": [[332, "create-a-batch-data-and-call-the-model"], [338, null]], "Create custom security group": [[101, "create-custom-security-group"], [106, "create-custom-security-group"]], "Creating Anyscale Resources": [[112, "creating-anyscale-resources"], [114, "creating-anyscale-resources"], [119, "creating-anyscale-resources"], [123, "creating-anyscale-resources"], [127, "creating-anyscale-resources"], [129, "creating-anyscale-resources"]], "Creating a Compute Config": [[75, "creating-a-compute-config"], [87, "creating-a-compute-config"]], "Creating a Container Image": [[75, "creating-a-container-image"], [87, "creating-a-container-image"]], "Custom batching using groupby": [[294, "custom-batching-using-groupby"], [318, "custom-batching-using-groupby"]], "Custom batching using groupby and aggregations": [[8, "custom-batching-using-groupby-and-aggregations"], [54, "custom-batching-using-groupby-and-aggregations"], [232, "custom-batching-using-groupby-and-aggregations"], [238, "custom-batching-using-groupby-and-aggregations"]], "Customization": [[0, "customization"]], "Customizing autoscaling": [[295, "customizing-autoscaling"], [323, "customizing-autoscaling"]], "Data Engineering Compute": [[7, "data-engineering-compute"], [44, "data-engineering-compute"], [225, "data-engineering-compute"], [227, "data-engineering-compute"]], "Data Pipeline Observability (Ray Data)": [[198, "data-pipeline-observability-ray-data"], [200, null]], "Data Processing and ML examples with Ray": [[333, null], [341, null], [349, null], [357, null]], "Data Processing with Ray Data": [[7, "data-processing-with-ray-data"], [47, null], [225, "data-processing-with-ray-data"], [230, null], [340, null], [342, null]], "Data flow": [[7, "data-flow"], [48, "data-flow"], [225, "data-flow"], [231, "data-flow"]], "Data lakes": [[7, "data-lakes"], [43, "data-lakes"], [225, "data-lakes"], [226, "data-lakes"]], "Data warehouses": [[7, "data-warehouses"], [43, "data-warehouses"], [225, "data-warehouses"], [226, "data-warehouses"]], "Databases": [[7, "databases"], [43, "databases"], [225, "databases"], [226, "databases"]], "Dataloaders": [[348, "dataloaders"], [353, "dataloaders"]], "Dataset": [[8, "dataset"], [51, "dataset"], [232, "dataset"], [235, "dataset"]], "Decode Phase": [[164, "decode-phase"], [165, "decode-phase"], [167, "decode-phase"]], "Default settings for Ray Tune": [[293, "default-settings-for-ray-tune"], [312, "default-settings-for-ray-tune"]], "Defining a data loader": [[292, "defining-a-data-loader"], [300, "defining-a-data-loader"]], "Deploy a Medium-Sized LLM with Ray Serve LLM": [[173, null], [174, null]], "Deploy the model": [[356, "deploy-the-model"], [360, "deploy-the-model"]], "Deploying Applications with Services": [[84, "deploying-applications-with-services"]], "Deploying Pipelines with Jobs": [[84, "deploying-pipelines-with-jobs"]], "Deploying at scale": [[332, "deploying-at-scale"], [338, "deploying-at-scale"]], "Deploying to Anyscale Services": [[173, "deploying-to-anyscale-services"], [178, null]], "Deployment": [[202, "deployment"]], "Deployment Example Structure": [[163, "deployment-example-structure"]], "Deployment Options: Virtual Machines vs. Kubernetes": [[108, null], [109, null]], "Deployments": [[10, "deployments"], [69, "deployments"], [252, "deployments"], [255, "deployments"], [295, "deployments"], [321, "deployments"]], "Developer Intro to Ray": [[405, "developer-intro-to-ray"]], "Developing in Anyscale Workspaces": [[84, "developing-in-anyscale-workspaces"]], "Disabling Notebook Execution and Outputs": [[0, "disabling-notebook-execution-and-outputs"]], "Distributed Computing Frameworks": [[7, "distributed-computing-frameworks"], [46, null], [225, "distributed-computing-frameworks"], [229, null]], "Distributed Data-Parallel Training with Ray Train": [[258, "distributed-data-parallel-training-with-ray-train"], [268, "distributed-data-parallel-training-with-ray-train"]], "Distributed training with Ray Train, PyTorch and Hugging Face": [[348, null], [350, null]], "Distributed training with Ray Train, PyTorch and HuggingFace": [[333, "distributed-training-with-ray-train-pytorch-and-huggingface"], [341, "distributed-training-with-ray-train-pytorch-and-huggingface"], [349, "distributed-training-with-ray-train-pytorch-and-huggingface"], [357, "distributed-training-with-ray-train-pytorch-and-huggingface"]], "Diving deeper into Ray Tune concepts": [[6, "diving-deeper-into-ray-tune-concepts"], [41, "diving-deeper-into-ray-tune-concepts"], [285, "diving-deeper-into-ray-tune-concepts"], [289, "diving-deeper-into-ray-tune-concepts"]], "Dual-Subnet Architecture": [[101, "dual-subnet-architecture"], [106, "dual-subnet-architecture"]], "Enabling LLM Monitoring": [[173, "enabling-llm-monitoring"], [179, "enabling-llm-monitoring"]], "End of Module 01 \u00b7 Introduction to Ray Train": [[258, "end-of-module-01-introduction-to-ray-train"], [271, "end-of-module-01-introduction-to-ray-train"]], "Environment state and action": [[369, "environment-state-and-action"], [370, "environment-state-and-action"]], "Example": [[193, "example"], [197, null]], "Example Workflow": [[0, "example-workflow"]], "Example: Car type description": [[181, "example-car-type-description"], [185, "example-car-type-description"]], "Example: Code Assistant LoRA": [[181, "example-code-assistant-lora"], [184, "example-code-assistant-lora"]], "Example: Deploying LoRA Adapters": [[181, "example-deploying-lora-adapters"], [184, null]], "Example: Getting Structured JSON Output": [[181, "example-getting-structured-json-output"], [185, null]], "Example: Setting up Tool Calling": [[181, "example-setting-up-tool-calling"], [186, null]], "Example: Weather Assistant with Tool Calling": [[181, "example-weather-assistant-with-tool-calling"], [186, "example-weather-assistant-with-tool-calling"]], "Execution mode": [[8, "execution-mode"], [52, "execution-mode"], [232, "execution-mode"], [236, "execution-mode"], [294, "execution-mode"], [317, "execution-mode"]], "Exercise": [[6, "exercise"], [41, "exercise"], [285, "exercise"], [289, "exercise"], [293, "exercise"], [312, "exercise"]], "Expected Output": [[181, "expected-output"], [185, "expected-output"]], "Exploring the Anyscale Log Viewer": [[77, "exploring-the-anyscale-log-viewer"], [89, "exploring-the-anyscale-log-viewer"]], "Exploring the Anyscale Metrics Tab": [[77, "exploring-the-anyscale-metrics-tab"], [89, "exploring-the-anyscale-metrics-tab"]], "Exploring the Ray Dashboard": [[77, "exploring-the-ray-dashboard"], [89, "exploring-the-ray-dashboard"]], "FastAPI webservice and deploy a model": [[356, "fastapi-webservice-and-deploy-a-model"], [360, null]], "Features": [[0, "features"]], "File based shuffle on read": [[8, "file-based-shuffle-on-read"], [54, "file-based-shuffle-on-read"], [232, "file-based-shuffle-on-read"], [238, "file-based-shuffle-on-read"], [294, "file-based-shuffle-on-read"], [318, "file-based-shuffle-on-read"]], "Filter Ray Dataset": [[340, "filter-ray-dataset"], [345, null]], "Forward process: adding noise": [[362, "forward-process-adding-noise"], [363, "forward-process-adding-noise"]], "Foundations": [[405, "foundations"]], "General-Purpose Distributed Computing": [[7, "general-purpose-distributed-computing"], [46, "general-purpose-distributed-computing"], [225, "general-purpose-distributed-computing"], [229, "general-purpose-distributed-computing"]], "Get User Profile": [[202, "get-user-profile"]], "Getting Started": [[84, "getting-started"]], "Getting Started with Ray Serve LLM": [[164, "getting-started-with-ray-serve-llm"], [165, "getting-started-with-ray-serve-llm"], [171, null]], "Getting started": [[6, "getting-started"], [41, "getting-started"], [285, "getting-started"], [289, "getting-started"], [293, "getting-started"], [311, "getting-started"]], "Gettingstarted": [[405, "gettingstarted"]], "How Navigation Works": [[0, "how-navigation-works"]], "How Other Sizes Differ": [[173, "how-other-sizes-differ"], [180, "how-other-sizes-differ"]], "How Resources are defined": [[101, "how-resources-are-defined"], [104, "how-resources-are-defined"]], "How to Choose an LLM?": [[181, "how-to-choose-an-llm"], [187, null]], "How to migrate this computer vision workload to a distributed setup using Ray on Anyscale": [[395, "how-to-migrate-this-computer-vision-workload-to-a-distributed-setup-using-ray-on-anyscale"], [396, "how-to-migrate-this-computer-vision-workload-to-a-distributed-setup-using-ray-on-anyscale"]], "How to migrate this diffusion-policy workload to a distributed setup using Ray on Anyscale": [[362, "how-to-migrate-this-diffusion-policy-workload-to-a-distributed-setup-using-ray-on-anyscale"], [363, "how-to-migrate-this-diffusion-policy-workload-to-a-distributed-setup-using-ray-on-anyscale"]], "How to migrate this recommendation system workload to a distributed setup using Ray on Anyscale": [[375, "how-to-migrate-this-recommendation-system-workload-to-a-distributed-setup-using-ray-on-anyscale"], [376, "how-to-migrate-this-recommendation-system-workload-to-a-distributed-setup-using-ray-on-anyscale"]], "How to migrate this tabular workload to a distributed setup using Ray on Anyscale": [[382, "how-to-migrate-this-tabular-workload-to-a-distributed-setup-using-ray-on-anyscale"], [383, "how-to-migrate-this-tabular-workload-to-a-distributed-setup-using-ray-on-anyscale"]], "How to migrate this time-series workload to a distributed multi-node setup using Ray on Anyscale": [[388, "how-to-migrate-this-time-series-workload-to-a-distributed-multi-node-setup-using-ray-on-anyscale"], [389, "how-to-migrate-this-time-series-workload-to-a-distributed-multi-node-setup-using-ray-on-anyscale"]], "How to scale this policy learning workload using Ray on Anyscale": [[369, "how-to-scale-this-policy-learning-workload-using-ray-on-anyscale"], [370, "how-to-scale-this-policy-learning-workload-using-ray-on-anyscale"]], "How we use Ray AI Libraries for this task": [[291, "how-we-use-ray-ai-libraries-for-this-task"], [298, "how-we-use-ray-ai-libraries-for-this-task"]], "Hyperparameter tune the PyTorch model using Ray Tune": [[6, "hyperparameter-tune-the-pytorch-model-using-ray-tune"], [41, "hyperparameter-tune-the-pytorch-model-using-ray-tune"], [285, "hyperparameter-tune-the-pytorch-model-using-ray-tune"], [289, "hyperparameter-tune-the-pytorch-model-using-ray-tune"]], "Import Libraries": [[332, "import-libraries"], [335, "import-libraries"]], "Import libraries": [[356, "import-libraries"], [359, "import-libraries"]], "Improving Concurrency": [[173, "improving-concurrency"], [179, "improving-concurrency"]], "In-memory data formats": [[7, "in-memory-data-formats"], [43, "in-memory-data-formats"], [225, "in-memory-data-formats"], [226, "in-memory-data-formats"]], "Inference: ranking items per user": [[375, "inference-ranking-items-per-user"], [376, "inference-ranking-items-per-user"]], "Initialize Ray and Load a Dataset": [[340, "initialize-ray-and-load-a-dataset"], [343, "initialize-ray-and-load-a-dataset"]], "Input: Images as tensors": [[362, "input-images-as-tensors"], [363, "input-images-as-tensors"]], "Input: user\u2013item\u2013rating triples": [[375, "input-useritemrating-triples"], [376, "input-useritemrating-triples"]], "Inputs": [[395, "inputs"], [396, "inputs"]], "Inspecting the features of the NYC taxi dataset": [[291, "inspecting-the-features-of-the-nyc-taxi-dataset"], [298, "inspecting-the-features-of-the-nyc-taxi-dataset"]], "Installation": [[0, "installation"], [333, "installation"], [341, "installation"], [349, "installation"], [357, "installation"]], "Integrating with FastAPI": [[295, "integrating-with-fastapi"], [323, "integrating-with-fastapi"]], "Intro to Ray Data": [[294, null], [314, null]], "Intro to Ray Data:  Ray Data + Unstructured Data": [[9, null], [56, null], [240, null], [241, null]], "Intro to Ray Serve": [[295, null], [320, null]], "Intro to Ray Tune": [[6, "intro-to-ray-tune"], [41, "intro-to-ray-tune"], [285, "intro-to-ray-tune"], [289, "intro-to-ray-tune"], [293, null], [308, null]], "Introduction": [[74, "introduction"], [75, "introduction"], [76, "introduction"], [77, "introduction"], [86, "introduction"], [87, "introduction"], [88, "introduction"], [89, "introduction"]], "Introduction to Ray Core (Advancement): Object store, Tasks, Actors": [[2, null], [17, null], [215, null], [216, null]], "Introduction to Ray Core: Getting Started": [[1, null], [12, null], [209, null], [210, null]], "Introduction to Ray Data: Industry Landscape": [[7, null], [43, null], [225, null], [226, null]], "Introduction to Ray Data: Ray Data + Structured Data": [[8, null], [49, null], [232, null], [233, null]], "Introduction to Ray Serve LLM: Foundations of Large Language Model Serving": [[164, null], [165, null], [166, null]], "Introduction to Ray Serve with PyTorch": [[10, null], [67, null], [252, null], [253, null]], "Introduction to Ray Train": [[292, null], [299, null]], "Introduction to Ray Train + PyTorch": [[4, null], [29, null]], "Introduction to Ray Train: Ray Train + PyTorch Lightning": [[5, null], [33, null], [326, null], [327, null]], "Introduction to Ray Tune": [[6, null], [38, null], [285, null], [286, null]], "Introduction to Ray: Developer": [[11, null], [72, null], [207, null], [208, null]], "Introduction to the Ray AI Libraries": [[291, null], [296, null]], "Introduction to the Ray AI Libraries: An example of using Ray data, Ray Train, Ray Tune, Ray Serve to implement a XGBoost regression model": [[3, null], [26, null], [203, null], [204, null]], "Introduction: Deploy Anyscale Ray on A New AWS EKS Cluster": [[127, null], [128, null]], "Introduction: Deploy Anyscale Ray on A New Google Kubernetes Engine (GKE) Cluster": [[150, null], [151, null]], "Introduction: Deploy Anyscale Ray on AWS EC2 Instances": [[112, null], [113, null]], "Introduction: Deploy Anyscale Ray on An Existing AWS EKS Cluster": [[137, null], [138, null]], "Introduction: Deploy Anyscale Ray on GCP Compute Engine Instances (GCE)": [[119, null], [120, null]], "Introduction: Why Anyscale?": [[84, "introduction-why-anyscale"]], "Join Two Ray Datasets": [[340, "join-two-ray-datasets"], [346, null]], "Key Benefits": [[181, "key-benefits"], [181, "id1"], [181, "id3"], [184, "key-benefits"], [185, "key-benefits"], [186, "key-benefits"]], "Key Components": [[173, "key-components"], [176, "key-components"]], "Key Concepts and Optimizations": [[164, "key-concepts-and-optimizations"], [165, "key-concepts-and-optimizations"], [168, null]], "Key Features": [[82, "key-features"], [96, "key-features"]], "Key Functions": [[101, "key-functions"], [103, "key-functions"]], "Key Ray Serve Features": [[295, "key-ray-serve-features"], [321, "key-ray-serve-features"]], "Key Takeaways": [[164, "key-takeaways"], [165, "key-takeaways"], [172, null], [173, "key-takeaways"], [180, "key-takeaways"], [181, "key-takeaways"], [188, "key-takeaways"]], "Key characteristics of Anyscale Services": [[79, "key-characteristics-of-anyscale-services"], [91, "key-characteristics-of-anyscale-services"]], "Key points": [[292, "key-points"], [302, "key-points"]], "Labels": [[395, "labels"], [396, "labels"]], "Lakehouses": [[7, "lakehouses"], [43, "lakehouses"], [225, "lakehouses"], [226, "lakehouses"]], "Last Updated 6/19": [[84, null]], "Launch Grafana": [[189, "launch-grafana"], [192, "launch-grafana"]], "Launching Ray Serve": [[173, "launching-ray-serve"], [177, "launching-ray-serve"]], "Launching a Anyscale Workspace": [[73, "launching-a-anyscale-workspace"], [85, "launching-a-anyscale-workspace"]], "Launching a Web Application using Ray Serve": [[198, "launching-a-web-application-using-ray-serve"], [201, "launching-a-web-application-using-ray-serve"]], "Launching a distributed training job with a TorchTrainer.": [[292, "launching-a-distributed-training-job-with-a-torchtrainer"], [305, "launching-a-distributed-training-job-with-a-torchtrainer"]], "Launching the Service": [[173, "launching-the-service"], [178, "launching-the-service"]], "Learn More": [[181, "learn-more"], [181, "id2"], [181, "id4"], [184, "learn-more"], [185, "learn-more"], [186, "learn-more"]], "Learning Approach": [[181, "learning-approach"], [183, "learning-approach"]], "Learning Path Overview and Objectives": [[84, "learning-path-overview-and-objectives"]], "Library Imports": [[340, "library-imports"], [343, null]], "Llm Serving": [[405, "llm-serving"]], "Load a dataset": [[332, "load-a-dataset"], [336, null]], "Loading and visualizing MNIST data": [[292, "loading-and-visualizing-mnist-data"], [300, "loading-and-visualizing-mnist-data"]], "Local Deployment & Inference": [[173, "local-deployment-inference"], [177, null]], "Local Development": [[202, "local-development"]], "Local IDE (VSCode / Cursor)": [[74, "local-ide-vscode-cursor"], [86, "local-ide-vscode-cursor"]], "Logging Configuration": [[198, "logging-configuration"], [201, "logging-configuration"]], "Machine Learning and AI Compute": [[7, "machine-learning-and-ai-compute"], [44, "machine-learning-and-ai-compute"], [225, "machine-learning-and-ai-compute"], [227, "machine-learning-and-ai-compute"]], "Managing Dependencies": [[11, "managing-dependencies"], [72, "managing-dependencies"], [207, "managing-dependencies"], [208, "managing-dependencies"]], "Materializing Data": [[294, "materializing-data"], [317, "materializing-data"]], "Model Recommendations by Use Case": [[181, "model-recommendations-by-use-case"], [187, "model-recommendations-by-use-case"]], "Model Selection Framework": [[181, "model-selection-framework"], [187, "model-selection-framework"]], "Model Size Comparison": [[173, "model-size-comparison"], [175, "model-size-comparison"]], "Model: embedding-based matrix factorization": [[375, "model-embedding-based-matrix-factorization"], [376, "model-embedding-based-matrix-factorization"]], "More Advanced Topics": [[181, "more-advanced-topics"], [188, "more-advanced-topics"]], "More about Datasets": [[294, "more-about-datasets"], [316, "more-about-datasets"]], "Multi-Actor Ray Serve Tracing Example": [[202, null]], "Next Steps": [[164, "next-steps"], [165, "next-steps"], [172, "next-steps"], [173, "next-steps"], [180, "next-steps"], [181, "next-steps"], [188, "next-steps"]], "Note on the Checkpoint Lifecycle": [[258, "note-on-the-checkpoint-lifecycle"], [268, "note-on-the-checkpoint-lifecycle"]], "Notebook": [[74, "notebook"], [86, "notebook"]], "Now launch a Ray worker node in the terminal:": [[189, "now-launch-a-ray-worker-node-in-the-terminal"], [192, "now-launch-a-ray-worker-node-in-the-terminal"]], "Observability": [[405, "observability"]], "Observability Introduction": [[189, null], [190, null]], "Observability Overview": [[189, "observability-overview"], [191, null]], "On Ray Data vs Spark": [[7, "on-ray-data-vs-spark"], [47, "on-ray-data-vs-spark"], [225, "on-ray-data-vs-spark"], [230, "on-ray-data-vs-spark"]], "Online Model Serving with Ray Serve": [[356, null], [358, null]], "Option 1: Create a New VPC": [[101, "option-1-create-a-new-vpc"], [106, "option-1-create-a-new-vpc"]], "Option 2: Use Existing VPC": [[101, "option-2-use-existing-vpc"], [106, "option-2-use-existing-vpc"]], "Organization": [[81, "organization"], [94, "organization"]], "Our Example: Llama-3.1-70B": [[173, "our-example-llama-3-1-70b"], [175, "our-example-llama-3-1-70b"]], "Out of memory errors": [[332, "out-of-memory-errors"], [339, "out-of-memory-errors"]], "Outline": [[332, "outline"], [334, "outline"], [348, "outline"], [350, "outline"], [356, "outline"], [358, "outline"]], "Outline of the notebook": [[340, "outline-of-the-notebook"], [342, "outline-of-the-notebook"]], "Outlook": [[101, "outlook"], [102, "outlook"]], "Outlook:  Ray Data in Production": [[294, "outlook-ray-data-in-production"], [319, "outlook-ray-data-in-production"]], "Overview": [[202, "overview"]], "Overview: Advanced Features Preview": [[181, "overview-advanced-features-preview"], [183, null]], "Overview: Why Medium-Sized Models?": [[173, "overview-why-medium-sized-models"], [175, null]], "Part 1. Creating and Submitting your first job": [[78, "part-1-creating-and-submitting-your-first-job"], [82, "part-1-creating-and-submitting-your-first-job"], [90, "part-1-creating-and-submitting-your-first-job"], [97, null]], "Part 1: Starting your first Anyscale Service": [[79, "part-1-starting-your-first-anyscale-service"], [83, "part-1-starting-your-first-anyscale-service"], [91, "part-1-starting-your-first-anyscale-service"], [100, null]], "Part 2. Automation and Scheduling": [[78, "part-2-automation-and-scheduling"], [82, "part-2-automation-and-scheduling"], [90, "part-2-automation-and-scheduling"], [98, null]], "Practical Selection Process": [[181, "practical-selection-process"], [187, "practical-selection-process"]], "Prefill Phase": [[164, "prefill-phase"], [165, "prefill-phase"], [167, "prefill-phase"]], "Preprocessing with a Tokenizer": [[340, "preprocessing-with-a-tokenizer"], [347, null]], "Prerequisites": [[11, "prerequisites"], [72, "prerequisites"], [112, "prerequisites"], [113, "prerequisites"], [119, "prerequisites"], [121, null], [127, "prerequisites"], [128, "prerequisites"], [137, "prerequisites"], [139, null], [150, "prerequisites"], [152, null], [163, "prerequisites"], [173, "prerequisites"], [177, "prerequisites"], [198, "prerequisites"], [199, "prerequisites"], [202, "prerequisites"], [207, "prerequisites"], [208, "prerequisites"]], "Prerequisites and Assumptions": [[189, "prerequisites-and-assumptions"], [192, "prerequisites-and-assumptions"]], "Projects": [[81, "projects"], [94, "projects"]], "Providers": [[127, "providers"], [128, "providers"]], "Publishing": [[0, "publishing"]], "Purpose": [[101, "purpose"], [103, "purpose"]], "Pytorch Lightning/00 Workload": [[405, "pytorch-lightning-00-workload"]], "Ray 101": [[405, "ray-101"]], "Ray Ai Libs": [[405, "ray-ai-libs"]], "Ray Core": [[405, "ray-core"]], "Ray Data": [[405, "ray-data"]], "Ray Data Batch Inference/00 Workload": [[405, "ray-data-batch-inference-00-workload"]], "Ray Data Logs": [[198, "ray-data-logs"], [200, "ray-data-logs"]], "Ray Data Metrics": [[198, "ray-data-metrics"], [200, "ray-data-metrics"]], "Ray Data Processing/00 Workload": [[405, "ray-data-processing-00-workload"]], "Ray Distributed Training/00 Workload": [[405, "ray-distributed-training-00-workload"]], "Ray Enablement Content": [[405, null]], "Ray Enablement Content: Jupyter Book Publishing": [[0, null]], "Ray Observability": [[193, "ray-observability"], [195, null]], "Ray Serve": [[7, "ray-serve"], [48, null], [225, "ray-serve"], [231, null]], "Ray Serve Alerts": [[198, "ray-serve-alerts"], [201, "ray-serve-alerts"]], "Ray Serve LLM + Anyscale Architecture": [[164, "ray-serve-llm-anyscale-architecture"], [165, "ray-serve-llm-anyscale-architecture"], [170, null]], "Ray Serve Logs": [[198, "ray-serve-logs"], [201, "ray-serve-logs"]], "Ray Serve Metrics": [[198, "ray-serve-metrics"], [201, "ray-serve-metrics"]], "Ray Serve Online Serving/00 Workload": [[405, "ray-serve-online-serving-00-workload"]], "Ray Serve Tracing (Anyscale Only)": [[198, "ray-serve-tracing-anyscale-only"], [201, "ray-serve-tracing-anyscale-only"]], "Ray Serve vs Ray Data": [[7, "ray-serve-vs-ray-data"], [48, "ray-serve-vs-ray-data"], [225, "ray-serve-vs-ray-data"], [231, "ray-serve-vs-ray-data"]], "Ray Serve/00 Serve": [[405, "ray-serve-00-serve"]], "Ray Train": [[405, "ray-train"]], "Ray Tune/00 Tune": [[405, "ray-tune-00-tune"]], "Ray Workloads Data Dashboard": [[198, "ray-workloads-data-dashboard"], [200, "ray-workloads-data-dashboard"]], "Ray and Anyscale Observability Introduction": [[193, null], [194, null]], "Ray and Anyscale Observability in Detail": [[198, null], [199, null]], "Recap": [[291, "recap"], [298, "recap"]], "Register New User": [[202, "register-new-user"]], "Related Examples": [[173, "related-examples"], [175, "related-examples"]], "Related Examples & Templates": [[173, "related-examples-templates"], [180, "related-examples-templates"]], "Replicas": [[10, "replicas"], [69, "replicas"], [252, "replicas"], [255, "replicas"]], "Reporting metrics": [[292, "reporting-metrics"], [300, "reporting-metrics"]], "Request Flow": [[202, "request-flow"]], "Requirements": [[127, "requirements"], [128, "requirements"]], "Resources": [[164, "resources"], [165, "resources"], [172, "resources"], [173, "resources"], [180, "resources"], [181, "resources"], [188, "resources"]], "Reverse diffusion: sampling new images": [[362, "reverse-diffusion-sampling-new-images"], [363, "reverse-diffusion-sampling-new-images"]], "Run a simple Data Pipeline": [[198, "run-a-simple-data-pipeline"], [200, "run-a-simple-data-pipeline"]], "Run inference on the entire dataset": [[332, "run-inference-on-the-entire-dataset"], [339, null]], "Running Inference on Anyscale": [[173, "running-inference-on-anyscale"], [178, "running-inference-on-anyscale"]], "Running this notebook": [[291, "running-this-notebook"], [296, "running-this-notebook"]], "Sample Requests": [[202, "sample-requests"]], "Saving a checkpoint in a local directory": [[292, "saving-a-checkpoint-in-a-local-directory"], [300, "saving-a-checkpoint-in-a-local-directory"]], "Scaling deployment": [[356, "scaling-deployment"], [360, "scaling-deployment"]], "Scheduling the training loop on a single GPU": [[292, "scheduling-the-training-loop-on-a-single-gpu"], [300, "scheduling-the-training-loop-on-a-single-gpu"]], "Sending Requests": [[173, "sending-requests"], [177, "sending-requests"]], "Setting Up Local Ray Observability": [[189, "setting-up-local-ray-observability"], [192, null]], "Setting Up a Local Ray server using Jupyter Notebook": [[11, "setting-up-a-local-ray-server-using-jupyter-notebook"], [72, "setting-up-a-local-ray-server-using-jupyter-notebook"], [207, "setting-up-a-local-ray-server-using-jupyter-notebook"], [208, "setting-up-a-local-ray-server-using-jupyter-notebook"]], "Setting up Ray Serve LLM": [[173, "setting-up-ray-serve-llm"], [176, null]], "Setting up the Configuration File": [[173, "setting-up-the-configuration-file"], [178, "setting-up-the-configuration-file"]], "Setup and Installation": [[202, "setup-and-installation"]], "Shuffle all rows globally": [[8, "shuffle-all-rows-globally"], [54, "shuffle-all-rows-globally"], [232, "shuffle-all-rows-globally"], [238, "shuffle-all-rows-globally"]], "Shuffle rows globally": [[294, "shuffle-rows-globally"], [318, "shuffle-rows-globally"]], "Shuffling block order": [[8, "shuffling-block-order"], [54, "shuffling-block-order"], [232, "shuffling-block-order"], [238, "shuffling-block-order"], [294, "shuffling-block-order"], [318, "shuffling-block-order"]], "Shuffling data": [[8, "shuffling-data"], [54, "shuffling-data"], [232, "shuffling-data"], [238, "shuffling-data"], [294, "shuffling-data"], [318, "shuffling-data"]], "Shutdown Ray": [[340, "shutdown-ray"], [347, "shutdown-ray"]], "Shutdown Ray cluster": [[332, "shutdown-ray-cluster"], [339, "shutdown-ray-cluster"]], "Shutdown the Ray Serve instances and Ray Cluster": [[356, "shutdown-the-ray-serve-instances-and-ray-cluster"], [361, "shutdown-the-ray-serve-instances-and-ray-cluster"]], "Shutting Down": [[173, "shutting-down"], [177, "shutting-down"]], "Shutting Down the Service": [[173, "shutting-down-the-service"], [178, "shutting-down-the-service"]], "Simulate Client: Send test requests": [[356, "simulate-client-send-test-requests"], [361, null]], "Sources": [[83, null], [99, null]], "Start by launching the Ray head node in the terminal:": [[189, "start-by-launching-the-ray-head-node-in-the-terminal"], [192, "start-by-launching-the-ray-head-node-in-the-terminal"]], "Stateful transformations with actors": [[294, "stateful-transformations-with-actors"], [317, "stateful-transformations-with-actors"]], "Step 1: Configuration": [[164, "step-1-configuration"], [165, "step-1-configuration"], [171, "step-1-configuration"]], "Step 1: Install Required Packages": [[189, "step-1-install-required-packages"], [192, "step-1-install-required-packages"]], "Step 2: Deployment": [[164, "step-2-deployment"], [165, "step-2-deployment"], [171, "step-2-deployment"]], "Step 2: Launch Prometheus": [[189, "step-2-launch-prometheus"], [192, "step-2-launch-prometheus"]], "Step 3: Launch Ray Cluster": [[189, "step-3-launch-ray-cluster"], [192, "step-3-launch-ray-cluster"]], "Step 3: Querying": [[164, "step-3-querying"], [165, "step-3-querying"], [171, "step-3-querying"]], "Step 4: Install and Launch Grafana": [[189, "step-4-install-and-launch-grafana"], [192, "step-4-install-and-launch-grafana"]], "Step 4: Shutdown": [[165, "step-4-shutdown"], [171, "step-4-shutdown"]], "Steps to run:": [[291, "steps-to-run"], [298, "steps-to-run"]], "Streaming Applications": [[7, "streaming-applications"], [46, "streaming-applications"], [225, "streaming-applications"], [229, "streaming-applications"]], "Structure of a data lake": [[7, "structure-of-a-data-lake"], [43, "structure-of-a-data-lake"], [225, "structure-of-a-data-lake"], [226, "structure-of-a-data-lake"]], "Summary": [[332, "summary"], [339, "summary"], [340, "summary"], [347, "summary"], [356, "summary"], [361, "summary"]], "Summary & Outlook": [[173, "summary-outlook"], [180, null]], "Supported Infrastructure Types": [[101, "supported-infrastructure-types"], [104, "supported-infrastructure-types"]], "Testing the Container Image and Compute Config with an Anyscale Workflow": [[75, "testing-the-container-image-and-compute-config-with-an-anyscale-workflow"], [87, "testing-the-container-image-and-compute-config-with-an-anyscale-workflow"]], "The Compute Layer": [[7, "the-compute-layer"], [44, null], [225, "the-compute-layer"], [227, null]], "The LLM Text Generation Process": [[164, "the-llm-text-generation-process"], [165, "the-llm-text-generation-process"], [167, "the-llm-text-generation-process"]], "The Orchestration Layer": [[7, "the-orchestration-layer"], [45, null], [225, "the-orchestration-layer"], [228, null]], "The data layer": [[7, "the-data-layer"], [43, "the-data-layer"], [225, "the-data-layer"], [226, "the-data-layer"]], "The following instructions will walk you through running your first job.": [[82, "the-following-instructions-will-walk-you-through-running-your-first-job"], [96, "the-following-instructions-will-walk-you-through-running-your-first-job"]], "The following instructions will walk you through running your first job. This notebook covers the following:": [[78, "the-following-instructions-will-walk-you-through-running-your-first-job-this-notebook-covers-the-following"], [90, "the-following-instructions-will-walk-you-through-running-your-first-job-this-notebook-covers-the-following"]], "This guide will walk you through deploying, updating, and managing Anyscale Services": [[83, "this-guide-will-walk-you-through-deploying-updating-and-managing-anyscale-services"], [99, "this-guide-will-walk-you-through-deploying-updating-and-managing-anyscale-services"]], "This notebook covers the following:": [[79, "this-notebook-covers-the-following"], [91, "this-notebook-covers-the-following"]], "Tokenizer": [[348, "tokenizer"], [353, "tokenizer"]], "Trace Structure": [[202, "trace-structure"]], "Tracing Configuration": [[202, "tracing-configuration"]], "Train Generative Cv/00 Workload": [[405, "train-generative-cv-00-workload"]], "Train Policy Learning/00 Workload": [[405, "train-policy-learning-00-workload"]], "Train Rec Sys/00 Workload": [[405, "train-rec-sys-00-workload"]], "Train Tabular/00 Workload": [[405, "train-tabular-00-workload"]], "Train Time Series/00 Workload": [[405, "train-time-series-00-workload"]], "Train Vision Pattern/00 Workload": [[405, "train-vision-pattern-00-workload"]], "Training objective": [[362, "training-objective"], [363, "training-objective"], [375, "training-objective"], [376, "training-objective"]], "Two Phases of LLM Inference": [[164, "two-phases-of-llm-inference"], [165, "two-phases-of-llm-inference"], [167, "two-phases-of-llm-inference"]], "Usage": [[0, "usage"]], "Users and Roles": [[81, "users-and-roles"], [94, "users-and-roles"]], "Using LoRA Adapters": [[181, "using-lora-adapters"], [184, "using-lora-adapters"]], "Using Structured Output": [[181, "using-structured-output"], [185, "using-structured-output"]], "Using Tool Calling": [[181, "using-tool-calling"], [186, "using-tool-calling"]], "Using fractions of a GPU": [[295, "using-fractions-of-a-gpu"], [323, "using-fractions-of-a-gpu"]], "VSCode": [[74, "vscode"], [86, "vscode"]], "Web Application Observability (Ray Serve)": [[198, "web-application-observability-ray-serve"], [201, null]], "Welcome to Anyscale Administration": [[163, null]], "What We Accomplished": [[173, "what-we-accomplished"], [180, "what-we-accomplished"], [181, "what-we-accomplished"], [188, "what-we-accomplished"]], "What We\u2019ll Cover": [[181, "what-we-ll-cover"], [183, "what-we-ll-cover"]], "What You\u2019ll Learn": [[163, "what-you-ll-learn"]], "What does the model learn?": [[395, "what-does-the-model-learn"], [396, "what-does-the-model-learn"]], "What is LLM Serving?": [[164, "what-is-llm-serving"], [165, "what-is-llm-serving"], [167, null]], "What is Ray Data ?": [[7, "what-is-ray-data"], [47, "what-is-ray-data"], [225, "what-is-ray-data"], [230, "what-is-ray-data"]], "What is Ray Serve ?": [[7, "what-is-ray-serve"], [48, "what-is-ray-serve"], [225, "what-is-ray-serve"], [231, "what-is-ray-serve"]], "What is Ray Serve?": [[356, "what-is-ray-serve"], [358, "what-is-ray-serve"]], "What is an Anyscale Service?": [[173, "what-is-an-anyscale-service"], [178, "what-is-an-anyscale-service"]], "What problem are you solving? (Diffusion as image de-noising)": [[362, "what-problem-are-you-solving-diffusion-as-image-de-noising"], [363, "what-problem-are-you-solving-diffusion-as-image-de-noising"]], "What problem are you solving? (Forest cover classification with XGBoost)": [[382, "what-problem-are-you-solving-forest-cover-classification-with-xgboost"], [383, "what-problem-are-you-solving-forest-cover-classification-with-xgboost"]], "What problem are you solving? (Inverted Pendulum, Diffusion-Style)": [[369, "what-problem-are-you-solving-inverted-pendulum-diffusion-style"], [370, "what-problem-are-you-solving-inverted-pendulum-diffusion-style"]], "What problem are you solving? (NYC taxi demand forecasting with a Transformer)": [[388, "what-problem-are-you-solving-nyc-taxi-demand-forecasting-with-a-transformer"], [389, "what-problem-are-you-solving-nyc-taxi-demand-forecasting-with-a-transformer"]], "What problem are you solving? (image classification with Food-101-Lite)": [[395, "what-problem-are-you-solving-image-classification-with-food-101-lite"], [396, "what-problem-are-you-solving-image-classification-with-food-101-lite"]], "What problem are you solving? (matrix factorization for recommendations)": [[375, "what-problem-are-you-solving-matrix-factorization-for-recommendations"], [376, "what-problem-are-you-solving-matrix-factorization-for-recommendations"]], "What you learn and take away": [[362, "what-you-learn-and-take-away"], [363, "what-you-learn-and-take-away"], [369, "what-you-learn-and-take-away"], [370, "what-you-learn-and-take-away"], [375, "what-you-learn-and-take-away"], [376, "what-you-learn-and-take-away"], [382, "what-you-learn-and-take-away"], [383, "what-you-learn-and-take-away"], [388, "what-you-learn-and-take-away"], [389, "what-you-learn-and-take-away"], [395, "what-you-learn-and-take-away"], [396, "what-you-learn-and-take-away"]], "What you\u2019ll learn & take away": [[258, "what-youll-learn-take-away"], [258, "id1"], [258, "id3"], [259, "what-youll-learn-take-away"], [272, "what-youll-learn-take-away"], [278, "what-youll-learn-take-away"]], "What\u2019s Next": [[189, "what-s-next"], [192, "what-s-next"]], "What\u2019s XGBoost?": [[382, "what-s-xgboost"], [383, "what-s-xgboost"]], "What\u2019s a policy?": [[369, "what-s-a-policy"], [370, "what-s-a-policy"]], "What\u2019s a sequence-to-sequence Transformer?": [[388, "what-s-a-sequence-to-sequence-transformer"], [389, "what-s-a-sequence-to-sequence-transformer"]], "When to use Ray Core over Ray Data ?": [[7, "when-to-use-ray-core-over-ray-data"], [47, "when-to-use-ray-core-over-ray-data"], [225, "when-to-use-ray-core-over-ray-data"], [230, "when-to-use-ray-core-over-ray-data"]], "When to use Ray Serve?": [[295, "when-to-use-ray-serve"], [321, "when-to-use-ray-serve"]], "Where can you take this next?": [[362, "where-can-you-take-this-next"], [368, "where-can-you-take-this-next"], [369, "where-can-you-take-this-next"], [374, "where-can-you-take-this-next"], [375, "where-can-you-take-this-next"], [381, "where-can-you-take-this-next"], [382, "where-can-you-take-this-next"], [387, "where-can-you-take-this-next"], [388, "where-can-you-take-this-next"], [394, "where-can-you-take-this-next"], [395, "where-can-you-take-this-next"], [404, "where-can-you-take-this-next"]], "Why Choose Medium-Sized Models?": [[173, "why-choose-medium-sized-models"], [175, "why-choose-medium-sized-models"]], "Why Ray Data ?": [[7, "why-ray-data"], [47, "why-ray-data"], [225, "why-ray-data"], [230, "why-ray-data"]], "Why Ray Serve ?": [[7, "why-ray-serve"], [48, "why-ray-serve"], [225, "why-ray-serve"], [231, "why-ray-serve"]], "Why Ray?": [[11, "why-ray"], [72, "why-ray"], [207, "why-ray"], [208, "why-ray"]], "Why Structured Output Matters": [[181, "why-structured-output-matters"], [185, "why-structured-output-matters"]], "Why These Features Matter": [[181, "why-these-features-matter"], [183, "why-these-features-matter"]], "Why Tool Calling Matters": [[181, "why-tool-calling-matters"], [186, "why-tool-calling-matters"]], "Why Use LoRA Adapters?": [[181, "why-use-lora-adapters"], [184, "why-use-lora-adapters"]], "Why not Kubernetes ?": [[164, "why-not-kubernetes"], [165, "why-not-kubernetes"], [169, "why-not-kubernetes"]], "Why not use just FastAPI or Flask?": [[356, "why-not-use-just-fastapi-or-flask"], [358, "why-not-use-just-fastapi-or-flask"]], "Why this works": [[362, "why-this-works"], [363, "why-this-works"]], "Workloads": [[81, "workloads"], [94, "workloads"], [405, "workloads"]], "Wrap up and next steps": [[362, "wrap-up-and-next-steps"], [368, "wrap-up-and-next-steps"], [369, "wrap-up-and-next-steps"], [374, "wrap-up-and-next-steps"], [375, "wrap-up-and-next-steps"], [381, "wrap-up-and-next-steps"], [382, "wrap-up-and-next-steps"], [387, "wrap-up-and-next-steps"], [388, "wrap-up-and-next-steps"], [394, "wrap-up-and-next-steps"], [395, "wrap-up-and-next-steps"], [404, "wrap-up-and-next-steps"]], "\u25b6\ufe0f 3. Activate the Environment": [[11, "activate-the-environment"], [72, "activate-the-environment"], [207, "activate-the-environment"], [208, "activate-the-environment"]], "\u2705 1. Install Conda": [[11, "install-conda"], [72, "install-conda"], [207, "install-conda"], [208, "install-conda"]], "\u2705 7. Verify Ray Installation with a Simple Example": [[11, "verify-ray-installation-with-a-simple-example"], [72, "verify-ray-installation-with-a-simple-example"], [207, "verify-ray-installation-with-a-simple-example"], [208, "verify-ray-installation-with-a-simple-example"]], "\u2705 Module 01 \u00b7 Introduction to Ray Train": [[258, "module-01-introduction-to-ray-train"], [284, "module-01-introduction-to-ray-train"]], "\u2705 Module 02 \u00b7 Integrating Ray Train with Ray Data": [[258, "module-02-integrating-ray-train-with-ray-data"], [284, "module-02-integrating-ray-train-with-ray-data"]], "\u2705 Module 03 \u00b7 Fault Tolerance in Ray Train": [[258, "module-03-fault-tolerance-in-ray-train"], [284, "module-03-fault-tolerance-in-ray-train"]], "\ud83c\udf89 Wrapping Up & Next Steps": [[258, "wrapping-up-next-steps"], [284, null]], "\ud83d\udccb Notebook Compute Requirements Legend": [[11, "notebook-compute-requirements-legend"], [72, "notebook-compute-requirements-legend"], [207, "notebook-compute-requirements-legend"], [208, "notebook-compute-requirements-legend"]], "\ud83d\udccc Overview of Structure": [[81, "overview-of-structure"], [94, null]], "\ud83d\udcda 01 \u00b7 Introduction to Ray Train": [[258, null], [259, null]], "\ud83d\udcda Next Tutorials in the Course": [[258, "next-tutorials-in-the-course"], [284, "next-tutorials-in-the-course"]], "\ud83d\udce6 4. Install UV and Dependencies": [[11, "install-uv-and-dependencies"], [72, "install-uv-and-dependencies"], [207, "install-uv-and-dependencies"], [208, "install-uv-and-dependencies"]], "\ud83d\udd04 02 \u00b7 Integrating Ray Train with Ray Data": [[258, "integrating-ray-train-with-ray-data"], [272, null]], "\ud83d\udd0e Integrating Ray Train with Ray Data": [[258, "id2"], [272, "id1"]], "\ud83d\udd0e When to use Ray Train": [[258, "when-to-use-ray-train"], [259, "when-to-use-ray-train"]], "\ud83d\udda5\ufe0f 5. (Optional but Recommended) Add Your Conda Environment to Jupyter": [[11, "optional-but-recommended-add-your-conda-environment-to-jupyter"], [72, "optional-but-recommended-add-your-conda-environment-to-jupyter"], [207, "optional-but-recommended-add-your-conda-environment-to-jupyter"], [208, "optional-but-recommended-add-your-conda-environment-to-jupyter"]], "\ud83d\udda5\ufe0f How Distributed Data Parallel (DDP) Works": [[258, "how-distributed-data-parallel-ddp-works"], [259, "how-distributed-data-parallel-ddp-works"]], "\ud83d\ude80 6. Launch Jupyter Notebook": [[11, "launch-jupyter-notebook"], [72, "launch-jupyter-notebook"], [207, "launch-jupyter-notebook"], [208, "launch-jupyter-notebook"]], "\ud83d\ude80 Where to go next": [[258, "where-to-go-next"], [284, "where-to-go-next"]], "\ud83d\udee0\ufe0f 2. Create a New Conda Environment": [[11, "create-a-new-conda-environment"], [72, "create-a-new-conda-environment"], [207, "create-a-new-conda-environment"], [208, "create-a-new-conda-environment"]], "\ud83d\udee1\ufe0f 03 \u00b7 Fault Tolerance in Ray Train": [[258, "fault-tolerance-in-ray-train"], [278, null]], "\ud83e\udde0 Summary": [[81, "summary"], [95, null]], "\ud83e\udde9 Miniforge Installation (It depends on your OS. In this case, we use ARM Macs)": [[11, "miniforge-installation-it-depends-on-your-os-in-this-case-we-use-arm-macs"], [72, "miniforge-installation-it-depends-on-your-os-in-this-case-we-use-arm-macs"], [207, "miniforge-installation-it-depends-on-your-os-in-this-case-we-use-arm-macs"], [208, "miniforge-installation-it-depends-on-your-os-in-this-case-we-use-arm-macs"]], "\ud83e\uddf9 8. Shut Down and Clean Up": [[11, "shut-down-and-clean-up"], [72, "shut-down-and-clean-up"], [207, "shut-down-and-clean-up"], [208, "shut-down-and-clean-up"]]}, "docnames": ["README", "courses/00_Developer_Intro_to_Ray/00_Intro_Ray_Core_Basics", "courses/00_Developer_Intro_to_Ray/00a_Intro_Ray_Core_Advancement", "courses/00_Developer_Intro_to_Ray/01_Intro_Ray_AI_Libs_Overview", "courses/00_Developer_Intro_to_Ray/02a_Intro_Ray_Train_with_PyTorch", "courses/00_Developer_Intro_to_Ray/02b_Intro_Ray_Train_with_PyTorch_Lightning", "courses/00_Developer_Intro_to_Ray/03_Intro_Ray_Tune", "courses/00_Developer_Intro_to_Ray/04a_Intro_Ray_Data_Industry_Landscape", "courses/00_Developer_Intro_to_Ray/04b_Intro_Ray_Data_Structured", "courses/00_Developer_Intro_to_Ray/04c_Intro_Ray_Data_Unstructured", "courses/00_Developer_Intro_to_Ray/05_Intro_Ray_Serve_PyTorch", "courses/00_Developer_Intro_to_Ray/README", "courses/00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_01", "courses/00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_02", "courses/00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_03", "courses/00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_04", "courses/00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_05", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_01", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_02", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_03", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_04", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_05", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_06", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_07", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_08", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_09", "courses/00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_01", "courses/00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_02", "courses/00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_03", "courses/00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_01", "courses/00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_02", "courses/00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_03", "courses/00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_04", "courses/00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_01", "courses/00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_02", "courses/00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_03", "courses/00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_04", "courses/00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_05", "courses/00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_01", "courses/00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_02", "courses/00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_03", "courses/00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_04", "courses/00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_05", "courses/00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_01", "courses/00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_02", "courses/00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_03", "courses/00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_04", "courses/00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_05", "courses/00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_06", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_01", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_02", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_03", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_04", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_05", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_06", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_07", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_01", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_02", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_03", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_04", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_05", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_06", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_07", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_08", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_09", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_10", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_11", "courses/00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_01", "courses/00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_02", "courses/00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_03", "courses/00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_04", "courses/00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_05", "courses/00_Developer_Intro_to_Ray/output/README_01", "courses/GettingStarted/101_01_anyscale_intro_workspace", "courses/GettingStarted/101_02_anyscale_development_intro", "courses/GettingStarted/101_03_anyscale_compute_runtime_intro", "courses/GettingStarted/101_04_anyscale_storage_options", "courses/GettingStarted/101_05_anyscale_logging_metrics", "courses/GettingStarted/101_06_anyscale_intro_jobs", "courses/GettingStarted/101_07_anyscale_intro_services", "courses/GettingStarted/101_08_anyscale_collaboration", "courses/GettingStarted/101_09_anyscale_org_setup", "courses/GettingStarted/101_anyscale_intro_jobs", "courses/GettingStarted/101_anyscale_intro_services", "courses/GettingStarted/README", "courses/GettingStarted/output/101_01_anyscale_intro_workspace_01", "courses/GettingStarted/output/101_02_anyscale_development_intro_01", "courses/GettingStarted/output/101_03_anyscale_compute_runtime_intro_01", "courses/GettingStarted/output/101_04_anyscale_storage_options_01", "courses/GettingStarted/output/101_05_anyscale_logging_metrics_01", "courses/GettingStarted/output/101_06_anyscale_intro_jobs_01", "courses/GettingStarted/output/101_07_anyscale_intro_services_01", "courses/GettingStarted/output/101_08_anyscale_collaboration_01", "courses/GettingStarted/output/101_09_anyscale_org_setup_01", "courses/GettingStarted/output/101_09_anyscale_org_setup_02", "courses/GettingStarted/output/101_09_anyscale_org_setup_03", "courses/GettingStarted/output/101_anyscale_intro_jobs_01", "courses/GettingStarted/output/101_anyscale_intro_jobs_02", "courses/GettingStarted/output/101_anyscale_intro_jobs_03", "courses/GettingStarted/output/101_anyscale_intro_services_01", "courses/GettingStarted/output/101_anyscale_intro_services_02", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/anyscale_administrator_overview", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_01", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_02", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_03", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_04", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_05", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_06", "courses/foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/anyscale_vm_vs_k8s", "courses/foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_01", "courses/foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_02", "courses/foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_03", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/deploy_to_ec2", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_01", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_02", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_03", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_04", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_05", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_06", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/deploy_to_GCE", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_01", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_02", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_03", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_04", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_05", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_06", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_07", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/deploy_to_a_new_EKS", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_01", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_02", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_03", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_04", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_05", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_06", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_07", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_08", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_09", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/deploy_to_an_existing_EKS", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_01", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_02", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_03", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_04", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_05", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_06", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_07", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_08", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_09", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_10", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_11", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_12", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/deploy_to_new_GKE", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_01", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_02", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_03", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_04", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_05", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_06", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_07", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_08", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_09", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_10", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_11", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_12", "courses/foundations/Anyscale_For_Admins/README", "courses/foundations/LLM_Serving/00_intro_serve_llm/README", "courses/foundations/LLM_Serving/00_intro_serve_llm/notebook", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_01", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_02", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_03", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_04", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_05", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_06", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_07", "courses/foundations/LLM_Serving/01_deploy_medium_llm/notebook", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_01", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_02", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_03", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_04", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_05", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_06", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_07", "courses/foundations/LLM_Serving/02_advanced_llm_features/notebook", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_01", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_02", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_03", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_04", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_05", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_06", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_07", "courses/foundations/Observability/01_Intro_and_setup/01_general_intro_and_setup", "courses/foundations/Observability/01_Intro_and_setup/output/01_general_intro_and_setup_01", "courses/foundations/Observability/01_Intro_and_setup/output/01_general_intro_and_setup_02", "courses/foundations/Observability/01_Intro_and_setup/output/01_general_intro_and_setup_03", "courses/foundations/Observability/02_Ray_Anyscale_Introduction/2_Ray_Anyscale_Observability_Overview", "courses/foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_01", "courses/foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_02", "courses/foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_03", "courses/foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_04", "courses/foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/03_Ray_Anyscale_Observability_in_Details", "courses/foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_01", "courses/foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_02", "courses/foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_03", "courses/foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/tracing_example/README", "courses/foundations/Ray_AI_Libs/00_Overview/01_Intro_Ray_AI_Libs_Overview", "courses/foundations/Ray_AI_Libs/00_Overview/output/01_Intro_Ray_AI_Libs_Overview_01", "courses/foundations/Ray_AI_Libs/00_Overview/output/01_Intro_Ray_AI_Libs_Overview_02", "courses/foundations/Ray_AI_Libs/00_Overview/output/01_Intro_Ray_AI_Libs_Overview_03", "courses/foundations/Ray_AI_Libs/00_intro/README", "courses/foundations/Ray_AI_Libs/00_intro/output/README_01", "courses/foundations/Ray_Core/00_Basics/00_Intro_Ray_Core_Basics", "courses/foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_01", "courses/foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_02", "courses/foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_03", "courses/foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_04", "courses/foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_05", "courses/foundations/Ray_Core/01_Advanced/00a_Intro_Ray_Core_Advancement", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_01", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_02", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_03", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_04", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_05", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_06", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_07", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_08", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_09", "courses/foundations/Ray_Data/00_Landscape/04a_Intro_Ray_Data_Industry_Landscape", "courses/foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_01", "courses/foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_02", "courses/foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_03", "courses/foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_04", "courses/foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_05", "courses/foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_06", "courses/foundations/Ray_Data/01_Structured/04b_Intro_Ray_Data_Structured", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_01", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_02", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_03", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_04", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_05", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_06", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_07", "courses/foundations/Ray_Data/02_Unstructured/04c_Intro_Ray_Data_Unstructured", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_01", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_02", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_03", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_04", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_05", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_06", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_07", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_08", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_09", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_10", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_11", "courses/foundations/Ray_Serve/00_Serve/05_Intro_Ray_Serve_PyTorch", "courses/foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_01", "courses/foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_02", "courses/foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_03", "courses/foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_04", "courses/foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_05", "courses/foundations/Ray_Train/01_02_03_intro_to_ray_train", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_01", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_02", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_03", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_04", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_05", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_06", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_07", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_08", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_09", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_10", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_11", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_12", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_13", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_14", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_15", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_16", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_17", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_18", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_19", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_20", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_21", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_22", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_23", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_24", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_25", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_26", "courses/foundations/Ray_Tune/00_Tune/03_Intro_Ray_Tune", "courses/foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_01", "courses/foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_02", "courses/foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_03", "courses/foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_04", "courses/foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_05", "courses/ray-101/1_AI_Libs_Intro", "courses/ray-101/2_Intro_Train", "courses/ray-101/3_Intro_Tune", "courses/ray-101/4_Intro_Data", "courses/ray-101/5_Intro_Serve", "courses/ray-101/output/1_AI_Libs_Intro_01", "courses/ray-101/output/1_AI_Libs_Intro_02", "courses/ray-101/output/1_AI_Libs_Intro_03", "courses/ray-101/output/2_Intro_Train_01", "courses/ray-101/output/2_Intro_Train_02", "courses/ray-101/output/2_Intro_Train_03", "courses/ray-101/output/2_Intro_Train_04", "courses/ray-101/output/2_Intro_Train_05", "courses/ray-101/output/2_Intro_Train_06", "courses/ray-101/output/2_Intro_Train_07", "courses/ray-101/output/2_Intro_Train_08", "courses/ray-101/output/2_Intro_Train_09", "courses/ray-101/output/3_Intro_Tune_01", "courses/ray-101/output/3_Intro_Tune_02", "courses/ray-101/output/3_Intro_Tune_03", "courses/ray-101/output/3_Intro_Tune_04", "courses/ray-101/output/3_Intro_Tune_05", "courses/ray-101/output/3_Intro_Tune_06", "courses/ray-101/output/4_Intro_Data_01", "courses/ray-101/output/4_Intro_Data_02", "courses/ray-101/output/4_Intro_Data_03", "courses/ray-101/output/4_Intro_Data_04", "courses/ray-101/output/4_Intro_Data_05", "courses/ray-101/output/4_Intro_Data_06", "courses/ray-101/output/5_Intro_Serve_01", "courses/ray-101/output/5_Intro_Serve_02", "courses/ray-101/output/5_Intro_Serve_03", "courses/ray-101/output/5_Intro_Serve_04", "courses/ray-101/output/5_Intro_Serve_05", "courses/ray-101/output/5_Intro_Serve_06", "courses/workloads/PyTorch_Lightning/00_workload/02b_Intro_Ray_Train_with_PyTorch_Lightning", "courses/workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_01", "courses/workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_02", "courses/workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_03", "courses/workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_04", "courses/workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_05", "courses/workloads/Ray_Data_Batch_Inference/00_workload/01_Ray_Data_batch_inference", "courses/workloads/Ray_Data_Batch_Inference/00_workload/README", "courses/workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_01", "courses/workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_02", "courses/workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_03", "courses/workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_04", "courses/workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_05", "courses/workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_06", "courses/workloads/Ray_Data_Processing/00_workload/02_Ray_Data_data_processing", "courses/workloads/Ray_Data_Processing/00_workload/README", "courses/workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_01", "courses/workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_02", "courses/workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_03", "courses/workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_04", "courses/workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_05", "courses/workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_06", "courses/workloads/Ray_Distributed_Training/00_workload/04_Ray_Train_distributed_training", "courses/workloads/Ray_Distributed_Training/00_workload/README", "courses/workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_01", "courses/workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_02", "courses/workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_03", "courses/workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_04", "courses/workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_05", "courses/workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_06", "courses/workloads/Ray_Serve_Online_Serving/00_workload/03_Ray_Serve_online_serving", "courses/workloads/Ray_Serve_Online_Serving/00_workload/README", "courses/workloads/Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_01", "courses/workloads/Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_02", "courses/workloads/Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_03", "courses/workloads/Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_04", "courses/workloads/Train_Generative_CV/00_workload/04d1_generative_cv_pattern", "courses/workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_01", "courses/workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_02", "courses/workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_03", "courses/workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_04", "courses/workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_05", "courses/workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_06", "courses/workloads/Train_Policy_Learning/00_workload/04d2_policy_learning_pattern", "courses/workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_01", "courses/workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_02", "courses/workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_03", "courses/workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_04", "courses/workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_05", "courses/workloads/Train_Rec_sys/00_workload/04e_rec_sys_workload_pattern", "courses/workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_01", "courses/workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_02", "courses/workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_03", "courses/workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_04", "courses/workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_05", "courses/workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_06", "courses/workloads/Train_Tabular/00_workload/04b_tabular_workload_pattern", "courses/workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_01", "courses/workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_02", "courses/workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_03", "courses/workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_04", "courses/workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_05", "courses/workloads/Train_Time_Series/00_workload/04c_time_series_workload_pattern", "courses/workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_01", "courses/workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_02", "courses/workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_03", "courses/workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_04", "courses/workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_05", "courses/workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_06", "courses/workloads/Train_Vision_Pattern/00_workload/04a_vision_pattern", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_01", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_02", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_03", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_04", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_05", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_06", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_07", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_08", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_09", "index"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["README.md", "courses/00_Developer_Intro_to_Ray/00_Intro_Ray_Core_Basics.ipynb", "courses/00_Developer_Intro_to_Ray/00a_Intro_Ray_Core_Advancement.ipynb", "courses/00_Developer_Intro_to_Ray/01_Intro_Ray_AI_Libs_Overview.ipynb", "courses/00_Developer_Intro_to_Ray/02a_Intro_Ray_Train_with_PyTorch.ipynb", "courses/00_Developer_Intro_to_Ray/02b_Intro_Ray_Train_with_PyTorch_Lightning.ipynb", "courses/00_Developer_Intro_to_Ray/03_Intro_Ray_Tune.ipynb", "courses/00_Developer_Intro_to_Ray/04a_Intro_Ray_Data_Industry_Landscape.ipynb", "courses/00_Developer_Intro_to_Ray/04b_Intro_Ray_Data_Structured.ipynb", "courses/00_Developer_Intro_to_Ray/04c_Intro_Ray_Data_Unstructured.ipynb", "courses/00_Developer_Intro_to_Ray/05_Intro_Ray_Serve_PyTorch.ipynb", "courses/00_Developer_Intro_to_Ray/README.ipynb", "courses/00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_01.ipynb", "courses/00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_02.ipynb", "courses/00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_03.ipynb", "courses/00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_04.ipynb", "courses/00_Developer_Intro_to_Ray/output/00_Intro_Ray_Core_Basics_05.ipynb", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_01.ipynb", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_02.ipynb", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_03.ipynb", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_04.ipynb", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_05.ipynb", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_06.ipynb", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_07.ipynb", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_08.ipynb", "courses/00_Developer_Intro_to_Ray/output/00a_Intro_Ray_Core_Advancement_09.ipynb", "courses/00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_01.ipynb", "courses/00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_02.ipynb", "courses/00_Developer_Intro_to_Ray/output/01_Intro_Ray_AI_Libs_Overview_03.ipynb", "courses/00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_01.ipynb", "courses/00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_02.ipynb", "courses/00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_03.ipynb", "courses/00_Developer_Intro_to_Ray/output/02a_Intro_Ray_Train_with_PyTorch_04.ipynb", "courses/00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_01.ipynb", "courses/00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_02.ipynb", "courses/00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_03.ipynb", "courses/00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_04.ipynb", "courses/00_Developer_Intro_to_Ray/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_05.ipynb", "courses/00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_01.ipynb", "courses/00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_02.ipynb", "courses/00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_03.ipynb", "courses/00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_04.ipynb", "courses/00_Developer_Intro_to_Ray/output/03_Intro_Ray_Tune_05.ipynb", "courses/00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_01.ipynb", "courses/00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_02.ipynb", "courses/00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_03.ipynb", "courses/00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_04.ipynb", "courses/00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_05.ipynb", "courses/00_Developer_Intro_to_Ray/output/04a_Intro_Ray_Data_Industry_Landscape_06.ipynb", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_01.ipynb", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_02.ipynb", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_03.ipynb", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_04.ipynb", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_05.ipynb", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_06.ipynb", "courses/00_Developer_Intro_to_Ray/output/04b_Intro_Ray_Data_Structured_07.ipynb", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_01.ipynb", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_02.ipynb", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_03.ipynb", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_04.ipynb", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_05.ipynb", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_06.ipynb", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_07.ipynb", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_08.ipynb", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_09.ipynb", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_10.ipynb", "courses/00_Developer_Intro_to_Ray/output/04c_Intro_Ray_Data_Unstructured_11.ipynb", "courses/00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_01.ipynb", "courses/00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_02.ipynb", "courses/00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_03.ipynb", "courses/00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_04.ipynb", "courses/00_Developer_Intro_to_Ray/output/05_Intro_Ray_Serve_PyTorch_05.ipynb", "courses/00_Developer_Intro_to_Ray/output/README_01.ipynb", "courses/GettingStarted/101_01_anyscale_intro_workspace.ipynb", "courses/GettingStarted/101_02_anyscale_development_intro.ipynb", "courses/GettingStarted/101_03_anyscale_compute_runtime_intro.ipynb", "courses/GettingStarted/101_04_anyscale_storage_options.ipynb", "courses/GettingStarted/101_05_anyscale_logging_metrics.ipynb", "courses/GettingStarted/101_06_anyscale_intro_jobs.ipynb", "courses/GettingStarted/101_07_anyscale_intro_services.ipynb", "courses/GettingStarted/101_08_anyscale_collaboration.ipynb", "courses/GettingStarted/101_09_anyscale_org_setup.ipynb", "courses/GettingStarted/101_anyscale_intro_jobs.ipynb", "courses/GettingStarted/101_anyscale_intro_services.ipynb", "courses/GettingStarted/README.md", "courses/GettingStarted/output/101_01_anyscale_intro_workspace_01.ipynb", "courses/GettingStarted/output/101_02_anyscale_development_intro_01.ipynb", "courses/GettingStarted/output/101_03_anyscale_compute_runtime_intro_01.ipynb", "courses/GettingStarted/output/101_04_anyscale_storage_options_01.ipynb", "courses/GettingStarted/output/101_05_anyscale_logging_metrics_01.ipynb", "courses/GettingStarted/output/101_06_anyscale_intro_jobs_01.ipynb", "courses/GettingStarted/output/101_07_anyscale_intro_services_01.ipynb", "courses/GettingStarted/output/101_08_anyscale_collaboration_01.ipynb", "courses/GettingStarted/output/101_09_anyscale_org_setup_01.ipynb", "courses/GettingStarted/output/101_09_anyscale_org_setup_02.ipynb", "courses/GettingStarted/output/101_09_anyscale_org_setup_03.ipynb", "courses/GettingStarted/output/101_anyscale_intro_jobs_01.ipynb", "courses/GettingStarted/output/101_anyscale_intro_jobs_02.ipynb", "courses/GettingStarted/output/101_anyscale_intro_jobs_03.ipynb", "courses/GettingStarted/output/101_anyscale_intro_services_01.ipynb", "courses/GettingStarted/output/101_anyscale_intro_services_02.ipynb", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/anyscale_administrator_overview.ipynb", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_01.ipynb", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_02.ipynb", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_03.ipynb", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_04.ipynb", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_05.ipynb", "courses/foundations/Anyscale_For_Admins/02_00_Anyscale_Admin_Overview/output/anyscale_administrator_overview_06.ipynb", "courses/foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/anyscale_vm_vs_k8s.ipynb", "courses/foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_01.ipynb", "courses/foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_02.ipynb", "courses/foundations/Anyscale_For_Admins/02_01_VM_vs_K8s/output/anyscale_vm_vs_k8s_03.ipynb", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/deploy_to_ec2.ipynb", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_01.ipynb", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_02.ipynb", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_03.ipynb", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_04.ipynb", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_05.ipynb", "courses/foundations/Anyscale_For_Admins/02_02a_Deploy_to_VM_AWS_EC2/output/deploy_to_ec2_06.ipynb", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/deploy_to_GCE.ipynb", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_01.ipynb", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_02.ipynb", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_03.ipynb", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_04.ipynb", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_05.ipynb", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_06.ipynb", "courses/foundations/Anyscale_For_Admins/02_02b_Deploy_to_VM_GCP_GCE/output/deploy_to_GCE_07.ipynb", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/deploy_to_a_new_EKS.ipynb", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_01.ipynb", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_02.ipynb", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_03.ipynb", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_04.ipynb", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_05.ipynb", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_06.ipynb", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_07.ipynb", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_08.ipynb", "courses/foundations/Anyscale_For_Admins/02_03a_Deploy_to_K8s_New_AWS_EKS/output/deploy_to_a_new_EKS_09.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/deploy_to_an_existing_EKS.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_01.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_02.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_03.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_04.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_05.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_06.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_07.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_08.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_09.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_10.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_11.ipynb", "courses/foundations/Anyscale_For_Admins/02_03b_Deploy_to_K8s_Existing_AWS_EKS/output/deploy_to_an_existing_EKS_12.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/deploy_to_new_GKE.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_01.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_02.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_03.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_04.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_05.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_06.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_07.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_08.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_09.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_10.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_11.ipynb", "courses/foundations/Anyscale_For_Admins/02_03c_Deploy_to_K8s_New_GCP_GKE/output/deploy_to_new_GKE_12.ipynb", "courses/foundations/Anyscale_For_Admins/README.md", "courses/foundations/LLM_Serving/00_intro_serve_llm/README.md", "courses/foundations/LLM_Serving/00_intro_serve_llm/notebook.ipynb", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_01.ipynb", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_02.ipynb", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_03.ipynb", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_04.ipynb", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_05.ipynb", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_06.ipynb", "courses/foundations/LLM_Serving/00_intro_serve_llm/output/notebook_07.ipynb", "courses/foundations/LLM_Serving/01_deploy_medium_llm/notebook.ipynb", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_01.ipynb", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_02.ipynb", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_03.ipynb", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_04.ipynb", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_05.ipynb", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_06.ipynb", "courses/foundations/LLM_Serving/01_deploy_medium_llm/output/notebook_07.ipynb", "courses/foundations/LLM_Serving/02_advanced_llm_features/notebook.ipynb", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_01.ipynb", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_02.ipynb", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_03.ipynb", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_04.ipynb", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_05.ipynb", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_06.ipynb", "courses/foundations/LLM_Serving/02_advanced_llm_features/output/notebook_07.ipynb", "courses/foundations/Observability/01_Intro_and_setup/01_general_intro_and_setup.ipynb", "courses/foundations/Observability/01_Intro_and_setup/output/01_general_intro_and_setup_01.ipynb", "courses/foundations/Observability/01_Intro_and_setup/output/01_general_intro_and_setup_02.ipynb", "courses/foundations/Observability/01_Intro_and_setup/output/01_general_intro_and_setup_03.ipynb", "courses/foundations/Observability/02_Ray_Anyscale_Introduction/2_Ray_Anyscale_Observability_Overview.ipynb", "courses/foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_01.ipynb", "courses/foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_02.ipynb", "courses/foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_03.ipynb", "courses/foundations/Observability/02_Ray_Anyscale_Introduction/output/2_Ray_Anyscale_Observability_Overview_04.ipynb", "courses/foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/03_Ray_Anyscale_Observability_in_Details.ipynb", "courses/foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_01.ipynb", "courses/foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_02.ipynb", "courses/foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/output/03_Ray_Anyscale_Observability_in_Details_03.ipynb", "courses/foundations/Observability/03_Ray_Anyscale_Observability_in_Detail/tracing_example/README.md", "courses/foundations/Ray_AI_Libs/00_Overview/01_Intro_Ray_AI_Libs_Overview.ipynb", "courses/foundations/Ray_AI_Libs/00_Overview/output/01_Intro_Ray_AI_Libs_Overview_01.ipynb", "courses/foundations/Ray_AI_Libs/00_Overview/output/01_Intro_Ray_AI_Libs_Overview_02.ipynb", "courses/foundations/Ray_AI_Libs/00_Overview/output/01_Intro_Ray_AI_Libs_Overview_03.ipynb", "courses/foundations/Ray_AI_Libs/00_intro/README.ipynb", "courses/foundations/Ray_AI_Libs/00_intro/output/README_01.ipynb", "courses/foundations/Ray_Core/00_Basics/00_Intro_Ray_Core_Basics.ipynb", "courses/foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_01.ipynb", "courses/foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_02.ipynb", "courses/foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_03.ipynb", "courses/foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_04.ipynb", "courses/foundations/Ray_Core/00_Basics/output/00_Intro_Ray_Core_Basics_05.ipynb", "courses/foundations/Ray_Core/01_Advanced/00a_Intro_Ray_Core_Advancement.ipynb", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_01.ipynb", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_02.ipynb", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_03.ipynb", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_04.ipynb", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_05.ipynb", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_06.ipynb", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_07.ipynb", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_08.ipynb", "courses/foundations/Ray_Core/01_Advanced/output/00a_Intro_Ray_Core_Advancement_09.ipynb", "courses/foundations/Ray_Data/00_Landscape/04a_Intro_Ray_Data_Industry_Landscape.ipynb", "courses/foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_01.ipynb", "courses/foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_02.ipynb", "courses/foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_03.ipynb", "courses/foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_04.ipynb", "courses/foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_05.ipynb", "courses/foundations/Ray_Data/00_Landscape/output/04a_Intro_Ray_Data_Industry_Landscape_06.ipynb", "courses/foundations/Ray_Data/01_Structured/04b_Intro_Ray_Data_Structured.ipynb", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_01.ipynb", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_02.ipynb", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_03.ipynb", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_04.ipynb", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_05.ipynb", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_06.ipynb", "courses/foundations/Ray_Data/01_Structured/output/04b_Intro_Ray_Data_Structured_07.ipynb", "courses/foundations/Ray_Data/02_Unstructured/04c_Intro_Ray_Data_Unstructured.ipynb", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_01.ipynb", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_02.ipynb", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_03.ipynb", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_04.ipynb", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_05.ipynb", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_06.ipynb", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_07.ipynb", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_08.ipynb", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_09.ipynb", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_10.ipynb", "courses/foundations/Ray_Data/02_Unstructured/output/04c_Intro_Ray_Data_Unstructured_11.ipynb", "courses/foundations/Ray_Serve/00_Serve/05_Intro_Ray_Serve_PyTorch.ipynb", "courses/foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_01.ipynb", "courses/foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_02.ipynb", "courses/foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_03.ipynb", "courses/foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_04.ipynb", "courses/foundations/Ray_Serve/00_Serve/output/05_Intro_Ray_Serve_PyTorch_05.ipynb", "courses/foundations/Ray_Train/01_02_03_intro_to_ray_train.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_01.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_02.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_03.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_04.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_05.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_06.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_07.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_08.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_09.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_10.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_11.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_12.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_13.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_14.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_15.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_16.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_17.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_18.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_19.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_20.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_21.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_22.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_23.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_24.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_25.ipynb", "courses/foundations/Ray_Train/output/01_02_03_intro_to_ray_train_26.ipynb", "courses/foundations/Ray_Tune/00_Tune/03_Intro_Ray_Tune.ipynb", "courses/foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_01.ipynb", "courses/foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_02.ipynb", "courses/foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_03.ipynb", "courses/foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_04.ipynb", "courses/foundations/Ray_Tune/00_Tune/output/03_Intro_Ray_Tune_05.ipynb", "courses/ray-101/1_AI_Libs_Intro.ipynb", "courses/ray-101/2_Intro_Train.ipynb", "courses/ray-101/3_Intro_Tune.ipynb", "courses/ray-101/4_Intro_Data.ipynb", "courses/ray-101/5_Intro_Serve.ipynb", "courses/ray-101/output/1_AI_Libs_Intro_01.ipynb", "courses/ray-101/output/1_AI_Libs_Intro_02.ipynb", "courses/ray-101/output/1_AI_Libs_Intro_03.ipynb", "courses/ray-101/output/2_Intro_Train_01.ipynb", "courses/ray-101/output/2_Intro_Train_02.ipynb", "courses/ray-101/output/2_Intro_Train_03.ipynb", "courses/ray-101/output/2_Intro_Train_04.ipynb", "courses/ray-101/output/2_Intro_Train_05.ipynb", "courses/ray-101/output/2_Intro_Train_06.ipynb", "courses/ray-101/output/2_Intro_Train_07.ipynb", "courses/ray-101/output/2_Intro_Train_08.ipynb", "courses/ray-101/output/2_Intro_Train_09.ipynb", "courses/ray-101/output/3_Intro_Tune_01.ipynb", "courses/ray-101/output/3_Intro_Tune_02.ipynb", "courses/ray-101/output/3_Intro_Tune_03.ipynb", "courses/ray-101/output/3_Intro_Tune_04.ipynb", "courses/ray-101/output/3_Intro_Tune_05.ipynb", "courses/ray-101/output/3_Intro_Tune_06.ipynb", "courses/ray-101/output/4_Intro_Data_01.ipynb", "courses/ray-101/output/4_Intro_Data_02.ipynb", "courses/ray-101/output/4_Intro_Data_03.ipynb", "courses/ray-101/output/4_Intro_Data_04.ipynb", "courses/ray-101/output/4_Intro_Data_05.ipynb", "courses/ray-101/output/4_Intro_Data_06.ipynb", "courses/ray-101/output/5_Intro_Serve_01.ipynb", "courses/ray-101/output/5_Intro_Serve_02.ipynb", "courses/ray-101/output/5_Intro_Serve_03.ipynb", "courses/ray-101/output/5_Intro_Serve_04.ipynb", "courses/ray-101/output/5_Intro_Serve_05.ipynb", "courses/ray-101/output/5_Intro_Serve_06.ipynb", "courses/workloads/PyTorch_Lightning/00_workload/02b_Intro_Ray_Train_with_PyTorch_Lightning.ipynb", "courses/workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_01.ipynb", "courses/workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_02.ipynb", "courses/workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_03.ipynb", "courses/workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_04.ipynb", "courses/workloads/PyTorch_Lightning/00_workload/output/02b_Intro_Ray_Train_with_PyTorch_Lightning_05.ipynb", "courses/workloads/Ray_Data_Batch_Inference/00_workload/01_Ray_Data_batch_inference.ipynb", "courses/workloads/Ray_Data_Batch_Inference/00_workload/README.md", "courses/workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_01.ipynb", "courses/workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_02.ipynb", "courses/workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_03.ipynb", "courses/workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_04.ipynb", "courses/workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_05.ipynb", "courses/workloads/Ray_Data_Batch_Inference/00_workload/output/01_Ray_Data_batch_inference_06.ipynb", "courses/workloads/Ray_Data_Processing/00_workload/02_Ray_Data_data_processing.ipynb", "courses/workloads/Ray_Data_Processing/00_workload/README.md", "courses/workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_01.ipynb", "courses/workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_02.ipynb", "courses/workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_03.ipynb", "courses/workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_04.ipynb", "courses/workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_05.ipynb", "courses/workloads/Ray_Data_Processing/00_workload/output/02_Ray_Data_data_processing_06.ipynb", "courses/workloads/Ray_Distributed_Training/00_workload/04_Ray_Train_distributed_training.ipynb", "courses/workloads/Ray_Distributed_Training/00_workload/README.md", "courses/workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_01.ipynb", "courses/workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_02.ipynb", "courses/workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_03.ipynb", "courses/workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_04.ipynb", "courses/workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_05.ipynb", "courses/workloads/Ray_Distributed_Training/00_workload/output/04_Ray_Train_distributed_training_06.ipynb", "courses/workloads/Ray_Serve_Online_Serving/00_workload/03_Ray_Serve_online_serving.ipynb", "courses/workloads/Ray_Serve_Online_Serving/00_workload/README.md", "courses/workloads/Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_01.ipynb", "courses/workloads/Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_02.ipynb", "courses/workloads/Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_03.ipynb", "courses/workloads/Ray_Serve_Online_Serving/00_workload/output/03_Ray_Serve_online_serving_04.ipynb", "courses/workloads/Train_Generative_CV/00_workload/04d1_generative_cv_pattern.ipynb", "courses/workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_01.ipynb", "courses/workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_02.ipynb", "courses/workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_03.ipynb", "courses/workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_04.ipynb", "courses/workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_05.ipynb", "courses/workloads/Train_Generative_CV/00_workload/output/04d1_generative_cv_pattern_06.ipynb", "courses/workloads/Train_Policy_Learning/00_workload/04d2_policy_learning_pattern.ipynb", "courses/workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_01.ipynb", "courses/workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_02.ipynb", "courses/workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_03.ipynb", "courses/workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_04.ipynb", "courses/workloads/Train_Policy_Learning/00_workload/output/04d2_policy_learning_pattern_05.ipynb", "courses/workloads/Train_Rec_sys/00_workload/04e_rec_sys_workload_pattern.ipynb", "courses/workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_01.ipynb", "courses/workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_02.ipynb", "courses/workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_03.ipynb", "courses/workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_04.ipynb", "courses/workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_05.ipynb", "courses/workloads/Train_Rec_sys/00_workload/output/04e_rec_sys_workload_pattern_06.ipynb", "courses/workloads/Train_Tabular/00_workload/04b_tabular_workload_pattern.ipynb", "courses/workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_01.ipynb", "courses/workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_02.ipynb", "courses/workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_03.ipynb", "courses/workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_04.ipynb", "courses/workloads/Train_Tabular/00_workload/output/04b_tabular_workload_pattern_05.ipynb", "courses/workloads/Train_Time_Series/00_workload/04c_time_series_workload_pattern.ipynb", "courses/workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_01.ipynb", "courses/workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_02.ipynb", "courses/workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_03.ipynb", "courses/workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_04.ipynb", "courses/workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_05.ipynb", "courses/workloads/Train_Time_Series/00_workload/output/04c_time_series_workload_pattern_06.ipynb", "courses/workloads/Train_Vision_Pattern/00_workload/04a_vision_pattern.ipynb", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_01.ipynb", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_02.ipynb", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_03.ipynb", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_04.ipynb", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_05.ipynb", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_06.ipynb", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_07.ipynb", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_08.ipynb", "courses/workloads/Train_Vision_Pattern/00_workload/output/04a_vision_pattern_09.ipynb", "index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 16, 18, 19, 20, 22, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 39, 40, 41, 43, 47, 48, 51, 52, 53, 54, 57, 59, 60, 62, 64, 68, 69, 70, 72, 74, 76, 77, 79, 80, 84, 86, 88, 89, 91, 92, 101, 106, 112, 114, 115, 118, 119, 123, 124, 127, 129, 130, 131, 140, 142, 143, 150, 159, 164, 165, 167, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 193, 196, 197, 198, 200, 201, 203, 204, 206, 207, 208, 209, 214, 215, 217, 218, 219, 221, 223, 224, 225, 226, 230, 231, 232, 235, 236, 237, 238, 240, 242, 244, 245, 247, 249, 252, 254, 255, 256, 258, 259, 260, 261, 262, 266, 267, 268, 271, 272, 274, 284, 285, 287, 288, 289, 291, 292, 293, 294, 295, 296, 298, 300, 301, 302, 303, 304, 305, 309, 310, 311, 313, 316, 318, 322, 323, 325, 326, 328, 329, 330, 332, 334, 336, 338, 339, 340, 343, 346, 347, 348, 350, 352, 353, 354, 362, 363, 364, 366, 368, 373, 374, 375, 376, 377, 378, 379, 380, 381, 384, 385, 386, 387, 390, 392, 394, 395, 396, 397, 398, 399, 400, 402, 404], "0": [2, 3, 4, 5, 6, 9, 11, 20, 22, 24, 25, 28, 31, 32, 35, 36, 39, 40, 41, 49, 53, 60, 61, 62, 72, 73, 75, 77, 85, 87, 89, 106, 112, 113, 114, 119, 121, 124, 127, 128, 129, 130, 131, 137, 139, 140, 142, 143, 150, 152, 159, 164, 165, 171, 173, 177, 178, 181, 184, 185, 186, 189, 192, 193, 197, 202, 203, 206, 207, 208, 215, 219, 221, 223, 224, 233, 237, 240, 245, 246, 247, 259, 260, 261, 262, 266, 267, 269, 271, 275, 276, 279, 280, 284, 285, 287, 288, 289, 291, 292, 293, 294, 295, 296, 298, 299, 300, 303, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 320, 322, 323, 326, 329, 330, 332, 336, 338, 340, 343, 344, 347, 348, 353, 355, 356, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 373, 374, 375, 377, 379, 381, 382, 383, 384, 385, 388, 390, 391, 392, 394, 395, 396, 397, 398, 400, 404], "00": [76, 88, 202, 291, 292, 293, 294, 298, 305, 311, 313, 318, 332, 338, 348, 355, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "000": [6, 39, 258, 260, 285, 287, 293, 309, 369, 371, 375, 377, 382, 384], "0000000000000": [112, 114], "00000000000000000": [112, 114], "0001": [5, 9, 36, 62, 240, 247, 326, 330], "0003573892": [293, 311], "0003590581": [293, 311], "0003788471": [293, 311], "0003824231": [293, 311], "0004189012": [293, 311], "00046369e": [332, 339], "00087994e": [332, 339], "00129196e": [332, 339], "00217544e": [332, 339], "00403815e": [332, 339], "0059": [291, 298], "00596860e": [332, 339], "00641076e": [332, 339], "006742": [292, 306], "00719017e": [332, 339], "00724374e": [332, 339], "00728178e": [332, 339], "00749106": [332, 338], "00753223": [332, 338], "007877049646500664": [293, 313], "00787705": [293, 313], "00844238": [332, 338], "00926834e": [332, 339], "0092816": [332, 338], "00958297e": [332, 339], "00974117e": [332, 339], "00982723e": [332, 339], "00994138e": [332, 339], "00_developer_intro_to_rai": [333, 341, 349, 357], "00a": 405, "00z": 202, "01": [3, 5, 28, 36, 203, 206, 292, 305, 326, 330, 332, 339, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397, 405], "01000227e": [332, 339], "01103884e": [332, 339], "01104600e": [332, 339], "01141734e": [332, 339], "01148352e": [332, 339], "01190887": [332, 338], "01222771": [332, 338], "01231135": [332, 338], "01273207e": [332, 339], "01347007e": [332, 339], "01351717e": [332, 339], "01387227e": [332, 339], "01402104e": [332, 339], "01455652": [332, 338], "01504247": [332, 338], "01505721e": [332, 339], "01544438e": [332, 339], "01616676e": [332, 339], "01646197e": [332, 339], "01848297e": [332, 339], "01875377e": [332, 339], "01946776e": [332, 339], "01951000e": [332, 339], "01958193e": [332, 339], "02": [3, 28, 203, 206, 332, 339, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397, 405], "02095584": [332, 338], "02202111": [332, 338], "02316421e": [332, 339], "02338964e": [332, 339], "02352677e": [332, 339], "0242": [291, 298], "02448604e": [332, 339], "02480531e": [332, 339], "02481507e": [332, 339], "02496293": [332, 338], "02508835e": [332, 339], "02556132": [332, 338], "02750473e": [332, 339], "02791084": [332, 338], "02842702e": [332, 339], "02_service_hello_world": [79, 91], "02a": 405, "02b": 405, "02d": [375, 377], "03": [3, 28, 203, 206, 291, 293, 298, 311, 332, 339, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397, 405], "03000000000000000": [112, 114], "03162946e": [332, 339], "03241184e": [332, 339], "03302041": [332, 338], "03319024e": [332, 339], "03347346e": [332, 339], "03351809e": [332, 339], "03357503": [332, 338], "03620186e": [332, 339], "03722222e": [332, 339], "03901269e": [332, 339], "03915609e": [332, 339], "03924675": [332, 338], "03974594e": [332, 339], "03d": [362, 366, 369, 373], "04": [332, 339, 364, 372, 375, 377, 382, 384, 388, 390, 395, 397, 405], "04023737e": [332, 339], "04127836e": [332, 339], "04148921": [332, 338], "04188204e": [332, 339], "04267104e": [332, 339], "04279362e": [332, 339], "04313433e": [332, 339], "04401015e": [332, 339], "04419766e": [332, 339], "04514116e": [332, 339], "04760937e": [332, 339], "04781413e": [332, 339], "04831458": [332, 338], "04871886e": [332, 339], "04a": 405, "04b": 405, "04c": 405, "04d1": 405, "04d2": 405, "04e": 405, "05": [5, 8, 35, 51, 54, 198, 200, 232, 235, 238, 291, 292, 298, 300, 305, 306, 326, 329, 348, 355, 362, 364, 369, 373, 375, 377, 382, 384, 388, 390, 395, 397, 405], "050227": [332, 338], "05029851e": [332, 339], "05031021e": [332, 339], "05048873e": [332, 339], "05110919e": [332, 339], "05117615e": [332, 339], "05286286": [332, 338], "05403318e": [332, 339], "05412337e": [332, 339], "0564279": [293, 313], "05699580e": [332, 339], "0582891": [293, 313], "05838008e": [332, 339], "05897461e": [332, 339], "05951829e": [332, 339], "05955295e": [332, 339], "05962829": [332, 338], "05964907e": [332, 339], "05_069833_2422": [292, 305], "06": [11, 72, 76, 88, 207, 208, 292, 305, 362, 364, 369, 373, 375, 377, 388, 390, 395, 398, 405], "06012297e": [332, 339], "06039613e": [332, 339], "06096685": [332, 338], "06099542": [332, 338], "06128380e": [332, 339], "06155156e": [332, 339], "06164196e": [332, 339], "06194988": [332, 338], "06202352e": [332, 339], "06234232e": [332, 339], "06241195e": [332, 339], "06251295": [332, 338], "06282867e": [332, 339], "06317782e": [332, 339], "06359579e": [332, 339], "06367093324661255": [292, 305, 306], "063671": [292, 306], "06383444e": [332, 339], "06465332e": [332, 339], "06659506e": [332, 339], "06678507e": [332, 339], "06857569e": [332, 339], "06872221": [332, 338], "06887527e": [332, 339], "07": [181, 186, 348, 355, 362, 364, 369, 373, 375, 378, 382, 384, 388, 390, 395, 398, 405], "07005756e": [332, 339], "07039157e": [332, 339], "07176238": [332, 338], "07316985e": [332, 339], "07334603e": [332, 339], "07348490e": [332, 339], "07420641e": [332, 339], "07510021": [332, 338], "07512747e": [332, 339], "07565679e": [332, 339], "07582638e": [332, 339], "07590961e": [332, 339], "07614997e": [332, 339], "07735191e": [332, 339], "07769895e": [332, 339], "07796153e": [332, 339], "07813133e": [332, 339], "07829855": [332, 338], "08": [173, 179, 202, 332, 339, 362, 365, 369, 374, 375, 379, 388, 390, 395, 398, 405], "08080895": [332, 338], "08113792": [332, 338], "08117312e": [332, 339], "08142687": [332, 338], "08161136e": [332, 339], "08306534e": [332, 339], "08318681e": [332, 339], "08386130e": [332, 339], "08393911e": [332, 339], "08423311e": [332, 339], "08562492e": [332, 339], "08593434e": [332, 339], "08834168e": [332, 339], "08847059e": [332, 339], "08849846e": [332, 339], "08855490e": [332, 339], "08866049e": [332, 339], "08888834e": [332, 339], "08900222e": [332, 339], "08926150e": [332, 339], "08967713e": [332, 339], "09": [292, 293, 300, 306, 311, 313, 362, 366, 369, 374, 375, 379, 382, 385, 388, 391, 395, 398, 405], "09058516e": [332, 339], "09158831e": [332, 339], "09305708e": [332, 339], "09318195e": [332, 339], "09376505e": [332, 339], "09640113e": [332, 339], "09668531e": [332, 339], "09694359e": [332, 339], "09729558e": [332, 339], "09788750e": [332, 339], "09841380e": [332, 339], "09954223e": [332, 339], "09_200164_18044": [348, 355], "0a000000000000000": [112, 114], "0bd7bde3f2c914b3": [112, 114], "0f8bb12ddf9a451e9": [112, 114, 127, 129, 137, 140], "0m": [292, 293, 295, 305, 311, 313, 322, 348, 355], "0x72c6d85fc9d0": [295, 323], "0x72c6d85fcf90": [295, 323], "0x72c6d85fd3d0": [295, 323], "0x72c6d85fd550": [295, 323], "0x72c6d85fe590": [295, 323], "0x72c6d85ff250": [295, 323], "0x72c6d85ff3d0": [295, 323], "0x72c6d8608750": [295, 323], "0x72c6d8609050": [295, 323], "0x72c6d860b6d0": [295, 323], "0x72c6d860b7d0": [295, 323], "0x72c6d8610490": [295, 323], "0x72c6d8610a50": [295, 323], "0x72c6d8611310": [295, 323], "0x72c6d8611ad0": [295, 323], "0x72c6d8611b90": [295, 323], "0x72c6d8612050": [295, 323], "0x72c6d8613690": [295, 323], "0x72c6d8620a90": [295, 323], "0x72c6d8620e10": [295, 323], "0x72c6d86218d0": [295, 323], "0x72c6d8621b90": [295, 323], "0x72c6d8622ad0": [295, 323], "0x72c6d8623590": [295, 323], "0x72c6d86281d0": [295, 323], "0x72c6d8628710": [295, 323], "0x72c6d862a1d0": [295, 323], "0x72c6d862ac50": [295, 323], "0x72c6d862b790": [295, 323], "0x72c6d862b7d0": [295, 323], "0x72c6d862c690": [295, 323], "0x72c6d872db50": [295, 323], "0x72c6d8747390": [295, 323], "0x72c6d87500d0": [295, 323], "0x72c6d8752290": [295, 323], "0x72c6d8752e50": [295, 323], "0x72c6d8757dd0": [295, 323], "0x72c6d87793d0": [295, 323], "0x72c6d8779b90": [295, 323], "0x72c6d877a010": [295, 323], "0x72c6d877a6d0": [295, 323], "0x72c6d877b010": [295, 323], "0x72c6d877bc10": [295, 323], "0x72c6d8785e50": [295, 323], "0x72c6d8785fd0": [295, 323], "0x72c6d8786a50": [295, 323], "0x72c6d8787c90": [295, 323], "0x72c6d8794350": [295, 323], "0x72c6d8795110": [295, 323], "0x72c6d8796b50": [295, 323], "0x72c6d8797150": [295, 323], "0x72c6d8797ed0": [295, 323], "0x72c6d87a0690": [295, 323], "0x72c6d87a14d0": [295, 323], "0x72c6d87a1b50": [295, 323], "0x72c6d87a1f50": [295, 323], "0x72c6d87a2c10": [295, 323], "0x72c6d87a3d50": [295, 323], "0x72c6d87a3ed0": [295, 323], "0x72c6d87a8690": [295, 323], "0x72c6d87a96d0": [295, 323], "0x72c6d87a9cd0": [295, 323], "0x72c6d87aa0d0": [295, 323], "0x72c6d87aa4d0": [295, 323], "0x72c6d87aad50": [295, 323], "0x72c6d87ab690": [295, 323], "0x72c6d87ac4d0": [295, 323], "0x72c6d87adb90": [295, 323], "0x72c6d87ae4d0": [295, 323], "0x72c6d87ae710": [295, 323], "0x72c6d87c0110": [295, 323], "0x72c6d87c1110": [295, 323], "0x72c6d87c1250": [295, 323], "0x72c6d87c18d0": [295, 323], "0x72c6d87c2350": [295, 323], "0x72c6d87c3a50": [295, 323], "0x72c6d87d0690": [295, 323], "0x72c6d87d0d90": [295, 323], "0x72c6d87d1c50": [295, 323], "0x72c6d87d1cd0": [295, 323], "0x72c6d87d3190": [295, 323], "0x72c6d87d3fd0": [295, 323], "0x72c6d87d8250": [295, 323], "0x72c6d87d8e90": [295, 323], "0x72c6d87d96d0": [295, 323], "0x72c6d87da1d0": [295, 323], "0x72c6d87e4810": [295, 323], "0x72c6d87e4f90": [295, 323], "0x72c6d87e62d0": [295, 323], "0x72c6d87e64d0": [295, 323], "0x72c6e01cbd50": [295, 323], "0x72c6e034a510": [295, 323], "0x72c6e034b950": [295, 323], "0x72c6e0351e10": [295, 323], "0x72c6e0353410": [295, 323], "0x72c6e035ca50": [295, 323], "0x72c6e035d5d0": [295, 323], "0x72c6e03660d0": [295, 323], "0x72c72000ddd0": [295, 323], "0x72c73032a850": [295, 323], "0xxxxxxxx": [112, 114], "0xxxxxxxxx": [112, 114], "0xxxxxxxxxx": [112, 114], "1": [15, 19, 23, 38, 40, 41, 49, 67, 70, 77, 89, 113, 121, 126, 128, 134, 139, 146, 152, 157, 162, 176, 177, 178, 180, 184, 185, 186, 193, 197, 198, 199, 201, 213, 218, 222, 233, 253, 256, 258, 259, 260, 261, 264, 265, 269, 270, 271, 276, 277, 279, 280, 282, 286, 288, 289, 296, 298, 299, 305, 306, 308, 310, 311, 312, 313, 314, 316, 317, 318, 320, 322, 323, 332, 336, 338, 339, 340, 343, 345, 346, 347, 352, 354, 355, 363, 365, 366, 368, 372, 373, 374, 376, 378, 379, 381, 383, 385, 386, 387, 389, 391, 392, 394, 396, 398, 400, 401, 404, 405], "10": [2, 3, 6, 9, 10, 11, 18, 20, 24, 25, 28, 31, 39, 41, 57, 61, 70, 72, 76, 77, 88, 89, 101, 106, 119, 123, 127, 128, 129, 139, 140, 150, 152, 154, 193, 197, 198, 200, 202, 203, 206, 207, 208, 215, 217, 219, 223, 224, 240, 242, 246, 252, 256, 261, 285, 287, 289, 291, 292, 293, 294, 295, 298, 300, 302, 305, 306, 309, 311, 313, 317, 322, 323, 332, 336, 338, 340, 346, 347, 348, 355, 363, 367, 368, 371, 373, 377, 381, 383, 384, 387, 390, 394, 396, 405], "100": [2, 6, 9, 25, 41, 61, 62, 77, 89, 181, 184, 202, 215, 224, 240, 246, 247, 258, 265, 285, 289, 293, 294, 295, 312, 317, 322, 323, 340, 344, 348, 353, 369, 374, 375, 377], "1000": [8, 9, 51, 59, 77, 89, 193, 197, 232, 235, 240, 244, 294, 316, 362, 365, 369, 371, 372], "10000": [388, 391], "100000000000": [5, 35, 326, 329], "100k": [376, 381], "100th": [340, 344], "101": [101, 106, 363, 368, 400, 404], "1010": [340, 347], "10129036e": [332, 339], "101_01_anyscale_intro_workspac": 84, "101_02_anyscale_development_intro": 84, "101_03_anycale_compute_runtime_intro": 84, "101_04_anyscale_storage_opt": 84, "101_05_anyscale_logging_and_metr": 84, "101_06_anyscale_intro_job": 84, "101_07_anyscale_intro_servic": 84, "101_08_anyscale_collaboration_intro": 84, "101_09_anyscale_org_setup": 84, "102": [101, 106], "1024": [2, 5, 8, 9, 18, 35, 51, 52, 61, 119, 123, 215, 217, 232, 235, 236, 240, 246, 326, 329, 388, 391], "10279503e": [332, 339], "10307": [293, 313], "10526211e": [332, 339], "10536157": [332, 338], "10537948e": [332, 339], "105m": [198, 201, 202], "10776436e": [332, 339], "10807291e": [332, 339], "10863163e": [332, 339], "10879738e": [332, 339], "108934": [292, 300], "10893423855304718": [292, 300], "10954670e": [332, 339], "10956261e": [332, 339], "10_000": [5, 35, 36, 326, 329, 330, 369, 371], "10am": [332, 338], "10m": [375, 381], "11": [11, 72, 207, 208, 291, 292, 293, 298, 305, 306, 311, 313, 332, 338, 348, 355, 405], "11016287e": [332, 339], "11058047e": [332, 339], "11085677e": [332, 339], "110m": [198, 201, 202], "11493243e": [332, 339], "11712754e": [332, 339], "11721872": [332, 338], "11745796e": [332, 339], "11788076e": [332, 339], "11897744e": [332, 339], "11_10": [348, 355], "11th": [332, 338], "12": [3, 11, 28, 72, 76, 88, 127, 130, 137, 142, 150, 157, 203, 206, 207, 208, 291, 292, 298, 305, 333, 341, 349, 357, 377, 390, 405], "12014441e": [332, 339], "12174596e": [332, 339], "12183236e": [332, 339], "12234001e": [332, 339], "123": 202, "123456": [119, 122], "12468980e": [332, 339], "12480514e": [332, 339], "12500": [340, 343, 346, 347], "12501": [340, 347], "12502": [340, 347], "12503": [340, 347], "12504": [340, 347], "12587933e": [332, 339], "12685782e": [332, 339], "127": [11, 72, 189, 192, 207, 208], "128": [4, 6, 31, 32, 40, 41, 258, 263, 285, 288, 289, 292, 293, 300, 305, 306, 310, 313, 332, 338, 369, 372, 388, 392, 394], "12821269e": [332, 339], "12832280e": [332, 339], "12841654e": [332, 339], "128k": [164, 165, 168, 181, 187], "12907687e": [332, 339], "12912727e": [332, 339], "12939501e": [332, 339], "129887": [292, 305], "12th": [332, 338], "12x": [293, 313], "12xlarg": [193, 197], "13": [127, 130, 137, 142, 291, 293, 298, 311, 384, 405], "13000": [340, 346, 347], "13086134e": [332, 339], "13095595e": [332, 339], "13100": [340, 346, 347], "13238472e": [332, 339], "13547181e": [332, 339], "13586960e": [332, 339], "13600": [340, 346, 347], "13700": [340, 346, 347], "138": [292, 305, 306], "13803817e": [332, 339], "13828215e": [332, 339], "13841531e": [332, 339], "13b": [173, 175, 180, 181, 187], "14": [173, 175, 332, 338, 348, 355, 364, 369, 371, 377, 384, 390, 397, 405], "140": [173, 175], "14019522e": [332, 339], "140gb": [173, 175, 177], "14159100e": [332, 339], "14268738e": [332, 339], "14443852e": [332, 339], "14533243e": [332, 339], "14656349e": [332, 339], "14703774e": [332, 339], "14777484e": [332, 339], "14787792e": [332, 339], "14892137e": [332, 339], "14971709e": [332, 339], "14gb": [164, 165, 169], "14th": [332, 338], "15": [2, 4, 24, 31, 112, 113, 119, 123, 127, 128, 129, 137, 139, 140, 150, 154, 181, 186, 189, 192, 215, 223, 291, 292, 298, 305, 332, 336, 338, 348, 355, 386, 405], "150": [332, 336, 338], "15072963e": [332, 339], "150m": 202, "15157820e": [332, 339], "15247765e": [332, 339], "15391724e": [332, 339], "15394783": [332, 338], "15428728e": [332, 339], "15451038e": [332, 339], "155": [8, 51, 232, 235], "15531293e": [332, 339], "15553670e": [332, 339], "15556864e": [332, 339], "15585802e": [332, 339], "155m": 202, "156": [291, 298], "15658525e": [332, 339], "15747452e": [332, 339], "15786707e": [332, 339], "15844142e": [332, 339], "15874708e": [332, 339], "15_08": [291, 298], "15_15": [291, 298], "15x": [292, 305], "16": [173, 179, 263, 291, 292, 293, 298, 305, 311, 313, 332, 338, 348, 355, 362, 364, 383, 385, 397, 398, 405], "160": [5, 35, 173, 175, 326, 329], "16129310e": [332, 339], "16142738e": [332, 339], "16249922e": [332, 339], "16273381e": [332, 339], "16315296e": [332, 339], "163491": [291, 298], "163492": [291, 298], "16707636e": [332, 339], "168": [388, 389, 390], "16848189e": [332, 339], "1693310400": 202, "16946062e": [332, 339], "16970104e": [332, 339], "16th": [332, 336, 338], "16xlarg": [193, 197], "17": [76, 88, 101, 106, 127, 130, 131, 137, 142, 143, 150, 159, 173, 179, 291, 298, 332, 338, 340, 343, 405], "17145060e": [332, 339], "172": [101, 106], "17218718e": [332, 339], "17278847e": [332, 339], "17306670e": [332, 339], "1732276209": [292, 306], "1732276227": [292, 306], "17342269e": [332, 339], "17458829e": [332, 339], "17503238e": [332, 339], "17549804e": [332, 339], "175m": [198, 201, 202], "17605399e": [332, 339], "17623755e": [332, 339], "17677706e": [332, 339], "17716263e": [332, 339], "17952654e": [332, 339], "17982033e": [332, 339], "17th": [332, 338], "18": [76, 88, 119, 124, 127, 131, 137, 143, 150, 159, 173, 179, 259, 260, 265, 292, 306, 332, 338, 395, 396, 405], "18025970e": [332, 339], "180m": [198, 201, 202], "18165373e": [332, 339], "18200418e": [332, 339], "18252768e": [332, 339], "18264270e": [332, 339], "18500029e": [332, 339], "18707759e": [332, 339], "1879": [11, 72, 207, 208], "18899436e": [332, 339], "18926680e": [332, 339], "18932852e": [332, 339], "18th": [332, 338], "19": [76, 88, 173, 179, 291, 293, 298, 311, 313, 332, 338, 362, 364, 388, 390, 395, 397, 405], "19172417e": [332, 339], "19192507e": [332, 339], "19254841e": [332, 339], "19275388e": [332, 339], "19408388e": [332, 339], "19601890e": [332, 339], "19630387e": [332, 339], "1967": [340, 343], "19670653e": [332, 339], "19684739e": [332, 339], "19716156e": [332, 339], "19767813e": [332, 339], "19797611e": [332, 339], "19835320e": [332, 339], "19861914e": [332, 339], "19884178e": [332, 339], "1995": [332, 338], "19986786e": [332, 339], "1_000_000": [2, 24, 215, 223], "1d": [369, 372], "1e": [4, 5, 6, 31, 32, 35, 40, 41, 258, 262, 273, 279, 285, 288, 289, 292, 293, 300, 302, 306, 310, 312, 313, 326, 329, 348, 354, 369, 372, 375, 379, 388, 392, 395, 401], "1f": [388, 390], "1gb": [8, 51, 232, 235], "1h34m20": [292, 305], "1m": [375, 381], "1m10": [295, 322], "1mb": [193, 197], "1pb": [193, 197], "1st": [2, 19, 215, 218, 332, 336, 338], "1xt4": [291, 292, 293, 298, 305, 311, 313], "2": [20, 23, 38, 39, 41, 49, 53, 67, 70, 73, 79, 85, 91, 113, 114, 126, 128, 129, 139, 140, 162, 175, 178, 180, 184, 185, 186, 193, 197, 198, 199, 201, 219, 222, 233, 237, 253, 256, 258, 259, 261, 263, 271, 274, 286, 287, 289, 296, 299, 300, 302, 305, 306, 308, 309, 311, 312, 313, 314, 318, 320, 323, 332, 336, 338, 339, 340, 345, 346, 347, 354, 355, 356, 360, 363, 368, 376, 379, 381, 385, 391, 392, 394, 396, 399, 400, 404, 405], "20": [6, 11, 39, 41, 72, 76, 88, 101, 106, 173, 179, 207, 208, 285, 287, 289, 291, 292, 293, 298, 300, 305, 306, 309, 311, 312, 313, 348, 355, 362, 364, 369, 371, 375, 377, 379, 382, 384, 388, 392, 405], "200": [332, 336, 338, 340, 344], "20093006e": [332, 339], "200m": 202, "20103974e": [332, 339], "20113872e": [332, 339], "2012": [101, 106, 332, 338], "2014": [388, 389, 390], "2015": [332, 338], "20152864e": [332, 339], "2017": [332, 336, 338], "20175812e": [332, 339], "2021": [3, 28, 203, 206, 291, 298], "2023": [8, 55, 232, 239], "2024": [8, 9, 55, 66, 202, 232, 239, 240, 251, 291, 292, 293, 294, 298, 305, 306, 311, 313, 319], "2025": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 17, 26, 29, 33, 38, 43, 49, 56, 72, 76, 82, 83, 84, 88, 96, 99, 112, 113, 119, 120, 127, 128, 137, 138, 150, 151, 153, 164, 165, 166, 173, 174, 181, 182, 186, 189, 190, 193, 194, 198, 199, 203, 204, 207, 208, 209, 210, 215, 216, 225, 226, 232, 233, 240, 241, 285, 286, 326, 327, 332, 334, 340, 342, 348, 350, 355, 356, 358], "20302368700504303": [293, 310], "20312032e": [332, 339], "20370263e": [332, 339], "20407227e": [332, 339], "20567256e": [332, 339], "20587808e": [332, 339], "205m": 202, "20716389e": [332, 339], "20yr": [332, 338], "21": [101, 106, 292, 305, 348, 355, 405], "210m": 202, "21206143e": [332, 339], "21334969e": [332, 339], "21377383e": [332, 339], "21380231e": [332, 339], "21405767e": [332, 339], "2147483648": [2, 22, 215, 221], "21503563e": [332, 339], "21508265e": [332, 339], "21584712e": [332, 339], "21600205e": [332, 339], "21637220e": [332, 339], "21745682e": [332, 339], "21776196e": [332, 339], "21796946e": [332, 339], "21971425e": [332, 339], "21st": [332, 338], "22": [292, 300, 305, 332, 338, 348, 355, 405], "22192677e": [332, 339], "222": [293, 311, 313], "22234142e": [332, 339], "22277103e": [332, 339], "22332841e": [332, 339], "224": [362, 364, 368, 395, 396, 397, 398], "22458421e": [332, 339], "225": [395, 398], "22552105e": [332, 339], "22804798e": [332, 339], "22867932e": [332, 339], "22891478e": [332, 339], "229": [395, 398], "22918031e": [332, 339], "22967193e": [332, 339], "22_06": [292, 305], "22_11": [292, 305, 306], "22nd": [332, 338], "23": [291, 298, 332, 338, 362, 364, 395, 397, 405], "23053056e": [332, 339], "23069037e": [332, 339], "23083012e": [332, 339], "23107583e": [332, 339], "23113478e": [332, 339], "23204021e": [332, 339], "23302741e": [332, 339], "23314434e": [332, 339], "23478852e": [332, 339], "235m": [198, 201, 202], "23639209e": [332, 339], "23694149e": [332, 339], "23694418e": [332, 339], "23702966e": [332, 339], "23793101e": [332, 339], "23815991e": [332, 339], "23960292e": [332, 339], "23982316e": [332, 339], "23x": [348, 355], "24": [2, 22, 101, 106, 215, 221, 291, 298, 388, 389, 390, 405], "24085984e": [332, 339], "240m": [198, 201, 202], "24192730e": [332, 339], "24219281e": [332, 339], "24473451e": [332, 339], "245m": [198, 201, 202], "24615501e": [332, 339], "24854468e": [332, 339], "24885803e": [332, 339], "24984046e": [332, 339], "24xlarg": [193, 197], "25": [127, 128, 137, 139, 150, 152, 291, 292, 293, 298, 305, 313, 348, 355, 405], "250": [340, 344], "25000": [340, 343, 344, 345], "25175510e": [332, 339], "25248020e": [332, 339], "25258800e": [332, 339], "25268223e": [332, 339], "25294994e": [332, 339], "25387060e": [332, 339], "25401214e": [332, 339], "255": [6, 39, 285, 287, 293, 294, 309, 317, 362, 364], "256": [5, 35, 36, 193, 197, 292, 300, 306, 326, 329, 330, 362, 364, 395, 397], "25669474e": [332, 339], "25707304e": [332, 339], "25723777e": [332, 339], "25795130e": [332, 339], "25806283e": [332, 339], "25912409e": [332, 339], "25934454e": [332, 339], "25_924022_2383": [291, 298], "25th": [332, 338], "26": [173, 175, 292, 293, 300, 305, 311, 348, 355, 405], "26000811e": [332, 339], "26009388e": [332, 339], "26156314e": [332, 339], "26208720e": [332, 339], "26244992e": [332, 339], "26258478e": [332, 339], "26309279e": [332, 339], "26314560e": [332, 339], "26320729e": [332, 339], "26351237e": [332, 339], "26371822e": [332, 339], "264131": [293, 313], "26429361e": [332, 339], "26502474e": [332, 339], "26816351e": [332, 339], "26948217e": [332, 339], "26990714e": [332, 339], "27": [291, 292, 298, 306, 332, 336, 338], "27106623e": [332, 339], "27159020e": [332, 339], "27211": [293, 311], "27212": [293, 311], "27213278e": [332, 339], "27219909e": [332, 339], "27394149e": [332, 339], "27486494e": [332, 339], "27514724e": [332, 339], "27598614e": [332, 339], "27818017e": [332, 339], "2784426808357239": [292, 300], "278443": [292, 300], "27902825e": [332, 339], "27904241e": [332, 339], "27935463e": [332, 339], "27x": [348, 355], "28": [9, 10, 61, 70, 198, 201, 240, 246, 252, 256, 258, 260, 292, 293, 294, 295, 305, 311, 317, 322, 323, 348, 355], "28050": [293, 313], "28076579e": [332, 339], "28086493e": [332, 339], "28125295e": [332, 339], "28131025e": [332, 339], "28160176e": [332, 339], "28330866e": [332, 339], "28415197e": [332, 339], "28529142e": [332, 339], "28545947e": [332, 339], "28572544e": [332, 339], "28628640e": [332, 339], "28712449e": [332, 339], "28749549e": [332, 339], "28796948e": [332, 339], "28858958e": [332, 339], "28869668e": [332, 339], "28947487e": [332, 339], "28947702e": [332, 339], "28th": [332, 338], "28x28": [6, 39, 285, 287, 293, 309], "29": [181, 186, 291, 292, 293, 298, 305, 306, 311, 313], "29297644e": [332, 339], "29473785e": [332, 339], "29535252e": [332, 339], "29715446e": [332, 339], "29792884e": [332, 339], "29807210e": [332, 339], "29825398e": [332, 339], "29964035e": [332, 339], "29_09": [293, 311], "29t10": 202, "2a": [127, 129, 137, 140], "2b": [127, 129, 137, 140], "2cpu": [127, 134, 137, 146], "2d": [6, 39, 285, 287, 293, 309, 375, 381], "2e": [362, 365], "2f": [2, 18, 77, 89, 215, 217, 375, 381, 382, 386], "2nd": [2, 19, 215, 218, 332, 338], "2ykut_ijz8q8gwt5vphvitzshksddol6msszjxzwe5a": [173, 178], "3": [16, 24, 37, 38, 40, 49, 61, 62, 67, 75, 87, 115, 126, 128, 135, 139, 148, 152, 162, 176, 177, 178, 183, 184, 185, 188, 193, 197, 198, 201, 202, 214, 223, 233, 246, 247, 253, 258, 259, 260, 261, 271, 273, 279, 280, 286, 288, 296, 299, 300, 306, 307, 308, 310, 312, 313, 314, 316, 318, 320, 331, 332, 333, 338, 339, 340, 341, 343, 347, 349, 354, 355, 357, 363, 365, 368, 372, 373, 374, 376, 379, 381, 385, 392, 394, 396, 401, 405], "30": [181, 186, 292, 305, 332, 338, 348, 355, 375, 377, 389, 394], "30478994e": [332, 339], "30517557e": [332, 339], "30540405e": [332, 339], "30551": [292, 306], "30557770e": [332, 339], "30565623e": [332, 339], "30582720e": [332, 339], "30603": [292, 305], "30618355e": [332, 339], "30638674e": [332, 339], "30715715e": [332, 339], "30746688e": [332, 339], "30834863e": [332, 339], "308870": [292, 306], "30887049436569214": [292, 305], "30980236e": [332, 339], "30981060e": [332, 339], "30999158e": [332, 339], "30min": [388, 390], "30th": [332, 338], "31": [11, 72, 207, 208, 291, 292, 293, 298, 305, 311, 313, 348, 355], "31019164e": [332, 339], "31141504e": [332, 339], "31172134e": [332, 339], "31209707e": [332, 339], "31449399e": [332, 339], "31499174e": [332, 339], "31562141e": [332, 339], "31659403e": [332, 339], "31913936e": [332, 339], "31973000e": [332, 339], "31st": [332, 338], "32": [2, 5, 9, 18, 25, 35, 61, 173, 179, 181, 184, 215, 217, 224, 240, 246, 326, 329, 362, 365, 366, 369, 373, 382, 385], "320": [5, 35, 326, 329], "32145682e": [332, 339], "32192443e": [332, 339], "32244647e": [332, 339], "32266051e": [332, 339], "32296453e": [332, 339], "32373542e": [332, 339], "32401919e": [332, 339], "32454751e": [332, 339], "32564947e": [332, 339], "326001912355423": [293, 310], "32635012e": [332, 339], "32654747e": [332, 339], "3266499161421599": [293, 311], "32665": [293, 311], "32722983e": [332, 339], "32756231e": [332, 339], "32768": [173, 176, 179, 181, 186], "32768166e": [332, 339], "32890965e": [332, 339], "32902160e": [332, 339], "32918817e": [332, 339], "32b": [181, 186, 187], "32gb": [293, 311, 313], "32k": [164, 165, 168, 181, 187], "32m": [292, 293, 305, 313, 348, 355], "33": [332, 336, 338, 339], "33023707e": [332, 339], "33163792e": [332, 339], "33167297e": [332, 339], "33281359e": [332, 339], "33300245e": [332, 339], "33315668e": [332, 339], "33572224e": [332, 339], "33688403e": [332, 339], "33728483e": [332, 339], "33760041e": [332, 339], "33768886e": [332, 339], "33827804e": [332, 339], "33832851e": [332, 339], "33951919e": [332, 339], "34": [292, 293, 294, 305, 311, 318, 332, 339], "34206163e": [332, 339], "34323069e": [332, 339], "34348310e": [332, 339], "34449054e": [332, 339], "34561165e": [332, 339], "34613437e": [332, 339], "34668782e": [332, 339], "34740751e": [332, 339], "34842591e": [332, 339], "34999743e": [332, 339], "35": [292, 293, 305, 306, 311, 313, 332, 339, 348, 355], "35016027e": [332, 339], "35024523e": [332, 339], "35026570e": [332, 339], "35185423e": [332, 339], "35189386e": [332, 339], "35268092e": [332, 339], "35481167e": [332, 339], "35665376e": [332, 339], "35665385e": [332, 339], "35833579e": [332, 339], "35873899e": [332, 339], "35890651e": [332, 339], "36": [173, 179, 293, 313, 348, 355], "36150215e": [332, 339], "36240765e": [332, 339], "365191": [292, 306], "36595646e": [332, 339], "36710434e": [332, 339], "36786141e": [332, 339], "36829392e": [332, 339], "36855166e": [332, 339], "36857450e": [332, 339], "36868265e": [332, 339], "36873224e": [332, 339], "36m": [292, 293, 295, 305, 311, 313, 322, 348, 355], "37": [173, 179, 292, 293, 305, 313], "37080820e": [332, 339], "37142141e": [332, 339], "37153175e": [332, 339], "37196398e": [332, 339], "37391533e": [332, 339], "37605290e": [332, 339], "37751494e": [332, 339], "37764162e": [332, 339], "37784477e": [332, 339], "37850042e": [332, 339], "37964366e": [332, 339], "38": [348, 355], "38109175e": [332, 339], "38115362e": [332, 339], "38281021e": [332, 339], "384": [173, 179, 332, 338, 339], "38448": [293, 311, 313], "384480": [293, 313], "38451725e": [332, 339], "38496622e": [332, 339], "38554320e": [332, 339], "38563488e": [332, 339], "38687068e": [332, 339], "38798335e": [332, 339], "38858718e": [332, 339], "38910706e": [332, 339], "39053045e": [332, 339], "39066431e": [332, 339], "39268537e": [332, 339], "39287962e": [332, 339], "39421923e": [332, 339], "39532143e": [332, 339], "39561000e": [332, 339], "39590132e": [332, 339], "39660065e": [332, 339], "39745891e": [332, 339], "39747020e": [332, 339], "39796034e": [332, 339], "39855982e": [332, 339], "39905545e": [332, 339], "3b": [181, 185], "3d": [369, 372], "3f": [382, 385, 386, 387], "3rd": [332, 338], "3x3": [258, 260, 271], "4": [20, 26, 29, 33, 38, 41, 49, 62, 67, 77, 89, 126, 157, 162, 174, 175, 176, 177, 184, 185, 186, 198, 201, 202, 204, 219, 233, 247, 253, 258, 259, 286, 289, 291, 298, 299, 305, 306, 308, 311, 313, 314, 316, 320, 323, 327, 332, 338, 339, 340, 347, 365, 366, 373, 376, 379, 381, 385, 392, 394, 398, 405], "40": [202, 292, 305, 332, 338, 340, 343], "4000": [2, 22, 215, 221], "40064341e": [332, 339], "40084913e": [332, 339], "400b": [173, 175, 180, 181, 187], "40222309e": [332, 339], "40240113e": [332, 339], "40254933e": [332, 339], "403": [292, 293, 305, 311, 313], "40336857e": [332, 339], "40409318e": [332, 339], "40456108e": [332, 339], "40510444e": [332, 339], "40537590e": [332, 339], "406": [395, 398], "40600796e": [332, 339], "40880044e": [332, 339], "40937243e": [332, 339], "40g": [173, 176, 177], "41": [11, 72, 207, 208, 348, 355], "41169238e": [332, 339], "41280317e": [332, 339], "41516277e": [332, 339], "41520910e": [332, 339], "41526775e": [332, 339], "41575071e": [332, 339], "41598": [348, 355], "41599": [348, 355], "415m": 202, "41709536e": [332, 339], "41786465e": [332, 339], "41920993e": [332, 339], "41922843e": [332, 339], "41933542e": [332, 339], "41968962e": [332, 339], "41985670e": [332, 339], "42": [3, 28, 203, 206, 375, 377, 382, 384, 395, 398], "420m": 202, "42177847e": [332, 339], "422321": [348, 355], "42241838e": [332, 339], "42471355e": [332, 339], "42482564e": [332, 339], "42548003e": [332, 339], "42604055e": [332, 339], "42662169e": [332, 339], "42837034e": [332, 339], "42856956e": [332, 339], "42857780e": [332, 339], "42904809e": [332, 339], "42943636e": [332, 339], "43057": [291, 298], "43168001e": [332, 339], "43248991e": [332, 339], "43267226e": [332, 339], "43328887e": [332, 339], "43732": [292, 300], "43747482e": [332, 339], "43779554e": [332, 339], "43806068e": [332, 339], "43821533e": [332, 339], "43902507e": [332, 339], "43916206e": [332, 339], "43940079e": [332, 339], "43996522e": [332, 339], "44": [291, 293, 298, 313], "44072895e": [332, 339], "44087312e": [332, 339], "44237953e": [332, 339], "44269560e": [332, 339], "44299744e": [332, 339], "443": [101, 106], "44326049e": [332, 339], "44500265e": [332, 339], "44628939e": [332, 339], "44769201e": [332, 339], "44773570": [292, 300], "44875658e": [332, 339], "44877301e": [332, 339], "44888324e": [332, 339], "44945610e": [332, 339], "45": [112, 115, 292, 305, 332, 338], "45237213e": [332, 339], "45387161e": [332, 339], "45463008e": [332, 339], "45558545e": [332, 339], "45565206e": [332, 339], "45596695e": [332, 339], "456": [202, 395, 398], "45615": [332, 336, 339], "45630976e": [332, 339], "45667797e": [332, 339], "45803327e": [332, 339], "45804777e": [332, 339], "45845979e": [332, 339], "45928478e": [332, 339], "45977615e": [332, 339], "45981687e": [332, 339], "46": [127, 130, 137, 142, 348, 355], "46038486e": [332, 339], "46128924e": [332, 339], "46165411e": [332, 339], "46190545e": [332, 339], "46210968e": [332, 339], "46212946e": [332, 339], "46281177e": [332, 339], "46350823e": [332, 339], "46354072e": [332, 339], "46371266e": [332, 339], "46490431e": [332, 339], "46654081e": [332, 339], "46736982e": [332, 339], "46787928e": [332, 339], "46938870e": [332, 339], "46954274e": [332, 339], "47110615e": [332, 339], "47293536e": [332, 339], "47399181e": [332, 339], "47439016e": [332, 339], "47477984e": [332, 339], "475m": 202, "47602344e": [332, 339], "47635157e": [332, 339], "47678024e": [332, 339], "47783903e": [332, 339], "47834991e": [332, 339], "47896763e": [332, 339], "47925606e": [332, 339], "47997355e": [332, 339], "48": [173, 179, 193, 197, 292, 306, 388, 389, 390], "48048115e": [332, 339], "480m": 202, "485": [395, 398], "485m": 202, "48663167e": [332, 339], "48813944e": [332, 339], "48855758e": [332, 339], "48856053e": [332, 339], "49": [164, 165, 171, 173, 178, 292, 305, 306, 348, 355], "49026504e": [332, 339], "49106100e": [332, 339], "49187856e": [332, 339], "49249397e": [332, 339], "49257514e": [332, 339], "49307863e": [332, 339], "49331436e": [332, 339], "49361154e": [332, 339], "49425897e": [332, 339], "49631714e": [332, 339], "49642932e": [332, 339], "49779003e": [332, 339], "49808554e": [332, 339], "49876371e": [332, 339], "49959813e": [332, 339], "4f": [375, 379], "4k": [164, 165, 168, 181, 187], "4m37": [293, 311], "4th": [332, 338], "5": [1, 6, 16, 19, 20, 25, 39, 40, 41, 49, 61, 113, 121, 128, 139, 152, 181, 184, 185, 187, 198, 201, 202, 209, 214, 218, 219, 224, 233, 246, 258, 262, 266, 271, 276, 285, 287, 288, 289, 291, 295, 298, 299, 300, 302, 303, 306, 308, 309, 310, 311, 312, 314, 316, 317, 318, 323, 332, 338, 339, 340, 346, 347, 353, 366, 368, 371, 376, 379, 392, 394, 401, 402, 404, 405], "50": [9, 59, 112, 114, 173, 179, 240, 244, 292, 294, 305, 306, 316, 340, 346, 356, 360, 361, 362, 368, 369, 374, 382, 385, 387], "500": [6, 41, 193, 197, 285, 289, 362, 364, 395, 397, 398], "50099332e": [332, 339], "50164117e": [332, 339], "50424745e": [332, 339], "50576949e": [332, 339], "50653918e": [332, 339], "50785267e": [332, 339], "50892793e": [332, 339], "50946071e": [332, 339], "50_per_index": [9, 59, 61, 64, 240, 244, 246, 249, 294, 295, 316, 318, 323], "51002133e": [332, 339], "51042950e": [332, 339], "51119480e": [332, 339], "512": [258, 277, 280, 282, 292, 300, 306, 375, 379], "51281480e": [332, 339], "51315774e": [332, 339], "51320172e": [332, 339], "51383309e": [332, 339], "51503164e": [332, 339], "51518283e": [332, 339], "51617597e": [332, 339], "51739728e": [332, 339], "51786283e": [332, 339], "51865722e": [332, 339], "52096841e": [332, 339], "52135583e": [332, 339], "52154651e": [332, 339], "52324782e": [332, 339], "525325868955": [101, 106], "52539432e": [332, 339], "52647242e": [332, 339], "53": [292, 305], "53193595e": [332, 339], "53377999e": [332, 339], "53381238e": [332, 339], "53534813e": [332, 339], "53647423e": [332, 339], "53716086e": [332, 339], "53754605e": [332, 339], "53959617e": [332, 339], "53998228e": [332, 339], "54": [291, 298, 348, 355, 382, 383, 384], "5404948": [291, 298], "54113623e": [332, 339], "54230055e": [332, 339], "54291149e": [332, 339], "54304842e": [332, 339], "54450669e": [332, 339], "54546804e": [332, 339], "54573391e": [332, 339], "54621774e": [332, 339], "54645248e": [332, 339], "54685497e": [332, 339], "55": [292, 305], "55025972e": [332, 339], "55099240e": [332, 339], "550_000": [5, 36, 326, 330], "5529555": [291, 298], "5552995": [291, 298], "55601753e": [332, 339], "55613178e": [332, 339], "55635225e": [332, 339], "55699139e": [332, 339], "5588189": [291, 298], "55900936e": [332, 339], "55923614e": [332, 339], "56011016e": [332, 339], "56041365e": [332, 339], "56115811e": [332, 339], "56188577e": [332, 339], "56274483e": [332, 339], "56389399e": [332, 339], "56662523e": [332, 339], "56688479e": [332, 339], "56718080e": [332, 339], "56896329e": [332, 339], "56896693e": [332, 339], "56920916e": [332, 339], "57": [173, 179], "57008413e": [332, 339], "57156566e": [332, 339], "57160601e": [332, 339], "57175567e": [332, 339], "57226282e": [332, 339], "57393692e": [332, 339], "57440994e": [332, 339], "57502690e": [332, 339], "57536250e": [332, 339], "57737350e": [332, 339], "57877821e": [332, 339], "57970206e": [332, 339], "58": [291, 298], "580": [193, 197, 382, 383, 384], "58003160e": [332, 339], "58086956e": [332, 339], "580k": [382, 384], "580x580x3": [193, 197], "58155808e": [332, 339], "58189368e": [332, 339], "58261052e": [332, 339], "58301930e": [332, 339], "58452298e": [332, 339], "58531007e": [332, 339], "58614498e": [332, 339], "58806413e": [332, 339], "58818898e": [332, 339], "58824509e": [332, 339], "58904049e": [332, 339], "59": [181, 186, 291, 298], "59060508e": [332, 339], "59105931e": [332, 339], "59260547e": [332, 339], "59349391e": [332, 339], "59438765e": [332, 339], "59552705e": [332, 339], "59555081e": [332, 339], "59728657e": [332, 339], "59733031e": [332, 339], "59831755e": [332, 339], "59980466e": [332, 339], "5_anyscalejob": [82, 96], "6": [49, 189, 192, 198, 201, 202, 233, 293, 294, 295, 299, 311, 313, 316, 318, 322, 323, 332, 338, 339, 371, 383, 392, 397], "60": [6, 39, 198, 201, 258, 260, 285, 287, 293, 309], "60254669e": [332, 339], "60417205": [291, 298], "60559933e": [332, 339], "60700288e": [332, 339], "60769555e": [332, 339], "60900429e": [332, 339], "60926636e": [332, 339], "60929009e": [332, 339], "61124960e": [332, 339], "61173157e": [332, 339], "61210120e": [332, 339], "61377022e": [332, 339], "61495838e": [332, 339], "61626707e": [332, 339], "61644816e": [332, 339], "61783993e": [332, 339], "61808310e": [332, 339], "62014505e": [332, 339], "62131321e": [332, 339], "62209135e": [332, 339], "62317707e": [332, 339], "62408248e": [332, 339], "62470581e": [332, 339], "62676229e": [332, 339], "62782574e": [332, 339], "6290559": [291, 298], "629055917263031": [291, 298], "63": [348, 355], "63008086e": [332, 339], "63077107e": [332, 339], "63363028e": [332, 339], "63391770e": [332, 339], "63410094e": [332, 339], "63496330e": [332, 339], "63529071e": [332, 339], "63559180e": [332, 339], "63716504e": [332, 339], "63769671e": [332, 339], "6379": [189, 192], "64": [4, 5, 6, 31, 35, 40, 41, 258, 261, 285, 288, 289, 292, 293, 300, 306, 310, 313, 326, 329, 332, 338, 375, 378, 379, 388, 391, 395, 401, 404], "640": [5, 35, 326, 329], "64042781e": [332, 339], "641551": [292, 306], "64353992e": [332, 339], "64574068e": [332, 339], "64824829e": [332, 339], "64927173e": [332, 339], "65101083e": [332, 339], "65288996e": [332, 339], "65297012e": [332, 339], "65683129e": [332, 339], "65831": [293, 311], "65908886e": [332, 339], "66008": [291, 298], "66033891e": [332, 339], "66034375e": [332, 339], "660569": [291, 298], "662196": [291, 298], "66246349e": [332, 339], "662499": [291, 298], "66510823e": [332, 339], "66672035e": [332, 339], "66712171e": [332, 339], "66808441e": [332, 339], "66871315e": [332, 339], "66888866e": [332, 339], "67074795e": [332, 339], "67096058e": [332, 339], "67168414e": [332, 339], "67200039e": [332, 339], "67249476e": [332, 339], "67394597e": [332, 339], "67530221e": [332, 339], "67625724e": [332, 339], "67702921e": [332, 339], "68044616e": [332, 339], "682": [375, 377], "68261507e": [332, 339], "68279577e": [332, 339], "68410710e": [332, 339], "68623075e": [332, 339], "68863142e": [332, 339], "68928802e": [332, 339], "68990344e": [332, 339], "69230062e": [332, 339], "69485952e": [332, 339], "69655108e": [332, 339], "69689246e": [332, 339], "69690510e": [332, 339], "69849765e": [332, 339], "69882979e": [332, 339], "69974936e": [332, 339], "6_000108_000000": [5, 35, 326, 329], "6_2024": [293, 311], "6_anyscaleservic": [83, 99], "6f": [77, 89, 348, 353], "6th": [332, 338], "6x": [293, 313], "7": [6, 31, 40, 41, 49, 198, 201, 202, 233, 258, 261, 285, 288, 289, 291, 293, 294, 298, 299, 300, 310, 311, 313, 316, 318, 332, 338, 339, 366, 379, 385, 392, 397], "70": [173, 175], "70078446e": [332, 339], "70130879e": [332, 339], "70160577e": [332, 339], "70176884e": [332, 339], "70207208e": [332, 339], "70480572e": [332, 339], "70483862e": [332, 339], "70502144e": [332, 339], "70606668e": [332, 339], "70623609e": [332, 339], "70640138e": [332, 339], "70758316e": [332, 339], "70849383e": [332, 339], "70991046e": [332, 339], "70b": [164, 165, 168, 176, 177, 178, 179, 180, 181, 187], "71": [291, 298], "71107422e": [332, 339], "71276686e": [332, 339], "71327189e": [332, 339], "71361454e": [332, 339], "71367359e": [332, 339], "71599907e": [332, 339], "71614686e": [332, 339], "71677093e": [332, 339], "71802861e": [332, 339], "71831726e": [332, 339], "72043703e": [332, 339], "72060728e": [332, 339], "72087287e": [332, 339], "72232352e": [332, 339], "72505680e": [332, 339], "72602186e": [332, 339], "72664893e": [332, 339], "72793153e": [332, 339], "72918749e": [332, 339], "72964428e": [332, 339], "73005784e": [332, 339], "73056117e": [332, 339], "73160497e": [332, 339], "73338448e": [332, 339], "73339425e": [332, 339], "73386657e": [332, 339], "73471044e": [332, 339], "73475703e": [332, 339], "73528048e": [332, 339], "73541475e": [332, 339], "73842654e": [332, 339], "73909385e": [332, 339], "73954112e": [332, 339], "73962507e": [332, 339], "74006203e": [332, 339], "74092592e": [332, 339], "74106744e": [332, 339], "74198601e": [332, 339], "74435990e": [332, 339], "74639919e": [332, 339], "74725649e": [332, 339], "75": [173, 179, 395, 404], "75087003e": [332, 339], "75092961e": [332, 339], "75342406e": [332, 339], "75359203e": [332, 339], "75361482e": [332, 339], "75378935e": [332, 339], "75653571e": [332, 339], "75755769e": [332, 339], "75899668e": [332, 339], "76055871e": [332, 339], "76067518e": [332, 339], "76138058e": [332, 339], "76263633e": [332, 339], "76323075e": [332, 339], "76346910e": [332, 339], "76389585e": [332, 339], "76404205e": [332, 339], "76448804e": [332, 339], "76463524e": [332, 339], "764641": [348, 355], "76568236e": [332, 339], "76702512e": [332, 339], "76715726e": [332, 339], "76780378e": [332, 339], "76795331e": [332, 339], "768": [173, 179], "76875392e": [332, 339], "76900255e": [332, 339], "76936167e": [332, 339], "76972622e": [332, 339], "77": [5, 35, 326, 329], "77095975e": [332, 339], "7721": [293, 311], "7722": [293, 311], "7725": [293, 311], "77374096e": [332, 339], "774": [11, 72, 207, 208], "77459675e": [332, 339], "77555919e": [332, 339], "77606642e": [332, 339], "77784879e": [332, 339], "77830246e": [332, 339], "78041089e": [332, 339], "78072055e": [332, 339], "78197911e": [332, 339], "78284839e": [332, 339], "7834368348121643": [292, 305], "783437": [292, 306], "78439620e": [332, 339], "78474542e": [332, 339], "78715137e": [332, 339], "78778227e": [332, 339], "78793629e": [332, 339], "78836194e": [332, 339], "78927866e": [332, 339], "79144512e": [332, 339], "79223316e": [332, 339], "79288665e": [332, 339], "79409343e": [332, 339], "79455946e": [332, 339], "79656491e": [332, 339], "79875319e": [332, 339], "79880509e": [332, 339], "79888725e": [332, 339], "799808": [348, 355], "79x": [173, 179], "7am": [332, 338], "7b": [164, 165, 169, 173, 175, 180, 181, 187], "7th": [332, 336, 338, 339], "7x": [4, 5, 32, 37, 292, 305, 307, 326, 331], "8": [5, 18, 22, 31, 35, 36, 49, 54, 173, 174, 175, 176, 177, 179, 180, 181, 187, 202, 217, 221, 233, 238, 258, 260, 263, 264, 271, 291, 294, 296, 316, 318, 326, 329, 330, 332, 338, 339, 340, 346, 354, 363, 364, 366, 370, 371, 373, 376, 377, 389, 391, 396, 397, 401, 402], "80": [173, 179, 362, 364, 369, 371, 375, 377, 382, 384], "800": [173, 175], "8000": [0, 3, 10, 28, 70, 164, 165, 171, 173, 177, 181, 184, 185, 186, 198, 201, 203, 206, 252, 256, 291, 295, 298, 322, 323, 356, 361], "80058852e": [332, 339], "80134752e": [332, 339], "80346647e": [332, 339], "80356482e": [332, 339], "80584863e": [332, 339], "80600139e": [332, 339], "80770779e": [332, 339], "80772168e": [332, 339], "80778313e": [332, 339], "80779386e": [332, 339], "8080": [189, 192], "80b": [173, 175, 181, 187], "81101489e": [332, 339], "81150190e": [332, 339], "81153491e": [332, 339], "81209888e": [332, 339], "81385726e": [332, 339], "8147535920143127": [292, 300], "814754": [292, 300], "81605020e": [332, 339], "81611199e": [332, 339], "81677291e": [332, 339], "81750199e": [332, 339], "8192": [164, 165, 171, 181, 184, 185], "81969379e": [332, 339], "81974494e": [332, 339], "81992236e": [332, 339], "82237032e": [332, 339], "82248098e": [332, 339], "82377563e": [332, 339], "82634446e": [332, 339], "8265": [11, 72, 189, 192, 207, 208], "82670507e": [332, 339], "82704625e": [332, 339], "82709087e": [332, 339], "82714777e": [332, 339], "82736081e": [332, 339], "82819171e": [332, 339], "82876396e": [332, 339], "82900697e": [332, 339], "82929088e": [332, 339], "82934299e": [332, 339], "82985464e": [332, 339], "83": [292, 300], "83045536e": [332, 339], "83186028e": [332, 339], "83414386e": [332, 339], "83462293e": [332, 339], "83483610e": [332, 339], "83486040e": [332, 339], "837": [173, 179], "83987024e": [332, 339], "84016372e": [332, 339], "84025085e": [332, 339], "84072098e": [332, 339], "84077434e": [332, 339], "84100178e": [332, 339], "84200376e": [332, 339], "84204574e": [332, 339], "84257627e": [332, 339], "84342591e": [332, 339], "84438897e": [332, 339], "84560393e": [332, 339], "84609653e": [332, 339], "84649059e": [332, 339], "84724203e": [332, 339], "84787306e": [332, 339], "84826868e": [332, 339], "85": [181, 184], "85011083e": [332, 339], "85030222e": [332, 339], "85491417e": [332, 339], "85630648e": [332, 339], "85674404e": [332, 339], "85712914e": [332, 339], "85737485e": [332, 339], "86": [112, 113, 119, 121, 127, 128, 137, 139, 150, 152, 181, 186], "86025219e": [332, 339], "86067504e": [332, 339], "86110076e": [332, 339], "86166140e": [332, 339], "86302094e": [332, 339], "86359452e": [332, 339], "86543170e": [332, 339], "86763499e": [332, 339], "87068461e": [332, 339], "87136489e": [332, 339], "87145798e": [332, 339], "87155861e": [332, 339], "87222108e": [332, 339], "87272584e": [332, 339], "87305135e": [332, 339], "87395632e": [332, 339], "87503409e": [332, 339], "87622940e": [332, 339], "87687856e": [332, 339], "87722724e": [332, 339], "87823978e": [332, 339], "87826851e": [332, 339], "88060308e": [332, 339], "88125470e": [332, 339], "88136353e": [332, 339], "88193573e": [332, 339], "88231084e": [332, 339], "88282757e": [332, 339], "88339034e": [332, 339], "88483773e": [332, 339], "88547347e": [332, 339], "88624009e": [332, 339], "88834351e": [332, 339], "88852262e": [332, 339], "89050034e": [332, 339], "89146360e": [332, 339], "89227986e": [332, 339], "89326443e": [332, 339], "89384127e": [332, 339], "89393270e": [332, 339], "89414667e": [332, 339], "89564747e": [332, 339], "89613281e": [332, 339], "89739510e": [332, 339], "89740060e": [332, 339], "89891556e": [332, 339], "89910729e": [332, 339], "8b": [164, 165, 171, 181, 184, 187], "8cpu": [293, 311, 313], "8gb": [127, 134, 137, 146], "8k": [164, 165, 168, 181, 187], "8th": [332, 336, 338], "8xl40": [173, 179], "9": [2, 6, 25, 31, 39, 40, 112, 113, 119, 121, 127, 128, 130, 131, 139, 142, 143, 152, 159, 193, 197, 202, 215, 224, 258, 260, 261, 275, 285, 287, 288, 291, 293, 294, 298, 309, 310, 316, 318, 332, 339, 348, 353, 364, 368, 390, 396, 397], "90": [127, 128, 181, 185, 193, 197, 332, 338], "90151963e": [332, 339], "90165711e": [332, 339], "90290013e": [332, 339], "90392175e": [332, 339], "90476887e": [332, 339], "90511677e": [332, 339], "90528610e": [332, 339], "90640": [293, 313], "90656148e": [332, 339], "90659517e": [332, 339], "90668219e": [332, 339], "90833239e": [332, 339], "91": [292, 305], "91010717e": [332, 339], "91011913e": [332, 339], "91205712e": [332, 339], "91437262e": [332, 339], "91462375e": [332, 339], "91614705e": [332, 339], "91802080e": [332, 339], "91938744e": [332, 339], "92106171e": [332, 339], "92230538e": [332, 339], "92250460e": [332, 339], "92267558e": [332, 339], "92452052e": [332, 339], "92608377e": [332, 339], "92633970e": [332, 339], "92704949e": [332, 339], "92848936e": [332, 339], "92968845e": [332, 339], "93108886e": [332, 339], "93218452e": [332, 339], "93256009e": [332, 339], "93267390e": [332, 339], "93274853e": [332, 339], "93358018e": [332, 339], "93396618e": [332, 339], "93505753e": [332, 339], "93599756e": [332, 339], "93615": [291, 298], "93653901e": [332, 339], "93655512e": [332, 339], "93872128e": [332, 339], "93877090e": [332, 339], "93991698e": [332, 339], "94008095e": [332, 339], "94048835e": [332, 339], "94202918e": [332, 339], "942508": [292, 306], "9425080418586731": [292, 305, 306], "943": [375, 377], "94449548e": [332, 339], "94474315e": [332, 339], "94507216e": [332, 339], "94511395e": [332, 339], "94559568e": [332, 339], "94806529e": [332, 339], "94919703e": [332, 339], "94921815e": [332, 339], "94926137e": [332, 339], "949393": [348, 355], "94980036e": [332, 339], "950654": [292, 300], "9506543874740601": [292, 300], "95128240e": [332, 339], "95309842e": [332, 339], "95409912e": [332, 339], "95493992e": [332, 339], "95530374e": [332, 339], "95612733e": [332, 339], "95642184e": [332, 339], "95678936e": [332, 339], "95717700e": [332, 339], "95755831e": [332, 339], "95777296e": [332, 339], "95807119e": [332, 339], "9590334296226501": [356, 361], "959243851260": [112, 114], "96": [294, 318], "96016713e": [332, 339], "96078059e": [332, 339], "96112816e": [332, 339], "96223371e": [332, 339], "96230914e": [332, 339], "96423475e": [332, 339], "96519734e": [332, 339], "96568063e": [332, 339], "96672040e": [332, 339], "96707787e": [332, 339], "96917129e": [332, 339], "97122377e": [332, 339], "97128675e": [332, 339], "97161290e": [332, 339], "97234564e": [332, 339], "97312343e": [332, 339], "97468323e": [332, 339], "97478577e": [332, 339], "97603959e": [332, 339], "97606084e": [332, 339], "97651729e": [332, 339], "97699012e": [332, 339], "97741865e": [332, 339], "97773625e": [332, 339], "97899076e": [332, 339], "97899440e": [332, 339], "97910169e": [332, 339], "97926176e": [332, 339], "97952076e": [332, 339], "97973699e": [332, 339], "98": [294, 318], "98070179e": [332, 339], "98221380e": [332, 339], "98234466e": [332, 339], "98250581e": [332, 339], "98440845e": [332, 339], "98496": [293, 311], "98530062e": [332, 339], "98645657e": [332, 339], "98712543e": [332, 339], "988": [294, 318], "99006638e": [332, 339], "99074054e": [332, 339], "99094741e": [332, 339], "99340957e": [332, 339], "99445761e": [332, 339], "99487356e": [332, 339], "99530393e": [332, 339], "99537045e": [332, 339], "999": [369, 371], "99955577e": [332, 339], "9996353387832642": [356, 361], "9998507499694824": [356, 361], "A": [1, 2, 3, 4, 5, 6, 8, 9, 10, 14, 18, 22, 25, 26, 28, 29, 32, 33, 36, 38, 41, 49, 51, 56, 59, 67, 69, 74, 75, 81, 86, 87, 94, 108, 110, 119, 121, 125, 137, 146, 164, 165, 166, 168, 169, 173, 174, 175, 181, 182, 184, 187, 202, 203, 204, 206, 209, 212, 215, 217, 221, 224, 232, 233, 235, 240, 241, 244, 252, 253, 255, 258, 261, 268, 270, 285, 286, 289, 292, 293, 294, 295, 302, 311, 312, 316, 321, 326, 327, 330, 332, 336, 337, 338, 340, 346, 347, 348, 350, 362, 365, 368, 369, 370, 372, 374, 375, 377, 378, 379, 381, 382, 384, 388, 389, 392], "AND": [79, 91], "And": [332, 338, 340, 343], "As": [11, 72, 74, 78, 82, 86, 90, 98, 181, 184, 193, 197, 207, 208, 294, 318, 340, 343, 347, 388, 394], "At": [1, 2, 4, 13, 20, 31, 101, 106, 198, 201, 209, 211, 215, 219, 292, 300, 332, 338, 340, 347, 362, 363, 369, 370, 395, 396], "Be": [332, 338], "But": [6, 40, 285, 288, 293, 310, 332, 338, 340, 343, 346, 347], "By": [2, 7, 9, 22, 46, 59, 61, 78, 82, 84, 90, 96, 198, 201, 215, 221, 225, 229, 240, 244, 246, 258, 259, 260, 268, 382, 385, 388, 389, 395, 396, 397, 398, 402, 404], "For": [1, 2, 3, 7, 8, 9, 10, 11, 13, 21, 23, 28, 48, 52, 53, 54, 55, 62, 64, 71, 72, 73, 74, 75, 76, 77, 78, 79, 83, 85, 86, 87, 88, 89, 90, 91, 100, 101, 102, 104, 108, 109, 110, 111, 127, 131, 137, 143, 150, 153, 159, 164, 165, 169, 173, 176, 177, 178, 181, 184, 185, 186, 187, 189, 192, 198, 200, 201, 203, 206, 207, 208, 209, 211, 215, 220, 222, 225, 231, 232, 236, 237, 238, 239, 240, 247, 249, 252, 257, 258, 268, 272, 291, 292, 294, 297, 304, 317, 318, 332, 333, 338, 340, 341, 342, 347, 348, 349, 351, 353, 357, 369, 370, 375, 376, 382, 386, 395, 396], "IN": [198, 201], "IT": [332, 338], "If": [1, 2, 3, 4, 6, 7, 8, 11, 15, 21, 22, 26, 31, 32, 41, 44, 47, 48, 53, 72, 74, 75, 76, 77, 84, 86, 87, 88, 89, 112, 113, 119, 126, 127, 128, 134, 137, 139, 146, 147, 150, 152, 155, 162, 181, 184, 203, 204, 207, 208, 209, 213, 215, 220, 221, 225, 227, 230, 231, 232, 237, 258, 264, 267, 279, 281, 282, 285, 289, 293, 312, 332, 338, 339, 340, 343, 345, 346, 347, 348, 354, 362, 368, 375, 379, 381, 388, 392, 395, 396, 402, 403], "In": [2, 3, 4, 8, 9, 10, 19, 22, 23, 28, 31, 47, 48, 54, 60, 61, 62, 64, 71, 73, 74, 75, 76, 77, 78, 79, 81, 84, 85, 86, 87, 88, 89, 90, 91, 94, 108, 111, 112, 114, 127, 129, 137, 140, 164, 165, 172, 173, 175, 181, 183, 184, 193, 195, 203, 206, 215, 218, 221, 222, 230, 231, 232, 238, 240, 245, 246, 247, 249, 252, 257, 258, 259, 260, 263, 268, 270, 272, 275, 278, 284, 294, 317, 318, 332, 334, 336, 337, 338, 339, 340, 343, 344, 345, 346, 347, 348, 353, 356, 358, 359, 360, 361, 362, 368, 369, 370, 374, 375, 381, 382, 383, 385, 388, 389, 392, 395, 396], "It": [0, 3, 4, 5, 6, 7, 8, 9, 12, 28, 31, 32, 35, 41, 47, 50, 51, 58, 61, 62, 74, 75, 81, 86, 87, 93, 101, 103, 106, 112, 113, 127, 128, 131, 137, 138, 143, 150, 151, 159, 173, 175, 181, 185, 198, 201, 203, 206, 210, 225, 230, 232, 234, 235, 240, 243, 246, 247, 258, 262, 263, 266, 285, 289, 294, 295, 316, 323, 326, 329, 332, 338, 339, 340, 343, 347, 348, 350, 353, 354, 355, 356, 358, 369, 372, 375, 378, 382, 383, 388, 391], "Its": [7, 47, 225, 230, 340, 347], "NOT": [332, 338], "No": [0, 8, 53, 108, 110, 173, 180, 189, 192, 232, 237, 258, 273, 332, 338, 362, 368, 369, 370, 374, 375, 376, 395, 402, 404], "Not": [2, 4, 5, 25, 29, 33, 35, 101, 102, 215, 224, 258, 283, 326, 327, 329, 332, 336, 338, 395, 404], "OR": [119, 122, 150, 153], "Of": [340, 346], "On": [75, 80, 87, 92, 101, 104, 108, 111, 150, 153, 164, 165, 168, 173, 179, 292, 304, 375, 379, 395, 396], "One": [74, 81, 86, 94, 181, 184, 340, 343, 347, 395, 401], "Or": [0, 76, 88, 164, 173, 176, 181, 184], "Such": [340, 347], "THE": [332, 338, 340, 346], "TO": [332, 338], "That": [2, 18, 84, 215, 217, 332, 338, 340, 346, 347], "The": [0, 1, 2, 3, 4, 5, 6, 8, 9, 14, 15, 19, 25, 27, 28, 31, 32, 36, 39, 41, 42, 46, 48, 51, 52, 54, 60, 61, 63, 74, 75, 76, 77, 79, 80, 81, 83, 84, 86, 87, 88, 89, 91, 92, 95, 98, 100, 101, 104, 106, 107, 108, 109, 110, 111, 112, 115, 119, 123, 124, 127, 130, 131, 137, 142, 143, 147, 150, 153, 159, 168, 169, 170, 171, 173, 176, 178, 179, 181, 184, 185, 186, 189, 191, 192, 193, 197, 198, 200, 201, 202, 203, 205, 206, 209, 212, 213, 215, 218, 224, 229, 231, 232, 235, 236, 238, 240, 245, 246, 248, 258, 259, 261, 263, 264, 268, 269, 270, 271, 272, 273, 275, 276, 279, 282, 285, 287, 289, 290, 291, 292, 293, 294, 298, 302, 309, 313, 316, 326, 330, 332, 334, 338, 339, 340, 343, 346, 347, 348, 350, 352, 353, 354, 355, 362, 363, 369, 370, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384, 385, 388, 391, 394, 395, 396, 404], "Their": [332, 338], "Then": [0, 7, 10, 11, 47, 70, 72, 112, 115, 119, 124, 127, 131, 137, 141, 143, 150, 159, 207, 208, 225, 230, 252, 256, 332, 336, 338, 339, 340, 346, 375, 381], "There": [8, 9, 51, 53, 54, 64, 78, 82, 90, 98, 232, 235, 237, 238, 240, 249, 294, 318, 332, 338, 340, 346, 347, 356, 358, 360, 361], "These": [0, 2, 3, 7, 9, 18, 22, 27, 46, 60, 73, 75, 77, 85, 87, 89, 101, 106, 119, 123, 164, 165, 168, 173, 175, 189, 191, 203, 205, 215, 217, 221, 225, 229, 240, 245, 258, 260, 269, 294, 318, 333, 340, 341, 347, 349, 357, 375, 377], "To": [2, 3, 4, 6, 7, 8, 9, 10, 11, 19, 23, 28, 32, 41, 45, 52, 54, 60, 61, 62, 63, 64, 71, 72, 74, 76, 77, 84, 86, 88, 89, 101, 106, 109, 112, 114, 127, 129, 137, 140, 164, 165, 171, 189, 191, 192, 198, 200, 201, 203, 206, 207, 208, 215, 218, 222, 225, 228, 232, 236, 238, 240, 245, 246, 247, 248, 249, 252, 257, 258, 268, 270, 276, 279, 280, 285, 289, 292, 293, 294, 295, 303, 304, 305, 306, 311, 312, 315, 317, 318, 322, 323, 332, 336, 337, 338, 348, 351, 354, 375, 381, 395, 398, 403], "With": [4, 11, 32, 72, 81, 95, 164, 165, 168, 181, 187, 193, 197, 207, 208, 258, 259, 271, 272, 277, 278, 281, 284, 295, 323, 340, 342, 347, 356, 358, 375, 376, 382, 383, 395, 396], "_": [2, 6, 20, 41, 77, 89, 181, 184, 215, 219, 285, 289, 293, 295, 312, 322, 323, 332, 338, 362, 363, 365, 368, 369, 370, 371, 375, 376, 388, 389, 395, 396, 404], "_2": [362, 363, 369, 370], "__call__": [3, 9, 10, 28, 62, 70, 198, 201, 203, 206, 240, 247, 252, 256, 291, 294, 295, 298, 317, 322, 323, 332, 334, 337, 382, 386, 388, 394, 395, 404], "__file__": [76, 88], "__getitem__": [5, 35, 326, 329, 388, 390, 395, 398], "__index_level_0__": [382, 385], "__init__": [2, 3, 5, 9, 10, 25, 28, 35, 62, 70, 76, 88, 203, 206, 215, 224, 240, 247, 252, 256, 258, 271, 291, 294, 295, 298, 317, 322, 323, 326, 329, 332, 337, 356, 360, 362, 365, 369, 372, 375, 378, 382, 386, 388, 390, 391, 394, 395, 398, 404], "__len__": [5, 35, 326, 329, 388, 390, 395, 398], "__main__": [77, 89, 193, 197], "__name__": [77, 89, 193, 197], "_arrow_table_from_shard": [382, 385], "_build": 0, "_class_nam": [5, 35, 326, 329], "_config": 0, "_diffusers_vers": [5, 35, 326, 329], "_dmat_from_arrow": [382, 385], "_k": [369, 370], "_model": [3, 28, 203, 206, 291, 298], "_sample_timestep": [5, 35, 326, 329], "_shared_step": [362, 365, 369, 372], "_static": 0, "_toc": 0, "a10": [395, 396], "a100": [173, 176, 177, 179, 395, 396], "a10g": [369, 370, 373, 374], "a_random_job_nam": [119, 125, 137, 146], "abandon": [340, 347], "abil": [2, 4, 5, 23, 30, 34, 73, 75, 85, 87, 193, 195, 215, 222, 258, 259, 326, 328, 340, 343], "abl": [4, 7, 8, 32, 47, 54, 112, 113, 127, 128, 137, 139, 147, 150, 152, 189, 192, 225, 230, 232, 238, 356, 361], "abortmultipartupload": [101, 106], "about": [4, 6, 12, 13, 17, 19, 22, 23, 24, 31, 32, 41, 75, 76, 77, 87, 88, 89, 108, 110, 112, 118, 164, 165, 169, 173, 178, 181, 184, 186, 193, 195, 197, 210, 211, 216, 218, 221, 222, 223, 258, 260, 262, 270, 285, 289, 291, 292, 293, 295, 298, 303, 306, 312, 323, 332, 334, 338, 340, 342, 343, 346, 347, 348, 350, 356, 358, 395, 396], "abov": [2, 4, 5, 22, 32, 36, 164, 165, 169, 170, 181, 184, 189, 192, 193, 197, 198, 201, 215, 221, 258, 259, 260, 261, 268, 270, 326, 330, 332, 338, 340, 347, 388, 392], "absenc": [198, 201, 332, 338, 382, 387], "absent": [340, 347], "absolut": [4, 32, 388, 390], "abstract": [3, 7, 27, 43, 84, 101, 103, 164, 165, 169, 170, 173, 176, 203, 205, 225, 226, 294, 315, 369, 370, 382, 383, 388, 394], "absurd": [340, 347], "academ": [181, 187, 388, 389], "academi": [340, 347], "acc": [2, 25, 215, 224, 292, 300, 302, 306, 382, 385], "acc_metr": [395, 400], "acceler": [1, 2, 5, 7, 9, 10, 11, 13, 22, 35, 36, 43, 62, 68, 72, 75, 84, 87, 112, 118, 150, 155, 207, 208, 209, 211, 215, 221, 225, 226, 240, 247, 252, 254, 326, 329, 330, 362, 366, 369, 373], "accelerator_shap": [291, 292, 293, 298, 305, 311, 313], "accelerator_typ": [9, 62, 164, 165, 171, 173, 176, 179, 181, 184, 185, 186, 240, 247, 291, 292, 293, 298, 305, 311, 313, 356, 360], "accept": [1, 6, 9, 10, 11, 16, 41, 61, 62, 68, 72, 207, 208, 209, 214, 240, 246, 247, 252, 254, 258, 261, 271, 285, 289, 293, 294, 311, 313, 317, 356, 358, 360, 388, 391], "access": [2, 7, 18, 25, 31, 43, 74, 76, 77, 80, 81, 84, 86, 88, 89, 92, 93, 94, 101, 104, 105, 106, 111, 137, 147, 173, 174, 176, 177, 181, 182, 184, 185, 186, 189, 192, 193, 197, 198, 201, 202, 215, 217, 224, 225, 226, 258, 263, 268, 270, 277, 299, 348, 353, 355, 356, 358, 382, 384, 395, 396, 397], "accident": [382, 385], "acclaim": [340, 347], "accomplish": [258, 284], "accord": [1, 8, 9, 16, 54, 64, 75, 87, 209, 214, 232, 238, 240, 249, 258, 269, 277, 294, 318], "accordingli": [181, 187, 348, 353, 369, 374], "account": [2, 7, 25, 47, 84, 101, 105, 106, 108, 110, 112, 113, 114, 119, 120, 123, 127, 128, 129, 137, 139, 140, 150, 152, 154, 162, 215, 224, 225, 230, 340, 343], "account_id": [101, 106], "accross": [164, 165, 168, 169], "accumul": [4, 32, 258, 262, 292, 302], "accur": [164, 165, 168, 388, 389], "accuraci": [6, 9, 40, 64, 173, 175, 181, 187, 240, 249, 285, 288, 292, 293, 294, 300, 302, 304, 305, 306, 310, 318, 348, 350, 352, 354, 382, 383, 385, 386, 387, 395, 400, 404], "accuracy_scor": [382, 384, 385], "achiev": [2, 4, 5, 8, 9, 10, 19, 24, 30, 34, 54, 62, 64, 68, 164, 165, 168, 215, 218, 223, 232, 238, 240, 247, 249, 252, 254, 258, 259, 294, 318, 326, 328], "acid": [7, 43, 225, 226], "acl": [81, 94], "across": [1, 2, 3, 4, 5, 7, 8, 9, 11, 13, 18, 21, 23, 28, 32, 36, 43, 46, 54, 55, 57, 59, 63, 64, 66, 72, 75, 76, 77, 81, 87, 88, 89, 95, 101, 103, 106, 108, 110, 163, 164, 165, 169, 170, 173, 176, 179, 180, 181, 184, 187, 193, 195, 197, 202, 203, 206, 207, 208, 209, 211, 215, 217, 220, 222, 225, 226, 229, 232, 238, 239, 240, 242, 244, 248, 249, 251, 258, 259, 260, 261, 262, 263, 265, 268, 269, 270, 272, 275, 276, 277, 284, 291, 292, 293, 294, 296, 302, 304, 305, 313, 315, 317, 318, 326, 330, 340, 344, 347, 348, 350, 354, 355, 356, 358, 362, 363, 364, 368, 369, 370, 371, 374, 375, 376, 377, 379, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 394, 395, 396, 400, 402, 404], "act": [101, 106, 258, 263, 340, 347], "act_dim": [369, 372, 374], "act_fn": [5, 35, 326, 329], "action": [101, 106, 181, 184, 186, 193, 197, 295, 323, 340, 346, 347, 371, 372], "action_spac": [369, 371], "activ": [0, 1, 2, 6, 8, 9, 16, 25, 41, 54, 61, 73, 78, 82, 85, 90, 96, 164, 165, 169, 202, 209, 214, 215, 224, 232, 238, 240, 246, 285, 289, 293, 312, 375, 377], "actor": [4, 5, 7, 8, 10, 18, 22, 32, 36, 47, 51, 56, 68, 69, 164, 165, 169, 193, 195, 217, 221, 225, 230, 232, 235, 241, 252, 254, 255, 261, 284, 292, 295, 302, 316, 321, 326, 330, 332, 334, 337, 382, 386, 387, 388, 389, 394, 395, 404], "actorpoolmapoper": [9, 63, 240, 248], "actorpoolstrategi": [382, 384, 386, 387], "actress": [340, 343], "actual": [1, 6, 9, 15, 41, 62, 112, 114, 119, 122, 127, 129, 132, 137, 140, 144, 150, 153, 156, 160, 181, 186, 209, 213, 240, 247, 258, 268, 285, 289, 293, 294, 311, 317, 332, 338, 340, 347, 369, 371, 375, 376], "ad": [5, 36, 75, 80, 84, 87, 92, 101, 106, 112, 114, 118, 258, 272, 284, 295, 322, 326, 330, 332, 338, 369, 370, 382, 385, 386], "adam": [4, 6, 29, 31, 32, 38, 40, 41, 258, 260, 262, 273, 279, 285, 286, 288, 289, 292, 293, 300, 302, 306, 310, 313, 362, 365, 369, 372, 375, 379, 388, 392, 395, 400], "adamw": [5, 35, 326, 329], "adapt": [164, 165, 168, 182, 183, 188, 258, 260, 265, 348, 354, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "adapter_config": [181, 184], "adapter_model": [181, 184], "adapter_nam": [181, 184], "adaptiveavgpool2d": [292, 300, 306], "add": [1, 2, 4, 5, 7, 8, 9, 10, 14, 15, 16, 18, 19, 21, 25, 32, 35, 36, 43, 52, 53, 61, 70, 73, 74, 75, 79, 83, 85, 86, 87, 91, 100, 101, 106, 119, 123, 127, 130, 132, 135, 137, 142, 144, 147, 148, 150, 153, 157, 160, 164, 165, 170, 181, 184, 186, 193, 197, 198, 200, 209, 212, 213, 214, 215, 217, 218, 220, 224, 225, 226, 232, 236, 237, 240, 246, 252, 256, 258, 260, 261, 263, 266, 271, 284, 292, 295, 303, 306, 322, 326, 329, 330, 333, 340, 341, 344, 349, 357, 362, 363, 368, 369, 371, 374, 375, 381, 382, 387, 388, 392, 394, 395, 404], "add_label": [9, 61, 64, 240, 246, 249, 294, 318], "add_nois": [5, 35, 326, 329], "add_ref": [2, 23, 215, 222], "add_subplot": [4, 31, 32, 258, 260, 271], "addit": [4, 8, 32, 52, 73, 74, 75, 77, 84, 85, 86, 87, 89, 101, 104, 181, 184, 188, 193, 196, 232, 236, 258, 265, 278, 279, 356, 358, 359, 375, 376, 381, 382, 387, 395, 404], "addition": [8, 9, 54, 61, 101, 106, 112, 118, 193, 197, 232, 238, 240, 246, 295, 323, 348, 354, 375, 376], "addr": [362, 366], "address": [1, 7, 13, 43, 101, 106, 112, 114, 127, 129, 137, 140, 189, 192, 209, 211, 225, 226, 258, 269, 332, 338], "adebayor": [332, 338], "adher": [340, 347], "adjust": [5, 8, 35, 53, 181, 187, 232, 237, 258, 261, 326, 329, 332, 338, 340, 346, 348, 355, 382, 385, 395, 404], "adjust_total_amount": [8, 52, 232, 236], "adjusted_data": [8, 53, 55, 232, 237, 239], "adjusted_data_rai": [8, 53, 55, 232, 237, 239], "adjusted_total_amount": [8, 52, 198, 200, 232, 236], "admin": [81, 94, 101, 102, 106], "administr": [340, 347, 405], "admittedli": [340, 343], "adopt": [8, 51, 232, 235], "adv": [332, 336, 338], "advanc": [5, 6, 7, 35, 40, 43, 47, 75, 87, 108, 110, 111, 112, 118, 164, 165, 172, 174, 180, 184, 198, 201, 225, 226, 230, 285, 288, 293, 310, 320, 326, 329, 395, 404, 405], "advantag": [7, 47, 173, 175, 225, 230], "adventureland": [332, 338], "adversari": [362, 363], "affect": [10, 69, 252, 255], "affin": [292, 300, 306], "afford": [173, 175, 332, 338], "after": [1, 2, 3, 4, 5, 10, 11, 16, 18, 24, 28, 31, 32, 35, 71, 72, 74, 75, 77, 83, 86, 87, 89, 99, 127, 131, 134, 137, 141, 143, 146, 150, 159, 164, 165, 168, 193, 197, 198, 201, 202, 203, 206, 207, 208, 209, 214, 215, 217, 223, 252, 257, 258, 260, 262, 268, 271, 292, 295, 306, 323, 326, 329, 332, 334, 338, 339, 340, 346, 348, 350, 355, 362, 363, 368, 369, 370, 375, 376, 377, 379, 381, 382, 384, 387, 388, 390, 392, 393, 395, 396, 400, 402], "afterward": [395, 396], "again": [2, 3, 8, 22, 26, 52, 75, 78, 87, 90, 112, 117, 203, 204, 215, 221, 232, 236, 340, 347, 362, 367, 375, 380, 382, 383, 395, 403], "against": [173, 178, 181, 184, 258, 281, 332, 336, 338, 340, 346, 347, 369, 374, 375, 376, 379, 381, 388, 394, 395, 402], "agent": [164, 165, 168, 181, 187, 369, 370, 374], "aggreg": [7, 46, 49, 56, 60, 225, 229, 233, 241, 245, 258, 259, 292, 302, 314, 362, 365, 366, 382, 386, 387, 395, 400], "aggress": [9, 61, 198, 201, 240, 246], "agil": [369, 370], "agnost": [388, 390], "ago": [340, 343], "agre": [340, 346], "aguero": [332, 338], "ahead": [173, 180, 181, 188, 340, 346], "ai": [2, 8, 9, 10, 11, 25, 55, 59, 61, 62, 64, 70, 72, 76, 78, 80, 82, 83, 84, 88, 90, 92, 96, 99, 164, 165, 171, 173, 180, 181, 183, 184, 186, 207, 208, 215, 224, 232, 239, 240, 244, 246, 247, 249, 252, 256, 294, 295, 316, 317, 318, 319, 322, 323], "air": [291, 298], "aj": [332, 336, 338], "ak": [101, 104], "ako": [332, 338], "alaska": [340, 346], "alb": [108, 111], "alberta": [340, 346], "album": [332, 338], "alciato": [332, 336, 338], "ald": [332, 338], "alert": [79, 82, 83, 91, 96, 99, 199, 258, 284], "algorithm": [6, 41, 84, 108, 111, 164, 165, 170, 285, 289, 291, 292, 293, 298, 305, 311, 312, 313, 348, 355, 382, 383], "alic": 202, "align": [7, 46, 225, 229, 258, 260, 362, 366, 395, 397, 400], "alik": [332, 334], "all": [0, 2, 3, 4, 5, 6, 7, 11, 12, 17, 18, 23, 24, 26, 27, 29, 32, 33, 36, 38, 41, 43, 49, 51, 55, 56, 61, 72, 74, 75, 76, 77, 78, 80, 81, 84, 86, 87, 88, 89, 90, 92, 94, 101, 104, 106, 108, 110, 112, 113, 119, 120, 122, 127, 128, 133, 134, 135, 137, 138, 145, 146, 148, 150, 151, 153, 155, 164, 165, 166, 167, 168, 173, 174, 181, 182, 184, 185, 188, 189, 190, 192, 193, 194, 197, 198, 199, 202, 203, 204, 205, 207, 208, 210, 215, 216, 217, 222, 223, 225, 226, 233, 235, 239, 241, 246, 258, 259, 260, 262, 263, 267, 268, 270, 277, 280, 281, 282, 285, 286, 289, 291, 292, 293, 294, 297, 304, 312, 313, 318, 326, 327, 330, 332, 333, 334, 337, 338, 340, 341, 342, 343, 346, 347, 348, 349, 350, 354, 356, 357, 358, 362, 366, 369, 371, 374, 375, 376, 377, 379, 381, 382, 384, 385, 386, 387, 389, 390, 395, 396, 399, 400, 402, 404], "all_fil": [76, 88], "all_results_at_onc": [2, 24, 215, 223], "alleg": [340, 343], "allegori": [340, 347], "alli": [340, 346], "allobjectact": [101, 106], "alloc": [6, 7, 9, 17, 41, 48, 57, 61, 101, 106, 108, 109, 112, 114, 127, 129, 137, 140, 216, 225, 231, 240, 242, 246, 258, 264, 271, 285, 289, 293, 312, 332, 334, 382, 385, 388, 389], "allow": [2, 3, 4, 5, 7, 18, 22, 27, 28, 30, 32, 34, 48, 73, 75, 77, 80, 81, 85, 87, 89, 92, 94, 101, 106, 137, 147, 173, 179, 181, 183, 184, 198, 201, 203, 205, 206, 215, 217, 221, 225, 231, 258, 259, 264, 265, 268, 277, 280, 282, 294, 295, 316, 317, 323, 326, 328, 332, 334, 338, 340, 347, 348, 350, 353, 354, 355, 356, 358, 360, 362, 366, 375, 380, 382, 385, 388, 392, 394, 395, 396], "allowedhead": [101, 106, 137, 147], "allowedmethod": [101, 106, 137, 147], "allowedorigin": [101, 106, 137, 147], "allreduc": [258, 259], "alltoallapi": [9, 64, 240, 249], "allus": [340, 347], "almost": [340, 347, 382, 384], "alon": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318], "along": [75, 87, 258, 267, 332, 338, 395, 396], "alongsid": [258, 278, 284, 382, 384, 395, 404], "alonso": [332, 338], "alphas_cumprod": [5, 35, 326, 329], "alreadi": [8, 9, 10, 11, 51, 64, 68, 72, 74, 76, 84, 86, 88, 127, 130, 137, 142, 193, 197, 207, 208, 232, 235, 240, 249, 252, 254, 258, 260, 262, 271, 282, 294, 318, 332, 336, 338, 375, 377, 381, 382, 386, 388, 390, 395, 403], "also": [2, 4, 8, 9, 10, 19, 31, 32, 55, 64, 70, 74, 76, 77, 78, 79, 81, 83, 86, 88, 89, 90, 91, 93, 99, 112, 113, 119, 121, 127, 128, 134, 137, 139, 146, 150, 152, 164, 165, 168, 193, 197, 198, 199, 201, 215, 218, 232, 239, 240, 249, 252, 256, 258, 260, 270, 280, 292, 294, 295, 300, 306, 318, 322, 323, 332, 336, 338, 339, 340, 342, 343, 346, 347, 356, 358, 359, 362, 366, 375, 377, 378, 379, 382, 384, 388, 392], "altern": [11, 72, 112, 113, 127, 128, 137, 139, 150, 152, 207, 208, 348, 353, 382, 387], "alwai": [0, 2, 22, 181, 184, 185, 193, 196, 215, 221, 382, 387, 388, 390], "am": [340, 343], "amaz": [181, 188, 332, 338, 340, 346], "amazon": [7, 43, 76, 77, 88, 89, 101, 104, 112, 113, 127, 128, 137, 139, 225, 226, 332, 338], "amazonaw": [101, 106, 292, 293, 305, 311, 313], "amazonelasticfilesystemclientreadwriteaccess": [137, 141, 147], "ambush": [340, 346], "america": [340, 343], "american": [340, 343, 346, 347], "ami": [108, 110, 332, 338], "amnt": [332, 338], "among": [8, 9, 54, 64, 173, 176, 232, 238, 240, 249, 294, 318, 340, 346, 347], "amount": [2, 3, 4, 5, 7, 8, 9, 25, 28, 30, 34, 43, 51, 61, 76, 88, 203, 206, 215, 224, 225, 226, 232, 235, 240, 246, 258, 259, 291, 298, 326, 328, 388, 392, 394, 395, 396], "amp": [332, 338, 362, 368, 395, 404], "amus": [340, 347], "an": [0, 1, 4, 7, 8, 9, 13, 15, 17, 19, 20, 21, 25, 27, 31, 43, 47, 48, 49, 53, 54, 55, 56, 58, 59, 60, 61, 62, 67, 69, 71, 74, 76, 78, 79, 80, 81, 84, 86, 88, 90, 91, 92, 93, 94, 96, 102, 105, 106, 107, 108, 111, 112, 113, 119, 125, 127, 128, 136, 139, 149, 164, 165, 168, 170, 171, 176, 177, 179, 182, 184, 189, 192, 193, 194, 197, 198, 200, 201, 205, 209, 211, 213, 216, 218, 219, 220, 224, 225, 226, 230, 231, 232, 233, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 253, 255, 257, 258, 259, 260, 292, 294, 296, 300, 304, 314, 316, 317, 321, 323, 332, 333, 336, 337, 338, 340, 341, 343, 345, 346, 347, 348, 349, 354, 356, 357, 358, 360, 362, 363, 368, 370, 375, 376, 382, 383, 385, 386, 387, 388, 389, 395, 396, 398, 405], "anal": [340, 347], "analys": [340, 347], "analysi": [7, 46, 77, 89, 163, 164, 165, 168, 181, 184, 187, 225, 229, 340, 347, 356, 358, 360, 361], "analyt": [7, 43, 44, 46, 225, 226, 227, 229], "analyz": [7, 43, 181, 184, 189, 191, 225, 226, 258, 270], "anatom": [340, 343], "anatomi": [332, 338], "angel": [340, 346, 347], "angelbr": [340, 347], "anger": [332, 338], "anggrek": [332, 338], "angl": [369, 370], "angular": [369, 370], "ani": [1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 22, 28, 38, 40, 41, 51, 62, 65, 67, 70, 72, 73, 74, 80, 84, 85, 86, 92, 112, 114, 119, 123, 126, 127, 129, 137, 140, 150, 162, 181, 184, 189, 192, 193, 197, 198, 200, 203, 206, 207, 208, 209, 211, 212, 215, 221, 232, 235, 240, 247, 250, 252, 253, 256, 258, 263, 276, 283, 285, 286, 288, 289, 293, 294, 295, 310, 311, 316, 317, 319, 322, 323, 332, 337, 340, 342, 343, 346, 347, 356, 360, 361, 362, 363, 366, 369, 374, 375, 376, 379, 381, 382, 383, 384, 385, 387, 388, 394, 395, 396, 404], "anniversari": [332, 338], "annot": [6, 41, 108, 111, 285, 289, 382, 386], "anon": [5, 35, 326, 329], "anonym": [198, 200, 291, 298], "anoth": [8, 9, 52, 60, 75, 78, 82, 87, 90, 98, 108, 111, 232, 236, 240, 245, 332, 336, 338, 340, 344, 346, 347, 362, 368], "answer": [164, 165, 168, 332, 338, 340, 343], "ant": [332, 338], "anthoni": [340, 346, 347], "anti": [2, 12, 19, 24, 210, 215, 218, 223, 332, 338, 340, 347], "antiwoman": [340, 347], "anymor": [362, 368, 375, 381], "anyon": [332, 338, 340, 343], "anyscal": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 26, 28, 29, 31, 32, 33, 37, 38, 43, 49, 51, 54, 56, 59, 61, 62, 64, 67, 70, 72, 94, 95, 104, 105, 111, 116, 117, 118, 121, 122, 125, 126, 130, 133, 134, 135, 136, 139, 141, 142, 145, 146, 147, 148, 149, 152, 153, 156, 161, 162, 166, 171, 172, 174, 175, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 197, 200, 202, 203, 204, 206, 207, 208, 209, 210, 215, 216, 225, 226, 232, 233, 235, 238, 240, 241, 244, 246, 247, 249, 252, 253, 256, 258, 259, 260, 284, 285, 286, 291, 292, 293, 294, 295, 296, 298, 305, 307, 311, 313, 316, 317, 318, 322, 323, 326, 327, 331, 332, 334, 336, 340, 342, 348, 350, 356, 358, 368, 374, 381, 387, 394, 401], "anyscale_101": [82, 83, 96, 99], "anyscale_artifact_storag": [5, 35, 76, 88, 193, 197, 326, 329], "anyscale_cloud_id": [119, 123], "anyscale_cloud_nam": [101, 107, 112, 113, 114, 115, 116, 117, 119, 120, 123, 124, 125, 126, 127, 128, 129, 131, 134, 135, 137, 138, 140, 143, 146, 148, 150, 151, 153, 154, 159, 161, 162], "anyscale_cloud_storage_bucket": [76, 88], "anyscale_cloud_storage_bucket_region": [76, 88], "anyscale_iam_rol": [137, 141], "anyscale_iam_role_arn": [101, 107], "anyscale_iam_s3_policy_arn": [137, 141], "anyscale_registration_command": [112, 114, 119, 123, 127, 129, 137, 140, 150, 154], "anyscale_s3_bucket_nam": [112, 114, 117, 127, 129, 135, 137, 140, 148], "anyscale_security_group": [101, 106], "anyscale_vpc": [101, 106], "anyscale_vpc_nam": [101, 106], "anyscalerai": [127, 135, 137, 148], "anyscaleuserdata": [173, 178], "anyth": [76, 88, 108, 111, 258, 263, 340, 343, 347, 395, 403], "anywher": [2, 18, 78, 90, 215, 217], "apach": [46, 229], "aperitif": [332, 338], "api": [2, 7, 8, 9, 10, 25, 45, 46, 47, 48, 50, 55, 61, 62, 68, 78, 79, 81, 82, 83, 84, 90, 91, 94, 96, 98, 100, 108, 109, 110, 111, 121, 152, 162, 164, 165, 170, 171, 173, 176, 181, 183, 185, 186, 188, 215, 224, 225, 228, 229, 230, 231, 232, 234, 239, 240, 246, 247, 252, 254, 292, 294, 295, 303, 317, 321, 332, 334, 336, 337, 339, 340, 345, 356, 358, 362, 366, 375, 377, 382, 387, 388, 394, 395, 396, 404], "api_kei": [164, 165, 171, 173, 177, 178, 181, 184, 185, 186], "apigatewai": [198, 201, 202], "app": [1, 3, 10, 13, 28, 71, 77, 79, 83, 89, 91, 99, 100, 137, 147, 164, 165, 169, 171, 173, 176, 177, 178, 179, 181, 184, 185, 186, 198, 201, 202, 203, 206, 209, 211, 252, 257, 295, 323, 356, 358, 360, 362, 368], "app1": [10, 71, 198, 201, 252, 257], "app_build": [10, 71, 252, 257], "apparatu": [369, 374], "appear": [164, 165, 169, 332, 338, 340, 343, 347], "append": [1, 2, 9, 16, 18, 24, 61, 76, 88, 181, 186, 209, 214, 215, 217, 223, 240, 246, 362, 364, 369, 371, 375, 379, 388, 390, 395, 397, 404], "appl": [11, 72, 207, 208, 332, 334, 338, 348, 350, 353], "appli": [0, 2, 3, 4, 5, 8, 9, 10, 25, 28, 31, 35, 50, 51, 52, 54, 58, 62, 64, 70, 112, 114, 115, 119, 123, 124, 126, 127, 129, 131, 137, 140, 143, 150, 154, 159, 162, 203, 206, 215, 224, 232, 234, 235, 236, 238, 240, 243, 247, 249, 252, 256, 259, 260, 262, 266, 269, 271, 291, 294, 295, 298, 317, 318, 322, 326, 329, 332, 334, 338, 339, 340, 342, 345, 347, 348, 353, 356, 360, 362, 364, 369, 370, 371, 375, 376, 377, 388, 392, 395, 396, 398], "applic": [2, 3, 8, 11, 20, 27, 43, 47, 48, 50, 67, 70, 71, 72, 73, 75, 78, 79, 80, 82, 83, 85, 87, 90, 91, 92, 96, 99, 100, 108, 111, 112, 118, 119, 122, 150, 153, 164, 165, 169, 171, 173, 175, 176, 178, 180, 181, 183, 185, 186, 188, 189, 191, 193, 195, 196, 199, 202, 203, 205, 207, 208, 215, 219, 226, 230, 231, 232, 234, 253, 256, 257, 291, 294, 295, 297, 315, 320, 321, 322, 323, 325, 356, 358, 360, 361, 375, 381], "application_log": [356, 360], "approach": [2, 7, 19, 48, 163, 215, 218, 225, 231, 332, 334, 340, 342, 347, 348, 350, 354, 362, 363, 375, 376, 377, 382, 384, 395, 396], "appropri": [127, 134, 137, 146, 164, 165, 169, 173, 176], "approv": [112, 114, 117, 119, 123, 126, 127, 129, 135, 137, 148, 150, 154, 162], "approx": [2, 18, 215, 217, 369, 370], "approxim": [164, 165, 169, 375, 376, 377], "april": [332, 338], "ar": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 22, 24, 25, 31, 32, 36, 37, 41, 42, 43, 45, 46, 47, 48, 51, 52, 53, 54, 55, 59, 60, 61, 62, 64, 68, 69, 72, 73, 75, 76, 77, 78, 80, 81, 82, 85, 87, 88, 89, 90, 92, 94, 98, 106, 108, 110, 111, 112, 113, 114, 117, 119, 122, 123, 127, 128, 129, 133, 134, 135, 137, 139, 140, 141, 145, 146, 147, 148, 150, 152, 153, 155, 162, 164, 165, 169, 173, 175, 176, 178, 179, 180, 181, 184, 185, 186, 188, 189, 192, 193, 197, 198, 199, 200, 201, 202, 207, 208, 209, 211, 213, 214, 215, 216, 217, 221, 223, 224, 225, 226, 228, 229, 230, 231, 232, 235, 236, 237, 238, 239, 240, 244, 245, 246, 247, 249, 252, 254, 255, 258, 259, 260, 261, 262, 263, 265, 266, 268, 269, 270, 271, 273, 276, 278, 282, 285, 289, 290, 292, 293, 294, 295, 302, 303, 307, 313, 315, 317, 318, 321, 323, 326, 330, 331, 332, 333, 334, 337, 338, 340, 341, 343, 346, 347, 348, 349, 353, 356, 357, 358, 360, 361, 364, 368, 371, 374, 379, 381, 387, 394, 397, 400, 404], "arang": [388, 391, 394], "arbitrari": [1, 13, 181, 185, 209, 211], "architectur": [4, 5, 10, 32, 35, 36, 69, 105, 108, 110, 163, 166, 172, 252, 255, 258, 261, 292, 295, 302, 321, 326, 329, 330, 334, 350, 358, 362, 368, 375, 378, 388, 389, 391, 395, 404], "archuleta": [332, 338], "area": [8, 54, 181, 188, 232, 238], "aree": 164, "aren": [137, 147, 388, 392], "arena": [181, 187], "arg": [181, 185, 388, 391, 395, 404], "argmax": [4, 9, 10, 31, 32, 62, 70, 240, 247, 252, 256, 258, 271, 292, 294, 295, 300, 306, 317, 322, 348, 352, 382, 385, 386, 395, 400, 404], "argu": [340, 347], "arguabl": [340, 343], "argument": [1, 4, 5, 6, 9, 10, 16, 17, 19, 22, 32, 36, 41, 62, 70, 78, 90, 181, 184, 186, 209, 214, 216, 218, 221, 240, 247, 252, 256, 258, 263, 265, 285, 289, 293, 294, 295, 311, 313, 317, 322, 326, 330, 332, 338, 340, 347, 348, 353], "arm": [340, 346], "arm64": [11, 72, 207, 208], "arn": [101, 106, 112, 114, 127, 129, 137, 140, 141], "around": [4, 5, 32, 36, 79, 83, 91, 99, 181, 184, 258, 261, 326, 330, 340, 343, 346, 347, 395, 404], "arr": [258, 271, 362, 364], "arrai": [6, 8, 9, 10, 39, 41, 52, 61, 70, 181, 185, 232, 236, 240, 246, 252, 256, 258, 260, 271, 275, 276, 285, 287, 289, 291, 293, 295, 298, 309, 311, 312, 322, 323, 332, 338, 339], "arrang": [2, 23, 215, 222], "array_equ": [2, 18, 215, 217], "array_split": [375, 377], "arriv": [7, 46, 225, 229, 369, 374], "arrow_ref": [382, 385], "arsen": [332, 338], "art": [164, 165, 170, 340, 346], "articl": [295, 324], "artifact": [4, 32, 76, 88, 258, 260, 268, 269, 283, 291, 292, 298, 305, 348, 355, 382, 387, 395, 404], "artifact_dir": [382, 387], "artifact_storag": [76, 88], "artifact_storage_path": [5, 35, 326, 329], "artifici": [369, 370], "artist": [340, 343], "as_directori": [4, 5, 32, 36, 258, 271, 279, 292, 306, 326, 330, 362, 366, 368, 369, 373, 374, 375, 379, 381, 382, 385, 388, 392, 394, 395, 400, 404], "as_fram": [382, 384], "as_index": [375, 379, 388, 392, 395, 402], "as_tensor": [5, 35, 258, 271, 326, 329], "asarrai": [362, 364], "asgi": 202, "ask": [2, 25, 215, 224, 340, 343, 362, 366, 395, 401], "aspen": [382, 383], "assert": [2, 9, 24, 61, 215, 223, 240, 246, 294, 295, 317, 323, 362, 368, 369, 374, 382, 384], "assess": [388, 392, 394, 395, 402], "assign": [8, 9, 53, 59, 80, 92, 150, 157, 232, 237, 240, 244, 258, 264, 269, 274, 294, 316, 375, 376, 382, 385, 395, 396], "assist": [187, 332, 338], "associ": [7, 48, 74, 86, 193, 195, 225, 231, 258, 270, 375, 381], "assum": [2, 18, 101, 106, 108, 110, 189, 192, 215, 217, 258, 260, 382, 386], "assumerol": [101, 106], "astral": [11, 72, 207, 208], "astyp": [5, 10, 35, 70, 252, 256, 326, 329, 369, 371, 375, 377, 382, 386, 388, 394, 395, 404], "async": [3, 10, 28, 70, 198, 201, 203, 206, 252, 256, 291, 295, 298, 322, 323], "asynchron": [6, 40, 285, 288], "asyncio": [3, 7, 26, 28, 48, 203, 204, 206, 225, 231], "athen": [332, 338], "atom": [7, 43, 225, 226, 332, 338], "attach": [108, 110, 111, 147, 258, 268, 271, 280, 375, 379, 388, 392, 395, 400], "attempt": [9, 60, 61, 240, 245, 246, 258, 279, 388, 392], "attend": [340, 347], "attent": [164, 165, 172, 340, 343, 348, 353, 388, 389, 394], "attention_head_dim": [5, 35, 326, 329], "attribut": [362, 366, 382, 387], "audienc": [340, 346, 347, 375, 381], "audio": [332, 338], "audit": [164, 165, 170], "augment": [258, 272, 284, 395, 404], "august": [332, 338], "auschwitz": [340, 347], "auth": [119, 122, 150, 153, 156, 388, 390], "authent": [74, 76, 86, 88, 101, 106, 108, 111, 120, 121, 152, 173, 177, 178], "author": [173, 177, 181, 184, 202], "auto": [5, 35, 36, 79, 91, 108, 110, 112, 114, 117, 119, 123, 126, 127, 129, 135, 137, 148, 150, 154, 162, 181, 186, 198, 200, 295, 323, 326, 329, 330, 362, 366, 369, 370, 373, 375, 379, 395, 396, 404], "auto_select_worker_config": [164, 165, 171, 173, 178], "autocal": [108, 110], "autocomplet": [181, 187], "autodiscoveri": [127, 130, 137, 142], "autograd": [258, 271], "autom": [74, 86, 96, 108, 109, 110, 181, 186, 188, 382, 383, 388, 394], "automat": [0, 2, 4, 5, 8, 9, 20, 30, 32, 34, 35, 51, 57, 62, 74, 78, 79, 82, 83, 86, 90, 91, 96, 99, 101, 106, 108, 110, 111, 119, 123, 164, 165, 170, 173, 178, 215, 219, 232, 235, 240, 242, 247, 259, 260, 261, 262, 263, 265, 266, 268, 270, 273, 274, 275, 277, 278, 281, 284, 292, 295, 303, 323, 326, 328, 329, 332, 334, 336, 337, 340, 343, 348, 350, 353, 356, 360, 362, 363, 366, 368, 369, 370, 371, 373, 374, 375, 376, 379, 380, 381, 382, 383, 385, 387, 388, 389, 392, 393, 394, 395, 396, 399, 400, 401, 402, 403, 404], "automodelforsequenceclassif": [348, 351, 353], "autosc": [7, 10, 48, 57, 69, 75, 77, 79, 83, 87, 89, 91, 99, 100, 108, 110, 112, 118, 119, 126, 164, 165, 169, 171, 225, 231, 242, 252, 255, 258, 259, 356, 358], "autoscal": [2, 4, 5, 9, 22, 30, 34, 62, 73, 75, 85, 87, 108, 110, 111, 112, 118, 133, 134, 135, 136, 145, 146, 147, 148, 149, 193, 195, 215, 221, 240, 247, 292, 293, 295, 305, 311, 322, 323, 326, 328, 356, 361], "autoscaling_config": [164, 165, 171, 173, 176, 179, 181, 186, 295, 323], "autotoken": [348, 351, 353], "autotun": [6, 42, 285, 290], "auxiliari": [369, 374], "avail": [4, 5, 7, 8, 9, 11, 17, 18, 19, 23, 24, 31, 36, 48, 54, 61, 62, 72, 74, 78, 79, 83, 86, 90, 91, 99, 101, 106, 112, 114, 127, 129, 137, 140, 164, 165, 167, 170, 173, 177, 181, 184, 187, 189, 192, 193, 196, 197, 198, 201, 207, 208, 216, 217, 218, 222, 223, 225, 231, 232, 238, 240, 246, 247, 258, 260, 261, 263, 268, 277, 279, 326, 330, 332, 338, 339, 340, 345, 348, 350, 353, 356, 358, 362, 368, 369, 373, 375, 377, 379, 388, 393, 394, 395, 400, 404], "available_resourc": [2, 22, 215, 221], "availi": [73, 79, 83, 85, 91, 99], "avalanch": [340, 346], "averag": [4, 5, 8, 32, 36, 54, 232, 238, 258, 259, 262, 326, 330, 340, 343, 375, 379, 382, 386, 395, 400], "avg_loss": [4, 31], "avg_train_loss": [375, 379, 388, 392], "avg_val_loss": [375, 379, 388, 392], "avgpool": [292, 300, 306], "avoid": [1, 2, 4, 5, 7, 8, 9, 10, 16, 23, 30, 34, 35, 46, 52, 53, 57, 61, 68, 77, 78, 79, 89, 90, 91, 164, 165, 171, 198, 201, 209, 214, 215, 222, 225, 229, 232, 236, 237, 240, 242, 246, 252, 254, 258, 259, 268, 271, 280, 283, 326, 328, 329, 332, 339, 340, 343, 346, 369, 370, 374, 375, 377, 382, 384, 385, 386, 388, 390, 395, 404], "aw": [7, 8, 9, 10, 43, 51, 59, 62, 70, 76, 80, 81, 88, 92, 94, 102, 103, 104, 106, 107, 108, 110, 111, 114, 117, 118, 129, 132, 134, 135, 136, 139, 140, 141, 144, 147, 148, 149, 150, 160, 163, 181, 184, 225, 226, 232, 235, 240, 244, 247, 252, 256, 291, 292, 293, 294, 295, 298, 305, 311, 313, 316, 317, 322, 340, 347], "awai": [9, 60, 74, 84, 86, 240, 245, 332, 338, 340, 343, 347, 394], "await": [3, 10, 28, 70, 203, 206, 252, 256, 291, 295, 298, 322, 323], "awak": [340, 347], "awar": [369, 370, 375, 381, 388, 390], "award": [332, 338, 340, 347], "aws_region": [101, 107, 112, 114, 127, 129, 130, 132, 137, 140, 142, 144, 181, 184], "aws_role_nam": [119, 123], "awsregion": [127, 130, 137, 142], "ax": [6, 39, 258, 260, 285, 287, 292, 293, 300, 306, 309, 362, 364, 368, 395, 397], "axi": [4, 6, 9, 10, 31, 32, 39, 60, 62, 70, 240, 245, 247, 252, 256, 258, 260, 271, 285, 287, 292, 293, 294, 295, 300, 306, 309, 317, 322, 348, 352, 362, 364, 368, 382, 385, 386, 388, 394, 395, 397, 404], "axvlin": [388, 394], "aydin": [181, 184], "azur": [101, 104, 258, 268, 284, 395, 404], "b": [1, 2, 10, 14, 16, 19, 22, 70, 209, 212, 214, 215, 218, 221, 252, 256, 258, 271, 332, 338, 362, 364, 365, 375, 381, 388, 391, 392, 394, 395, 404], "babi": [332, 336, 338], "back": [2, 3, 25, 28, 79, 91, 198, 201, 203, 206, 215, 224, 258, 274, 275, 291, 295, 298, 323, 332, 336, 338, 339, 340, 346, 347, 362, 368, 369, 370, 374, 375, 377, 382, 385, 386, 395, 404], "backbon": [258, 261, 362, 368], "backdrop": [340, 347], "backend": [173, 179, 181, 184, 193, 196, 197, 198, 199, 348, 353, 354, 395, 404], "background": [1, 15, 209, 213, 340, 347], "backpressur": [7, 47, 48, 164, 165, 169, 198, 200, 225, 230, 231], "backpropag": [348, 353], "backward": [4, 5, 6, 31, 32, 36, 40, 41, 258, 259, 262, 273, 279, 285, 288, 289, 292, 293, 300, 302, 306, 310, 313, 326, 330, 340, 347, 348, 353, 362, 363, 375, 379, 388, 392, 395, 400], "bad": [332, 338, 340, 347], "bai": [340, 347], "bake": [2, 21, 215, 220], "balanc": [2, 10, 25, 68, 79, 83, 91, 99, 100, 101, 106, 108, 111, 112, 118, 135, 136, 148, 149, 164, 165, 170, 173, 175, 176, 178, 181, 187, 215, 224, 252, 254, 356, 358, 360, 369, 370], "bale": [332, 338], "ball": [332, 338], "band": [332, 338], "bandwidth": [164, 165, 167], "bank": [340, 347], "bar": [375, 377, 382, 384, 395, 397], "barca": [332, 338], "barcelona": [181, 184, 332, 338], "barh": [382, 386], "barr": [340, 347], "barrier": [362, 366, 369, 373], "base": [3, 4, 5, 6, 7, 11, 28, 30, 34, 35, 36, 41, 43, 45, 46, 48, 53, 58, 59, 62, 72, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 94, 99, 108, 109, 110, 111, 127, 128, 137, 138, 150, 151, 163, 164, 165, 169, 170, 181, 183, 184, 187, 188, 193, 197, 198, 201, 203, 206, 207, 208, 225, 226, 228, 229, 231, 237, 243, 244, 247, 258, 259, 268, 271, 285, 289, 293, 295, 312, 316, 317, 323, 326, 328, 329, 330, 332, 338, 340, 342, 346, 348, 353, 355, 356, 360, 362, 363, 364, 369, 370, 371, 381, 383, 384, 386, 388, 394, 395, 396, 402, 404], "base_dir": [395, 404], "base_model_id": [181, 184], "base_s3_path": [181, 184], "base_url": [79, 91, 164, 165, 171, 173, 177, 178, 181, 184, 185, 186], "baselin": [6, 40, 258, 260, 285, 288, 293, 310, 369, 374, 375, 378], "basemodel": [3, 26, 28, 181, 185, 203, 204, 206], "bash": [11, 72, 189, 192, 207, 208], "bash_profil": [11, 72, 207, 208], "basic": [1, 4, 6, 9, 10, 12, 29, 31, 38, 40, 41, 64, 71, 78, 84, 90, 101, 105, 108, 111, 163, 181, 182, 183, 188, 189, 192, 198, 199, 209, 210, 240, 249, 252, 257, 285, 286, 288, 289, 292, 293, 294, 299, 308, 310, 312, 318, 388, 390, 405], "basicblock": [292, 300, 306], "basicvariantgener": [6, 41, 285, 289, 293, 312, 313], "bastion": [101, 106], "batch": [4, 5, 6, 10, 17, 22, 26, 31, 32, 35, 36, 39, 47, 48, 52, 55, 57, 60, 61, 62, 68, 70, 77, 78, 81, 82, 89, 90, 94, 96, 169, 170, 172, 198, 200, 204, 216, 221, 230, 231, 236, 239, 242, 245, 246, 247, 252, 254, 256, 258, 259, 262, 263, 266, 268, 271, 272, 273, 274, 277, 279, 284, 285, 287, 291, 292, 293, 295, 298, 302, 303, 309, 317, 321, 322, 323, 326, 329, 330, 333, 339, 341, 348, 349, 350, 351, 353, 354, 357, 362, 364, 365, 369, 371, 372, 373, 374, 375, 376, 377, 379, 383, 385, 387, 389, 396], "batch_df": [362, 364], "batch_first": [388, 391], "batch_format": [8, 52, 232, 236, 362, 364, 369, 371, 375, 377, 382, 384, 386, 387, 388, 394, 395, 404], "batch_idx": [5, 35, 326, 329, 362, 365, 369, 372], "batch_pr": [9, 62, 240, 247, 294, 317], "batch_siz": [2, 4, 5, 6, 8, 9, 24, 31, 32, 35, 36, 39, 40, 41, 52, 60, 61, 62, 215, 223, 232, 236, 240, 245, 246, 247, 258, 262, 266, 273, 274, 279, 285, 287, 288, 289, 292, 293, 294, 295, 300, 302, 303, 306, 309, 310, 313, 317, 322, 326, 329, 330, 332, 338, 339, 348, 353, 362, 366, 369, 373, 375, 379, 382, 384, 388, 390, 392, 394, 395, 398, 399, 400, 401, 404], "batch_size_per_work": [5, 36, 326, 330, 348, 353, 354], "batchnorm2d": [292, 300, 306], "bathtub": [340, 347], "bathtuby": [340, 347], "batman": [332, 338], "batteri": [291, 296], "battl": [332, 336, 338, 339, 340, 346, 347], "battleship": [340, 347], "bayesian": [6, 41, 285, 289, 293, 312], "bbc": [332, 338], "bc": [369, 374], "bd1": [332, 338], "beach": [181, 184], "bearer": 202, "beast": [332, 338], "beauti": [332, 338, 340, 346, 347, 356, 361], "bebr": [340, 347], "becaus": [2, 6, 8, 20, 41, 53, 74, 86, 108, 110, 112, 117, 127, 135, 137, 147, 148, 164, 165, 168, 171, 193, 197, 215, 219, 232, 237, 285, 289, 293, 311, 340, 343, 346, 347, 362, 364, 366, 367, 382, 387, 395, 397, 402], "becom": [2, 7, 8, 18, 24, 48, 51, 193, 197, 215, 217, 223, 225, 231, 232, 235, 258, 263, 271, 332, 338, 362, 363], "bee": [332, 336, 338], "been": [7, 47, 74, 75, 80, 86, 87, 92, 225, 230, 340, 346, 347, 382, 385], "befor": [2, 3, 4, 5, 6, 8, 9, 24, 26, 28, 32, 36, 40, 41, 54, 64, 73, 84, 85, 112, 113, 119, 121, 127, 128, 137, 139, 150, 152, 153, 162, 164, 165, 168, 198, 199, 203, 204, 206, 215, 223, 232, 238, 240, 249, 258, 260, 268, 272, 273, 276, 277, 279, 280, 282, 285, 288, 289, 291, 292, 293, 294, 298, 304, 310, 313, 318, 326, 330, 340, 343, 356, 360, 362, 364, 375, 377, 382, 384, 388, 390, 395, 396, 397, 398], "beforehand": [74, 86, 181, 184], "begin": [74, 84, 86, 112, 113, 119, 121, 127, 128, 137, 139, 150, 152, 181, 187, 198, 199, 332, 334, 340, 347, 375, 379], "beginn": [333, 341, 349, 357], "behalf": [189, 191], "behavior": [2, 19, 75, 87, 181, 183, 184, 189, 191, 193, 195, 198, 201, 215, 218, 258, 278, 369, 374, 375, 377, 395, 397, 400, 402], "behaviour": [362, 364, 382, 386], "behind": [108, 111, 164, 165, 169, 340, 346, 347, 375, 376], "being": [4, 7, 32, 47, 75, 77, 87, 89, 225, 230, 292, 295, 304, 323, 340, 343, 346, 347, 356, 361, 362, 364, 395, 397], "believ": [340, 346], "belong": [395, 396], "below": [1, 2, 4, 6, 7, 16, 20, 25, 31, 32, 41, 43, 74, 75, 77, 78, 79, 84, 86, 87, 89, 90, 91, 98, 108, 110, 164, 165, 169, 173, 179, 198, 200, 209, 214, 215, 219, 224, 225, 226, 258, 262, 270, 285, 289, 293, 312, 362, 368, 382, 387, 395, 404], "ben": [332, 336, 338, 339, 340, 346], "benchmark": [185, 382, 387, 395, 396], "benefit": [2, 3, 6, 9, 11, 19, 27, 40, 61, 72, 101, 106, 188, 203, 205, 207, 208, 215, 218, 240, 246, 285, 288, 291, 293, 297, 310], "bergman": [340, 343], "berni": [332, 338], "bert": [333, 341, 348, 349, 350, 353, 354, 355, 357], "besok": [332, 338], "best": [3, 4, 6, 8, 9, 28, 32, 41, 54, 64, 75, 87, 101, 104, 119, 123, 164, 181, 184, 187, 193, 196, 203, 206, 232, 238, 240, 249, 258, 259, 268, 270, 275, 284, 285, 289, 291, 293, 294, 298, 311, 313, 318, 332, 338, 339, 340, 346, 347, 348, 350, 369, 374, 375, 381, 382, 385, 387, 388, 392, 394, 395, 396, 402, 404], "best_ckpt": [362, 366, 368, 369, 373, 374, 382, 385, 386, 387, 388, 392, 395, 401], "best_ckpt_path": [388, 394, 395, 404], "best_result": [6, 41, 285, 289, 293, 311, 313], "better": [2, 6, 7, 9, 22, 40, 46, 61, 77, 79, 89, 91, 181, 183, 215, 221, 225, 229, 240, 246, 258, 284, 285, 288, 293, 310, 332, 338, 340, 343, 345, 346, 356, 358, 362, 368, 369, 374, 375, 381, 382, 386], "between": [2, 6, 7, 8, 9, 10, 19, 39, 41, 43, 45, 46, 51, 54, 57, 61, 64, 68, 76, 88, 101, 102, 103, 106, 108, 110, 137, 147, 163, 164, 165, 169, 173, 175, 181, 183, 184, 193, 196, 197, 215, 218, 225, 226, 228, 229, 232, 235, 238, 240, 242, 246, 249, 252, 254, 258, 263, 285, 287, 289, 293, 294, 309, 312, 316, 318, 340, 343, 344, 375, 376, 382, 384, 388, 390], "beyonc": [332, 338], "beyond": [80, 92, 181, 182, 186, 332, 338, 340, 346], "bf16": [5, 35, 36, 326, 329, 330], "bfloat16": [395, 404], "bia": [4, 6, 31, 40, 41, 258, 261, 285, 288, 289, 292, 293, 300, 306, 310, 313, 382, 384], "bias": [258, 284, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "bidder": [340, 346], "bieber": [332, 338], "big": [7, 43, 47, 225, 226, 230, 340, 346, 348, 350, 362, 363, 369, 370, 375, 376], "bigger": [332, 338], "bigl": [395, 396], "bigqueri": [7, 43, 225, 226], "bigr": [395, 396], "bill": [81, 94, 119, 121, 150, 152], "billion": [173, 175, 193, 197], "bin": [0, 150, 153, 375, 377], "binari": [291, 298, 382, 383, 387], "bind": [3, 7, 10, 28, 43, 70, 79, 83, 91, 100, 198, 201, 203, 206, 225, 226, 252, 256, 291, 295, 298, 322, 323, 356, 360], "birthdai": [332, 338], "bit": [2, 24, 215, 223, 340, 346, 347], "bitten": [340, 346], "bjork": [340, 347], "bjp": [332, 338], "black": [6, 39, 285, 287, 293, 309, 332, 338, 340, 347, 375, 377], "blair": [332, 338], "blank": [73, 85], "bless": [332, 338], "blind": [340, 347], "blob": [258, 268, 375, 377, 395, 404], "block": [1, 2, 4, 6, 10, 15, 16, 17, 23, 24, 32, 40, 51, 52, 53, 57, 60, 61, 62, 69, 70, 71, 127, 135, 137, 148, 164, 165, 171, 173, 177, 179, 181, 184, 185, 186, 198, 200, 201, 209, 213, 214, 215, 216, 222, 223, 235, 236, 237, 242, 245, 246, 247, 252, 255, 256, 257, 258, 269, 272, 273, 285, 288, 292, 295, 305, 316, 322, 323, 332, 334, 336, 340, 345, 362, 364, 375, 376, 377, 382, 385], "block_out_channel": [5, 35, 326, 329], "blockbust": [340, 347], "blog": [4, 5, 6, 32, 37, 42, 285, 290, 292, 307, 326, 331], "blow": [332, 338], "blue": [164, 165, 168, 332, 336, 338, 362, 363, 395, 396], "bn1": [292, 300, 306], "bn2": [292, 300, 306], "board": [340, 347], "boat": [340, 346], "bob": [332, 338], "bodi": [10, 70, 252, 256, 295, 322, 340, 343, 347], "boi": [340, 343, 347], "boilerpl": [258, 265, 268, 362, 363, 369, 370, 382, 383, 395, 404], "bomb": [340, 347], "bon": [332, 338], "book": [332, 336, 338, 339, 340, 346], "bookkeep": [395, 399], "bool": [395, 404], "boolean": [291, 298], "boost": [3, 28, 203, 206, 291, 298, 382, 383, 384, 385, 387], "booster": [3, 28, 203, 206, 291, 298, 382, 385, 386, 387], "boot": [332, 338], "booth": [332, 338], "bootstrap": [108, 110], "border": [340, 346], "bore": [340, 346], "both": [0, 7, 9, 43, 48, 57, 81, 84, 94, 101, 106, 108, 110, 137, 141, 173, 174, 181, 185, 189, 191, 193, 195, 198, 201, 225, 226, 231, 240, 242, 258, 268, 270, 272, 275, 278, 282, 332, 338, 348, 350, 354, 362, 364, 382, 384, 385], "boto3": [76, 88, 181, 184], "bottleneck": [189, 191, 193, 197, 382, 384], "bottom": [2, 24, 80, 92, 215, 223], "bound": [17, 101, 106, 216], "boundari": [7, 46, 225, 229], "bouquet": [332, 338], "bout": [332, 336, 338, 339], "box": [4, 32, 77, 80, 89, 92, 258, 259], "br": [340, 343, 346, 347], "brain": [340, 346], "branch": 0, "brand": [181, 185], "braun": [332, 338], "break": [5, 6, 35, 39, 77, 89, 285, 287, 293, 309, 326, 329, 340, 347, 395, 398], "breakdown": [7, 43, 225, 226], "breakneck": [340, 347], "breakpoint": [348, 353], "breez": [340, 343], "brennan": [340, 346], "brew": [3, 26, 112, 113, 127, 128, 137, 139, 150, 152, 189, 192, 203, 204], "bridg": [7, 43, 225, 226, 258, 263, 294, 295, 315, 324, 340, 347], "brief": [181, 184], "bring": [3, 27, 203, 205, 258, 269, 332, 336, 338, 340, 346, 347, 382, 384], "brit": [332, 338], "british": [332, 338, 340, 347], "broadcast": [258, 259], "broader": [7, 47, 225, 230], "brock": [332, 338], "brought": [340, 346], "brown": [332, 338, 340, 343], "brows": 202, "browser": [0, 11, 72, 74, 86, 119, 122, 207, 208], "bryant": [332, 338], "bst": [3, 28, 203, 206], "bubbl": [332, 338], "bucket": [76, 88, 101, 105, 106, 107, 112, 114, 117, 118, 119, 120, 123, 126, 127, 129, 135, 137, 140, 147, 148, 150, 154, 162, 181, 184], "bucket_nam": [119, 123, 181, 184], "budget": [181, 187], "buf": [362, 364, 395, 397], "buffalo": [332, 338], "buffer": [7, 43, 164, 165, 169, 225, 226, 258, 274], "bug": [189, 191], "bui": [332, 338, 340, 346], "build": [1, 2, 3, 5, 7, 8, 9, 10, 11, 16, 17, 27, 28, 32, 35, 43, 46, 48, 50, 57, 60, 67, 69, 70, 71, 72, 73, 75, 84, 85, 87, 101, 105, 173, 180, 181, 183, 186, 188, 203, 205, 206, 207, 208, 209, 214, 215, 216, 225, 226, 229, 231, 232, 234, 240, 242, 245, 252, 253, 255, 256, 257, 260, 262, 265, 273, 275, 291, 295, 297, 304, 320, 321, 323, 326, 329, 340, 347, 362, 363, 364, 369, 370, 375, 376, 377, 381, 383, 384, 388, 390, 394, 395, 398, 400, 404], "build_app": [10, 71, 252, 257], "build_data_load": [6, 39, 40, 285, 287, 288, 293, 309, 310], "build_data_loader_ray_train": [4, 32, 258, 262, 266, 292, 302, 303, 306], "build_data_loader_ray_train_ray_data": [258, 273, 274, 279], "build_data_loader_torch": [4, 31, 292, 300], "build_dataload": [388, 390, 392, 395, 399, 400], "build_inference_dataset": [395, 404], "build_openai_app": [164, 165, 171, 173, 176, 179, 181, 184, 185, 186], "build_resnet18": [4, 31, 32, 258, 261, 265, 271, 292, 300, 303, 306], "builder": [10, 71, 252, 257], "built": [0, 1, 3, 4, 5, 7, 8, 13, 27, 30, 32, 34, 36, 43, 50, 74, 75, 77, 86, 87, 89, 108, 111, 112, 118, 119, 123, 164, 165, 169, 189, 192, 193, 195, 202, 203, 205, 209, 211, 225, 226, 232, 234, 258, 259, 261, 273, 291, 295, 297, 322, 324, 326, 328, 330, 356, 358, 369, 370, 373, 375, 380, 382, 384, 385, 386, 387, 388, 394, 395, 396, 400, 404], "bulk": [78, 82, 90, 96], "bundl": [75, 87], "bunni": [340, 343], "burden": 84, "burrito": [395, 396], "bursti": [73, 75, 85, 87, 164, 165, 169], "busi": [7, 10, 43, 69, 181, 186, 225, 226, 252, 255, 356, 360], "button": [74, 75, 79, 80, 86, 87, 91, 92], "bx1": [362, 365], "bx3xhxw": [362, 365], "bypass": [2, 19, 215, 218], "bystand": [340, 347], "byte": [9, 61, 198, 200, 240, 246, 362, 364, 368, 395, 397], "bytesio": [362, 364, 395, 397, 398, 404], "byth": [76, 88], "c": [2, 10, 11, 22, 70, 72, 75, 76, 87, 88, 207, 208, 215, 221, 252, 256, 258, 271, 332, 338, 340, 346, 375, 379, 382, 384, 385, 388, 392, 395, 402, 404], "cab": [3, 8, 28, 51, 54, 198, 200, 203, 206, 232, 235, 238, 291, 298], "cabin": [340, 347], "cabl": [340, 343], "cach": [2, 18, 75, 87, 101, 105, 167, 169, 172, 173, 179, 215, 217, 258, 284, 294, 317, 362, 364, 369, 371, 375, 377, 381, 382, 384, 388, 390, 395, 397, 398, 404], "cactu": [332, 336, 338], "caesar": [395, 396], "cahse": [332, 338], "calcul": [4, 8, 32, 52, 77, 89, 232, 236, 258, 262, 292, 302, 348, 352, 353], "call": [2, 3, 4, 5, 6, 8, 9, 12, 15, 19, 24, 25, 28, 32, 36, 41, 54, 55, 60, 61, 64, 79, 91, 165, 172, 182, 183, 188, 198, 201, 202, 203, 206, 210, 213, 215, 218, 223, 224, 232, 238, 239, 240, 245, 246, 249, 258, 260, 262, 265, 268, 269, 273, 277, 279, 280, 281, 282, 285, 289, 292, 293, 294, 304, 305, 311, 313, 318, 326, 330, 339, 340, 347, 348, 355, 362, 364, 366, 367, 375, 379, 382, 384, 387, 395, 397, 401], "call_id": [181, 186], "callabl": [9, 10, 62, 71, 181, 186, 240, 247, 252, 257, 294, 317, 332, 334, 337, 339], "callback": [5, 36, 326, 330, 362, 365, 366, 369, 373, 374, 382, 385, 387], "caller": [332, 338], "came": [332, 338], "camera": [340, 346, 347], "campu": [332, 338], "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 38, 40, 41, 44, 46, 47, 48, 49, 51, 52, 53, 54, 56, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 104, 106, 108, 110, 111, 112, 113, 114, 116, 117, 118, 119, 123, 125, 126, 127, 128, 129, 134, 135, 136, 137, 139, 140, 141, 146, 147, 148, 149, 150, 152, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 177, 178, 179, 181, 182, 183, 184, 186, 189, 191, 192, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 227, 229, 230, 231, 232, 233, 235, 236, 237, 238, 240, 241, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 263, 264, 267, 269, 270, 271, 272, 275, 276, 278, 279, 280, 282, 284, 285, 286, 288, 289, 291, 292, 293, 294, 295, 296, 300, 304, 306, 310, 312, 313, 316, 317, 318, 319, 321, 322, 323, 326, 328, 329, 330, 332, 334, 336, 337, 338, 339, 340, 342, 343, 345, 346, 347, 348, 350, 353, 354, 355, 356, 358, 360, 363, 364, 365, 366, 370, 372, 376, 377, 383, 384, 389, 390, 393, 396, 397, 398], "canadian": [340, 346], "cancel": [340, 346], "candid": [181, 184, 362, 366, 369, 373, 374], "cannon": [340, 347], "cannot": [2, 11, 18, 72, 75, 87, 112, 115, 117, 119, 124, 127, 131, 137, 143, 150, 159, 207, 208, 215, 217, 340, 343], "canopi": [382, 387], "cant": [340, 347], "canva": [4, 5, 32, 37, 292, 307, 326, 331], "capabl": [7, 10, 43, 47, 69, 74, 76, 86, 88, 108, 111, 173, 175, 180, 181, 182, 183, 186, 187, 188, 193, 194, 196, 202, 225, 226, 230, 252, 255, 348, 354, 356, 358], "capac": [75, 87, 112, 114, 127, 129, 137, 140, 164, 165, 167, 168, 375, 376], "capit": [164, 165, 171, 181, 184], "captain": [340, 346], "caption_lat": [5, 35, 326, 329], "captur": [80, 92, 198, 201, 362, 366, 375, 379, 388, 389, 394], "car_typ": [181, 185], "card": [8, 51, 173, 176, 232, 235], "cardescript": [181, 185], "cardiffnlp": [332, 336], "care": [258, 268, 340, 346, 347, 388, 390], "carli": [332, 338], "carriag": [340, 347], "carrow": [332, 338], "cartograph": [382, 383], "cartpol": [369, 374], "cartyp": [181, 185], "case": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 19, 25, 27, 28, 32, 36, 37, 41, 42, 46, 54, 55, 62, 64, 71, 75, 77, 87, 89, 108, 110, 112, 114, 127, 129, 137, 140, 164, 165, 168, 173, 175, 180, 183, 184, 188, 193, 196, 203, 205, 206, 209, 211, 215, 218, 224, 225, 229, 232, 238, 239, 240, 247, 249, 252, 257, 258, 280, 285, 289, 290, 291, 292, 293, 294, 297, 298, 301, 307, 311, 317, 318, 326, 330, 331, 332, 338, 339, 340, 347, 348, 353, 375, 376, 382, 383, 388, 392], "cash": [8, 51, 232, 235], "castl": [340, 346], "casual": [332, 338], "cat": [362, 365, 369, 372, 388, 392], "catalog": [375, 376], "catch": [332, 338], "categor": [7, 44, 46, 77, 89, 225, 227, 229], "categori": [9, 60, 108, 110, 240, 245, 348, 350, 395, 396], "cattl": [340, 346], "cattleman": [340, 346], "caus": [4, 5, 17, 30, 34, 112, 114, 127, 129, 137, 140, 193, 197, 216, 258, 259, 326, 328], "cd": [0, 10, 71, 78, 79, 82, 83, 84, 90, 91, 96, 100, 112, 116, 119, 125, 127, 134, 137, 146, 150, 161, 181, 188, 193, 197, 198, 201, 252, 257, 395, 404], "cdot": [362, 363, 369, 370], "ceil_mod": [292, 300, 306], "cell": [3, 4, 5, 6, 8, 9, 10, 28, 29, 32, 33, 37, 42, 55, 66, 71, 74, 75, 76, 78, 82, 86, 87, 88, 90, 98, 203, 206, 232, 239, 240, 251, 252, 257, 258, 260, 271, 285, 290, 292, 307, 326, 327, 331, 375, 377, 388, 390], "celsiu": [2, 25, 181, 186, 215, 224], "cena": [332, 336, 338], "center": [258, 266, 332, 338, 340, 343, 362, 364, 395, 396, 397], "center_input_sampl": [5, 35, 326, 329], "centercrop": [362, 364, 395, 397], "central": [181, 184, 193, 196, 258, 268], "centric": [7, 46, 225, 229], "ceph": [7, 43, 225, 226], "cerebr": [340, 346], "cert": [108, 111], "certain": [4, 5, 6, 8, 29, 33, 41, 52, 232, 236, 285, 289, 293, 312, 326, 327, 340, 343, 356, 360], "certif": [108, 111], "chain": [17, 216, 294, 318], "chair": [332, 338], "chalk": [340, 347], "challeng": [4, 5, 9, 10, 30, 34, 57, 68, 84, 166, 172, 240, 242, 252, 254, 258, 259, 272, 326, 328], "chanc": [2, 20, 215, 219, 332, 338], "chang": [2, 4, 5, 6, 7, 9, 10, 18, 30, 34, 36, 41, 43, 65, 68, 71, 76, 77, 79, 83, 88, 89, 91, 100, 112, 114, 119, 123, 127, 129, 137, 140, 147, 173, 178, 180, 181, 184, 193, 195, 198, 201, 215, 217, 225, 226, 240, 250, 252, 254, 257, 258, 259, 285, 289, 293, 313, 326, 328, 330, 332, 338, 340, 346, 348, 354, 362, 363, 366, 368, 369, 370, 375, 376, 382, 383, 388, 394, 395, 396, 403, 404], "channel": [9, 61, 193, 197, 198, 201, 240, 246, 258, 260, 261, 271, 292, 294, 295, 300, 317, 323, 340, 347, 362, 363, 364, 365, 388, 394, 395, 396], "chao": [340, 347], "chap": [112, 113, 127, 128, 137, 139], "charact": [164, 165, 167, 340, 347, 356, 361], "characterist": [7, 8, 10, 43, 51, 69, 164, 165, 167, 225, 226, 232, 235, 252, 255, 294, 316], "charg": [8, 51, 232, 235], "charli": [332, 338], "charm": [332, 338, 340, 346], "chart": [127, 130, 132, 137, 142, 144, 150, 160, 382, 384], "chase": [332, 336, 338], "chat": [164, 165, 168, 171, 173, 177, 178, 181, 184, 185, 186, 187], "chatbot": [181, 186, 187], "cheap": [332, 338], "cheaper": [7, 45, 225, 228], "cheapli": [340, 343], "cheat": [340, 346], "check": [2, 4, 5, 8, 9, 10, 22, 31, 32, 36, 51, 53, 61, 62, 70, 76, 77, 78, 79, 80, 88, 89, 90, 91, 92, 99, 112, 116, 119, 125, 127, 133, 134, 137, 145, 146, 147, 150, 155, 161, 164, 165, 169, 181, 186, 198, 200, 202, 215, 221, 232, 235, 237, 240, 246, 247, 252, 256, 258, 260, 268, 269, 279, 292, 306, 326, 330, 332, 338, 348, 353, 366, 369, 373, 375, 377, 382, 384, 387], "check_cal": [362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "check_val_every_n_epoch": [362, 366, 369, 373], "checkout": [77, 79, 89, 91], "checkpoint": [8, 9, 30, 34, 35, 55, 57, 76, 88, 232, 239, 240, 242, 259, 260, 261, 262, 269, 270, 273, 277, 278, 281, 283, 284, 291, 293, 298, 299, 302, 305, 306, 311, 328, 329, 348, 355, 363, 364, 366, 370, 371, 374, 376, 377, 381, 383, 385, 389, 390, 392, 394, 395, 396, 397, 400, 401, 402, 403, 404], "checkpoint_": [395, 404], "checkpoint_000000": [292, 306], "checkpoint_000001": [292, 306], "checkpoint_at_end": [388, 392], "checkpoint_config": [362, 366, 369, 373, 375, 379, 382, 385, 388, 392, 395, 401], "checkpoint_dir": [395, 404], "checkpoint_dir_nam": [292, 306], "checkpoint_frequ": [362, 366, 369, 373, 382, 385, 395, 401], "checkpoint_nam": [382, 385], "checkpoint_path": [4, 5, 31, 36, 292, 300, 326, 330, 388, 394, 395, 404], "checkpoint_root": [395, 404], "checkpoint_score_": [388, 392], "checkpoint_score_attribut": [362, 366, 369, 373, 382, 385, 388, 392, 395, 401], "checkpoint_score_ord": [362, 366, 369, 373, 382, 385, 388, 392, 395, 401], "checkpointconfig": [362, 363, 364, 366, 369, 370, 371, 373, 375, 376, 377, 379, 382, 383, 384, 385, 388, 390, 392, 395, 397, 401], "cheekbon": [332, 338], "chelsea": [332, 338], "cheri": [332, 338], "chill": [332, 338], "chip": [11, 72, 207, 208], "chloe": [340, 343], "chmod": [189, 192], "choic": [7, 8, 48, 55, 108, 110, 164, 165, 171, 173, 177, 178, 181, 184, 185, 186, 225, 231, 232, 239, 356, 358, 388, 389], "choos": [9, 11, 63, 72, 73, 74, 75, 85, 86, 87, 101, 102, 104, 137, 147, 150, 157, 164, 165, 169, 182, 188, 207, 208, 240, 248, 294, 317, 340, 347, 375, 381], "choreo": [332, 338], "chose": [4, 32, 292, 304], "chown": [189, 192], "chri": [332, 338], "chrisbrown": [332, 338], "christian": [332, 338], "chromadb": [7, 43, 225, 226], "chronolog": [193, 195], "chuck": [332, 338], "chunk": [7, 9, 46, 64, 77, 89, 164, 165, 171, 173, 177, 178, 181, 184, 225, 229, 240, 249, 294, 318], "church": [332, 338], "churn": [388, 394], "chw": [362, 364], "ci": [78, 82, 90, 96, 181, 188, 258, 284, 395, 404], "ciara": [332, 338], "cidr": [101, 106], "cidr_block": [101, 106], "cif": [332, 338], "cifar": [258, 277, 280, 282], "cifar10": [258, 275, 283], "cinema": [340, 343, 346, 347], "cinemat": [340, 347], "cinematograph": [340, 347], "cinematographi": [340, 346, 347], "cineworld": [332, 338], "citi": [3, 8, 28, 51, 181, 186, 203, 206, 232, 235, 291, 298, 332, 338, 340, 347, 388, 389], "citizenship": [332, 338], "ckpt": [4, 5, 32, 36, 292, 306, 326, 330, 362, 363, 366, 368, 369, 370, 373, 374, 375, 379, 382, 385, 386, 388, 392, 394, 395, 400], "ckpt_dir": [4, 5, 32, 36, 258, 271, 279, 292, 306, 326, 330, 362, 368, 369, 374, 375, 379, 381, 388, 392, 394, 395, 400, 404], "ckpt_file": [362, 368, 369, 374], "ckpt_out": [375, 379, 388, 392, 395, 400], "ckpt_path": [5, 36, 326, 330, 362, 366, 369, 373], "ckpt_root": [362, 366, 369, 373], "claim": [7, 47, 225, 230, 340, 343, 346], "clamp": [362, 368], "clarifi": [81, 93], "class": [2, 3, 4, 5, 6, 9, 10, 25, 28, 32, 35, 36, 39, 41, 59, 62, 70, 181, 185, 198, 201, 203, 206, 215, 224, 240, 244, 247, 252, 256, 258, 261, 269, 271, 275, 285, 287, 289, 291, 293, 294, 295, 298, 309, 311, 312, 316, 317, 322, 323, 326, 329, 330, 334, 338, 339, 356, 360, 362, 363, 364, 365, 368, 369, 372, 375, 378, 383, 386, 388, 390, 391, 394, 395, 396, 397, 398, 404], "class_nam": [2, 25, 215, 224], "classic": [369, 370, 374, 375, 376, 382, 383], "classif": [3, 28, 67, 203, 206, 253, 258, 260, 261, 262, 291, 294, 298, 317, 348, 350, 351, 353, 355, 400], "classifi": [6, 10, 40, 70, 252, 256, 285, 288, 293, 310, 320, 348, 350, 395, 396], "classmat": [340, 343], "claud": [181, 187], "cld": [76, 88, 173, 178], "cld_g54aiirwj1s8t9ktgzikqur41k": [76, 88], "cldrsrc_12345abcdefgh67890ijklmnop": [127, 131, 132, 137, 143, 144, 150, 159, 160], "clean": [0, 10, 69, 112, 117, 119, 126, 150, 162, 252, 255, 268, 340, 347, 363, 365, 366, 377, 388, 392, 394, 396, 397, 400, 403], "cleaner": [258, 260], "cleanli": [258, 268, 375, 377], "cleanup": [3, 4, 5, 6, 8, 9, 10, 28, 32, 37, 42, 55, 66, 71, 78, 90, 108, 110, 163, 203, 206, 232, 239, 240, 251, 252, 257, 258, 260, 283, 285, 290, 291, 292, 294, 298, 307, 319, 326, 331, 362, 368, 369, 374, 375, 381, 382, 387, 395, 404], "clear": [0, 81, 95, 340, 346, 369, 374, 382, 387, 388, 394, 395, 396, 404], "clearli": [198, 199, 340, 347], "cli": [74, 76, 77, 78, 86, 88, 89, 90, 101, 102, 112, 113, 119, 121, 127, 128, 137, 139, 150, 152, 158, 198, 201, 202], "click": [1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 16, 17, 25, 26, 29, 32, 33, 36, 38, 41, 49, 56, 61, 67, 73, 74, 75, 76, 77, 79, 80, 85, 86, 87, 88, 89, 91, 92, 101, 106, 112, 113, 127, 128, 137, 139, 147, 150, 152, 164, 165, 166, 173, 174, 179, 181, 182, 189, 192, 198, 200, 201, 203, 204, 209, 210, 214, 215, 216, 224, 232, 233, 240, 241, 246, 252, 253, 285, 286, 289, 292, 293, 306, 312, 326, 327, 330, 332, 334, 340, 342, 348, 350, 356, 358], "client": [76, 88, 164, 165, 170, 171, 173, 177, 178, 181, 184, 185, 186, 358], "cliff": [332, 338], "clipboard": [79, 91], "clitori": [340, 343], "clock": [340, 347], "clog": [340, 347], "clone": [0, 79, 91, 369, 374], "close": [258, 268, 332, 338, 340, 347], "cloud": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 17, 26, 29, 32, 33, 38, 49, 56, 67, 72, 73, 75, 80, 83, 84, 85, 87, 92, 95, 99, 102, 105, 106, 108, 110, 111, 113, 114, 116, 117, 118, 120, 121, 123, 125, 126, 128, 129, 132, 133, 134, 135, 136, 138, 140, 144, 145, 146, 148, 149, 151, 152, 154, 160, 161, 162, 163, 164, 165, 166, 170, 171, 173, 174, 178, 181, 182, 184, 193, 197, 203, 204, 207, 208, 209, 210, 215, 216, 232, 233, 240, 241, 252, 253, 258, 259, 268, 284, 285, 286, 326, 327, 332, 334, 340, 342, 348, 350, 354, 356, 358, 362, 368, 375, 381, 382, 383, 395, 396], "cloud_deployment_id": [127, 132, 137, 144, 150, 160], "cloud_nam": [127, 134, 137, 146], "clouddeploymentid": [127, 129, 132, 137, 140, 144, 150, 160], "cloudflar": [7, 43, 225, 226], "cloudform": [101, 106], "cloudfound": [101, 106, 119, 123], "cloudprovid": [127, 129, 132, 137, 140, 144, 150, 160], "cloudresourcemanag": [119, 122, 150, 153], "cloudwatch": [101, 106], "club": [332, 336, 338, 340, 346], "cluster": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 21, 23, 25, 26, 28, 29, 30, 33, 34, 38, 46, 49, 53, 55, 56, 57, 59, 60, 61, 62, 63, 66, 67, 69, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 85, 86, 87, 89, 90, 91, 92, 96, 98, 99, 101, 103, 104, 105, 106, 108, 109, 110, 111, 112, 114, 116, 117, 118, 119, 125, 126, 129, 133, 134, 135, 136, 139, 140, 141, 145, 146, 147, 148, 149, 156, 161, 162, 163, 164, 165, 166, 170, 171, 173, 174, 178, 181, 182, 191, 193, 195, 196, 198, 199, 203, 204, 206, 207, 208, 209, 210, 212, 213, 216, 217, 218, 220, 222, 224, 225, 229, 232, 233, 237, 239, 240, 241, 242, 244, 245, 246, 247, 248, 251, 252, 253, 255, 259, 260, 261, 264, 266, 268, 269, 270, 271, 272, 275, 276, 277, 280, 284, 285, 286, 291, 292, 293, 294, 295, 296, 298, 305, 311, 313, 315, 316, 317, 321, 322, 326, 327, 328, 334, 336, 338, 340, 342, 350, 354, 358, 362, 363, 364, 368, 369, 370, 371, 374, 375, 376, 377, 379, 381, 382, 383, 384, 387, 388, 389, 395, 396, 401, 404], "cluster_id": [77, 89], "cluster_storag": [3, 4, 5, 8, 9, 10, 28, 31, 36, 37, 53, 62, 70, 76, 88, 198, 200, 203, 206, 232, 237, 240, 247, 252, 256, 258, 260, 261, 266, 268, 270, 275, 283, 291, 292, 294, 295, 298, 305, 306, 307, 317, 319, 322, 323, 325, 326, 330, 331, 362, 364, 366, 368, 369, 373, 374, 375, 377, 379, 381, 382, 384, 385, 387, 388, 389, 390, 395, 396, 397, 398, 400, 401, 404], "clusternam": [127, 130, 137, 142], "clusteronc": [112, 116], "cm": [382, 386], "cm_norm": [382, 386], "cmap": [4, 6, 9, 31, 32, 39, 60, 240, 245, 258, 260, 271, 285, 287, 292, 293, 295, 300, 306, 309, 323, 382, 386], "cnn": [258, 260, 362, 365, 368, 395, 396], "co": [181, 184, 369, 370, 371, 374, 388, 391], "coach": [332, 338], "coars": [10, 69, 252, 255], "cocki": [340, 346], "code": [0, 1, 2, 4, 5, 6, 8, 10, 11, 13, 22, 25, 26, 30, 32, 34, 36, 41, 51, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 84, 86, 87, 88, 89, 90, 91, 92, 96, 98, 101, 102, 163, 173, 178, 180, 183, 187, 193, 197, 198, 201, 204, 207, 208, 209, 211, 215, 221, 224, 232, 235, 252, 256, 257, 258, 259, 262, 263, 264, 265, 266, 267, 272, 284, 285, 289, 292, 293, 295, 306, 312, 313, 322, 326, 328, 330, 332, 338, 356, 358, 362, 363, 369, 370, 375, 376, 381, 382, 383, 384, 388, 389, 390, 394, 395, 396, 404], "coder": [181, 187], "cogent": [340, 343], "coher": [340, 346, 347], "coi": [340, 346], "col": [4, 5, 31, 32, 35, 258, 260, 271, 326, 329, 375, 379, 388, 392, 395, 402], "colbert": [332, 338], "cold": [164, 165, 171], "collabor": [81, 94, 95, 375, 376, 378, 381, 405], "collat": [5, 35, 326, 329, 348, 353], "collate_fn": [348, 353], "colleagu": [332, 338], "collect": [1, 2, 8, 9, 13, 16, 18, 51, 59, 64, 101, 103, 189, 191, 192, 209, 211, 214, 215, 217, 232, 235, 240, 244, 249, 258, 260, 267, 269, 271, 295, 321, 332, 338, 369, 373, 374, 382, 385, 386, 395, 400, 405], "collector": [258, 271], "collison": [332, 339], "colour": [340, 347], "column": [3, 5, 8, 9, 28, 35, 51, 54, 60, 74, 86, 203, 206, 232, 235, 238, 240, 245, 258, 270, 275, 326, 329, 332, 337, 340, 344, 347, 362, 364, 366, 368, 369, 373, 375, 377, 379, 381, 382, 384, 385, 388, 390, 392, 394, 395, 397, 398, 402, 404], "column_nam": [382, 385], "column_stack": [382, 385], "columnar": [7, 43, 225, 226, 258, 275, 362, 364, 382, 384, 388, 390, 395, 397], "com": [0, 11, 72, 77, 79, 82, 83, 84, 89, 91, 96, 99, 100, 101, 106, 108, 111, 112, 113, 119, 121, 122, 123, 127, 128, 137, 139, 147, 150, 152, 153, 154, 173, 178, 202, 207, 208, 292, 293, 305, 311, 313, 388, 390], "combin": [2, 7, 22, 43, 215, 221, 225, 226, 258, 268, 340, 346, 347, 362, 363], "combur": [332, 338], "comcast": [332, 338], "come": [2, 21, 75, 77, 84, 87, 89, 108, 110, 215, 220, 332, 338, 340, 343, 346, 347, 382, 387, 388, 394, 395, 404], "comedi": [340, 347], "comfort": [395, 404], "command": [74, 77, 78, 79, 86, 89, 90, 91, 98, 101, 104, 107, 112, 114, 115, 124, 126, 127, 129, 130, 131, 135, 137, 140, 142, 143, 148, 150, 153, 159, 162, 189, 192, 193, 197, 198, 201, 369, 374], "commend": [340, 343], "comment": [79, 83, 91, 100, 356, 360], "commerci": [7, 43, 45, 225, 226, 228], "commiss": [3, 8, 28, 51, 203, 206, 232, 235, 291, 298], "commit": [362, 364, 395, 397], "common": [1, 2, 3, 8, 9, 13, 25, 27, 51, 53, 59, 62, 137, 147, 150, 155, 181, 188, 189, 191, 198, 201, 203, 205, 209, 211, 215, 224, 232, 235, 237, 240, 244, 247, 332, 338, 340, 344, 346, 347], "common_prefix": [119, 123], "commonli": [7, 9, 43, 46, 58, 225, 226, 229, 240, 243, 375, 378], "commun": [2, 7, 8, 9, 25, 47, 54, 64, 101, 106, 164, 165, 168, 173, 179, 180, 181, 188, 215, 224, 225, 230, 232, 238, 240, 249, 294, 318, 388, 390], "compact": [10, 68, 252, 254, 362, 364, 368, 395, 396, 397], "compani": [81, 93, 108, 111], "compar": [6, 7, 41, 46, 75, 87, 164, 165, 167, 173, 175, 193, 194, 225, 229, 285, 289, 293, 294, 312, 315, 362, 368, 369, 374, 388, 392, 395, 402, 404], "comparison": [340, 347], "compat": [164, 165, 170, 173, 176, 181, 184, 198, 199, 258, 274, 395, 396], "compet": [7, 47, 225, 230], "competit": [332, 338], "compil": [11, 72, 207, 208, 333, 341, 349, 357], "complet": [2, 3, 4, 5, 11, 23, 28, 30, 32, 34, 72, 74, 77, 78, 82, 84, 86, 89, 90, 96, 108, 110, 112, 114, 127, 134, 137, 146, 164, 165, 167, 168, 171, 173, 174, 177, 178, 181, 184, 185, 186, 187, 188, 193, 197, 202, 203, 206, 207, 208, 215, 222, 258, 259, 269, 279, 280, 282, 284, 292, 305, 306, 326, 328, 340, 347, 348, 355, 362, 366, 367, 368, 369, 373, 374, 395, 402], "complex": [3, 7, 10, 28, 43, 46, 47, 48, 68, 84, 108, 110, 164, 165, 168, 170, 173, 175, 180, 181, 183, 187, 203, 206, 225, 226, 229, 230, 231, 252, 254, 295, 323, 362, 363], "compli": [5, 36, 326, 330], "complianc": [101, 104, 173, 178, 181, 188], "compliant": [101, 106], "compon": [1, 5, 6, 7, 10, 13, 36, 41, 43, 68, 75, 77, 87, 89, 101, 104, 106, 109, 136, 149, 150, 156, 164, 165, 169, 170, 172, 193, 195, 196, 202, 209, 211, 225, 226, 252, 254, 258, 260, 285, 289, 293, 312, 326, 330, 388, 390, 395, 397], "compos": [4, 5, 6, 9, 10, 29, 31, 32, 35, 38, 39, 41, 56, 61, 68, 69, 240, 241, 246, 252, 254, 255, 258, 260, 266, 276, 285, 286, 287, 289, 292, 293, 294, 300, 303, 309, 313, 317, 326, 329, 362, 364, 395, 397, 398, 404], "composit": [7, 48, 225, 231, 340, 347], "comprehens": [8, 9, 11, 51, 53, 57, 65, 72, 101, 105, 150, 151, 163, 164, 165, 166, 173, 179, 180, 181, 183, 184, 185, 186, 188, 202, 207, 208, 232, 235, 237, 240, 242, 250, 294, 316, 319], "compress": [382, 384, 388, 394], "comput": [1, 2, 3, 4, 5, 8, 9, 10, 13, 15, 16, 17, 18, 22, 25, 28, 30, 31, 32, 34, 36, 43, 45, 47, 54, 55, 57, 61, 63, 64, 66, 68, 73, 74, 77, 78, 79, 81, 82, 83, 84, 85, 86, 89, 90, 91, 94, 95, 96, 100, 101, 104, 106, 108, 110, 111, 112, 118, 122, 123, 126, 127, 129, 134, 137, 140, 146, 150, 153, 154, 155, 162, 163, 164, 165, 167, 168, 170, 171, 203, 206, 209, 211, 213, 214, 215, 216, 217, 221, 224, 226, 228, 230, 232, 238, 239, 240, 242, 246, 248, 249, 251, 252, 254, 258, 259, 261, 262, 273, 291, 294, 295, 296, 297, 298, 300, 302, 316, 317, 318, 321, 323, 326, 328, 330, 332, 334, 340, 344, 348, 350, 352, 353, 354, 356, 358, 364, 375, 376, 379, 381, 382, 385, 386, 387, 400, 404, 405], "computation": [6, 40, 285, 288, 293, 310], "compute_accuraci": [9, 64, 240, 249, 294, 318], "compute_config": [127, 134, 137, 146, 164, 165, 171, 173, 178, 193, 197], "compute_metr": [348, 352], "compute_nodes_service_account_email": [119, 123, 150, 154], "compute_tip_percentag": [8, 52, 232, 236], "computeconfig": [127, 134, 137, 146], "con": [332, 338], "conc": [119, 125], "concat_t": [382, 385], "concept": [7, 9, 45, 56, 108, 110, 163, 166, 198, 199, 225, 228, 240, 241, 258, 261, 308], "conceptu": [4, 31], "concern": [1, 10, 13, 69, 209, 211, 252, 255, 340, 346], "concert": [332, 338], "concis": [181, 184], "conclus": [182, 340, 342], "concomit": [332, 338], "concret": [101, 102], "concurr": [2, 3, 7, 8, 10, 22, 28, 48, 55, 62, 69, 164, 165, 168, 180, 203, 206, 215, 221, 225, 231, 232, 239, 247, 252, 255, 258, 262, 291, 294, 295, 298, 317, 322, 332, 334, 338, 340, 345, 388, 394, 395, 404], "concurrency_limit": [9, 61, 240, 246], "concuss": [332, 336, 338, 339], "conda": [189, 192], "condit": [2, 5, 18, 35, 101, 106, 181, 184, 215, 217, 326, 329, 340, 342, 362, 368], "conductor": [340, 347], "confid": [258, 278, 362, 368, 369, 374, 375, 381, 382, 387], "config": [3, 4, 5, 6, 10, 28, 32, 36, 41, 71, 119, 122, 150, 153, 189, 192, 198, 201, 203, 206, 252, 257, 258, 261, 262, 263, 264, 269, 273, 279, 282, 285, 289, 291, 292, 293, 295, 298, 302, 306, 311, 312, 313, 323, 326, 330, 348, 353, 362, 366, 369, 370, 373, 375, 379, 382, 385, 388, 392, 395, 397, 400], "configur": [6, 9, 10, 17, 35, 41, 57, 61, 69, 71, 73, 77, 78, 79, 82, 85, 89, 90, 91, 96, 98, 99, 101, 103, 104, 105, 106, 108, 109, 111, 112, 113, 114, 118, 121, 123, 127, 128, 129, 134, 137, 139, 140, 146, 152, 154, 155, 170, 172, 174, 180, 183, 188, 189, 192, 193, 197, 216, 240, 242, 246, 252, 255, 257, 259, 260, 261, 263, 278, 282, 284, 285, 289, 293, 295, 313, 321, 329, 348, 350, 351, 353, 354, 355, 356, 360, 362, 366, 369, 373, 375, 376, 379, 380, 383, 388, 389, 392, 395, 396, 400, 404], "configure_optim": [5, 35, 326, 329, 362, 365, 369, 372], "confirm": [79, 91, 181, 184, 258, 260, 269, 282, 362, 364, 366, 375, 377, 379, 382, 384, 387, 388, 390, 395, 397], "conflict": [258, 271], "confluent": [7, 46, 225, 229], "confus": [9, 61, 240, 246, 395, 404], "confusion_matrix": [382, 384, 386], "congratul": [173, 180, 181, 188], "congress": [332, 338], "conjur": [340, 347], "connect": [2, 4, 5, 9, 19, 30, 34, 58, 73, 74, 76, 81, 85, 86, 88, 94, 101, 106, 108, 111, 112, 118, 127, 130, 137, 142, 150, 156, 215, 218, 240, 243, 258, 259, 277, 326, 328, 332, 336, 340, 347, 382, 386], "connector": [8, 9, 55, 58, 232, 239, 240, 243], "consecut": [332, 336, 338], "consid": [1, 2, 4, 5, 16, 18, 20, 21, 22, 24, 32, 36, 67, 173, 180, 181, 187, 198, 199, 209, 214, 215, 217, 219, 220, 221, 223, 253, 292, 301, 326, 330, 340, 343, 345, 346, 362, 364], "consider": [84, 108, 110], "consist": [6, 7, 39, 43, 73, 75, 85, 87, 163, 181, 183, 185, 188, 225, 226, 258, 259, 260, 261, 272, 285, 287, 293, 294, 309, 316, 333, 341, 349, 357, 369, 374, 382, 385, 387, 388, 390, 391], "consol": [74, 78, 79, 86, 90, 91, 98, 112, 115, 116, 119, 124, 125, 127, 131, 134, 137, 143, 146, 147, 150, 159, 161, 181, 188, 189, 191, 198, 199, 202, 375, 379], "conspicu": [332, 338], "constant": [5, 35, 164, 165, 168, 326, 329, 340, 347, 388, 394], "constraint": [5, 35, 164, 165, 169, 181, 187, 326, 329, 332, 339, 340, 347], "construct": [2, 5, 25, 35, 215, 224, 258, 265, 266, 326, 329, 369, 370, 388, 392, 395, 398, 399], "constructor": [2, 9, 10, 25, 62, 70, 215, 224, 240, 247, 252, 256, 294, 295, 317, 322, 332, 334], "consum": [6, 8, 9, 41, 51, 53, 58, 60, 112, 114, 127, 129, 137, 140, 232, 235, 237, 240, 243, 245, 258, 272, 277, 284, 285, 289, 293, 294, 312, 317, 388, 390], "consumptionapi": [9, 60, 64, 240, 245, 249], "contain": [0, 2, 3, 4, 5, 9, 19, 28, 32, 36, 59, 73, 74, 76, 79, 85, 86, 88, 91, 108, 110, 111, 127, 135, 137, 148, 150, 153, 156, 181, 186, 203, 206, 215, 218, 240, 244, 258, 261, 270, 282, 291, 292, 294, 298, 306, 316, 326, 330, 340, 347, 375, 377, 382, 384, 385, 388, 390, 394, 395, 396, 402, 405], "container": [10, 68, 163, 252, 254], "containerfil": [164, 165, 171, 173, 178], "content": [9, 61, 76, 84, 88, 164, 165, 171, 173, 177, 178, 181, 184, 185, 186, 202, 240, 246, 375, 381, 395, 404], "context": [167, 169, 173, 176, 179, 193, 195, 197, 362, 366, 369, 373, 375, 381, 388, 389, 395, 396], "contextu": [189, 191, 193, 196, 197], "contigu": [9, 59, 240, 244, 375, 376, 377], "continu": [4, 7, 32, 48, 73, 76, 85, 88, 170, 172, 181, 187, 193, 197, 225, 231, 258, 279, 280, 281, 282, 292, 304, 332, 338, 340, 347, 362, 364, 369, 374, 375, 380, 395, 397, 400, 402, 403], "contrast": [7, 46, 47, 225, 229, 230, 340, 346, 347], "control": [3, 7, 8, 28, 43, 52, 75, 80, 81, 84, 87, 92, 94, 103, 104, 105, 109, 111, 135, 136, 148, 149, 164, 165, 169, 171, 181, 184, 193, 197, 198, 201, 203, 206, 225, 226, 232, 236, 258, 262, 274, 295, 323, 332, 334, 338, 369, 370, 374, 375, 376, 382, 385, 395, 396], "controversi": [340, 343], "conv1": [4, 6, 31, 40, 41, 258, 261, 285, 288, 289, 292, 293, 300, 306, 310, 313], "conv2": [292, 300, 306], "conv2d": [4, 6, 31, 40, 41, 258, 261, 285, 288, 289, 292, 293, 300, 306, 310, 313, 362, 365], "convei": [340, 347], "conveni": [3, 4, 11, 27, 31, 72, 203, 205, 207, 208, 258, 260], "convent": [258, 259, 340, 347], "converg": [362, 366, 368, 369, 373, 375, 379, 388, 392, 395, 402], "convers": [181, 184, 186, 187, 258, 276], "convert": [2, 5, 8, 25, 35, 52, 164, 165, 167, 215, 224, 232, 236, 258, 266, 271, 274, 275, 276, 292, 304, 326, 329, 332, 336, 339, 342, 348, 353, 356, 360, 362, 364, 366, 375, 376, 377, 382, 383, 385, 388, 390, 395, 397, 398, 404], "convnext": [395, 404], "convolut": [258, 261, 362, 363], "cool": [340, 347], "coordin": [101, 106, 362, 363, 369, 370, 382, 383, 385, 395, 396, 404], "cop": [82, 83, 96, 99], "copi": [2, 4, 7, 18, 32, 43, 74, 75, 78, 79, 82, 86, 87, 90, 91, 98, 198, 200, 215, 217, 225, 226, 258, 259, 266, 332, 338, 375, 377, 379, 382, 385, 388, 392, 394, 395, 402, 404], "cor": [101, 106, 137, 147], "core": [3, 5, 6, 9, 10, 13, 22, 27, 35, 40, 41, 57, 68, 77, 89, 203, 205, 211, 221, 240, 242, 252, 254, 258, 260, 285, 288, 289, 291, 293, 297, 310, 312, 326, 329, 332, 336, 362, 363, 364, 366, 368, 369, 374, 375, 376, 379, 382, 385, 395, 396, 397], "corner": [74, 86, 332, 338], "correct": [4, 7, 32, 48, 193, 197, 225, 231, 258, 261, 262, 265, 266, 268, 273, 279, 280, 292, 302, 303, 332, 338, 375, 380, 382, 383, 386, 387, 388, 390, 395, 396, 399, 400], "correct_squar": [2, 20, 215, 219], "correct_square_mod": [2, 20, 215, 219], "correctli": [11, 72, 81, 93, 137, 147, 207, 208, 258, 260, 269, 271, 282, 362, 364, 375, 377, 379, 382, 384, 388, 390, 395, 397, 398], "correl": [6, 41, 285, 289, 293, 311], "correspond": [1, 7, 15, 48, 209, 213, 225, 231, 258, 270, 292, 300, 375, 378], "corrupt": [362, 363, 364], "cost": [1, 4, 5, 7, 13, 32, 37, 43, 45, 47, 75, 77, 78, 79, 87, 89, 90, 91, 168, 170, 171, 172, 173, 175, 180, 184, 193, 197, 209, 211, 225, 226, 228, 230, 292, 307, 326, 331, 369, 374], "costum": [332, 336, 338], "could": [2, 8, 20, 24, 54, 164, 165, 169, 215, 219, 223, 232, 238, 332, 337, 338, 340, 346, 347, 356, 358], "couldn": [332, 338], "count": [1, 8, 9, 13, 54, 55, 64, 189, 191, 209, 211, 232, 238, 239, 240, 249, 294, 318, 340, 347, 362, 364, 369, 371, 375, 377, 379, 382, 384, 386, 389], "countri": [181, 186, 332, 338, 340, 343, 375, 381], "countrymen": [340, 343], "coup": [181, 185], "coupl": [340, 347], "cours": [101, 104, 163, 181, 188, 189, 191, 192, 198, 199, 340, 346, 347, 405], "cover": [73, 74, 75, 77, 84, 85, 86, 87, 89, 101, 104, 164, 165, 172, 173, 174, 180, 188, 189, 190, 191, 332, 333, 339, 340, 341, 347, 348, 349, 355, 357, 386, 387], "cover_typ": [382, 384], "covtyp": [382, 384, 385, 387], "covtype_xgb_cpu": [382, 385], "coward": [340, 347], "cp": [9, 10, 62, 70, 240, 247, 252, 256, 294, 295, 317, 322], "cpu": [2, 3, 4, 5, 6, 8, 9, 10, 22, 23, 25, 28, 31, 32, 35, 36, 40, 41, 53, 55, 57, 59, 61, 62, 70, 71, 73, 75, 77, 85, 87, 89, 189, 191, 192, 193, 195, 203, 206, 215, 221, 222, 224, 232, 237, 239, 240, 242, 244, 246, 247, 252, 256, 257, 258, 261, 264, 265, 266, 268, 269, 271, 272, 277, 284, 285, 288, 289, 291, 292, 293, 294, 295, 296, 298, 302, 305, 306, 311, 312, 313, 315, 316, 317, 322, 323, 326, 329, 330, 332, 334, 337, 338, 339, 340, 342, 348, 350, 353, 354, 355, 362, 368, 369, 370, 374, 375, 379, 381, 383, 384, 385, 387, 388, 392, 394, 395, 400, 404], "cpus_per_work": [382, 385], "craft": [340, 346, 347], "crappi": [340, 343], "crash": [7, 46, 225, 229, 258, 281, 332, 336, 338, 339, 382, 383, 395, 403], "crazi": [332, 336, 338, 340, 347], "cream": [332, 338], "creat": [2, 3, 6, 7, 8, 9, 12, 16, 18, 25, 27, 28, 32, 41, 44, 45, 50, 52, 58, 73, 74, 76, 77, 79, 80, 81, 83, 85, 86, 88, 89, 91, 92, 94, 99, 103, 104, 105, 107, 108, 110, 111, 115, 116, 118, 120, 121, 124, 125, 126, 130, 131, 132, 134, 136, 141, 142, 143, 144, 146, 149, 152, 156, 157, 159, 160, 161, 162, 164, 165, 168, 171, 173, 176, 177, 178, 180, 181, 184, 185, 186, 188, 189, 192, 193, 197, 203, 205, 206, 210, 214, 215, 217, 224, 225, 227, 228, 232, 234, 236, 240, 243, 260, 268, 271, 274, 275, 282, 284, 285, 289, 291, 292, 293, 294, 295, 298, 302, 304, 305, 311, 312, 316, 322, 325, 333, 334, 336, 337, 341, 342, 349, 356, 357, 358, 359, 360, 362, 364, 376, 382, 387, 388, 389, 395, 396, 398, 399, 404], "create_us": 202, "creation": [2, 18, 163, 215, 217], "cred": [332, 336, 338], "credenti": [112, 113, 119, 122, 127, 128, 137, 139, 150, 153, 156], "credit": [8, 51, 232, 235, 340, 347], "creepi": [340, 347], "creepybr": [340, 347], "creighton": [332, 338], "crime": [340, 347], "criteria": [9, 10, 57, 68, 164, 165, 167, 240, 242, 252, 254], "criterion": [4, 6, 31, 32, 40, 41, 258, 262, 273, 279, 285, 288, 289, 293, 310, 313, 395, 400], "critic": [7, 48, 76, 88, 225, 231, 332, 338], "crop": [362, 364, 395, 396, 397], "cross": [101, 105, 106, 108, 110, 137, 147, 258, 260, 388, 390, 395, 396], "cross_attention_dim": [5, 35, 326, 329], "crossattndownblock2d": [5, 35, 326, 329], "crossattnupblock2d": [5, 35, 326, 329], "crossentropyloss": [4, 6, 29, 31, 32, 38, 40, 41, 258, 260, 262, 273, 279, 285, 286, 288, 289, 292, 293, 300, 302, 306, 310, 313, 395, 400], "crouch": [340, 347], "crow": [340, 346], "crucial": [181, 187, 340, 342, 348, 353], "crush": [332, 338], "cry": [340, 343], "css": 0, "csv": [4, 7, 9, 29, 31, 43, 59, 76, 88, 225, 226, 240, 244, 258, 260, 272, 292, 300, 375, 377, 381, 382, 387, 388, 389, 390, 395, 402, 404], "csv_path": [388, 390], "ctor": [395, 404], "ctrl": [11, 72, 207, 208], "cu128": [164, 165, 171, 173, 178, 193, 197], "cub": [332, 338], "cuda": [4, 6, 9, 31, 32, 40, 62, 164, 165, 170, 240, 247, 258, 262, 264, 265, 268, 269, 271, 273, 285, 288, 292, 293, 294, 295, 300, 303, 310, 313, 317, 322, 332, 337, 338, 348, 353, 362, 368, 369, 374, 388, 394, 395, 404], "cultur": [340, 343], "cumprod": [5, 35, 326, 329], "cumul": [375, 381], "cup": [340, 347], "cure": [340, 347], "curiou": [258, 284, 340, 343], "curl": [11, 72, 202, 207, 208], "current": [2, 4, 7, 8, 22, 31, 47, 54, 79, 83, 91, 100, 127, 130, 137, 142, 150, 153, 181, 186, 198, 200, 215, 221, 225, 230, 232, 238, 258, 267, 268, 274, 280, 291, 292, 293, 295, 298, 305, 311, 313, 323, 348, 355, 362, 366, 369, 370, 373, 375, 377], "current_training_step": [5, 35, 326, 329], "curti": [332, 336, 338, 339], "curv": [258, 260, 270, 365, 388, 392, 396, 397], "custom": [2, 3, 5, 10, 21, 22, 27, 35, 61, 68, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 94, 100, 104, 105, 108, 110, 111, 112, 113, 119, 120, 123, 127, 128, 137, 138, 150, 151, 164, 165, 171, 173, 178, 180, 181, 184, 188, 193, 195, 198, 201, 203, 205, 215, 220, 221, 246, 252, 254, 257, 258, 261, 291, 297, 326, 329, 340, 342, 343, 347, 362, 363, 375, 376, 379, 382, 383, 387, 396, 404], "custom_hid": 0, "custom_light": 0, "custom_nam": [181, 184], "customer_ingress_cidr_rang": [101, 106], "cut": [4, 5, 32, 37, 292, 307, 326, 331, 388, 390], "cv": [181, 184], "cv_job_match": [181, 184], "cybersecur": [181, 184], "d": [8, 9, 51, 52, 54, 59, 60, 61, 193, 197, 198, 200, 202, 232, 235, 236, 238, 240, 244, 245, 246, 294, 295, 316, 317, 322, 323, 332, 336, 338, 339, 340, 346, 347, 362, 364, 366, 369, 371, 373, 374, 375, 376, 381, 382, 385, 386, 388, 390, 394, 395, 397, 404], "d3a9a7d0": [119, 123, 150, 154], "d89d0_00000": [292, 306], "d_": [4, 31, 292, 300], "d_model": [388, 391, 392, 394], "da": [332, 338], "dag": [7, 45, 48, 225, 228, 231], "dai": [181, 186, 332, 338, 340, 347], "daili": [382, 387], "dalla": [332, 338], "damn": [332, 338], "dancer": [340, 347], "daniel": [332, 338, 340, 346], "dark": [202, 340, 346, 347], "darwin": [332, 338], "dash": [340, 347], "dashboard": [4, 5, 7, 11, 30, 34, 44, 46, 72, 74, 79, 83, 86, 91, 99, 108, 111, 173, 179, 180, 189, 191, 192, 193, 195, 196, 197, 199, 201, 207, 208, 225, 227, 229, 258, 259, 284, 295, 323, 326, 328, 369, 374], "dask": [7, 46, 47, 225, 229, 230], "data": [1, 10, 13, 17, 18, 31, 33, 35, 37, 38, 41, 42, 45, 46, 60, 62, 68, 69, 74, 75, 76, 84, 86, 87, 88, 101, 105, 106, 127, 135, 137, 148, 165, 171, 181, 185, 186, 187, 188, 189, 191, 193, 197, 199, 202, 209, 211, 216, 217, 228, 229, 245, 247, 252, 254, 255, 260, 262, 264, 266, 279, 283, 286, 289, 290, 291, 295, 298, 302, 303, 305, 307, 308, 311, 313, 322, 323, 327, 329, 331, 336, 337, 339, 343, 344, 347, 348, 350, 351, 353, 355, 363, 366, 368, 369, 370, 371, 373, 374, 376, 379, 381, 383, 384, 385, 387, 389, 390, 392, 396, 397, 398], "data_dir": [388, 390, 392, 394], "data_load": [4, 5, 6, 31, 32, 35, 39, 40, 41, 258, 262, 273, 274, 279, 285, 287, 288, 289, 292, 293, 300, 302, 306, 309, 310, 313, 326, 329], "data_path": [8, 51, 54, 232, 235, 238], "data_url": [375, 377], "databas": [9, 58, 181, 183, 186, 202, 240, 243], "databaseservic": [198, 201, 202], "databrick": [7, 9, 43, 59, 225, 226, 240, 244], "datadog": [189, 191], "datafram": [3, 7, 8, 28, 46, 52, 203, 206, 225, 229, 232, 236, 259, 260, 275, 291, 298, 342, 362, 364, 366, 375, 377, 379, 381, 382, 386, 387, 388, 390, 395, 404], "dataload": [6, 32, 33, 36, 38, 39, 41, 260, 262, 268, 272, 273, 276, 285, 286, 287, 289, 292, 293, 300, 303, 309, 313, 327, 330, 351, 362, 364, 369, 371, 392, 396, 397, 400], "dataset": [3, 5, 6, 7, 9, 28, 29, 33, 35, 36, 38, 39, 40, 41, 43, 44, 45, 50, 52, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 76, 88, 198, 200, 203, 206, 225, 226, 227, 228, 234, 236, 238, 239, 240, 242, 243, 244, 245, 246, 248, 249, 250, 259, 261, 263, 266, 268, 271, 272, 273, 274, 276, 277, 280, 282, 283, 284, 285, 286, 287, 288, 289, 293, 295, 299, 300, 301, 305, 306, 309, 310, 311, 313, 315, 317, 318, 319, 322, 326, 327, 329, 330, 334, 335, 337, 338, 342, 347, 348, 350, 351, 353, 354, 355, 362, 363, 364, 366, 368, 373, 374, 376, 379, 381, 383, 385, 387, 389, 392, 394, 395, 396, 397, 398, 399, 404], "dataset_": [198, 200], "dataset_iter": [258, 274], "dataset_uri": [375, 377], "datasourc": [8, 9, 53, 59, 232, 237, 240, 244, 294, 316], "date": [181, 186, 292, 306, 332, 338], "datetim": [4, 29, 31, 258, 260, 292, 300, 388, 390], "david": [202, 332, 336, 338], "dawson": [340, 346], "day_of_week": [291, 298], "db": 202, "ddim": [362, 368], "ddp": [4, 5, 32, 36, 260, 261, 264, 265, 268, 269, 280, 284, 326, 330, 362, 366, 375, 377, 378, 381, 388, 389, 392, 394, 395, 400, 404], "ddpmschedul": [5, 33, 35, 326, 327, 329], "ddpstrategi": [5, 35, 326, 329], "de": [2, 18, 215, 217, 332, 338, 365, 368, 369, 370, 374, 388, 394], "deactiv": [11, 72, 207, 208], "dead": [340, 347], "deadlock": [2, 23, 215, 222], "deal": [7, 48, 225, 231], "dear": [332, 338], "debat": [332, 338], "debug": [7, 10, 46, 71, 74, 80, 84, 86, 92, 181, 188, 189, 191, 192, 193, 195, 197, 198, 199, 201, 225, 229, 252, 257, 258, 260, 267, 271, 362, 363], "debut": [332, 338], "decemb": [332, 338], "decid": [1, 6, 13, 41, 181, 186, 209, 211, 258, 261, 269, 285, 289, 293, 294, 312, 317, 332, 338, 340, 347, 369, 370, 388, 392], "decis": [108, 110, 382, 383, 384], "declar": [258, 264, 362, 363, 369, 370, 375, 376, 382, 383, 395, 396], "decod": [172, 363, 368, 388, 389, 390, 391, 392, 394], "decode_and_norm": [362, 364], "decoder_input": [388, 391, 392], "decor": [1, 2, 9, 10, 14, 22, 25, 60, 64, 70, 209, 212, 215, 221, 224, 240, 245, 249, 252, 256, 295, 322, 323, 356, 360], "decoupl": [10, 71, 252, 257, 258, 284], "decreas": [258, 270, 388, 392, 395, 402], "dedic": [6, 41, 78, 79, 82, 83, 90, 91, 96, 99, 173, 178, 181, 187, 189, 192, 258, 271, 285, 289, 293, 313, 340, 347], "dedupl": [293, 313, 348, 355], "deep": [8, 51, 173, 179, 232, 235, 258, 260, 332, 334, 340, 347, 348, 350, 351, 354, 355, 375, 377, 381, 395, 397], "deeper": [7, 44, 164, 165, 172, 181, 183, 188, 225, 227, 308], "deepli": [193, 197], "deepseek": [181, 187], "deepspe": [4, 5, 32, 37, 258, 284, 292, 307, 326, 331], "def": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 31, 32, 35, 36, 39, 40, 41, 52, 61, 62, 64, 70, 72, 74, 77, 78, 82, 86, 89, 90, 97, 181, 186, 193, 197, 198, 200, 201, 203, 206, 207, 208, 209, 212, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 232, 236, 240, 246, 247, 249, 252, 256, 258, 261, 262, 265, 266, 267, 268, 271, 273, 274, 276, 279, 280, 285, 287, 288, 289, 291, 292, 293, 294, 295, 298, 300, 302, 303, 304, 306, 309, 310, 311, 312, 313, 317, 318, 322, 323, 326, 329, 330, 332, 337, 340, 347, 348, 352, 353, 354, 356, 360, 362, 364, 365, 366, 368, 369, 371, 372, 373, 374, 375, 377, 378, 379, 382, 385, 386, 388, 390, 391, 392, 394, 395, 398, 399, 400, 404], "default": [0, 2, 4, 5, 6, 8, 9, 10, 20, 22, 31, 35, 41, 51, 52, 59, 61, 71, 73, 75, 76, 77, 79, 80, 85, 87, 88, 89, 91, 92, 112, 114, 119, 122, 123, 127, 129, 137, 140, 150, 153, 181, 186, 193, 197, 198, 201, 215, 219, 221, 232, 235, 236, 240, 244, 246, 252, 257, 258, 261, 279, 285, 289, 291, 298, 313, 326, 329, 340, 345, 348, 355, 362, 364, 366, 382, 384, 388, 389, 395, 404], "default_cluster_storag": [198, 200], "default_data_col": [348, 353], "default_root_dir": [5, 35, 326, 329, 362, 366, 369, 373], "default_tracing_servic": 202, "defens": [332, 338, 388, 392], "defin": [1, 2, 3, 4, 6, 9, 10, 16, 20, 22, 25, 28, 31, 32, 41, 61, 70, 71, 73, 75, 78, 79, 82, 83, 85, 87, 90, 91, 98, 100, 103, 127, 134, 137, 146, 150, 153, 164, 165, 168, 173, 176, 181, 185, 187, 193, 195, 203, 206, 209, 214, 215, 219, 221, 224, 240, 246, 252, 256, 257, 259, 264, 265, 266, 268, 271, 272, 277, 285, 289, 291, 293, 298, 311, 313, 332, 334, 338, 339, 340, 347, 348, 350, 353, 354, 356, 360, 362, 364, 366, 377, 383, 386, 387, 388, 389, 390, 394, 395, 398, 399, 400, 404], "definit": [75, 87, 181, 185, 186, 369, 371], "degre": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318], "del": [258, 271], "delai": [295, 323, 340, 346], "deleg": [3, 28, 203, 206], "delet": [4, 31, 76, 88, 101, 106, 112, 114, 117, 119, 126, 127, 129, 135, 137, 140, 148, 150, 162, 258, 260, 283, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "delete_object": [76, 88], "deleteobject": [101, 106], "delhi": [332, 338], "deliv": [193, 197, 340, 346], "deloy": [79, 91], "delta": [7, 43, 164, 165, 171, 173, 177, 178, 181, 184, 225, 226, 382, 387], "demand": [11, 72, 73, 75, 79, 83, 85, 87, 91, 99, 108, 109, 111, 207, 208, 295, 321, 362, 368, 390], "demo": [101, 104, 258, 262, 362, 368, 369, 374, 375, 381], "demonstr": [5, 33, 76, 88, 104, 173, 174, 181, 183, 193, 197, 198, 199, 200, 202, 258, 271, 326, 327, 332, 339, 340, 344, 346, 347, 348, 350, 355, 362, 364, 367, 369, 373, 375, 377, 380, 381, 388, 393, 396, 397], "denizen": [340, 343], "denni": [332, 338], "deped": [75, 87], "depend": [0, 7, 9, 17, 23, 45, 46, 47, 61, 73, 74, 75, 84, 85, 86, 87, 101, 106, 112, 114, 127, 129, 137, 140, 157, 164, 165, 167, 169, 202, 216, 222, 225, 228, 229, 230, 240, 246, 258, 272, 333, 341, 348, 349, 350, 357, 362, 364, 369, 371, 375, 377, 382, 384, 388, 389, 390, 395, 397], "depict": [340, 347], "deploi": [3, 10, 28, 67, 71, 75, 79, 87, 91, 101, 103, 104, 105, 106, 114, 123, 129, 140, 163, 164, 165, 166, 167, 169, 170, 171, 172, 175, 177, 180, 182, 183, 185, 186, 188, 198, 201, 202, 203, 206, 252, 253, 257, 291, 295, 298, 320, 321, 334, 358, 361, 369, 374, 382, 387, 388, 394, 405], "deploy": [0, 3, 7, 28, 48, 70, 71, 79, 80, 83, 91, 92, 99, 100, 102, 103, 106, 107, 110, 112, 114, 119, 120, 122, 123, 127, 129, 131, 132, 137, 140, 143, 144, 147, 150, 153, 154, 159, 160, 169, 170, 172, 174, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 193, 196, 198, 201, 203, 206, 225, 231, 256, 257, 291, 298, 322, 324, 358, 375, 381, 388, 394, 395, 404], "deployment_config": [164, 165, 171, 173, 176, 179, 181, 186], "deploymenthandl": [356, 360], "deploymentrespons": [295, 323], "depress": [340, 343], "depth": [292, 304], "deriv": [375, 379], "derp": [112, 114, 127, 129, 137, 140], "desc": [4, 31, 395, 397], "descent": [340, 347], "describ": [112, 114, 127, 129, 137, 140, 141, 340, 347, 369, 370], "descript": [8, 11, 51, 72, 101, 105, 106, 164, 165, 169, 184, 186, 207, 208, 232, 235, 369, 371], "deseri": [1, 7, 13, 46, 209, 211, 225, 229], "design": [1, 7, 8, 9, 11, 13, 43, 46, 47, 50, 53, 60, 72, 163, 164, 165, 168, 181, 184, 188, 207, 208, 209, 211, 225, 226, 229, 230, 232, 234, 237, 240, 245, 295, 321, 323, 340, 347, 348, 350, 354, 355, 356, 358, 382, 385, 388, 389, 395, 400], "desir": [292, 301, 395, 404], "desktop": [74, 86], "despit": [340, 347], "destin": [181, 184], "destroi": [112, 114, 117, 119, 126, 127, 135, 137, 148, 150, 162, 332, 338, 340, 347], "destruct": [340, 347], "detach": [258, 271, 388, 394], "detail": [2, 4, 5, 6, 8, 9, 10, 22, 30, 32, 34, 36, 39, 54, 57, 68, 71, 76, 77, 81, 88, 89, 94, 101, 104, 106, 108, 109, 119, 123, 127, 129, 137, 140, 150, 154, 173, 179, 181, 184, 200, 201, 202, 215, 221, 232, 238, 240, 242, 252, 254, 257, 258, 259, 264, 268, 272, 273, 285, 287, 292, 293, 295, 302, 305, 311, 322, 326, 328, 330, 333, 340, 341, 347, 349, 356, 357, 360, 405], "detailsbr": [340, 347], "detect": [7, 46, 181, 184, 193, 197, 225, 229, 258, 282, 332, 337, 362, 367, 395, 402], "determin": [9, 60, 164, 165, 167, 240, 245, 340, 345], "determinist": [382, 384], "determint": [9, 64, 240, 249], "dev": [112, 114, 127, 129, 137, 140, 369, 370], "deval": [382, 385], "develop": [1, 3, 7, 8, 13, 27, 46, 47, 48, 54, 67, 68, 73, 76, 77, 78, 79, 81, 82, 85, 88, 89, 90, 91, 94, 96, 112, 113, 114, 119, 121, 127, 128, 129, 137, 139, 140, 150, 152, 173, 174, 189, 191, 198, 201, 203, 205, 209, 211, 225, 229, 230, 231, 232, 238, 253, 254, 291, 295, 297, 298, 321, 324, 332, 338, 348, 354, 395, 396], "deviat": [395, 398], "devic": [1, 4, 5, 6, 9, 10, 13, 31, 32, 35, 36, 40, 41, 62, 70, 71, 108, 111, 135, 136, 148, 149, 164, 165, 171, 209, 211, 240, 247, 252, 256, 257, 258, 261, 262, 264, 265, 266, 268, 269, 271, 273, 274, 285, 288, 289, 292, 300, 302, 303, 306, 326, 329, 330, 332, 334, 338, 348, 350, 353, 362, 365, 366, 368, 369, 370, 373, 374, 388, 392, 394, 395, 396, 399, 400, 404], "devop": [84, 163], "df": [3, 5, 8, 28, 35, 51, 52, 53, 54, 203, 206, 232, 235, 236, 237, 238, 258, 275, 326, 329, 362, 366, 369, 373, 375, 377, 379, 381, 382, 384, 386, 387, 388, 390, 392, 395, 398, 402], "di": [2, 20, 215, 219, 340, 346], "diagnos": [189, 191], "diagnost": [388, 392], "diagon": [382, 386], "diagram": [3, 5, 6, 7, 28, 35, 36, 41, 46, 48, 84, 101, 105, 108, 110, 164, 165, 170, 203, 206, 225, 229, 231, 258, 259, 268, 285, 289, 292, 293, 300, 301, 312, 326, 329, 330, 348, 350], "diari": [332, 338], "dict": [2, 3, 4, 5, 6, 9, 10, 19, 28, 31, 32, 35, 36, 41, 61, 62, 64, 70, 164, 165, 171, 173, 176, 179, 181, 184, 186, 193, 197, 203, 206, 215, 218, 240, 246, 247, 249, 252, 256, 258, 262, 268, 273, 274, 276, 277, 279, 280, 284, 285, 289, 291, 292, 293, 294, 295, 298, 300, 302, 304, 311, 317, 318, 322, 323, 326, 329, 330, 332, 335, 337, 348, 351, 353, 362, 364, 369, 371, 388, 394], "dictat": [340, 347], "dictionari": [2, 3, 6, 22, 28, 41, 203, 206, 215, 221, 258, 263, 267, 273, 274, 285, 289, 293, 311, 313, 348, 353, 375, 379], "did": [2, 20, 215, 219, 332, 338, 340, 346, 347, 362, 366, 368, 369, 373, 374], "didn": [332, 338], "diego": [332, 338], "differ": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 16, 28, 30, 34, 41, 45, 54, 61, 64, 69, 72, 74, 76, 86, 88, 101, 102, 104, 106, 108, 110, 150, 155, 163, 164, 165, 167, 168, 169, 175, 181, 183, 184, 189, 192, 193, 196, 198, 199, 201, 203, 206, 207, 208, 209, 214, 225, 228, 232, 238, 240, 246, 249, 252, 255, 258, 259, 262, 264, 272, 273, 274, 285, 289, 291, 293, 294, 298, 311, 312, 318, 326, 328, 332, 334, 338, 340, 343, 348, 353, 354, 362, 368, 369, 374, 382, 385, 388, 392, 395, 396, 404], "differenti": [382, 383], "difficult": [7, 46, 193, 197, 225, 229], "diffus": [4, 32, 33, 36, 37, 292, 307, 327, 330, 331, 366, 371, 373], "diffusionpolici": [373, 374], "digit": [6, 10, 39, 40, 70, 252, 256, 261, 275, 285, 287, 288, 293, 309, 310], "dii": [164, 165, 169], "dilat": [292, 300, 306], "dim": [258, 271, 362, 365, 369, 370, 372, 375, 378, 395, 400, 404], "dimens": [258, 271, 375, 376, 379, 388, 390], "dimension": [382, 383, 384], "dinger": [332, 338], "dir": [75, 76, 77, 87, 88, 89, 258, 260, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397, 400, 404], "direct": [6, 41, 101, 106, 108, 110, 181, 187, 285, 289, 293, 311, 340, 347, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "directli": [2, 7, 18, 19, 43, 74, 77, 81, 86, 89, 94, 101, 106, 108, 110, 111, 181, 185, 215, 217, 218, 225, 226, 258, 272, 362, 363, 366, 369, 370, 374, 375, 376, 377, 379, 382, 384, 385, 388, 389, 395, 396, 402], "director": [340, 346, 347], "directori": [0, 4, 8, 31, 53, 74, 76, 79, 83, 86, 88, 91, 100, 127, 130, 137, 142, 202, 232, 237, 258, 260, 268, 271, 283, 362, 368, 375, 377, 381, 382, 383, 387, 388, 390, 394, 395, 400, 404], "dirpath": [362, 366, 369, 373], "disabl": [5, 36, 258, 271, 292, 293, 295, 305, 311, 313, 322, 326, 330, 348, 355], "disaggreg": [9, 66, 240, 251], "disappoint": [332, 336, 338], "discern": [340, 343], "disconnect": [375, 379], "discontinu": [369, 370], "discount": [375, 381], "discov": [340, 347], "discret": [7, 46, 225, 229], "discuss": [6, 40, 41, 285, 288, 289, 291, 293, 296, 312], "disengag": [8, 51, 232, 235], "disjoint": [258, 262, 340, 346, 347], "disk": [4, 9, 31, 57, 63, 76, 77, 88, 89, 189, 191, 193, 195, 198, 200, 201, 240, 242, 248, 258, 260, 275, 280, 294, 317, 362, 368, 375, 381, 382, 387, 388, 394, 395, 404], "dismiss": [332, 338], "displai": [4, 11, 31, 72, 78, 90, 101, 106, 173, 176, 198, 201, 207, 208, 258, 260, 270, 271, 282, 292, 300, 340, 343, 347, 366, 395, 402], "disrupt": [340, 346], "dist": [258, 277], "dist_val_acc": [395, 400], "distanc": [3, 6, 8, 28, 41, 51, 54, 203, 206, 232, 235, 238, 285, 289, 291, 293, 298, 311, 362, 368, 382, 387], "distil": [164, 165, 168, 388, 394], "distilbert": [356, 360], "distinct": [108, 110, 164, 165, 167, 193, 196, 258, 261, 375, 377], "distract": [340, 347], "distribut": [1, 2, 6, 8, 9, 11, 13, 17, 18, 23, 26, 27, 29, 30, 33, 34, 40, 43, 47, 48, 49, 50, 51, 53, 55, 56, 57, 59, 60, 63, 72, 75, 77, 84, 87, 89, 101, 106, 164, 165, 169, 170, 173, 179, 180, 202, 204, 205, 207, 208, 209, 211, 215, 216, 217, 222, 226, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 244, 245, 248, 260, 261, 262, 264, 266, 269, 270, 272, 275, 276, 277, 284, 285, 288, 291, 293, 294, 296, 297, 299, 302, 306, 310, 314, 315, 317, 327, 328, 332, 339, 340, 342, 344, 347, 351, 353, 354, 355, 356, 358, 364, 368, 370, 371, 374, 377, 381, 384, 387, 390, 392, 397, 400, 404], "distributeddataparallel": [4, 5, 32, 36, 258, 259, 262, 265, 268, 269, 292, 303, 304, 326, 330, 375, 378], "distributedsampl": [4, 32, 258, 262, 266, 268, 292, 303, 395, 399, 400], "div_term": [388, 391], "dive": [84, 164, 165, 172, 181, 182, 183, 188, 308, 388, 390], "divers": [7, 43, 46, 225, 226, 229], "divid": [7, 46, 101, 106, 225, 229], "dl_dw": [6, 41, 285, 289, 293, 312], "dmatrix": [3, 28, 203, 206, 291, 298, 382, 384, 385, 386], "dn": [108, 110], "do": [2, 3, 6, 8, 19, 22, 26, 40, 52, 53, 54, 74, 76, 86, 88, 119, 121, 150, 152, 181, 184, 186, 203, 204, 215, 218, 221, 232, 236, 237, 238, 285, 288, 291, 292, 293, 296, 304, 310, 332, 334, 338, 340, 343, 346, 347], "doc": [4, 5, 8, 9, 10, 11, 32, 36, 51, 53, 54, 64, 65, 71, 72, 77, 81, 82, 83, 89, 94, 96, 99, 101, 106, 112, 113, 119, 121, 127, 128, 137, 139, 150, 152, 164, 165, 171, 181, 184, 198, 201, 207, 208, 232, 235, 237, 238, 240, 249, 250, 252, 257, 258, 264, 270, 292, 293, 294, 295, 302, 304, 306, 313, 316, 318, 319, 323, 326, 330, 332, 336, 348, 355, 356, 358, 360], "docker": [108, 110], "dockerfil": [164, 165, 171, 173, 178], "document": [6, 7, 41, 43, 47, 48, 74, 78, 86, 90, 101, 106, 108, 109, 164, 165, 168, 172, 173, 180, 181, 185, 187, 188, 198, 201, 225, 226, 230, 231, 285, 289, 293, 295, 312, 323], "documentari": [340, 343], "doe": [2, 3, 5, 6, 7, 8, 9, 22, 23, 28, 35, 41, 47, 51, 61, 77, 78, 82, 89, 90, 96, 108, 111, 164, 165, 168, 169, 189, 192, 193, 197, 203, 206, 215, 221, 222, 225, 230, 232, 235, 240, 246, 258, 276, 285, 289, 293, 312, 326, 329, 332, 338, 339, 340, 343, 347, 362, 368, 369, 374, 375, 381], "doesn": [2, 4, 8, 9, 19, 31, 54, 64, 76, 88, 108, 110, 164, 165, 169, 215, 218, 232, 238, 240, 249, 258, 260, 294, 318, 332, 338, 340, 343, 346, 347, 388, 390], "doesnt": [340, 347], "dog": [395, 396], "dogma": [340, 347], "dolocationid": [8, 51, 232, 235], "domain": [382, 386, 387], "domin": [7, 46, 225, 229, 382, 386], "don": [1, 2, 4, 8, 9, 11, 16, 21, 32, 52, 61, 72, 84, 207, 208, 209, 214, 215, 220, 232, 236, 240, 246, 258, 259, 260, 264, 294, 317, 332, 338, 340, 343, 347, 362, 364, 368, 375, 381, 395, 396, 399], "donald": [332, 338], "done": [4, 8, 32, 54, 74, 77, 78, 79, 86, 89, 90, 91, 112, 117, 119, 126, 150, 162, 164, 165, 171, 173, 177, 178, 198, 200, 232, 238, 258, 262, 271, 292, 306, 340, 346, 347, 356, 361, 375, 377, 382, 383], "dont": [340, 347], "dool": [332, 338], "dorset": [332, 338], "dot": [2, 22, 215, 221, 332, 336, 338, 362, 363, 369, 370, 375, 376, 378, 381, 382, 383, 395, 396], "dot_product": [375, 378], "doubl": [332, 336, 338, 340, 343], "down": [4, 5, 32, 37, 78, 82, 90, 96, 108, 110, 111, 137, 147, 164, 165, 169, 179, 258, 268, 292, 295, 307, 321, 323, 326, 331, 332, 334, 338, 340, 342, 347, 348, 350, 369, 370], "down_block_typ": [5, 35, 326, 329], "downblock2d": [5, 35, 326, 329], "download": [4, 6, 11, 31, 32, 39, 41, 72, 74, 76, 77, 79, 84, 86, 88, 89, 91, 150, 153, 181, 184, 207, 208, 266, 283, 285, 287, 289, 292, 293, 294, 295, 300, 303, 305, 309, 311, 313, 317, 322, 356, 359, 375, 377, 388, 389, 390], "downsampl": [292, 300, 306], "downsample_pad": [5, 35, 326, 329], "downscal": [295, 323, 356, 361], "downscale_delay_": [295, 323], "downstream": [9, 63, 181, 183, 185, 240, 248, 294, 317, 340, 342, 375, 381], "downtim": [79, 83, 91, 99, 198, 201], "draft": [332, 336, 338, 339], "drag": [332, 338], "dragon": [340, 347], "drama": [340, 343], "draw": [340, 347], "dread": [332, 338], "dream": [340, 346, 347], "dreambr": [340, 347], "dreamnightmar": [340, 347], "dress": [332, 338], "drill": [7, 44, 225, 227], "drive": [340, 346], "driver": [2, 9, 19, 23, 57, 62, 108, 111, 193, 195, 198, 201, 215, 218, 222, 240, 242, 247, 332, 338, 375, 377, 382, 386, 388, 394, 395, 404], "driver_artifact": [291, 292, 298, 305, 348, 355], "drop": [164, 165, 170, 258, 266, 271, 332, 338, 362, 364, 382, 385, 388, 390, 395, 404], "drop_column": [291, 298, 362, 364], "drop_last": [4, 6, 31, 32, 39, 41, 258, 266, 285, 287, 289, 292, 293, 300, 303, 309, 313, 388, 390], "dropdown": [74, 86, 173, 179, 198, 200], "dropna": [375, 379, 388, 392, 395, 402], "dropout": [388, 391], "ds_adjust": [8, 52, 53, 232, 236, 237], "ds_block_based_shuffl": [8, 54, 232, 238], "ds_file_shuffl": [8, 54, 232, 238], "ds_iter": [382, 385], "ds_label": [9, 61, 240, 246], "ds_limit": [8, 53, 232, 237], "ds_meta": [340, 344, 346], "ds_normal": [9, 61, 62, 240, 246, 247, 294, 317], "ds_pred": [9, 62, 63, 64, 65, 240, 247, 248, 249, 250, 294, 317, 318, 319], "ds_randomized_block": [9, 64, 240, 249, 294, 318], "ds_randomized_row": [9, 64, 240, 249, 294, 318], "ds_review": [340, 344, 345], "ds_row_based_shuffl": [8, 54, 232, 238], "ds_tip": [8, 52, 232, 236], "ds_tmp": [395, 404], "dsl": [7, 45, 225, 228], "dtest": [3, 28, 203, 206], "dtrain": [3, 28, 203, 206, 382, 385], "dtype": [5, 35, 193, 197, 258, 276, 291, 295, 298, 323, 326, 329, 332, 338, 339, 362, 364, 369, 371, 374, 375, 379, 388, 390, 391], "due": [2, 4, 5, 7, 9, 10, 20, 30, 34, 46, 57, 61, 68, 164, 165, 168, 173, 179, 193, 197, 215, 219, 225, 229, 240, 242, 246, 252, 254, 258, 259, 326, 328, 332, 336, 340, 346, 347, 356, 361], "dummi": [164, 165, 171, 181, 186], "dummy_data_1000_500": [76, 88], "dummy_data_1000_720": [76, 88], "dummy_data_xxl": [76, 88], "dummy_kei": [165, 171], "dump": [10, 70, 181, 186, 198, 201, 252, 256, 295, 322, 323], "duplic": [258, 259, 268, 280, 388, 390, 395, 396], "durabl": [7, 43, 225, 226], "durat": [77, 89, 198, 201, 202], "dure": [0, 2, 4, 5, 22, 32, 36, 76, 88, 112, 114, 127, 129, 137, 140, 164, 165, 168, 169, 198, 201, 215, 221, 258, 259, 267, 270, 277, 292, 306, 326, 330, 332, 339, 340, 343, 347, 348, 350, 353, 362, 363, 364, 366, 375, 379, 381, 382, 384, 385, 388, 389, 391, 394, 395, 397, 402], "dustin": [332, 338], "dvd": [340, 346], "dynam": [7, 8, 10, 48, 54, 68, 101, 106, 108, 109, 181, 184, 225, 231, 232, 238, 252, 254, 295, 321, 388, 389], "dynamic_lora_loading_path": [181, 184], "e": [0, 1, 2, 4, 6, 7, 8, 9, 10, 13, 19, 20, 22, 32, 41, 43, 46, 52, 53, 57, 59, 61, 68, 69, 71, 74, 76, 77, 79, 80, 83, 86, 88, 89, 91, 92, 99, 100, 101, 106, 108, 110, 111, 112, 113, 114, 119, 120, 127, 128, 129, 133, 134, 135, 137, 138, 140, 145, 146, 148, 150, 151, 164, 165, 168, 173, 179, 189, 191, 193, 195, 198, 200, 209, 211, 215, 218, 219, 221, 225, 226, 229, 232, 236, 237, 240, 242, 244, 246, 252, 254, 255, 257, 258, 262, 263, 268, 269, 270, 272, 274, 278, 281, 284, 285, 289, 291, 293, 294, 295, 298, 312, 316, 317, 323, 332, 334, 362, 363, 369, 370, 375, 376, 379, 382, 385, 388, 394, 395, 397], "each": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 16, 18, 28, 31, 32, 35, 36, 39, 41, 48, 51, 52, 53, 59, 61, 62, 69, 72, 75, 76, 77, 79, 81, 83, 87, 88, 89, 91, 94, 99, 101, 104, 106, 127, 130, 137, 142, 163, 164, 165, 167, 168, 173, 176, 179, 181, 183, 184, 188, 193, 195, 196, 197, 198, 200, 201, 202, 203, 206, 207, 208, 209, 214, 215, 217, 225, 231, 232, 235, 236, 237, 240, 244, 246, 247, 252, 255, 258, 259, 260, 261, 262, 264, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 280, 285, 287, 289, 291, 292, 293, 294, 295, 296, 302, 309, 311, 312, 313, 316, 317, 321, 323, 326, 329, 330, 332, 334, 336, 337, 338, 340, 344, 347, 348, 350, 353, 354, 356, 358, 360, 362, 363, 364, 369, 370, 373, 375, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 388, 389, 390, 392, 394, 395, 396, 397, 398, 400, 402, 404], "earli": [6, 41, 285, 289, 293, 312, 332, 338, 362, 368, 382, 387, 388, 390, 394, 395, 404], "earlier": [74, 75, 77, 86, 87, 89, 340, 346, 362, 364, 395, 403], "early_stopping_round": [382, 387], "earn": [332, 338], "earth": [340, 346], "eas": [7, 45, 225, 228], "easi": [0, 7, 8, 48, 50, 84, 164, 165, 169, 173, 179, 181, 185, 186, 188, 193, 197, 198, 201, 225, 231, 232, 234, 258, 270, 272, 295, 321, 348, 353, 354, 356, 358, 362, 363], "easier": [5, 7, 35, 48, 108, 110, 225, 231, 326, 329, 340, 347, 348, 350, 375, 381], "easili": [1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 17, 26, 29, 33, 38, 49, 56, 67, 79, 83, 91, 99, 164, 165, 166, 170, 173, 174, 181, 182, 193, 197, 203, 204, 209, 210, 215, 216, 232, 233, 240, 241, 252, 253, 285, 286, 326, 327, 332, 334, 340, 342, 348, 350, 354, 356, 358, 369, 370], "eastern": [340, 346, 347], "eat": [340, 346], "ec2": [77, 89, 102, 104, 106, 107, 108, 110, 111, 114, 115, 118, 127, 129, 137, 140, 405], "echo": [150, 153, 332, 338], "eclips": [332, 338], "ecolog": [382, 387], "ecosystem": [3, 4, 5, 7, 27, 30, 34, 46, 47, 203, 205, 225, 229, 230, 258, 259, 291, 297, 298, 326, 328], "ed": [332, 338], "eddi": [332, 338, 340, 346, 347], "edg": [332, 338, 388, 394], "edgecolor": [375, 377], "edit": [74, 75, 86, 87, 332, 338], "editor": [74, 75, 78, 86, 87, 90, 119, 121, 150, 152], "educ": [395, 396], "ef": [105, 107, 108, 110, 112, 114, 118, 137, 141, 294, 295, 317, 322], "effect": [2, 3, 19, 28, 76, 88, 101, 106, 173, 175, 181, 184, 203, 206, 215, 218, 258, 263, 340, 346, 347, 375, 378, 379, 388, 394], "effici": [7, 9, 10, 11, 43, 46, 47, 57, 68, 69, 72, 75, 81, 87, 95, 164, 165, 167, 173, 175, 181, 184, 207, 208, 225, 226, 229, 230, 240, 242, 252, 254, 255, 258, 259, 271, 272, 275, 284, 332, 334, 339, 340, 342, 347, 348, 350, 353, 354, 355, 362, 363, 364, 375, 376, 377, 379, 381, 388, 389, 390, 394, 395, 396, 398, 404], "efs_id": [101, 107, 112, 114], "egress": [108, 110], "eid": [332, 338], "eight": [369, 373, 395, 401], "eip": [112, 114, 127, 129, 137, 140], "eipalloc": [112, 114, 127, 129, 137, 140], "either": [8, 9, 52, 58, 78, 82, 90, 98, 164, 165, 169, 198, 201, 232, 236, 240, 243, 258, 271, 294, 317, 332, 338, 340, 347, 375, 377], "eject": [332, 338], "ek": [101, 102, 104, 106, 108, 111, 129, 130, 131, 136, 139, 140, 142, 143, 149, 405], "eks_cluster_nam": [127, 129, 130, 137, 140, 141, 142], "elam": [340, 346], "elaps": [291, 298], "elast": [101, 106, 112, 114, 127, 129, 137, 140], "element": [295, 321, 340, 347], "elev": [382, 383, 386], "elif": [348, 353, 362, 368, 388, 390], "elimin": [7, 43, 164, 165, 168, 225, 226, 382, 384], "ellipsi": [80, 92], "els": [4, 6, 9, 31, 32, 40, 62, 79, 91, 181, 186, 240, 247, 258, 271, 283, 285, 288, 332, 338, 348, 353, 356, 360, 362, 368, 369, 374, 375, 377, 379, 381, 382, 385, 388, 390, 392, 394, 395, 400, 404], "elt": [7, 43, 225, 226], "email": [81, 82, 94, 96, 119, 123, 150, 154, 198, 201, 202], "emb": [332, 337, 338, 375, 376, 381], "embed": [0, 78, 82, 90, 96, 332, 333, 334, 337, 338, 339, 341, 349, 357, 362, 368, 369, 374, 377, 378, 381], "embedd": 0, "embedding_dim": [258, 263, 375, 378, 379, 381], "emit": [164, 165, 168, 362, 366], "emmanuel": [332, 338], "emotion": [340, 346, 347], "emploi": [7, 43, 225, 226], "empti": [79, 83, 91, 100, 112, 114, 117, 119, 126, 127, 129, 135, 137, 148, 150, 162], "emption": [388, 389], "en": [11, 72, 164, 165, 171, 207, 208, 293, 313, 332, 336, 340, 347, 348, 355, 356, 358, 360], "enabl": [1, 2, 3, 7, 8, 9, 10, 13, 17, 22, 27, 43, 46, 48, 53, 55, 57, 69, 75, 76, 77, 79, 83, 84, 87, 88, 89, 91, 99, 101, 105, 106, 108, 109, 111, 121, 152, 162, 180, 181, 183, 184, 186, 188, 189, 192, 193, 197, 198, 201, 202, 203, 205, 209, 211, 215, 216, 221, 225, 226, 229, 231, 232, 237, 239, 240, 242, 252, 255, 272, 278, 280, 281, 284, 291, 297, 298, 332, 334, 339, 340, 342, 344, 347, 348, 354, 362, 363, 364, 368, 369, 370, 374, 375, 376, 379, 382, 383, 388, 389, 390, 394, 395, 396, 401, 404], "enable_access_log": [198, 201], "enable_auto_tool_choic": [181, 186], "enable_checkpoint": [5, 36, 326, 330], "enable_filestor": [119, 123], "enable_lora": [181, 184], "enable_progress_bar": [362, 366, 369, 373], "encapsul": [258, 269, 395, 396], "encod": [164, 165, 167, 198, 201, 332, 337, 338, 340, 342, 368, 369, 370, 376, 381, 388, 390, 391], "encode_batch": [375, 377], "encount": [2, 4, 5, 20, 29, 33, 150, 155, 215, 219, 326, 327, 356, 361], "encourag": [362, 363, 375, 376], "end": [2, 7, 22, 26, 27, 46, 47, 77, 89, 108, 110, 163, 164, 165, 167, 168, 169, 171, 173, 177, 178, 180, 181, 184, 187, 198, 201, 204, 205, 215, 221, 225, 229, 230, 277, 282, 284, 295, 296, 297, 321, 332, 338, 340, 346, 347, 356, 361, 362, 363, 368, 369, 370, 374, 375, 381, 382, 383, 387, 388, 389, 390, 394, 395, 396, 404], "endpoint": [10, 70, 79, 91, 108, 110, 164, 165, 169, 171, 173, 177, 178, 180, 252, 256, 295, 322, 323, 356, 360, 362, 368, 375, 381, 382, 387], "enforc": [0, 2, 7, 9, 22, 43, 61, 75, 87, 181, 185, 215, 221, 225, 226, 240, 246], "engag": [8, 51, 181, 184, 232, 235], "engin": [1, 4, 5, 8, 9, 10, 13, 30, 34, 43, 45, 46, 47, 55, 57, 68, 80, 92, 101, 104, 108, 111, 123, 153, 154, 162, 163, 171, 173, 179, 181, 184, 198, 199, 209, 211, 226, 228, 229, 230, 232, 239, 240, 242, 252, 254, 258, 259, 295, 324, 326, 328, 348, 350, 355, 382, 386, 387, 388, 389, 390], "engine_arg": [164, 165, 171], "engine_kwarg": [164, 165, 171, 173, 176, 179, 181, 184, 185, 186], "english": [356, 360], "enhanc": [7, 43, 47, 181, 183, 186, 189, 191, 193, 196, 197, 225, 226, 230], "enjoi": [332, 338, 340, 347], "enough": [2, 9, 25, 64, 75, 87, 215, 224, 240, 249, 258, 268, 294, 318, 362, 364, 375, 377, 395, 397], "ensembl": [26, 204, 382, 383], "ensu": [340, 347], "ensur": [2, 4, 5, 7, 8, 11, 22, 25, 30, 32, 34, 43, 53, 72, 73, 75, 85, 87, 112, 113, 115, 119, 121, 124, 127, 128, 131, 137, 139, 143, 147, 150, 152, 159, 181, 185, 189, 192, 198, 199, 207, 208, 215, 221, 224, 225, 226, 232, 237, 258, 259, 262, 265, 268, 271, 272, 274, 276, 280, 292, 302, 304, 326, 328, 332, 333, 338, 341, 348, 349, 353, 357, 362, 366, 369, 374, 375, 377, 379, 382, 384, 385, 387, 388, 390, 395, 400], "enter": [74, 78, 79, 82, 86, 90, 91, 98, 202, 340, 343], "enterpris": [79, 83, 91, 99, 164, 165, 170, 173, 178, 180, 181, 188], "entir": [2, 4, 5, 7, 8, 9, 22, 32, 35, 46, 51, 60, 63, 64, 80, 92, 108, 109, 150, 151, 164, 165, 168, 215, 221, 225, 229, 232, 235, 240, 245, 248, 249, 258, 259, 262, 294, 317, 318, 326, 329, 334, 340, 347, 348, 353, 362, 368, 375, 377, 381, 382, 385, 388, 390, 395, 396], "entiti": [80, 92], "entri": [202, 258, 276, 388, 394], "entropi": [395, 396], "entrypoint": [78, 82, 90, 98, 295, 323], "enum": [181, 185, 186], "enumer": [6, 39, 285, 287, 293, 309, 340, 344, 375, 377, 381], "env": [2, 21, 75, 87, 173, 178, 215, 220, 258, 260, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "env_var": [2, 21, 22, 173, 176, 179, 181, 184, 185, 186, 215, 220, 221], "environ": [0, 3, 4, 5, 7, 8, 9, 10, 17, 22, 28, 31, 35, 46, 53, 62, 69, 70, 73, 74, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92, 94, 96, 101, 103, 106, 112, 113, 118, 119, 120, 127, 128, 136, 137, 138, 149, 150, 151, 153, 163, 164, 165, 167, 173, 176, 179, 181, 184, 186, 189, 190, 192, 193, 197, 198, 199, 200, 201, 203, 206, 216, 221, 225, 229, 232, 237, 240, 247, 252, 255, 256, 326, 329, 332, 334, 348, 350, 351, 354, 356, 358, 362, 363, 364, 366, 371, 373, 374, 375, 377, 382, 383, 384, 388, 390, 395, 396, 397], "environment": [75, 87], "eot": [112, 114, 119, 123, 127, 129, 137, 140, 150, 154], "ep": [292, 300, 306], "ephemer": [258, 260], "epic": [332, 338], "episod": [369, 374], "epoch": [4, 6, 31, 32, 40, 41, 258, 262, 267, 268, 270, 272, 273, 278, 279, 280, 282, 284, 285, 288, 289, 292, 293, 300, 302, 304, 305, 306, 310, 312, 313, 348, 353, 354, 355, 362, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 379, 380, 381, 388, 389, 392, 394, 395, 396, 400, 401, 402, 403, 404], "epoch_loss": [4, 31], "equival": [8, 51, 53, 232, 235, 237], "ergonom": [369, 371], "ernst": [340, 347], "ernsthugo": [340, 347], "erotica": [340, 343], "errno": [8, 53, 232, 237], "error": [2, 4, 5, 7, 8, 9, 20, 29, 33, 46, 53, 57, 61, 75, 87, 127, 135, 137, 148, 150, 155, 181, 185, 189, 191, 193, 197, 198, 201, 215, 219, 225, 229, 232, 237, 240, 242, 246, 292, 293, 305, 311, 313, 326, 327, 334, 356, 361, 362, 363, 375, 376, 381, 382, 383], "erupt": [340, 347], "escap": [340, 347], "especi": [2, 4, 8, 19, 22, 32, 55, 75, 87, 215, 218, 221, 232, 239, 258, 266, 272, 294, 295, 315, 323, 332, 334, 340, 346, 348, 353, 362, 364, 388, 392, 395, 397], "essenti": [7, 46, 101, 105, 164, 165, 172, 173, 180, 225, 229, 258, 278, 348, 353], "establish": [6, 40, 101, 103, 181, 187, 285, 288, 293, 310], "estim": [4, 32, 77, 89, 258, 262], "estimate_pi": [77, 89], "eta": [3, 28, 203, 206, 362, 363, 369, 370, 382, 385, 387], "etc": [1, 2, 3, 4, 5, 8, 9, 13, 25, 28, 30, 34, 51, 53, 59, 101, 102, 103, 106, 107, 108, 111, 173, 176, 198, 200, 201, 203, 206, 209, 211, 215, 224, 232, 235, 237, 240, 244, 258, 259, 263, 282, 291, 298, 326, 328, 382, 385], "ether": [340, 347], "etl": [7, 43, 46, 225, 226, 229, 294, 315], "euler": [362, 368], "europ": [340, 346, 347], "europa": [332, 338, 340, 347], "ev": [332, 338], "eval": [3, 4, 5, 9, 10, 28, 31, 32, 36, 62, 70, 203, 206, 240, 247, 252, 256, 258, 271, 292, 294, 295, 300, 306, 317, 322, 326, 330, 348, 353, 362, 368, 369, 374, 375, 379, 381, 382, 385, 388, 392, 394, 395, 400, 404], "eval_arrow": [382, 385], "eval_dataset": [348, 353], "eval_metr": [3, 28, 203, 206, 382, 385], "eval_pr": [348, 352], "evals_result": [3, 28, 203, 206, 382, 385], "evalu": [2, 6, 22, 40, 101, 104, 163, 181, 187, 215, 221, 258, 271, 285, 288, 293, 295, 310, 323, 348, 350, 351, 352, 353, 362, 363, 368, 369, 370, 374, 375, 376, 381, 383, 384, 387, 395, 396, 400, 404], "evan": [332, 338], "even": [2, 22, 77, 89, 164, 165, 168, 181, 188, 193, 197, 215, 221, 258, 268, 295, 323, 332, 338, 340, 343, 347, 356, 360, 361, 388, 394, 395, 400], "evenli": [258, 262, 263], "event": [4, 5, 7, 30, 34, 46, 77, 89, 189, 191, 193, 195, 196, 225, 229, 258, 259, 326, 328], "eventu": [258, 271], "ever": [3, 27, 203, 205, 291, 297, 340, 343, 346], "everi": [0, 1, 16, 76, 78, 80, 82, 88, 90, 92, 96, 209, 214, 258, 262, 267, 268, 276, 277, 332, 338, 340, 344, 362, 365, 369, 370, 373, 375, 379, 382, 383, 384, 385, 395, 396, 397, 398, 402, 404], "every_n_epoch": [362, 366, 369, 373], "everyon": [340, 347], "everyth": [79, 91, 108, 110, 258, 269, 340, 343, 347, 362, 368, 369, 374, 375, 377, 381, 388, 392, 395, 397], "evil": [340, 346, 347], "evolut": [7, 43, 225, 226], "evolv": [375, 379, 382, 383], "ex": [362, 364], "exact": [2, 9, 11, 22, 61, 72, 73, 85, 173, 178, 181, 185, 207, 208, 215, 221, 240, 246], "exactli": [101, 106, 362, 364, 375, 380, 395, 396, 397, 398, 404], "examin": [127, 134, 137, 146], "exampl": [2, 4, 6, 7, 8, 9, 10, 18, 21, 22, 23, 25, 31, 41, 43, 52, 53, 57, 59, 60, 62, 70, 71, 74, 78, 79, 86, 90, 91, 102, 104, 106, 110, 112, 114, 115, 119, 122, 127, 128, 129, 137, 138, 140, 150, 151, 153, 155, 164, 165, 168, 169, 177, 179, 182, 183, 187, 188, 189, 191, 192, 194, 198, 199, 200, 201, 215, 217, 220, 221, 222, 224, 225, 226, 232, 236, 237, 240, 242, 244, 245, 247, 252, 256, 257, 258, 260, 263, 268, 270, 272, 284, 285, 289, 294, 295, 296, 299, 317, 323, 332, 334, 337, 338, 340, 342, 345, 348, 353, 356, 360, 362, 363, 368, 369, 370, 375, 376, 381, 382, 383, 385, 386, 387, 388, 394, 395, 396, 397, 402, 404], "exce": [356, 360], "excel": [173, 175, 181, 187], "except": [2, 5, 20, 36, 215, 219, 258, 279, 295, 322, 326, 330, 332, 338, 362, 364, 395, 397], "excess": [395, 396], "excit": [332, 338], "exclus": [4, 32, 164, 165, 169], "exdb": [292, 293, 305, 311], "execut": [2, 3, 4, 5, 6, 7, 12, 14, 16, 18, 19, 21, 23, 24, 28, 32, 35, 36, 41, 43, 47, 48, 51, 55, 56, 57, 61, 62, 63, 74, 77, 78, 81, 86, 89, 90, 94, 96, 98, 101, 102, 106, 127, 134, 137, 146, 150, 153, 164, 165, 170, 181, 183, 186, 189, 191, 198, 200, 203, 206, 210, 212, 214, 215, 217, 218, 220, 222, 223, 225, 226, 230, 231, 235, 239, 241, 242, 246, 247, 248, 258, 259, 260, 261, 262, 276, 285, 289, 293, 311, 326, 329, 330, 332, 338, 339, 348, 350, 353, 362, 364, 369, 371, 375, 377, 379, 382, 383, 384, 385, 387, 388, 389, 390, 392, 395, 396, 397, 400, 404], "execute_notebook": 0, "exercis": 84, "exhaust": [164, 165, 169, 258, 278, 382, 385], "exhibit": [340, 347, 388, 390], "exisitng": [108, 111], "exist": [3, 8, 28, 53, 74, 75, 76, 77, 79, 83, 86, 87, 88, 89, 91, 100, 108, 109, 110, 111, 112, 113, 114, 127, 128, 129, 136, 139, 140, 149, 181, 186, 198, 200, 201, 203, 206, 232, 237, 258, 283, 332, 336, 340, 343, 348, 354, 356, 358, 362, 366, 368, 369, 373, 374, 375, 377, 379, 381, 382, 387, 388, 390, 392, 394, 395, 396, 400, 402, 404, 405], "exist_ok": [4, 31, 292, 300, 362, 364, 366, 369, 373, 375, 377, 382, 384, 388, 390, 395, 397], "existing_vpc_id": [101, 106], "exit": [362, 367], "exogen": [388, 394], "exp": [388, 391], "expand": [77, 89, 112, 113, 127, 128, 137, 139, 147, 150, 152, 198, 200, 258, 271, 362, 365], "expect": [4, 6, 32, 41, 74, 86, 164, 165, 169, 258, 261, 268, 285, 289, 293, 295, 311, 323, 362, 366, 375, 377, 382, 384, 388, 394, 395, 397], "expens": [3, 6, 9, 10, 28, 40, 62, 68, 173, 175, 181, 184, 203, 206, 240, 247, 252, 254, 285, 288, 291, 293, 294, 298, 310, 317, 332, 337, 340, 346, 362, 364], "expensive_comput": [2, 24, 215, 223], "expensive_squar": [1, 2, 16, 19, 23, 24, 209, 214, 215, 218, 222, 223], "experi": [1, 4, 6, 13, 32, 41, 73, 74, 75, 79, 84, 85, 86, 87, 91, 163, 173, 180, 181, 184, 188, 189, 191, 193, 197, 198, 199, 209, 211, 258, 260, 262, 284, 285, 289, 311, 340, 343, 356, 361, 369, 374, 382, 387, 395, 396, 403, 404], "experiment": [10, 71, 252, 257, 375, 380], "experiment_nam": [5, 36, 258, 280, 326, 330], "experinc": [83, 99], "expert": [7, 47, 225, 230, 340, 347, 362, 363, 369, 370, 395, 397], "expertli": [340, 347], "explain": [81, 93, 101, 105, 108, 110, 198, 201, 332, 338, 340, 346], "explan": [181, 184, 198, 200, 356, 360], "explicit": [181, 187, 340, 343, 375, 376, 382, 385], "explicitli": [5, 6, 8, 9, 35, 41, 52, 60, 79, 83, 91, 100, 232, 236, 240, 245, 285, 289, 326, 329, 332, 334, 336], "explor": [7, 43, 74, 76, 79, 84, 86, 88, 91, 164, 165, 166, 169, 173, 179, 180, 181, 182, 183, 188, 198, 201, 225, 226, 258, 284, 340, 343, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "explos": [193, 197], "export": [150, 153, 173, 176, 177, 181, 184, 189, 192, 202, 369, 374], "expos": [108, 111, 332, 338], "exposehead": [101, 106, 137, 147], "exposur": [101, 106], "expr": [340, 345], "express": [4, 31, 77, 89, 258, 260, 340, 345, 362, 368], "expresswai": [332, 338], "extend": [2, 25, 101, 106, 215, 224, 258, 272, 279, 280, 284, 362, 363, 368, 369, 374, 375, 381, 382, 385, 387, 388, 394, 395, 398, 404], "extens": [9, 59, 74, 76, 86, 88, 181, 186, 240, 244], "extern": [7, 8, 46, 50, 101, 106, 111, 137, 147, 150, 157, 181, 183, 186, 188, 193, 195, 225, 229, 232, 234, 258, 284], "extra": [164, 165, 169, 332, 338, 375, 376, 377, 379, 382, 384, 388, 392, 394, 395, 402], "extra_st": [258, 279, 280], "extract": [5, 7, 9, 35, 43, 61, 137, 141, 225, 226, 240, 246, 292, 293, 305, 313, 326, 329, 375, 377, 381, 395, 402], "extract_dir": [375, 377], "extractal": [375, 377], "extrem": [76, 88, 164, 165, 168, 193, 197, 295, 323, 356, 361, 382, 383], "f": [2, 3, 4, 5, 6, 8, 9, 10, 18, 21, 22, 24, 28, 31, 32, 33, 35, 40, 51, 53, 62, 65, 70, 75, 76, 77, 79, 87, 88, 89, 91, 112, 114, 164, 165, 171, 173, 178, 181, 184, 185, 186, 193, 197, 198, 200, 202, 203, 206, 215, 217, 220, 221, 223, 232, 235, 237, 240, 247, 250, 252, 256, 258, 262, 267, 271, 283, 285, 288, 292, 293, 300, 306, 310, 326, 327, 329, 348, 353, 354, 362, 364, 366, 368, 369, 373, 374, 375, 377, 379, 381, 382, 384, 385, 386, 387, 388, 389, 390, 391, 392, 394, 395, 397, 400, 404], "f1": [332, 338, 395, 404], "f_": [362, 363, 369, 370, 382, 383, 388, 389, 395, 396], "face": [4, 5, 30, 34, 84, 101, 106, 164, 165, 169, 173, 176, 177, 181, 184, 186, 258, 259, 272, 295, 321, 326, 328, 332, 334, 336, 338, 339, 340, 343, 347, 351, 352, 355, 356, 359, 361, 395, 396, 397, 404], "facial": [340, 347], "facilit": [7, 43, 47, 76, 88, 225, 226, 230], "fact": [332, 338, 340, 343, 346, 347], "factor": [379, 381], "fahrenheit": [2, 25, 181, 186, 215, 224], "fail": [2, 4, 5, 9, 20, 30, 34, 57, 61, 193, 197, 215, 219, 240, 242, 246, 258, 259, 278, 280, 281, 292, 293, 305, 311, 313, 326, 328, 375, 379, 382, 385, 388, 393], "failur": [4, 5, 7, 9, 17, 20, 30, 34, 46, 57, 61, 78, 79, 82, 83, 90, 91, 96, 99, 173, 178, 189, 191, 193, 195, 197, 216, 219, 225, 229, 240, 242, 246, 258, 259, 278, 280, 281, 282, 326, 328, 369, 373, 382, 383, 387, 388, 389, 392, 394, 395, 396, 400, 404], "failure_config": [258, 280, 282, 362, 366, 369, 373, 375, 379, 382, 385, 388, 392, 395, 401], "failureconfig": [278, 281, 284, 362, 363, 364, 366, 369, 370, 371, 373, 375, 376, 377, 379, 382, 383, 384, 385, 388, 389, 390, 392, 395, 397, 400, 401, 404], "fair": [332, 338], "fake": [340, 344], "fake_kei": [164, 173, 177, 181, 184, 185, 186], "fall": [375, 377], "fallback": [362, 368, 369, 374], "fals": [3, 4, 5, 6, 10, 28, 31, 32, 35, 36, 40, 41, 70, 198, 201, 203, 206, 252, 256, 258, 261, 264, 285, 288, 289, 291, 292, 293, 295, 298, 300, 306, 310, 313, 322, 323, 326, 329, 330, 362, 365, 366, 368, 369, 372, 373, 374, 375, 377, 379, 382, 384, 385, 388, 390, 392, 394, 395, 400, 402, 404], "famili": [332, 338], "familiar": [163, 198, 199, 258, 274], "fan": [332, 338, 340, 343], "fanatic": [340, 347], "fanchant": [332, 338], "fantasi": [340, 346], "fantast": [340, 347], "far": [340, 343, 346, 382, 385], "fare": [340, 347], "fare_amount": [3, 28, 203, 206, 291, 298], "fashion": [8, 55, 232, 239, 294, 315], "fast": [4, 8, 9, 31, 50, 61, 84, 108, 110, 164, 165, 169, 170, 181, 187, 232, 234, 240, 246, 258, 259, 260, 369, 370, 382, 383, 387, 395, 397, 400], "fastapi": [3, 7, 26, 28, 48, 79, 83, 91, 100, 202, 203, 204, 206, 225, 231, 359, 361], "fastapideploy": [79, 83, 91, 100], "faster": [6, 41, 173, 179, 180, 258, 271, 285, 289, 340, 345, 348, 354, 362, 368], "fastest": [74, 86], "fate": [340, 347], "father": [340, 347], "fault": [4, 5, 7, 8, 9, 30, 34, 46, 50, 55, 57, 83, 99, 101, 105, 106, 173, 178, 225, 229, 232, 234, 239, 240, 242, 259, 279, 280, 282, 326, 328, 362, 363, 364, 366, 368, 369, 370, 373, 374, 375, 376, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 393, 394, 396, 400, 401, 404], "fc": [292, 300, 306], "feasibl": [369, 374], "featur": [3, 7, 28, 43, 46, 47, 49, 51, 52, 74, 86, 101, 104, 108, 110, 164, 165, 169, 170, 173, 178, 179, 180, 188, 189, 192, 193, 194, 198, 201, 203, 206, 225, 226, 229, 230, 233, 235, 236, 320, 340, 343, 356, 358, 362, 364, 375, 381, 383, 384, 385, 387, 388, 394, 395, 397, 404], "feature_col": [382, 385, 386], "feature_column": [382, 384, 385, 386, 387], "feature_nam": [382, 385], "feb": [332, 338], "fed": [332, 338], "feder": [101, 106], "fee": [3, 28, 203, 206, 291, 298], "feed": [8, 50, 52, 232, 234, 236, 258, 272, 332, 338, 388, 389, 392, 395, 398], "feedback": [74, 86], "feel": [79, 83, 91, 100, 258, 274, 332, 338, 340, 343, 346, 347, 362, 368, 369, 374, 375, 381, 382, 387, 395, 404], "femal": [340, 343], "fenc": [332, 338], "fend": [340, 346], "ferrari": [332, 338], "ferri": [332, 338], "fetch": [4, 5, 17, 18, 19, 30, 34, 216, 217, 218, 258, 259, 260, 271, 274, 326, 328, 348, 353, 382, 384, 388, 390], "fetch_covtyp": [382, 384], "few": [73, 74, 75, 85, 86, 87, 150, 157, 181, 184, 198, 199, 332, 339, 340, 342, 343, 346, 347, 362, 363, 366, 368, 369, 374, 375, 376, 377, 381, 382, 387, 388, 394, 395, 404], "fewer": [7, 46, 119, 123, 225, 229], "ff": [332, 338], "fiat": [332, 338], "fid": [362, 368], "field": [8, 51, 79, 83, 91, 100, 181, 185, 232, 235, 258, 276, 369, 371], "fifo": [291, 292, 293, 298, 305, 311, 313, 348, 355], "fifoschedul": [6, 41, 285, 289, 293, 312, 313], "fig": [6, 39, 285, 287, 292, 293, 300, 306, 309, 362, 364, 368, 395, 397], "figsiz": [4, 6, 31, 32, 39, 258, 260, 271, 285, 287, 292, 293, 300, 306, 309, 362, 364, 366, 368, 369, 373, 375, 377, 379, 382, 384, 388, 390, 392, 394, 395, 397, 402], "figur": [4, 8, 31, 32, 51, 232, 235, 258, 260, 271, 294, 316, 362, 366, 369, 373, 375, 377, 379, 388, 390, 392, 394, 395, 402], "file": [0, 3, 4, 5, 6, 7, 10, 11, 28, 31, 32, 35, 37, 42, 43, 51, 53, 55, 58, 59, 62, 66, 71, 72, 74, 75, 77, 78, 79, 84, 86, 87, 89, 90, 91, 101, 106, 108, 110, 112, 114, 118, 119, 122, 123, 127, 129, 130, 137, 140, 142, 150, 153, 154, 181, 184, 193, 197, 198, 201, 203, 206, 207, 208, 225, 226, 235, 237, 239, 243, 244, 247, 251, 252, 257, 258, 260, 268, 275, 280, 283, 284, 285, 290, 291, 292, 298, 307, 316, 317, 326, 329, 331, 332, 333, 338, 341, 349, 357, 362, 364, 368, 369, 370, 374, 375, 376, 377, 381, 388, 390, 395, 396, 397, 398, 400, 404], "file_nam": [181, 184], "filenam": [74, 86, 258, 260, 362, 366, 369, 373], "filenotfounderror": [8, 53, 232, 237, 362, 368, 395, 404], "filestor": [108, 110, 119, 120, 123, 150, 154], "filestore_capacity_gb": [119, 123], "filestore_instance_nam": [119, 123, 150, 154], "filestore_loc": [119, 123, 150, 154], "filestore_ti": [119, 123], "filesystem": [5, 35, 198, 200, 258, 260, 292, 293, 306, 311, 326, 329, 348, 355, 388, 389], "fill": [332, 338, 340, 347], "film": [332, 338, 340, 343, 346, 347], "filmbr": [340, 347], "filmmak": [340, 343], "filter": [8, 55, 75, 77, 87, 89, 112, 114, 119, 122, 127, 129, 137, 140, 150, 153, 155, 198, 201, 232, 239, 258, 261, 342, 346, 347, 375, 376, 378, 381], "filterwarn": [362, 366, 369, 373], "final": [1, 2, 6, 9, 16, 23, 41, 65, 77, 84, 89, 150, 153, 181, 186, 209, 214, 215, 222, 240, 250, 258, 261, 266, 270, 271, 277, 281, 282, 283, 284, 285, 289, 293, 294, 313, 319, 340, 346, 347, 348, 355, 362, 365, 369, 374, 375, 377, 381, 382, 385, 387, 388, 392, 394, 395, 400, 401, 403, 404], "find": [2, 3, 4, 5, 9, 21, 28, 30, 34, 61, 76, 77, 78, 79, 80, 84, 88, 89, 90, 91, 92, 101, 106, 112, 114, 119, 126, 127, 129, 137, 140, 141, 147, 150, 153, 162, 198, 200, 203, 206, 215, 220, 240, 246, 258, 259, 284, 326, 328, 340, 343, 346, 347], "fine": [6, 40, 78, 82, 90, 96, 108, 110, 181, 183, 184, 258, 284, 285, 288, 340, 346, 362, 366, 368, 382, 387, 395, 396, 400], "finer": [2, 22, 215, 221], "finest": [332, 336, 338], "finetun": [4, 5, 6, 32, 37, 41, 285, 289, 292, 293, 307, 312, 326, 331, 356, 360], "finish": [2, 24, 164, 165, 168, 215, 223, 258, 270, 369, 374, 382, 385, 395, 403], "fiorentina": [332, 338], "fiorina": [332, 338], "fir": [332, 338, 382, 383], "fire": [332, 338], "firewal": [101, 106, 119, 123, 126, 150, 154], "firewall_policy_nam": [119, 123, 150, 154], "first": [1, 2, 3, 5, 6, 10, 11, 13, 14, 16, 19, 21, 27, 36, 41, 68, 70, 72, 76, 77, 88, 89, 112, 115, 119, 122, 124, 127, 131, 137, 141, 143, 150, 153, 159, 164, 165, 168, 169, 173, 176, 181, 184, 193, 197, 203, 205, 207, 208, 209, 211, 212, 214, 215, 218, 220, 252, 254, 256, 258, 261, 271, 285, 289, 291, 292, 293, 295, 297, 300, 304, 313, 322, 323, 326, 330, 332, 336, 338, 340, 343, 346, 347, 362, 364, 366, 368, 375, 377, 381, 388, 390, 395, 400], "fit": [3, 4, 6, 9, 28, 31, 32, 35, 40, 41, 64, 164, 165, 168, 203, 206, 240, 249, 270, 275, 277, 281, 282, 285, 288, 289, 291, 292, 293, 294, 298, 300, 305, 306, 310, 311, 312, 313, 316, 318, 329, 340, 342, 348, 354, 362, 366, 367, 369, 373, 375, 379, 380, 382, 383, 385, 387, 388, 392, 393, 394, 395, 396, 401, 403], "fit_model": [6, 40, 285, 288], "five": [340, 346, 347, 362, 366, 369, 373, 395, 401], "fix": [258, 262, 348, 353, 362, 363, 375, 377, 388, 390], "flag": [77, 89], "flap": [340, 343], "flashi": [340, 347], "flatten": [362, 364, 395, 397], "flavor": [75, 87], "flawless": [332, 338], "fleet": [340, 343, 347, 388, 389], "flew": [332, 338], "flexibl": [2, 7, 8, 10, 23, 43, 45, 46, 51, 69, 81, 95, 164, 165, 170, 181, 182, 183, 215, 222, 225, 226, 228, 229, 232, 235, 252, 255, 294, 295, 315, 316, 321, 332, 334, 340, 342, 348, 354], "flexibli": [295, 321], "flink": [7, 46, 225, 229], "flip": [395, 396], "flip_sin_to_co": [5, 35, 326, 329], "flippen": [340, 346], "float": [2, 3, 4, 5, 6, 8, 9, 10, 20, 28, 31, 32, 35, 40, 41, 51, 62, 70, 203, 206, 215, 219, 232, 235, 240, 247, 252, 256, 258, 268, 280, 285, 288, 289, 291, 292, 293, 294, 295, 298, 300, 304, 310, 311, 312, 317, 322, 326, 329, 332, 339, 362, 365, 369, 372, 375, 379, 382, 386, 388, 392], "float16": [5, 35, 326, 329], "float32": [10, 70, 252, 256, 291, 298, 332, 338, 339, 362, 364, 369, 371, 374, 375, 379, 388, 390, 391, 394], "floral": [112, 114, 127, 129, 137, 140], "flore": [332, 338], "flow": [46, 81, 95, 101, 106, 181, 186, 189, 191, 229, 369, 370], "flush": [2, 20, 164, 165, 171, 173, 177, 178, 181, 184, 215, 219], "fly": [258, 272], "fmt": [382, 386], "fn_arg": [181, 186], "fn_call": [181, 186], "fn_callabl": [181, 186], "fn_constructor_arg": [382, 386, 387, 388, 394, 395, 404], "fn_constructor_kwarg": [9, 62, 240, 247, 294, 295, 317, 322], "fn_kwarg": [294, 317], "fname": [388, 390], "foam": [332, 338], "focu": [84, 181, 183, 193, 196, 258, 272, 340, 343, 388, 389], "focus": [0, 7, 43, 45, 108, 110, 164, 165, 167, 189, 192, 225, 226, 228, 332, 338, 388, 394], "folder": [3, 4, 8, 9, 10, 28, 31, 53, 62, 70, 74, 76, 78, 86, 88, 90, 181, 184, 202, 203, 206, 232, 237, 240, 247, 252, 256, 333, 341, 349, 357, 382, 387, 388, 394, 395, 404], "follow": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 16, 18, 30, 31, 32, 34, 35, 36, 41, 45, 48, 51, 57, 62, 68, 72, 73, 74, 75, 76, 77, 80, 84, 85, 86, 87, 88, 89, 92, 98, 101, 104, 106, 108, 110, 112, 113, 119, 121, 126, 127, 128, 130, 135, 137, 139, 142, 147, 148, 150, 152, 155, 162, 163, 164, 165, 171, 173, 175, 181, 184, 187, 189, 191, 192, 193, 197, 198, 201, 202, 207, 208, 209, 214, 215, 217, 225, 228, 231, 232, 235, 240, 242, 247, 252, 254, 258, 259, 261, 272, 273, 285, 289, 292, 293, 294, 295, 306, 311, 312, 316, 318, 321, 326, 328, 329, 330, 340, 347, 348, 354, 369, 374, 375, 376, 381, 382, 383, 388, 389, 394, 395, 396, 398], "followup": [340, 347], "fontsiz": [362, 364, 395, 397], "food": [363, 368, 404], "food101": [362, 364, 395, 396, 397, 404], "food101_diffusion_ft": [362, 366], "food101_diffusion_result": [362, 366], "food101_ft_resum": [395, 401, 404], "food101_ft_run": [395, 404], "food101_lit": [362, 364, 395, 397, 398, 400, 401, 404], "food101_single_run": [395, 404], "food101dataset": [396, 399, 404], "footag": [332, 338], "footbal": [332, 336, 338], "footer": 0, "forbidden": [292, 293, 305, 311, 313], "forc": [258, 271, 389, 391, 394, 395, 404], "forcibli": [340, 346], "ford": [340, 343], "forecast": 394, "foreground": [340, 347], "foregroundbr": [340, 347], "forest": [384, 386], "forg": [11, 72, 207, 208], "forget": [332, 338, 340, 347], "forgotten": [340, 347], "forgottenbr": [340, 347], "fork": 0, "form": [2, 18, 215, 217, 291, 297, 298, 340, 347, 375, 377], "format": [6, 9, 39, 59, 61, 84, 181, 183, 184, 185, 186, 188, 202, 240, 244, 246, 258, 272, 275, 285, 287, 293, 309, 348, 353, 362, 364, 375, 377, 388, 390, 395, 396, 397], "fort": [340, 346], "forum": [173, 180, 181, 188], "forward": [5, 35, 258, 259, 262, 273, 279, 292, 300, 326, 329, 332, 338, 348, 353, 365, 366, 369, 370, 372, 373, 375, 376, 378, 382, 384, 388, 391, 394], "found": [6, 41, 101, 106, 258, 264, 279, 282, 283, 285, 289, 293, 311, 340, 347, 362, 368, 369, 374, 375, 376, 382, 385, 395, 404], "foundat": [6, 7, 40, 43, 172, 181, 188, 225, 226, 285, 288, 293, 310, 375, 381], "four": [4, 5, 32, 36, 164, 165, 168, 258, 261, 326, 330, 375, 377], "fourth": [332, 338, 340, 346, 347], "fox": [332, 338], "foxx": [332, 338], "fp16": [164, 165, 169, 173, 175, 179], "fp8": [173, 179], "frac": [395, 398], "fraction": [10, 17, 25, 68, 216, 224, 252, 254, 321, 356, 360], "fragrant": [332, 338], "frame": [382, 384, 385], "framework": [3, 4, 5, 8, 10, 27, 28, 30, 34, 43, 48, 50, 67, 69, 84, 188, 203, 205, 206, 226, 231, 232, 234, 252, 253, 255, 258, 259, 291, 294, 295, 297, 298, 316, 320, 321, 326, 328, 340, 342, 356, 358], "franc": [164, 165, 171, 181, 184], "francisco": [181, 186], "frank": [332, 338], "fraud": [7, 46, 225, 229], "freak": [340, 346], "free": [2, 21, 77, 78, 79, 83, 84, 89, 90, 91, 100, 173, 179, 215, 220, 258, 271, 332, 334, 338, 348, 350, 382, 387, 388, 394, 395, 404], "freed": [258, 271], "freeli": [8, 51, 232, 235, 294, 316], "freq_shift": [5, 35, 326, 329], "frequenc": [5, 35, 326, 329, 375, 377, 382, 384], "frequent": [7, 43, 46, 225, 226, 229], "fresh": [258, 271], "fri": [395, 396], "friction": [1, 13, 209, 211], "fridai": [332, 338], "friend": [332, 338], "friendli": [78, 82, 90, 96, 173, 175, 193, 197, 362, 364, 375, 381, 395, 396, 397], "frighten": [340, 346, 347], "frill": [340, 347], "from": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 18, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 41, 46, 50, 52, 53, 55, 56, 57, 59, 61, 62, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 90, 91, 92, 95, 98, 100, 101, 105, 106, 108, 111, 112, 113, 114, 116, 119, 120, 123, 125, 126, 127, 128, 129, 131, 132, 134, 137, 138, 141, 143, 144, 146, 147, 150, 151, 159, 160, 161, 162, 164, 165, 167, 168, 169, 171, 173, 174, 176, 177, 178, 179, 181, 183, 184, 185, 186, 188, 189, 192, 193, 195, 197, 198, 200, 201, 203, 204, 205, 206, 207, 208, 215, 217, 220, 222, 224, 225, 229, 232, 234, 236, 237, 239, 240, 241, 242, 244, 246, 247, 252, 253, 254, 257, 259, 260, 261, 262, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 283, 284, 285, 286, 289, 291, 292, 293, 294, 295, 298, 300, 302, 304, 305, 309, 310, 311, 312, 315, 316, 317, 322, 323, 324, 326, 327, 328, 330, 332, 334, 335, 336, 338, 339, 340, 342, 343, 346, 347, 348, 351, 352, 353, 356, 359, 361, 363, 364, 366, 370, 371, 373, 376, 379, 381, 383, 384, 385, 389, 390, 392, 394, 395, 396, 397, 398, 400, 402, 403, 404], "from_directori": [4, 32, 258, 268, 280, 292, 304, 375, 379, 388, 392, 394, 395, 400, 404], "from_huggingfac": [332, 336], "from_item": [193, 197, 295, 322, 340, 344, 362, 364, 369, 371, 388, 394], "from_numpi": [388, 394, 395, 404], "from_pretrain": [5, 35, 326, 329, 348, 353], "from_pydict": [395, 397], "from_pylist": [388, 390], "from_torch": [9, 59, 240, 244], "fromarrai": [258, 276], "front": [382, 384, 395, 397], "frontal": [340, 343], "fr\u00e9chet": [362, 368], "fsdp": [4, 32, 258, 260, 265, 284], "ft": [332, 336, 338], "fuck": [332, 338], "full": [3, 5, 8, 9, 28, 35, 51, 57, 63, 78, 90, 96, 101, 104, 106, 108, 110, 137, 147, 181, 184, 193, 197, 198, 201, 203, 206, 232, 235, 240, 242, 248, 263, 270, 278, 284, 294, 317, 326, 329, 340, 346, 347, 362, 363, 369, 370, 375, 377, 379, 381, 382, 385, 388, 392, 395, 397, 398, 402, 404], "full_path": [395, 398], "fulli": [2, 4, 5, 18, 30, 34, 73, 81, 84, 85, 94, 101, 102, 215, 217, 258, 259, 261, 272, 277, 295, 323, 326, 328, 362, 363, 366, 369, 370, 375, 376, 377, 379, 382, 383, 385, 395, 396, 400], "fullyshardeddataparallel": [4, 32, 258, 265], "function": [2, 3, 4, 5, 6, 8, 9, 10, 12, 16, 20, 25, 28, 32, 33, 35, 36, 41, 43, 47, 51, 52, 53, 54, 59, 61, 64, 65, 69, 76, 80, 88, 92, 137, 147, 173, 176, 181, 183, 186, 188, 203, 206, 210, 214, 215, 219, 224, 226, 230, 232, 235, 236, 237, 238, 240, 244, 246, 249, 250, 252, 255, 258, 261, 262, 265, 267, 268, 276, 285, 289, 292, 293, 294, 302, 303, 304, 306, 311, 312, 313, 316, 318, 319, 326, 327, 329, 330, 332, 338, 340, 345, 347, 350, 352, 355, 356, 360, 362, 364, 369, 370, 373, 374, 375, 376, 377, 379, 382, 383, 387, 388, 389, 395, 396, 400], "fundament": [2, 10, 17, 69, 108, 110, 163, 164, 165, 166, 167, 171, 198, 199, 215, 216, 252, 255, 295, 321], "further": [9, 59, 62, 75, 87, 240, 244, 247, 258, 270, 340, 347, 356, 360, 395, 398], "fuse": [9, 61, 240, 246], "futur": [1, 8, 15, 54, 198, 201, 209, 213, 232, 238, 340, 343, 346, 347, 369, 370, 388, 389, 390, 391, 392], "future_tru": [388, 394], "g": [0, 1, 2, 6, 7, 8, 9, 10, 13, 19, 20, 22, 41, 43, 46, 53, 57, 59, 61, 68, 69, 74, 76, 77, 79, 80, 83, 86, 88, 89, 91, 92, 99, 100, 101, 106, 108, 110, 111, 112, 113, 119, 120, 126, 127, 128, 137, 138, 150, 151, 162, 173, 179, 189, 191, 193, 195, 198, 200, 209, 211, 215, 218, 219, 221, 225, 226, 229, 232, 237, 240, 242, 244, 246, 252, 254, 255, 258, 262, 263, 268, 269, 270, 272, 274, 278, 281, 284, 285, 289, 291, 293, 294, 298, 312, 316, 317, 332, 334, 336, 338, 375, 379, 382, 385, 388, 394], "g54aiirwj1": [76, 88], "g54aiirwj1s8t9ktgzikqur41k": [76, 88], "gain": [375, 381, 382, 386], "galaxi": [332, 338], "galleri": [332, 338], "gallo": [340, 343], "gambl": [340, 346], "game": [332, 338], "gan": [362, 363], "gandhi": [332, 338], "gang": [340, 346], "gannon": [340, 346], "gap": [7, 43, 181, 184, 225, 226, 295, 324, 388, 390], "gape": [340, 343], "garbag": [1, 13, 209, 211, 258, 260, 271], "garden": [332, 338], "gate": [173, 176, 177, 181, 185, 186], "gatewai": [101, 106, 112, 114, 127, 129, 137, 140], "gather": [3, 28, 77, 89, 203, 206, 395, 397], "gaussian": [362, 363, 368, 369, 371, 388, 394], "gb": [2, 18, 76, 88, 173, 175, 179, 215, 217], "gc": [8, 53, 108, 110, 119, 120, 126, 150, 162, 181, 184, 232, 237, 258, 260, 268, 271, 284, 375, 381, 395, 404], "gca": [382, 386], "gce": [101, 102, 108, 111, 124, 150, 153, 405], "gcloud": [119, 121, 122, 150, 152, 153, 155, 156, 162], "gcp": [80, 81, 92, 94, 101, 102, 106, 108, 110, 111, 121, 122, 123, 125, 126, 150, 152, 153, 154, 158, 163], "gcp_if_": [119, 123], "gcp_project_id": [119, 122, 123, 150, 153, 154, 156, 162], "gcp_region": [119, 122, 123, 150, 153, 154, 155, 156, 160, 162], "gcs_bucket_nam": [119, 123, 126, 150, 154, 162], "gear": [332, 338], "gee": [332, 338], "gener": [1, 8, 9, 10, 11, 13, 35, 52, 54, 60, 62, 64, 70, 72, 76, 77, 78, 82, 88, 89, 90, 96, 119, 123, 168, 172, 181, 183, 184, 185, 186, 187, 188, 193, 197, 198, 200, 201, 202, 207, 208, 209, 211, 232, 236, 238, 240, 245, 247, 249, 252, 256, 258, 260, 271, 284, 292, 294, 295, 300, 306, 316, 317, 318, 323, 329, 332, 333, 334, 337, 340, 341, 343, 349, 357, 366, 370, 374, 375, 376, 381, 388, 389, 394], "generate_synthetic_imag": [193, 197], "generated_bi": [193, 197], "generative_cv": [362, 366, 368], "genit": [340, 343], "geniu": [340, 347], "genr": [375, 381], "geo": [382, 383], "german": [340, 347], "germani": [332, 338, 340, 347], "get": [3, 4, 5, 7, 10, 11, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 32, 36, 40, 46, 70, 72, 74, 76, 77, 78, 82, 86, 88, 89, 90, 97, 101, 106, 112, 113, 114, 115, 119, 123, 124, 127, 128, 129, 131, 133, 134, 135, 137, 139, 141, 143, 145, 146, 147, 148, 150, 156, 157, 159, 166, 172, 173, 176, 178, 179, 182, 184, 186, 193, 196, 198, 200, 201, 203, 204, 206, 207, 208, 216, 217, 218, 219, 220, 221, 222, 224, 225, 229, 252, 256, 258, 261, 262, 271, 288, 291, 295, 296, 298, 310, 313, 322, 323, 326, 330, 332, 338, 340, 346, 347, 348, 353, 356, 360, 361, 362, 363, 366, 368, 369, 373, 374, 375, 377, 379, 382, 385, 388, 390, 392, 394, 395, 397, 400, 404], "get_best_result": [3, 6, 28, 41, 203, 206, 285, 289, 291, 293, 298, 311, 313], "get_checkpoint": [258, 278, 279, 284, 362, 364, 366, 369, 371, 373, 375, 377, 379, 382, 384, 385, 387, 388, 390, 392, 395, 396, 397, 400], "get_config_dict": [5, 35, 326, 329], "get_context": [3, 4, 28, 32, 203, 206, 258, 262, 267, 268, 273, 279, 280, 292, 302, 304, 306, 362, 364, 366, 369, 371, 373, 375, 377, 379, 382, 384, 385, 388, 390, 392, 395, 397, 400], "get_current_temperatur": [181, 186], "get_dataset_shard": [5, 36, 258, 274, 326, 330, 362, 366, 369, 373, 375, 377, 379, 382, 384, 385], "get_devic": [5, 33, 35, 326, 327, 329, 348, 353], "get_linear_schedule_with_warmup": [5, 33, 35, 326, 327, 329], "get_model": [382, 385, 386], "get_scor": [382, 386, 387], "get_temperature_d": [181, 186], "get_us": 202, "get_user_profil": 202, "get_world_rank": [3, 4, 28, 32, 203, 206, 258, 267, 268, 280, 292, 304, 306, 362, 366, 369, 373, 375, 379, 382, 385, 388, 392, 395, 400], "get_world_s": [4, 32, 258, 262, 273, 279, 292, 302, 306], "getbucketloc": [101, 106], "getenv": [75, 76, 87, 88], "getlogg": [198, 201], "getobject": [101, 106], "getsizeof": [2, 18, 215, 217], "gettempdir": [362, 366, 369, 373], "gettingstart": 84, "getvalu": [362, 364, 395, 397], "gh": 0, "ghetto": [332, 338], "giant": [340, 347], "gib": [291, 293, 298, 311, 313], "gift": [332, 338], "girl": [332, 338], "git": [0, 79, 80, 83, 84, 91, 92, 100], "github": [0, 11, 72, 79, 84, 91, 101, 106, 127, 130, 132, 137, 142, 144, 150, 157, 160, 207, 208, 388, 390], "githubusercont": [388, 390], "give": [6, 40, 73, 75, 79, 80, 85, 87, 91, 92, 137, 141, 164, 165, 170, 258, 261, 280, 285, 288, 293, 310, 340, 346, 375, 377, 381, 382, 384], "given": [1, 3, 4, 6, 7, 9, 14, 28, 32, 41, 46, 47, 48, 64, 80, 92, 181, 186, 198, 201, 203, 206, 209, 212, 225, 229, 230, 231, 240, 249, 285, 289, 292, 293, 294, 304, 312, 318, 356, 360, 362, 365, 369, 370, 372, 382, 383, 388, 389], "gke": [101, 102, 104, 108, 111, 153, 154, 156, 159, 405], "glanc": [73, 85], "glass": [332, 338], "glob": [362, 368, 369, 371, 374], "global": [112, 114, 119, 123, 127, 129, 137, 140, 150, 153, 154, 258, 262, 362, 365, 375, 377, 395, 398, 400], "global_batch_s": [4, 32, 258, 262, 263, 269, 273, 277, 279, 280, 282, 292, 302, 305, 306, 348, 354], "gloriou": [340, 346], "gloss": [340, 347], "gm": [332, 336, 338], "go": [2, 19, 73, 85, 101, 106, 164, 165, 170, 173, 179, 181, 184, 215, 218, 332, 334, 338, 340, 346, 347, 395, 397], "goal": [3, 28, 83, 84, 99, 203, 206, 332, 338, 348, 350, 369, 370, 395, 396], "goaldotcom": [332, 338], "god": [332, 338], "goe": [77, 80, 89, 92, 332, 336, 338, 340, 343], "gold": [340, 346], "golions2012": [332, 338], "gone": [340, 347], "gonna": [332, 338], "good": [6, 7, 40, 48, 112, 114, 127, 129, 137, 140, 173, 175, 193, 197, 225, 231, 258, 260, 271, 275, 285, 288, 293, 310, 332, 338, 340, 343, 346, 347, 382, 386, 388, 390], "googl": [7, 43, 101, 103, 104, 108, 111, 121, 123, 152, 225, 226, 332, 338], "google_cloud": [150, 153], "google_project_id": [119, 123, 150, 154, 162], "google_region": [119, 123, 150, 154, 162], "googleapi": [119, 122, 150, 153], "gore": [340, 347], "got": [2, 24, 215, 223, 332, 338, 340, 347], "gotrib": [332, 338], "gotten": [340, 347], "gpu": [2, 3, 6, 7, 8, 9, 10, 11, 22, 25, 26, 28, 29, 30, 33, 34, 38, 40, 41, 47, 55, 57, 61, 62, 66, 68, 69, 72, 73, 75, 85, 87, 108, 111, 112, 118, 127, 130, 137, 142, 164, 165, 166, 167, 168, 169, 170, 173, 174, 175, 176, 177, 179, 180, 181, 182, 187, 188, 189, 191, 193, 195, 203, 204, 206, 207, 208, 215, 221, 224, 225, 230, 232, 239, 240, 242, 246, 247, 251, 252, 254, 255, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 271, 272, 277, 284, 285, 286, 288, 289, 291, 293, 294, 296, 298, 305, 310, 311, 313, 315, 317, 321, 327, 328, 332, 334, 338, 339, 348, 350, 353, 354, 355, 356, 360, 362, 363, 366, 368, 369, 370, 373, 374, 375, 376, 379, 381, 382, 385, 389, 395, 396, 399, 401, 404], "grab": [362, 364, 395, 404], "gracefulli": [79, 83, 91, 99, 356, 361], "grad": [258, 262], "grade": [164, 165, 166, 170, 173, 180, 181, 188, 362, 368], "grader": [332, 338], "gradient": [3, 4, 5, 28, 32, 36, 203, 206, 258, 259, 262, 265, 268, 291, 292, 298, 302, 326, 330, 348, 353, 382, 383, 384, 388, 390], "gradual": [83, 99, 193, 197, 362, 363, 382, 383], "grafana": [77, 79, 83, 89, 91, 99, 173, 179, 191, 198, 200, 201], "grai": [4, 6, 9, 31, 32, 39, 60, 240, 245, 258, 260, 271, 285, 287, 292, 293, 295, 300, 306, 309, 323], "grain": [2, 10, 22, 69, 108, 110, 215, 221, 252, 255], "grand": [332, 338], "grant": [101, 106, 108, 110, 340, 343], "granular": [80, 92, 198, 201], "granularli": [295, 323], "graph": [1, 2, 13, 19, 189, 192, 193, 197, 209, 211, 215, 218], "grass": [340, 347], "grayscal": [4, 6, 31, 39, 258, 260, 261, 271, 285, 287, 292, 293, 300, 309], "great": [80, 92, 173, 178, 332, 338, 340, 347, 356, 361], "greater": [76, 77, 88, 89, 291, 298], "greec": [332, 338], "green": [362, 363, 395, 396], "grei": [332, 338], "grep": [112, 114, 127, 129, 133, 134, 135, 137, 140, 145, 146, 148], "grid": [6, 41, 258, 260, 271, 285, 289, 293, 312, 362, 366, 369, 373, 374, 375, 379, 388, 390, 392, 394, 395, 402], "grim": [340, 346, 347], "grimnoir": [340, 347], "ground": [9, 61, 64, 240, 246, 249, 258, 260, 294, 318, 369, 371, 388, 389, 392, 394, 395, 404], "ground_truth_label": [9, 64, 240, 249, 294, 318], "group": [49, 56, 73, 77, 80, 81, 85, 89, 92, 94, 105, 107, 108, 110, 112, 114, 118, 127, 129, 137, 140, 141, 147, 163, 233, 241, 258, 259, 269, 293, 311, 313, 314, 332, 338, 362, 363, 375, 381, 388, 389, 395, 396, 397, 398, 402], "groupbi": [7, 47, 55, 225, 230, 239, 375, 377, 379, 388, 392, 395, 402], "grouplen": [375, 377], "grow": [1, 3, 13, 27, 84, 203, 205, 209, 211, 291, 297, 340, 343], "grpc": [7, 10, 48, 68, 70, 225, 231, 252, 254, 256, 295, 322], "gserviceaccount": [119, 123, 150, 154], "gsutil": [119, 126, 150, 162], "gt": [340, 347], "guarante": [7, 47, 181, 185, 225, 230, 258, 268], "guard": [375, 379, 395, 402], "gucci": [332, 338], "gui": [332, 338], "guid": [4, 5, 9, 11, 32, 36, 59, 72, 79, 84, 91, 100, 108, 110, 112, 113, 127, 128, 137, 138, 150, 151, 163, 173, 180, 181, 183, 184, 185, 186, 188, 189, 190, 192, 198, 199, 201, 207, 208, 240, 244, 258, 268, 292, 293, 304, 306, 313, 326, 330, 332, 338, 348, 355, 356, 360], "gunman": [340, 346], "gym": [369, 370, 371, 374], "gymnasium": [369, 370, 371], "gz": [292, 293, 305, 311, 313], "h": [4, 10, 31, 70, 202, 252, 256, 258, 271, 292, 300, 362, 363, 364, 365, 388, 390, 395, 404], "ha": [2, 4, 5, 7, 11, 18, 30, 31, 34, 46, 47, 48, 72, 73, 75, 76, 77, 80, 81, 83, 85, 87, 88, 89, 92, 94, 99, 101, 104, 119, 126, 137, 147, 150, 162, 173, 175, 181, 184, 188, 193, 197, 198, 201, 207, 208, 215, 217, 225, 229, 230, 231, 258, 259, 261, 275, 276, 295, 323, 326, 328, 332, 336, 338, 339, 340, 343, 346, 347, 348, 353, 356, 361, 375, 377], "had": [8, 54, 232, 238, 332, 338, 340, 343], "hadoop": [7, 46, 225, 229], "hahha": [332, 338], "hail": [340, 347, 388, 389], "half": [332, 338, 340, 346, 347, 388, 389, 390], "halfstarv": [340, 347], "halloween": [332, 336, 338], "halv": [6, 41, 285, 289, 293, 312], "ham": [332, 338], "hamburg": [395, 396], "hand": [11, 72, 84, 163, 164, 165, 172, 181, 183, 207, 208, 332, 338, 340, 346, 375, 377, 395, 396], "handheld": [340, 347], "handl": [2, 3, 7, 9, 10, 20, 22, 25, 28, 43, 46, 47, 48, 57, 68, 69, 73, 78, 83, 84, 85, 90, 96, 99, 101, 106, 108, 109, 110, 150, 157, 164, 165, 167, 170, 173, 176, 178, 181, 185, 189, 191, 193, 197, 202, 203, 206, 215, 219, 221, 224, 225, 226, 229, 230, 231, 240, 242, 252, 254, 255, 258, 259, 260, 261, 262, 264, 266, 271, 272, 273, 277, 278, 280, 283, 291, 295, 298, 323, 332, 339, 340, 342, 348, 350, 353, 356, 358, 362, 363, 366, 368, 369, 370, 371, 375, 376, 377, 379, 381, 382, 384, 385, 388, 389, 395, 396, 397, 399, 400, 402], "handwritten": [6, 10, 39, 40, 70, 252, 256, 258, 260, 285, 287, 288, 293, 309, 310], "hang": [189, 191, 340, 346, 347, 369, 370], "happen": [1, 6, 7, 15, 41, 48, 193, 197, 209, 213, 225, 231, 258, 280, 285, 289, 293, 311, 340, 346, 347], "happi": [332, 338], "happybirthdayremuslupin": [332, 336, 338, 339], "hard": [340, 346, 347], "hardli": [340, 343], "hardwar": [4, 5, 9, 10, 30, 34, 57, 61, 62, 68, 69, 75, 77, 84, 87, 89, 164, 165, 169, 170, 175, 176, 177, 188, 240, 242, 246, 247, 252, 254, 255, 258, 259, 272, 280, 326, 328, 348, 350, 353, 354, 355, 382, 383], "hark": [340, 346], "harm": [12, 210], "harri": [332, 338], "hasattr": [395, 400], "hasek": [332, 338], "hash": [8, 54, 232, 238], "hashicorp": [112, 113, 119, 121, 127, 128, 137, 139, 150, 152], "hashtag": [332, 338], "hat": [375, 376, 395, 396], "hater": [332, 338], "have": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 20, 23, 24, 26, 32, 36, 41, 45, 46, 53, 57, 61, 62, 64, 68, 70, 72, 74, 75, 76, 80, 84, 86, 87, 88, 92, 112, 113, 114, 118, 119, 121, 127, 128, 129, 130, 136, 137, 139, 140, 142, 149, 150, 152, 164, 165, 168, 173, 180, 193, 197, 198, 199, 203, 204, 207, 208, 215, 219, 222, 223, 225, 228, 229, 232, 237, 240, 242, 246, 247, 249, 252, 254, 256, 258, 268, 277, 285, 289, 292, 293, 294, 295, 301, 312, 316, 318, 321, 326, 330, 332, 338, 340, 343, 344, 345, 346, 347, 348, 353, 356, 358, 375, 376, 382, 384, 385, 395, 396, 404], "hdf": [7, 8, 46, 53, 225, 229, 232, 237], "he": [332, 338, 340, 346, 347], "head": [2, 8, 18, 22, 51, 53, 73, 75, 76, 77, 78, 79, 80, 85, 87, 88, 89, 90, 91, 92, 99, 101, 105, 106, 108, 110, 127, 134, 137, 146, 193, 196, 197, 215, 217, 221, 232, 235, 237, 293, 311, 313, 340, 347, 362, 366, 369, 373, 382, 384, 388, 390, 394], "head_nod": [127, 134, 137, 146], "header": [0, 4, 31, 292, 300, 375, 381], "headlei": [332, 336, 338], "headless": [108, 110], "headnodeconfig": [127, 134, 137, 146], "health": [83, 99, 108, 109, 164, 165, 169, 202, 362, 366], "healthi": [75, 79, 87, 91, 388, 392], "heap": [2, 24, 215, 223], "hear": [332, 338], "heard": [340, 343], "heart": [340, 346, 388, 392], "heat": [356, 361], "heatmap": [382, 386], "heaven": [340, 346], "heavi": [4, 8, 9, 32, 54, 64, 73, 85, 232, 238, 240, 249, 258, 272, 294, 318], "heavili": [340, 347], "heavli": [258, 266], "hebdo": [332, 338], "hei": [101, 106, 332, 338], "height": [9, 61, 193, 197, 240, 246, 294, 295, 317, 323, 362, 364, 382, 387], "held": [332, 338], "hell": [332, 338], "hello": [74, 76, 78, 82, 86, 88, 90, 97, 98, 164, 198, 201, 332, 338], "hello_world": [11, 72, 74, 78, 86, 90, 207, 208], "helm": [108, 109, 127, 128, 129, 130, 132, 135, 137, 139, 140, 142, 144, 148, 150, 152, 157, 160, 162], "helm_upgrade_command": [127, 129, 137, 140], "help": [6, 7, 9, 11, 40, 46, 61, 72, 74, 86, 101, 104, 108, 110, 164, 165, 168, 189, 191, 198, 200, 207, 208, 225, 229, 240, 246, 258, 260, 285, 288, 293, 295, 310, 323, 340, 347, 382, 384, 386, 388, 389, 390], "helper": [181, 186, 258, 260, 265, 266, 267, 268, 375, 377, 382, 384, 390, 396, 404], "helper_tool_map": [181, 186], "her": [332, 338, 340, 343, 346, 347], "here": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 16, 17, 25, 26, 28, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 52, 53, 54, 55, 56, 59, 61, 64, 67, 69, 70, 71, 84, 112, 114, 127, 129, 137, 147, 164, 165, 166, 167, 170, 173, 174, 180, 181, 182, 184, 185, 187, 188, 193, 197, 198, 199, 200, 201, 203, 204, 206, 209, 210, 213, 214, 215, 216, 224, 225, 226, 227, 228, 229, 231, 232, 233, 236, 237, 238, 239, 240, 241, 244, 246, 249, 252, 253, 255, 256, 257, 258, 260, 262, 263, 270, 271, 273, 280, 284, 285, 286, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 300, 301, 302, 304, 306, 307, 308, 310, 311, 312, 314, 316, 317, 318, 320, 321, 322, 323, 326, 327, 329, 330, 331, 332, 334, 338, 340, 342, 344, 346, 347, 348, 350, 356, 358, 360, 362, 363, 364, 369, 370, 375, 376], "herm": [181, 186], "hero": [332, 338, 340, 347], "herself": [340, 347], "heteregen": [9, 57, 240, 242], "heterogen": [3, 7, 8, 9, 28, 47, 55, 57, 66, 203, 206, 225, 230, 232, 239, 240, 242, 251, 294, 315, 317], "hf": [173, 176], "hf_d": [362, 364], "hf_dataset": [332, 336], "hf_token": [173, 176, 177, 178, 179, 181, 184, 185, 186], "hi": [332, 336, 338, 340, 343, 346, 347], "hidden": [0, 340, 347, 369, 374], "hide": [340, 346], "hierarch": [198, 201], "hierarchi": [81, 95], "high": [2, 4, 5, 6, 7, 9, 10, 22, 31, 32, 36, 40, 43, 46, 47, 61, 68, 69, 79, 83, 91, 99, 101, 106, 164, 165, 167, 168, 169, 170, 181, 187, 215, 221, 225, 226, 229, 230, 240, 246, 252, 254, 255, 258, 261, 269, 285, 288, 292, 293, 295, 300, 302, 310, 321, 326, 330, 332, 338, 339, 340, 347, 356, 358, 361, 369, 374, 375, 376, 377, 379, 395, 396], "higher": [7, 47, 76, 88, 164, 165, 168, 173, 179, 180, 181, 187, 225, 230, 258, 272, 294, 315, 375, 376, 377], "highest": [340, 346, 362, 366, 375, 381], "highli": [101, 106, 108, 110, 193, 197, 382, 384], "highlight": [2, 5, 7, 18, 36, 46, 215, 217, 225, 229, 258, 268, 326, 330, 340, 347, 375, 377, 382, 386], "hike": [332, 338], "him": [332, 338, 340, 346, 347], "himself": [332, 338, 340, 346], "hindu": [332, 338], "hint": [1, 2, 4, 5, 6, 9, 16, 25, 32, 36, 41, 61, 209, 214, 215, 224, 240, 246, 285, 289, 292, 293, 306, 312, 326, 330, 348, 351], "hire": [340, 346], "hist": [3, 28, 203, 206, 375, 377, 382, 385], "histor": [7, 43, 46, 225, 226, 229, 375, 376, 388, 389], "histori": [181, 186, 258, 270, 375, 379, 388, 390, 392, 394, 395, 402, 404], "hit": [112, 114, 127, 129, 137, 140, 193, 197, 332, 338, 375, 381], "hitchhik": [332, 338], "hiya": [332, 338], "hmu": [332, 338], "hmw": [332, 338], "hoc": [369, 370, 382, 386], "hogan": [332, 338], "hogwart": [332, 336, 338, 339], "hold": [8, 9, 51, 59, 232, 235, 240, 244, 258, 262, 294, 316, 348, 353], "hole": [332, 338], "holidai": [388, 394], "hollywood": [332, 338, 340, 346, 347], "home": [76, 88, 293, 311, 332, 338], "homebrew": [112, 113, 127, 128, 137, 139, 150, 152, 189, 192], "homecom": [332, 338], "homepath": [189, 192], "hong": [340, 346], "hood": [2, 9, 19, 59, 215, 218, 240, 244, 258, 264], "hook": [340, 346, 347, 369, 374], "hop": [332, 338], "hope": [332, 338, 340, 346], "horizon": [388, 390, 391, 392, 394], "horizont": [173, 176, 179], "horribl": [340, 347], "horror": [340, 347], "hospit": [340, 347], "host": [4, 32, 73, 74, 81, 85, 86, 93, 94, 101, 104, 106, 108, 111, 258, 266, 362, 363], "hostnam": [292, 306], "hot": [10, 71, 252, 257, 382, 386, 395, 396], "hotwif": [332, 338], "hour": [164, 165, 169, 193, 197, 291, 298, 332, 338, 362, 364, 388, 389, 390, 394, 395, 397], "hourli": [389, 394], "hous": [340, 346], "housekeep": [258, 260], "hoverboard": [332, 338], "how": [2, 3, 4, 5, 6, 7, 20, 28, 31, 32, 33, 35, 36, 41, 42, 44, 49, 51, 52, 53, 54, 56, 62, 73, 76, 79, 81, 83, 84, 85, 88, 91, 93, 100, 102, 112, 114, 119, 120, 123, 127, 129, 137, 140, 147, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175, 178, 182, 183, 186, 188, 193, 197, 198, 199, 201, 202, 203, 206, 215, 219, 225, 227, 233, 235, 236, 237, 238, 241, 247, 261, 262, 263, 264, 268, 272, 273, 278, 280, 285, 289, 290, 292, 293, 294, 295, 300, 302, 311, 312, 314, 322, 323, 326, 327, 329, 330, 332, 333, 334, 336, 338, 339, 340, 341, 342, 345, 346, 347, 348, 349, 350, 355, 356, 357, 361, 377, 379, 381, 385, 390, 404], "howev": [2, 7, 8, 9, 22, 46, 53, 54, 64, 108, 110, 215, 221, 225, 229, 232, 237, 238, 240, 249, 258, 268, 294, 318, 340, 346], "html": [0, 11, 72, 82, 83, 96, 99, 112, 113, 127, 128, 137, 139, 164, 165, 171, 207, 208, 293, 313, 332, 336, 348, 355, 356, 358, 360], "http": [0, 3, 7, 10, 11, 28, 48, 70, 72, 77, 79, 82, 83, 84, 89, 91, 96, 99, 100, 101, 106, 108, 111, 112, 113, 119, 121, 127, 128, 130, 132, 137, 139, 142, 144, 147, 150, 152, 157, 160, 164, 165, 171, 173, 177, 178, 181, 184, 185, 186, 189, 192, 198, 201, 202, 203, 206, 207, 208, 225, 231, 252, 256, 291, 292, 293, 295, 298, 305, 311, 313, 322, 323, 332, 336, 348, 355, 356, 358, 360, 361, 375, 377, 388, 390], "huddleston": [332, 338], "hudi": [7, 43, 225, 226], "hug": [173, 176, 177, 181, 184, 186, 332, 334, 336, 339, 340, 343, 351, 352, 355, 356, 359, 361, 395, 396, 397, 404], "huge": [340, 347], "huggingfac": [4, 5, 30, 34, 164, 165, 171, 173, 176, 177, 178, 181, 184, 185, 326, 328, 332, 335], "huggingface_hub": [181, 184], "hugo": [340, 347], "hulk": [332, 338], "human": [8, 51, 232, 235, 258, 268, 332, 338], "humbl": [340, 346], "humor": [340, 346, 347], "hundr": [382, 383], "hunt": [332, 338], "hurt": [332, 338], "hustl": [332, 338], "hvar": [332, 338], "hxwxc": [193, 197], "hybrid": [181, 187, 375, 381], "hydrologi": [382, 383], "hyperband": [6, 41, 285, 289, 293, 312], "hyperparam": [388, 394], "hyperparamet": [4, 5, 7, 26, 32, 36, 38, 40, 42, 46, 204, 225, 229, 258, 262, 263, 269, 277, 280, 282, 286, 288, 290, 291, 292, 298, 302, 308, 310, 311, 312, 326, 330, 362, 368, 369, 374, 375, 381, 382, 385, 387, 388, 394, 395, 404], "hypnot": [340, 347], "i": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 31, 32, 33, 35, 36, 38, 39, 40, 41, 43, 44, 46, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 99, 106, 108, 109, 111, 112, 116, 117, 119, 123, 125, 127, 128, 129, 133, 134, 135, 137, 138, 140, 145, 146, 147, 148, 150, 151, 161, 163, 166, 168, 169, 170, 174, 177, 181, 182, 183, 184, 185, 186, 187, 189, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 226, 227, 229, 233, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 269, 271, 272, 274, 275, 276, 278, 279, 280, 282, 285, 286, 287, 288, 289, 291, 292, 293, 294, 295, 296, 300, 301, 302, 304, 306, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 326, 327, 329, 330, 332, 334, 336, 337, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 350, 353, 354, 355, 360, 361, 362, 363, 364, 366, 368, 369, 370, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384, 385, 388, 389, 390, 391, 392, 393, 395, 396, 397, 398, 400, 401, 402, 404], "iam": [104, 105, 107, 108, 110, 111, 112, 113, 114, 118, 119, 120, 122, 123, 127, 128, 129, 139, 140, 147, 150, 153, 154], "ic": [332, 338], "iceberg": [7, 9, 43, 59, 225, 226, 240, 244], "ichiro": [332, 338], "icon": [74, 86, 181, 185, 340, 347], "id": [12, 73, 77, 85, 89, 107, 112, 114, 119, 122, 123, 127, 129, 131, 132, 137, 140, 143, 144, 150, 153, 154, 159, 160, 181, 184, 186, 193, 197, 198, 201, 202, 210, 258, 269, 340, 344, 345, 346, 347, 348, 353, 376, 395, 397], "idea": [112, 114, 127, 129, 137, 140, 340, 347], "ideal": [3, 7, 28, 43, 46, 74, 86, 173, 175, 180, 203, 206, 225, 226, 229, 340, 347, 382, 384, 388, 394], "ident": [80, 92, 101, 106, 108, 111, 119, 123, 127, 129, 137, 140, 150, 154, 258, 259, 268, 273], "identifi": [112, 114, 127, 129, 137, 140, 173, 176, 181, 184, 193, 197, 258, 267, 268], "idiot": [332, 338, 340, 347], "idl": [112, 114, 127, 129, 137, 140, 164, 165, 168, 169], "idx": [5, 35, 258, 271, 326, 329, 375, 381, 388, 390, 395, 398, 404], "idx1": [292, 293, 305, 313], "idx2item": [375, 381], "idx3": [292, 293, 305, 311, 313], "ig": [332, 338], "ignor": [362, 366, 369, 373], "iid": [375, 377, 381], "ill": [332, 338], "illustr": [9, 59, 84, 108, 110, 240, 244, 332, 338, 362, 368], "iloc": [5, 35, 326, 329, 375, 381, 388, 390, 394, 395, 398], "im": [332, 338, 340, 347], "imag": [2, 4, 5, 6, 7, 9, 21, 29, 31, 32, 35, 36, 39, 40, 41, 43, 59, 60, 61, 62, 67, 73, 76, 79, 83, 85, 88, 91, 100, 108, 110, 164, 165, 171, 173, 178, 193, 197, 198, 201, 215, 220, 225, 226, 240, 244, 245, 246, 247, 253, 260, 261, 262, 266, 271, 273, 274, 275, 279, 285, 287, 288, 289, 292, 293, 294, 295, 300, 301, 302, 305, 306, 309, 310, 311, 313, 316, 317, 322, 323, 326, 329, 330, 340, 347, 365, 368, 404], "image_arr": [258, 276], "image_arrai": [193, 197], "image_batch": [295, 323], "image_byt": [362, 364, 395, 397, 398, 404], "image_bytes_raw": [362, 364], "image_classifi": [295, 323], "image_classifier_ingress": [295, 323], "image_height": [193, 197], "image_id": [9, 61, 193, 197, 240, 246], "image_latents_256": [5, 35, 326, 329], "image_uri": [164, 165, 171, 173, 178, 193, 197], "image_width": [193, 197], "imagebatchpredictor": [395, 404], "imagenet": [258, 261, 395, 397, 398], "imagenet_mean": [395, 398, 404], "imagenet_std": [395, 398, 404], "imageri": [340, 347], "imageserviceingress": [295, 323], "imagin": [340, 346, 347], "imbalanc": [382, 384], "imdb": [340, 342, 343, 344, 346, 347], "img": [4, 9, 31, 32, 60, 240, 245, 258, 260, 271, 362, 364, 368, 395, 397, 398, 404], "immatur": [7, 47, 225, 230], "immedi": [1, 2, 7, 9, 15, 22, 46, 60, 79, 83, 91, 100, 164, 165, 168, 209, 213, 215, 221, 225, 229, 240, 245, 258, 282, 362, 367, 395, 398], "immut": [2, 18, 215, 217], "impact": [7, 47, 76, 88, 164, 165, 168, 169, 181, 187, 225, 230, 340, 347], "implement": [1, 4, 5, 6, 7, 8, 9, 16, 32, 35, 36, 40, 43, 47, 48, 54, 61, 62, 67, 68, 79, 83, 91, 100, 101, 105, 198, 201, 202, 209, 214, 225, 226, 230, 231, 232, 238, 240, 246, 247, 253, 254, 258, 261, 262, 272, 285, 288, 293, 294, 310, 317, 320, 321, 326, 329, 330, 332, 334, 337, 395, 396], "implementaiton": [292, 303], "impli": [340, 343], "implicit": [362, 368], "import": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 16, 17, 22, 26, 28, 29, 31, 33, 38, 49, 56, 67, 71, 72, 74, 75, 76, 77, 78, 79, 82, 83, 86, 87, 88, 89, 90, 91, 97, 98, 100, 164, 165, 171, 173, 176, 177, 178, 179, 181, 184, 185, 186, 193, 196, 197, 198, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 214, 215, 216, 221, 232, 233, 240, 241, 252, 253, 257, 267, 285, 286, 291, 292, 293, 294, 295, 298, 300, 302, 303, 304, 305, 309, 310, 311, 316, 317, 322, 323, 326, 327, 334, 342, 347, 350, 358, 361, 366, 368, 373, 379, 383, 387, 392, 394, 400, 404], "import_path": [79, 83, 91, 100, 164, 165, 171, 173, 178, 181, 185], "importance_typ": [382, 386], "imposs": [340, 347], "impress": [340, 347], "improv": [1, 8, 9, 10, 16, 54, 55, 57, 66, 68, 181, 184, 185, 189, 191, 193, 196, 209, 214, 232, 238, 239, 240, 242, 251, 252, 254, 258, 272, 362, 368, 382, 383, 387, 388, 392, 394], "imshow": [4, 6, 9, 31, 32, 39, 60, 240, 245, 258, 260, 271, 285, 287, 292, 293, 295, 300, 306, 309, 323, 362, 364, 368, 395, 397, 404], "in_channel": [4, 5, 31, 35, 258, 261, 292, 300, 326, 329], "in_count": [77, 89], "in_featur": [292, 300, 306], "in_proj": [388, 391], "inaccess": [193, 197], "incept": [362, 368], "includ": [0, 2, 3, 4, 7, 8, 9, 10, 21, 22, 28, 31, 32, 43, 46, 47, 51, 64, 69, 74, 75, 76, 77, 78, 79, 82, 86, 87, 88, 89, 90, 91, 96, 101, 104, 108, 110, 112, 118, 127, 136, 137, 149, 164, 165, 169, 181, 184, 189, 191, 192, 198, 200, 203, 206, 215, 220, 221, 225, 226, 229, 230, 232, 235, 240, 249, 252, 255, 258, 270, 280, 283, 291, 292, 296, 298, 305, 306, 348, 350, 353, 354, 356, 358, 375, 377, 379, 388, 392, 395, 402], "include_path": [9, 59, 61, 240, 244, 246, 294, 295, 316, 323], "incom": [295, 321, 395, 404], "incomplet": [258, 266], "incorpor": [7, 43, 225, 226, 395, 396], "incorrect_squar": [2, 20, 215, 219], "increas": [164, 165, 168, 173, 179, 193, 197, 258, 284, 356, 361, 362, 368, 375, 379], "increasingli": [11, 72, 207, 208], "increment": [7, 43, 79, 83, 91, 99, 225, 226, 395, 396], "incur": [7, 47, 198, 201, 225, 230], "independ": [8, 9, 10, 55, 59, 69, 76, 88, 173, 179, 232, 239, 240, 244, 252, 255, 258, 264, 272, 276, 388, 389, 392, 395, 398], "index": [0, 3, 7, 28, 43, 82, 83, 96, 99, 198, 200, 203, 206, 225, 226, 258, 260, 271, 356, 358, 375, 377, 382, 384, 385, 388, 390, 395, 398, 404], "index_col": [382, 385], "indi": [340, 343], "indian": [332, 338], "indic": [2, 11, 22, 72, 207, 208, 215, 221, 258, 271, 375, 376, 377, 381, 382, 386, 395, 398], "individu": [1, 3, 16, 27, 193, 196, 203, 205, 209, 214, 291, 297], "indonesiasayshbdforjustinbieb": [332, 338], "industri": 405, "ineffect": [340, 346], "ineffici": [164, 165, 168, 332, 334], "infer": [2, 7, 8, 9, 10, 22, 25, 26, 46, 47, 48, 51, 55, 57, 62, 66, 70, 75, 78, 82, 83, 87, 90, 96, 99, 169, 174, 180, 181, 184, 187, 204, 215, 221, 224, 225, 229, 230, 231, 232, 235, 239, 240, 242, 247, 251, 252, 256, 259, 260, 268, 270, 284, 291, 294, 295, 298, 317, 319, 322, 333, 338, 341, 349, 356, 357, 360, 362, 363, 368, 369, 370, 374, 377, 383, 385, 389, 390, 396], "inference_mod": [258, 271], "inference_row": [395, 404], "inferf": [375, 376], "infinit": [9, 61, 240, 246], "influenc": [340, 347, 369, 370], "info": [11, 72, 173, 179, 198, 201, 207, 208, 291, 293, 298, 311, 313, 332, 338], "inform": [4, 32, 76, 88, 127, 128, 137, 138, 150, 151, 181, 186, 189, 192, 193, 197, 198, 200, 202, 258, 262, 292, 306, 332, 338, 356, 358, 395, 402], "infrastructur": [4, 5, 11, 30, 34, 72, 74, 79, 81, 83, 84, 86, 91, 93, 94, 99, 102, 103, 109, 110, 119, 120, 163, 169, 173, 178, 180, 181, 184, 188, 193, 196, 197, 207, 208, 258, 259, 281, 326, 328, 369, 370, 375, 381, 395, 396], "ingest": [3, 28, 203, 206, 258, 272, 277, 284, 291, 294, 298, 316, 382, 383, 384, 387, 395, 396], "ingmar": [340, 343], "ingress": [3, 28, 108, 110, 111, 135, 136, 148, 149, 162, 203, 206, 295, 323, 356, 360], "ingress_from_cidr_map": [101, 106], "ingress_with_self": [101, 106], "inher": 84, "inherit": [3, 27, 79, 83, 91, 100, 203, 205, 291, 297], "ini": [189, 192], "init": [11, 72, 77, 89, 112, 114, 119, 123, 127, 129, 137, 140, 150, 154, 207, 208, 258, 260, 332, 336, 340, 343, 348, 354], "initi": [2, 5, 7, 9, 11, 19, 35, 36, 47, 62, 72, 79, 91, 108, 110, 112, 114, 119, 123, 127, 129, 137, 140, 150, 154, 181, 184, 207, 208, 215, 218, 225, 230, 240, 247, 258, 259, 269, 271, 292, 294, 300, 302, 317, 326, 329, 330, 332, 333, 336, 337, 341, 342, 348, 349, 350, 353, 354, 357, 375, 376, 388, 389], "initial_replica": [295, 323], "inject": [198, 201, 258, 263, 266, 362, 363, 369, 370, 371, 372, 395, 399], "inlin": [356, 360], "inner": [340, 346], "inning": [332, 336, 338], "innings": [332, 336, 338], "innoc": [340, 346, 347], "inplac": [292, 300, 306, 382, 384], "input": [5, 8, 9, 10, 35, 51, 53, 54, 57, 61, 62, 63, 64, 65, 70, 76, 88, 164, 165, 167, 198, 200, 232, 235, 237, 238, 240, 242, 246, 247, 248, 249, 250, 252, 256, 258, 260, 261, 262, 272, 284, 291, 294, 295, 298, 316, 318, 319, 323, 326, 329, 332, 337, 340, 345, 348, 353, 356, 360, 365, 382, 383, 388, 389, 390, 391, 392, 394], "input_window": [388, 390, 391, 392, 394], "inputdatabuff": [9, 63, 240, 248], "inscrut": [7, 46, 225, 229], "insert": [164, 165, 168], "insid": [2, 8, 23, 25, 55, 76, 77, 81, 88, 89, 94, 198, 200, 201, 215, 222, 224, 232, 239, 258, 260, 263, 277, 340, 343, 362, 366, 369, 370, 382, 385, 387, 395, 396, 398, 404], "insight": [7, 46, 193, 195, 197, 225, 229], "inspect": [2, 3, 4, 5, 22, 28, 31, 32, 35, 76, 79, 88, 91, 203, 206, 215, 221, 259, 260, 284, 292, 300, 306, 326, 329, 332, 334, 362, 364, 397], "inspir": [332, 338], "instal": [2, 3, 21, 26, 74, 75, 76, 86, 87, 88, 108, 109, 111, 112, 113, 114, 121, 128, 129, 135, 136, 138, 139, 140, 148, 149, 151, 152, 156, 158, 163, 173, 177, 203, 204, 215, 220, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "instanc": [2, 3, 4, 8, 9, 11, 22, 25, 28, 31, 32, 54, 57, 64, 72, 73, 75, 77, 85, 87, 89, 105, 107, 108, 110, 114, 118, 123, 127, 134, 137, 146, 150, 154, 173, 179, 193, 197, 198, 201, 202, 203, 206, 207, 208, 215, 221, 224, 232, 238, 240, 242, 249, 258, 260, 266, 271, 291, 294, 298, 318, 332, 334, 340, 347, 360], "instance_iam_role_arn": [101, 107], "instance_profile_arn": [112, 114], "instance_typ": [127, 134, 137, 146, 193, 197], "instanceid": [112, 114, 127, 129, 137, 140], "instant": [74, 86], "instanti": [2, 5, 25, 35, 215, 224, 295, 322, 326, 329, 395, 396, 401], "instead": [2, 3, 4, 6, 8, 19, 20, 24, 28, 32, 41, 51, 53, 54, 76, 77, 79, 83, 88, 89, 91, 100, 203, 206, 215, 218, 219, 223, 232, 235, 237, 238, 258, 259, 264, 265, 272, 273, 274, 279, 285, 289, 292, 293, 303, 304, 313, 332, 334, 337, 340, 346, 347, 362, 363, 375, 376, 377, 382, 383, 385, 386, 388, 389, 395, 397, 400], "instruct": [75, 84, 87, 108, 109, 164, 165, 171, 173, 175, 176, 179, 181, 184, 185, 187], "instrument": [202, 332, 338], "insubordin": [340, 346], "int": [2, 3, 4, 5, 6, 9, 18, 20, 22, 28, 31, 32, 35, 39, 40, 41, 61, 64, 193, 197, 203, 206, 215, 217, 219, 221, 240, 246, 249, 258, 266, 267, 271, 274, 280, 285, 287, 288, 289, 292, 293, 294, 300, 303, 304, 309, 310, 312, 318, 326, 329, 362, 364, 365, 369, 371, 372, 375, 378, 382, 386, 387, 388, 390, 392, 395, 397, 399, 400, 404], "int32": [382, 386, 388, 390], "int4": [173, 179], "int64": [332, 336, 339, 340, 344, 345, 369, 371, 375, 377], "intact": [258, 262], "integ": [258, 276, 291, 298, 375, 376, 377, 395, 396], "integr": [3, 4, 5, 7, 8, 27, 30, 32, 34, 43, 46, 47, 48, 55, 73, 79, 83, 85, 91, 99, 101, 105, 108, 111, 163, 164, 165, 170, 173, 179, 181, 183, 185, 186, 188, 189, 191, 192, 193, 197, 198, 201, 203, 205, 225, 226, 229, 230, 231, 232, 239, 259, 266, 273, 274, 277, 291, 292, 297, 298, 303, 326, 328, 332, 334, 340, 342, 348, 354, 356, 358, 363, 369, 370, 373, 374, 375, 376, 382, 387, 388, 390, 395, 396, 404], "intellig": [7, 43, 181, 186, 225, 226], "intend": [76, 79, 88, 91, 340, 343, 348, 354], "intens": [2, 3, 6, 7, 11, 22, 28, 39, 47, 72, 164, 165, 169, 173, 175, 203, 206, 207, 208, 215, 221, 225, 230, 258, 272, 285, 287, 293, 309, 340, 347], "intent": [340, 346, 347, 362, 363, 382, 383], "interact": [7, 46, 74, 81, 84, 86, 94, 108, 110, 164, 165, 169, 170, 181, 186, 188, 225, 229, 295, 323, 340, 347, 375, 376, 377, 382, 387], "interconnect": [173, 179], "interest": [332, 338, 340, 343], "interfac": [3, 4, 7, 27, 31, 45, 189, 192, 203, 205, 225, 228, 258, 260, 272, 356, 358, 375, 379], "intermedi": [2, 4, 9, 19, 32, 57, 164, 165, 167, 215, 218, 240, 242, 258, 268, 292, 304, 382, 387, 388, 394, 395, 404], "intern": [6, 42, 101, 106, 193, 195, 258, 273, 285, 290, 375, 379, 381, 395, 399], "internet": [101, 106], "interoper": [7, 43, 225, 226], "interpret": [375, 381, 382, 387, 388, 394], "interrupt": [75, 87, 258, 280, 282, 388, 393, 395, 396], "interv": [5, 7, 35, 48, 225, 231, 295, 323, 326, 329, 388, 389, 390], "intervent": [258, 280, 375, 380, 388, 393, 395, 396], "interview": [8, 55, 232, 239, 294, 319, 332, 338], "intrigu": [340, 346, 347], "intro": [10, 71, 127, 128, 137, 139, 150, 152, 252, 257, 291, 298], "introduc": [1, 7, 10, 13, 46, 67, 74, 86, 189, 190, 193, 196, 209, 211, 225, 229, 252, 253, 295, 320], "introduct": [272, 294, 295, 308, 314, 320, 348, 350], "introductori": [84, 299], "intuit": [7, 48, 225, 231], "invari": [340, 343], "invent": [340, 346, 347, 388, 389], "invert_yaxi": [382, 386], "invest": [332, 336, 338], "invit": [81, 94], "invoc": [1, 14, 16, 209, 212, 214], "invok": [1, 2, 15, 16, 23, 209, 213, 214, 215, 222, 382, 387], "involv": [8, 9, 54, 64, 164, 165, 171, 232, 238, 240, 249, 294, 318, 332, 338, 340, 346, 347, 356, 358], "io": [0, 9, 11, 17, 58, 72, 127, 128, 130, 132, 137, 139, 142, 144, 150, 152, 157, 160, 207, 208, 216, 240, 243, 258, 260, 293, 313, 332, 336, 348, 355, 356, 358, 360, 362, 364, 388, 390, 395, 397, 398, 404], "iot": [7, 46, 225, 229], "ip": [101, 104, 106, 112, 114, 127, 129, 137, 140, 150, 157, 258, 269, 292, 293, 305, 306, 313, 395, 396], "ipykernel": [11, 72, 207, 208], "ipynb": [74, 76, 84, 86, 88], "iran": [332, 338], "iron": [332, 338], "irrupt": [332, 338], "is_avail": [4, 6, 31, 32, 40, 285, 288, 348, 353, 362, 368, 369, 374, 388, 394, 395, 404], "is_big_tip": [291, 298], "isdir": [258, 283, 395, 404], "isfil": [395, 404], "isinst": [2, 19, 215, 218], "islam": [332, 338], "isn": [4, 32, 137, 147, 164, 165, 169, 258, 266, 292, 303, 332, 338, 340, 343, 362, 368, 395, 396], "isol": [7, 10, 43, 69, 101, 103, 106, 225, 226, 252, 255], "issu": [1, 4, 5, 7, 13, 30, 34, 46, 77, 89, 137, 147, 150, 155, 181, 188, 189, 191, 193, 197, 209, 211, 225, 229, 258, 259, 271, 280, 326, 328, 340, 343, 395, 396], "itali": [332, 338], "itbr": [340, 347], "item": [1, 2, 4, 5, 6, 9, 16, 24, 31, 32, 35, 39, 41, 61, 181, 184, 189, 192, 193, 197, 209, 214, 215, 223, 240, 246, 258, 267, 285, 287, 289, 292, 293, 300, 304, 306, 309, 313, 326, 329, 340, 347, 348, 353, 362, 364, 369, 371, 378, 379, 382, 386, 388, 392, 394, 395, 400, 404], "item2idx": [375, 377, 381], "item_col": [375, 377], "item_embed": [375, 378, 381], "item_id": [375, 377, 381], "item_idx": [375, 376, 377, 378, 379], "item_metadata": [375, 381], "item_vec": [375, 378], "item_vector": [375, 381], "iter": [8, 9, 10, 52, 58, 68, 73, 74, 85, 86, 164, 165, 168, 181, 187, 232, 236, 240, 243, 252, 254, 258, 262, 274, 291, 293, 298, 311, 313, 348, 353, 362, 363, 366, 368, 369, 373, 374, 375, 377, 379, 380, 382, 387, 388, 390], "iter_torch_batch": [258, 272, 274, 284, 362, 366, 369, 373, 375, 376, 379, 381], "iterations_since_restor": [292, 306], "iterrow": [375, 381], "its": [1, 2, 4, 6, 7, 8, 9, 10, 13, 18, 22, 31, 41, 43, 53, 55, 59, 69, 76, 79, 81, 83, 88, 91, 94, 99, 137, 147, 164, 165, 168, 170, 173, 179, 193, 196, 197, 198, 200, 201, 209, 211, 215, 217, 221, 225, 226, 232, 237, 239, 240, 244, 252, 255, 258, 259, 260, 262, 269, 270, 271, 285, 289, 293, 294, 313, 316, 319, 332, 334, 338, 340, 347, 356, 358, 361, 362, 363, 364, 375, 376, 379, 382, 383, 384, 385, 386, 388, 389, 395, 398, 400], "itself": [8, 51, 193, 197, 232, 235], "iv": [340, 347], "j": [0, 1, 16, 209, 214, 332, 338, 375, 377, 381], "jack": [340, 346], "jackson": [332, 338], "jadwal": [332, 338], "jai": [332, 336, 338, 340, 346], "jail": [332, 338], "jame": [332, 338, 340, 346], "jami": [332, 338], "jan": [332, 338], "janet": [332, 338], "januari": [332, 336, 338], "java": [7, 46, 225, 229], "jean": [340, 347], "jeanmarc": [340, 347], "jeff": [340, 346], "jgz99": [173, 178], "jit": [9, 10, 62, 70, 240, 247, 252, 256, 294, 295, 317, 322], "job": [3, 5, 6, 28, 30, 34, 36, 41, 75, 76, 77, 80, 81, 87, 88, 89, 92, 94, 101, 106, 108, 110, 111, 112, 116, 118, 119, 125, 127, 134, 137, 146, 147, 150, 161, 181, 184, 193, 195, 197, 198, 200, 203, 206, 258, 259, 261, 262, 264, 268, 269, 271, 277, 278, 280, 281, 284, 285, 289, 293, 299, 301, 306, 311, 326, 328, 330, 332, 336, 338, 339, 340, 346, 347, 362, 368, 369, 374, 375, 381, 382, 383, 387, 388, 394, 395, 396, 401, 404, 405], "job_config": [78, 82, 90, 98], "job_descript": [181, 184], "job_id": [78, 82, 90, 98], "jobconfig": [78, 82, 90, 98], "joe": [332, 338], "john": [332, 336, 338, 340, 343, 346], "johnson": [332, 338, 340, 343], "joi": [332, 338], "join": [4, 5, 7, 8, 31, 32, 36, 47, 55, 76, 88, 101, 106, 181, 184, 188, 193, 197, 202, 225, 230, 232, 239, 258, 268, 271, 279, 280, 292, 300, 304, 306, 326, 330, 332, 338, 342, 344, 347, 362, 366, 368, 369, 373, 374, 377, 379, 382, 384, 385, 388, 390, 392, 394, 395, 397, 400, 404], "join_typ": [340, 346], "joint": [362, 363, 388, 389, 395, 397], "joke": [173, 177], "journei": [202, 340, 347], "jpeg": [7, 43, 225, 226, 362, 363, 364, 368, 395, 397], "jq": [112, 114, 127, 129, 137, 140], "json": [3, 7, 9, 10, 28, 43, 59, 67, 70, 165, 171, 182, 183, 184, 186, 188, 198, 201, 202, 203, 206, 225, 226, 240, 244, 252, 253, 256, 291, 295, 298, 322, 323, 356, 361, 362, 364, 369, 371, 375, 377, 382, 384, 395, 397, 400], "json_method1": [181, 185], "json_request": [10, 70, 198, 201, 252, 256, 295, 322, 323], "json_schema": [181, 185], "juda": [332, 338], "judg": [340, 346, 382, 384], "juggl": [10, 68, 252, 254], "jule": [332, 338], "jump": [10, 70, 252, 256, 295, 322, 340, 347, 369, 370], "jun": [332, 338], "june": [3, 28, 84, 150, 153, 203, 206, 291, 298], "jupyt": [75, 87], "jupyter_execute_notebook": 0, "jupyterlab": [74, 86], "just": [6, 8, 40, 41, 51, 53, 74, 80, 86, 92, 112, 116, 119, 125, 127, 134, 137, 146, 150, 161, 164, 165, 169, 181, 186, 232, 235, 237, 258, 272, 280, 285, 288, 289, 293, 294, 312, 316, 332, 338, 340, 343, 344, 346, 347, 362, 363, 364, 375, 376, 395, 397, 404], "justifi": [332, 338, 340, 346], "justin": [332, 338], "j\u00e4reg\u00e5rd": [340, 347], "k": [164, 165, 168, 332, 336, 338, 348, 353, 369, 370, 374, 375, 381, 382, 383, 388, 394, 395, 404], "k8": [101, 102, 104, 111, 127, 129, 130, 134, 137, 140, 142, 146, 150, 153, 161, 163, 189, 192, 405], "kafka": [7, 46, 225, 229], "katharina": [340, 347], "ke": [332, 338], "keep": [5, 35, 75, 80, 87, 92, 164, 165, 171, 258, 259, 261, 262, 268, 271, 272, 273, 280, 283, 326, 329, 332, 338, 339, 340, 345, 362, 364, 366, 369, 370, 373, 374, 375, 376, 377, 379, 382, 384, 385, 388, 392, 394, 395, 397, 400, 401, 402, 404], "keeper": [340, 346], "kei": [6, 7, 8, 9, 10, 31, 41, 43, 54, 56, 64, 69, 76, 84, 88, 104, 106, 108, 110, 112, 114, 127, 129, 137, 140, 166, 167, 171, 179, 198, 200, 225, 226, 232, 238, 240, 241, 249, 252, 255, 258, 260, 261, 262, 268, 273, 279, 285, 289, 293, 294, 312, 318, 348, 350, 375, 381, 382, 385, 386, 395, 400], "kenni": [332, 338], "kept": [332, 338, 375, 377], "kernel": [11, 72, 108, 111, 164, 165, 170, 207, 208, 258, 261], "kernel_s": [4, 6, 31, 40, 41, 258, 261, 285, 288, 289, 292, 293, 300, 306, 310, 313], "kerri": [332, 336, 338], "kessler": [340, 347], "keylogg": [181, 184], "kick": [375, 379, 395, 401], "kiddo": [332, 338], "kill": [6, 41, 258, 271, 285, 289, 293, 312, 340, 343, 346, 347, 362, 364], "kim": [332, 338], "kind": [11, 72, 207, 208, 382, 384], "kingdom": [340, 347], "kitchen": [332, 338], "klaviyo": [295, 324], "klondik": [340, 346], "km": [101, 106], "know": [2, 7, 24, 47, 181, 184, 193, 197, 215, 223, 225, 230, 258, 278, 280, 340, 346, 347, 388, 389], "knowledg": [163, 173, 180, 198, 199, 382, 386, 387], "known": [362, 363], "kong": [340, 346], "kpop": [332, 338], "kri": [332, 338], "kube": [127, 130, 135, 137, 142, 147, 148], "kubeconfig": [127, 130, 137, 142], "kubectl": [127, 128, 130, 133, 134, 135, 137, 139, 142, 145, 146, 147, 148, 152, 157, 162], "kuberai": [189, 192], "kubernet": [10, 68, 101, 103, 104, 128, 129, 131, 136, 139, 140, 143, 149, 152, 153, 157, 159, 162, 163, 252, 254], "kucinich": [332, 338], "kueue": [108, 110], "kurt": [332, 338], "kv": [167, 169, 172, 173, 179, 382, 386], "kv_cache_util": [173, 179], "kvedzwag2qa8i5bj": [173, 178], "l": [3, 4, 8, 9, 28, 31, 32, 51, 53, 59, 137, 147, 203, 206, 232, 235, 237, 240, 244, 292, 294, 300, 316, 362, 363, 369, 370, 375, 376, 395, 396], "l4": [164, 165, 171, 181, 184, 185], "l40": [173, 176, 177, 179, 181, 186], "l6": [332, 337], "lab": [6, 41, 285, 289, 293, 312], "label": [3, 4, 6, 9, 10, 28, 31, 32, 39, 40, 41, 61, 62, 64, 70, 198, 199, 203, 206, 240, 246, 247, 249, 252, 256, 258, 260, 262, 271, 273, 274, 275, 276, 279, 285, 287, 288, 289, 291, 292, 293, 294, 298, 300, 302, 305, 306, 309, 310, 313, 317, 318, 332, 336, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 352, 353, 356, 361, 362, 364, 366, 368, 369, 373, 375, 379, 382, 384, 385, 386, 387, 388, 392, 394, 397, 398, 402, 404], "label_col": [382, 385], "label_column": [3, 28, 203, 206, 291, 298, 382, 385], "label_nam": [362, 364, 395, 397, 404], "labeled_batch": [9, 61, 240, 246], "labia": [340, 343], "labour": [332, 338], "lack": [7, 43, 47, 225, 226, 230], "lag": [388, 394], "lai": [332, 338], "lakehous": [9, 59, 240, 244, 258, 272, 284], "lambda": [5, 35, 76, 88, 193, 197, 326, 329, 340, 345, 382, 386, 387], "land": [0, 382, 383], "landscap": [46, 229, 356, 361, 405], "languag": [4, 5, 7, 32, 37, 43, 45, 46, 167, 225, 226, 228, 229, 292, 307, 326, 331, 375, 381], "laptop": [11, 72, 207, 208, 340, 342], "lar": [340, 347], "larami": [340, 346], "larg": [0, 3, 4, 5, 7, 8, 9, 17, 18, 19, 25, 28, 32, 35, 36, 43, 46, 55, 57, 76, 88, 167, 168, 169, 173, 175, 180, 181, 187, 193, 197, 203, 206, 216, 217, 218, 224, 225, 226, 229, 232, 239, 240, 242, 258, 278, 292, 294, 301, 315, 326, 329, 330, 332, 334, 337, 339, 340, 342, 345, 347, 348, 350, 353, 354, 355, 356, 358, 362, 363, 364, 368, 375, 377, 381, 382, 383, 384, 387, 388, 389, 394, 395, 397], "large_mat_from_object_stor": [2, 18, 215, 217], "large_matrix": [2, 18, 215, 217], "larger": [7, 47, 76, 88, 225, 230, 258, 284, 295, 323, 340, 345, 362, 368, 369, 374, 375, 376, 395, 404], "largest": [181, 184], "last": [2, 4, 5, 7, 24, 30, 34, 46, 47, 79, 83, 91, 100, 137, 141, 164, 165, 168, 181, 186, 215, 223, 225, 229, 230, 259, 266, 270, 278, 279, 280, 294, 315, 326, 328, 332, 336, 338, 339, 348, 355, 375, 379, 380, 382, 385, 387, 388, 390, 392, 395, 398, 402], "last_login": 202, "lastmodifi": [76, 88], "latenc": [7, 10, 46, 48, 68, 76, 88, 168, 172, 173, 179, 181, 187, 198, 201, 225, 229, 231, 252, 254, 369, 374, 395, 404], "latent": [5, 35, 326, 329, 375, 376], "later": [6, 40, 74, 86, 164, 165, 170, 202, 258, 260, 264, 268, 270, 275, 276, 285, 288, 292, 293, 295, 300, 310, 323, 340, 347, 362, 364, 365, 369, 372, 375, 376, 377, 379, 382, 384, 395, 398], "latest": [4, 11, 32, 72, 74, 86, 112, 113, 127, 128, 137, 139, 150, 158, 207, 208, 258, 270, 278, 279, 280, 281, 282, 292, 306, 332, 336, 340, 346, 356, 358, 360, 366, 369, 370, 373, 374, 375, 376, 379, 380, 381, 388, 389, 392, 393, 394, 395, 396, 403], "latin": [375, 381], "laugh": [332, 338], "laughter": [332, 338], "launch": [1, 2, 3, 5, 6, 8, 9, 10, 12, 17, 24, 26, 29, 33, 38, 49, 56, 67, 75, 79, 80, 81, 83, 87, 91, 92, 94, 99, 101, 103, 164, 165, 166, 174, 181, 182, 199, 203, 204, 209, 210, 215, 216, 223, 232, 233, 240, 241, 252, 253, 262, 264, 271, 285, 286, 299, 302, 326, 327, 332, 334, 340, 342, 345, 348, 350, 356, 358, 363, 370, 382, 383, 385, 387, 389, 394, 396], "layer": [3, 27, 101, 103, 173, 176, 179, 203, 205, 258, 261, 362, 368, 375, 377, 388, 389], "layer1": [292, 300, 306], "layer2": [292, 300, 306], "layer3": [292, 300, 306], "layer4": [292, 300, 306], "layers_per_block": [5, 35, 326, 329], "layout": [375, 377], "lazi": [8, 51, 52, 56, 232, 235, 236, 241, 294, 317, 332, 338, 339, 375, 377, 382, 384], "lbc": [127, 130, 137, 142], "lbl": [362, 364], "le": [332, 338], "lead": [2, 7, 22, 24, 47, 215, 221, 223, 225, 230, 332, 338, 340, 347], "leader": [332, 338], "leagu": [332, 338], "leakag": [388, 390], "lean": [395, 396], "learn": [2, 3, 4, 5, 6, 8, 9, 20, 22, 27, 32, 35, 41, 43, 46, 55, 66, 112, 118, 164, 165, 166, 173, 180, 188, 193, 194, 195, 203, 205, 215, 219, 221, 226, 229, 232, 239, 240, 251, 260, 262, 270, 285, 289, 292, 293, 294, 303, 306, 312, 319, 326, 329, 332, 333, 334, 337, 339, 340, 341, 342, 343, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 358, 368, 374, 377, 378, 379, 381, 384, 390, 392, 394, 397, 404], "learning_r": [258, 263], "least": [2, 20, 22, 101, 106, 108, 110, 111, 164, 165, 171, 215, 219, 221], "leav": [4, 31, 73, 75, 79, 85, 87, 91, 112, 114, 127, 129, 340, 346, 362, 366, 382, 384, 387, 388, 394, 395, 404], "lecun": [292, 293, 305, 311], "left": [1, 7, 16, 48, 74, 75, 86, 87, 164, 165, 168, 209, 214, 225, 231, 340, 347, 375, 380, 381, 382, 387, 388, 393], "leftarrow": [362, 363, 369, 370], "leftov": [258, 283], "legend": [362, 366, 369, 373, 375, 379, 388, 392, 394, 395, 402], "leigh": [332, 338], "lemieux": [332, 338], "len": [2, 4, 5, 24, 31, 32, 35, 77, 89, 215, 223, 258, 260, 271, 326, 329, 340, 344, 356, 360, 375, 377, 379, 381, 382, 384, 385, 386, 387, 388, 390, 392, 395, 397, 398], "lena": [340, 343], "length": [9, 57, 112, 114, 127, 129, 137, 140, 164, 165, 167, 168, 169, 173, 176, 181, 187, 240, 242, 356, 360, 388, 390], "leo": [340, 347], "leopold": [340, 347], "lesnar": [332, 338], "less": [181, 184, 340, 343, 362, 368], "lesson": [291, 296], "let": [1, 2, 3, 4, 5, 6, 8, 9, 10, 16, 18, 19, 20, 22, 24, 25, 26, 28, 31, 32, 35, 36, 39, 40, 41, 51, 52, 53, 54, 59, 60, 62, 64, 65, 70, 74, 75, 76, 79, 80, 86, 87, 88, 91, 92, 119, 123, 127, 129, 130, 137, 142, 164, 165, 169, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 198, 200, 203, 204, 206, 209, 214, 215, 217, 218, 219, 221, 223, 224, 232, 235, 236, 237, 238, 240, 244, 245, 247, 249, 250, 252, 256, 258, 260, 261, 262, 266, 268, 285, 287, 288, 289, 291, 292, 293, 294, 295, 296, 300, 301, 302, 305, 309, 310, 311, 316, 318, 319, 322, 323, 325, 326, 329, 330, 362, 363, 364, 365, 366, 369, 370, 375, 376, 382, 383, 384, 388, 392, 395, 397, 399, 404], "level": [0, 4, 5, 6, 7, 10, 17, 20, 31, 32, 36, 40, 46, 69, 77, 80, 89, 92, 101, 106, 108, 111, 164, 165, 168, 170, 189, 191, 193, 196, 198, 201, 216, 219, 225, 229, 252, 255, 258, 261, 269, 285, 288, 292, 293, 295, 300, 302, 310, 321, 326, 330, 340, 343, 375, 377, 379, 388, 389, 394, 395, 396], "leverag": [7, 9, 10, 43, 57, 66, 68, 108, 109, 198, 201, 225, 226, 240, 242, 251, 252, 254, 332, 334, 339, 340, 342, 348, 350, 354, 362, 368, 369, 374, 382, 387], "lexu": [181, 185, 332, 338], "lgbm": [4, 5, 30, 34, 258, 259, 326, 328], "lh": [8, 53, 232, 237], "li": [340, 347], "liar": [332, 338], "lib": [76, 88, 332, 338], "libomp": [3, 26, 203, 204], "librari": [1, 4, 6, 7, 8, 9, 10, 13, 32, 40, 41, 46, 47, 50, 51, 59, 61, 62, 64, 69, 70, 73, 76, 77, 85, 88, 89, 193, 197, 209, 211, 225, 229, 230, 232, 234, 235, 240, 244, 246, 247, 249, 252, 255, 256, 258, 260, 285, 288, 289, 293, 294, 295, 310, 311, 315, 316, 317, 318, 322, 323, 333, 334, 341, 342, 349, 350, 352, 354, 357, 358, 361, 362, 364, 369, 371, 375, 377, 388, 390, 395, 397], "licens": [11, 72, 207, 208], "lie": [332, 338, 369, 371], "life": [332, 338, 340, 343, 347], "lifecycl": [7, 10, 48, 69, 76, 78, 82, 84, 88, 90, 96, 98, 108, 109, 110, 225, 231, 252, 255, 259, 292, 304], "lift": [73, 85], "light": [0, 9, 61, 240, 246, 332, 338], "lightli": 84, "lightn": [4, 30, 34, 328, 363, 364, 365, 368, 369, 370, 371, 373, 374], "lightning_training_loop": [5, 35, 326, 329], "lightningmodul": [5, 35, 326, 329, 363, 370], "lightweight": [10, 68, 77, 89, 252, 254, 332, 337, 375, 376, 377, 381, 382, 384, 388, 390, 394, 395, 396], "lik": [340, 347], "like": [2, 3, 4, 5, 6, 7, 8, 9, 19, 20, 21, 22, 28, 31, 32, 36, 41, 43, 46, 47, 48, 51, 53, 55, 62, 74, 75, 86, 87, 101, 107, 108, 110, 111, 112, 114, 115, 119, 122, 123, 124, 125, 127, 129, 131, 137, 140, 143, 146, 150, 159, 164, 165, 170, 173, 176, 177, 181, 185, 203, 206, 215, 218, 219, 220, 221, 225, 226, 229, 230, 231, 232, 235, 237, 239, 240, 247, 258, 259, 262, 263, 267, 269, 274, 285, 289, 292, 293, 294, 295, 300, 301, 302, 312, 316, 317, 323, 326, 330, 332, 338, 340, 342, 343, 346, 347, 348, 354, 356, 358, 361, 362, 368, 369, 374, 375, 376, 377, 381, 382, 383, 385], "likeeeeeeeee": [332, 338], "likelihood": [395, 396], "limit": [6, 7, 8, 41, 43, 53, 62, 75, 76, 87, 88, 108, 111, 112, 114, 127, 129, 137, 140, 164, 165, 167, 181, 184, 225, 226, 232, 237, 247, 285, 289], "limousin": [3, 8, 28, 51, 203, 206, 232, 235, 291, 298], "line": [74, 79, 83, 86, 91, 100, 189, 192, 340, 347, 362, 363, 388, 389, 395, 396], "linear": [2, 6, 25, 41, 215, 224, 285, 289, 292, 293, 300, 306, 312, 369, 372, 388, 391], "linearmodel": [2, 25, 215, 224], "lineup": [332, 336, 338, 339], "link": [0, 79, 91, 108, 110, 181, 183, 188, 258, 264], "linux": [189, 192], "list": [2, 3, 8, 9, 19, 28, 51, 53, 59, 65, 74, 76, 78, 81, 86, 88, 90, 94, 112, 114, 116, 117, 119, 122, 125, 127, 129, 133, 134, 135, 137, 140, 141, 145, 146, 148, 150, 153, 155, 161, 162, 164, 165, 169, 181, 184, 193, 197, 203, 206, 215, 218, 232, 235, 237, 240, 244, 250, 258, 270, 271, 275, 294, 316, 319, 340, 346, 362, 364, 369, 371, 375, 377, 381, 382, 384, 385, 388, 394], "list_": [388, 390], "list_objects_v2": [76, 88, 181, 184], "listbucket": [101, 106], "listbucketmultipartupload": [101, 106], "listdir": [395, 404], "listfil": [9, 63, 240, 248], "listmultipartuploadpart": [101, 106], "lit": [332, 336, 338], "lite": [362, 363, 364, 397], "liter": [332, 338], "littl": [332, 338, 340, 346, 347], "live": [332, 338, 340, 346, 356, 361, 375, 381, 388, 389], "ll": [4, 5, 6, 11, 32, 35, 40, 72, 73, 74, 77, 84, 85, 86, 89, 101, 102, 119, 121, 127, 131, 134, 137, 143, 146, 150, 152, 154, 159, 164, 165, 166, 172, 173, 174, 175, 176, 178, 182, 184, 193, 194, 207, 208, 260, 261, 263, 264, 269, 284, 285, 288, 293, 310, 326, 329, 332, 338, 340, 346, 388, 389], "llama": [164, 165, 171, 176, 177, 178, 179, 181, 184, 187], "llamafactoryai": [181, 184], "llm": [9, 57, 168, 172, 175, 177, 178, 180, 183, 185, 186, 188, 240, 242], "llm_config": [164, 165, 171, 173, 176, 179, 181, 184, 185, 186], "llmconfig": [164, 165, 171, 173, 176, 179, 181, 184, 186], "lo": [11, 72, 207, 208], "load": [2, 3, 7, 10, 22, 25, 28, 32, 35, 38, 43, 48, 49, 55, 56, 57, 62, 68, 70, 74, 75, 79, 83, 86, 87, 91, 99, 100, 101, 106, 108, 111, 112, 118, 135, 136, 148, 149, 164, 165, 170, 171, 173, 176, 178, 181, 184, 186, 203, 206, 215, 221, 224, 225, 226, 231, 233, 239, 241, 242, 247, 252, 254, 256, 259, 260, 266, 268, 272, 278, 280, 282, 284, 286, 291, 295, 298, 306, 308, 314, 315, 317, 322, 323, 329, 334, 337, 339, 342, 347, 348, 350, 351, 352, 353, 354, 355, 356, 358, 360, 363, 367, 368, 369, 374, 376, 379, 381, 383, 386, 387, 389, 392, 394, 396, 398, 400, 404], "load_data": [3, 28, 203, 206], "load_dataset": [332, 335, 336, 340, 343, 348, 351, 353, 362, 364, 388, 390, 395, 397, 404], "load_from_checkpoint": [5, 36, 326, 330], "load_model": [3, 28, 203, 206, 291, 298, 382, 385], "load_model_ray_train": [4, 32, 258, 262, 265, 273, 279, 292, 302, 303, 306], "load_model_torch": [4, 31, 292, 300], "load_state_dict": [4, 31, 32, 258, 271, 279, 292, 300, 306, 362, 368, 369, 374, 375, 379, 381, 388, 392, 394, 395, 400, 404], "loadbalanc": [108, 111], "loaded_df": [5, 35, 326, 329], "loaded_model": [4, 31, 292, 300], "loaded_model_ray_train": [4, 5, 32, 36, 292, 306, 326, 330], "loader": [4, 32, 258, 273, 274, 276, 279, 302, 303, 348, 350, 362, 366, 375, 376, 388, 390, 395, 396, 398, 399, 404], "loan": [332, 338], "loc": [291, 293, 298, 311, 313], "local": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 17, 23, 26, 28, 29, 31, 32, 33, 38, 46, 49, 53, 56, 62, 65, 67, 68, 70, 71, 79, 83, 84, 91, 100, 101, 106, 112, 115, 119, 124, 127, 131, 135, 137, 143, 148, 150, 159, 164, 165, 166, 171, 174, 180, 181, 182, 190, 191, 198, 199, 200, 201, 203, 204, 206, 209, 210, 215, 216, 222, 225, 229, 232, 233, 237, 240, 241, 247, 250, 252, 253, 254, 256, 257, 258, 259, 260, 268, 271, 272, 285, 286, 293, 294, 295, 304, 306, 311, 317, 321, 326, 327, 332, 334, 336, 338, 340, 342, 348, 350, 354, 355, 356, 358, 362, 363, 364, 366, 369, 370, 373, 375, 376, 382, 383, 385, 388, 389, 395, 400, 404], "local_fil": [76, 88], "local_file_path": [181, 184], "local_idx": [395, 398], "local_path": [4, 9, 10, 31, 32, 62, 70, 181, 184, 198, 201, 240, 247, 252, 256, 292, 294, 295, 300, 317, 322, 323], "local_pred_fold": [9, 65, 240, 250], "local_storag": [5, 35, 292, 300, 326, 329], "local_zip": [375, 377], "localhost": [0, 3, 10, 28, 70, 164, 165, 171, 173, 177, 181, 184, 185, 186, 198, 201, 203, 206, 252, 256, 291, 295, 298, 322, 323, 356, 361], "locat": [4, 11, 31, 32, 72, 76, 80, 88, 92, 119, 123, 150, 154, 181, 186, 198, 201, 207, 208, 258, 260, 268, 270, 382, 383], "lock": [11, 72, 77, 89, 207, 208, 333, 340, 341, 346, 349, 357], "lodg": [382, 383], "lofton": [332, 338], "log": [4, 5, 7, 9, 30, 32, 34, 35, 43, 46, 63, 74, 78, 79, 84, 86, 90, 91, 96, 101, 105, 106, 112, 115, 116, 119, 120, 124, 125, 127, 131, 134, 137, 143, 146, 147, 150, 159, 161, 164, 165, 170, 173, 179, 189, 191, 193, 195, 196, 197, 199, 202, 225, 226, 229, 240, 248, 258, 259, 260, 262, 267, 268, 269, 270, 273, 277, 282, 284, 291, 292, 293, 298, 304, 313, 326, 328, 329, 348, 355, 362, 365, 366, 368, 369, 370, 371, 372, 373, 374, 375, 376, 379, 382, 383, 385, 387, 388, 391, 392, 394, 395, 396, 400, 405], "log_engine_metr": [173, 176, 179], "log_every_n_step": [5, 35, 326, 329], "log_level": [198, 201], "log_result": [77, 89], "logdir": [291, 292, 298, 305, 348, 355], "logger": [198, 201], "logging_config": [198, 201], "logic": [2, 4, 5, 7, 9, 10, 22, 32, 36, 47, 48, 61, 69, 101, 103, 106, 181, 187, 215, 221, 225, 230, 231, 240, 246, 252, 255, 258, 261, 273, 279, 291, 292, 293, 295, 298, 305, 311, 313, 323, 326, 330, 348, 355, 356, 360, 361, 362, 363, 366, 368, 369, 370, 375, 376, 379, 388, 390, 395, 396, 400], "login": [74, 86, 112, 115, 119, 122, 124, 127, 131, 137, 143, 150, 153, 159], "logist": [291, 298], "logit": [9, 10, 62, 70, 240, 247, 252, 256, 258, 261, 271, 294, 295, 317, 322, 348, 352, 353, 395, 400, 404], "logloss": [291, 298], "loguniform": [6, 41, 285, 289, 293, 312, 313], "loki": [332, 338], "lol": [332, 338], "london": [332, 338], "long": [2, 3, 4, 5, 6, 22, 28, 30, 32, 34, 36, 40, 81, 94, 101, 105, 164, 165, 168, 169, 181, 187, 203, 206, 215, 221, 258, 259, 278, 285, 288, 291, 292, 293, 298, 301, 310, 326, 328, 330, 332, 338, 340, 347, 375, 377, 379, 388, 389], "longer": [4, 7, 32, 48, 225, 231, 258, 262, 271, 273, 283, 284, 362, 368], "longrightarrow": [369, 370, 388, 389], "look": [2, 3, 4, 6, 7, 8, 9, 25, 28, 31, 32, 41, 48, 54, 60, 64, 112, 114, 115, 119, 124, 127, 129, 131, 137, 140, 141, 143, 150, 159, 173, 180, 181, 184, 188, 198, 200, 203, 206, 215, 224, 225, 231, 232, 238, 240, 245, 249, 258, 260, 262, 274, 285, 289, 292, 294, 295, 300, 302, 318, 322, 323, 332, 336, 338, 340, 346, 347, 362, 368, 382, 384], "look_back_period_": [295, 323], "lookup": [375, 376], "loop": [12, 30, 34, 36, 181, 186, 210, 259, 260, 261, 263, 264, 268, 269, 270, 272, 276, 277, 278, 280, 281, 282, 284, 299, 304, 328, 330, 348, 350, 353, 362, 363, 366, 368, 374, 376, 383, 387, 389, 395, 396, 400, 404], "lora": [164, 165, 168, 172, 182, 183, 188], "lora_checkpoint": [181, 184], "lora_config": [181, 184], "lose": [258, 278, 281], "loss": [4, 5, 6, 31, 32, 35, 40, 41, 258, 260, 261, 262, 267, 268, 270, 273, 279, 285, 288, 289, 291, 292, 293, 298, 300, 302, 304, 305, 306, 310, 312, 313, 326, 329, 340, 347, 348, 353, 354, 355, 363, 365, 370, 372, 374, 382, 383, 385, 387, 394, 396, 397, 400, 401], "loss_fn": [5, 35, 326, 329, 362, 365, 369, 372, 388, 392], "loss_funct": [292, 300, 302, 306], "loss_ms": [5, 35, 326, 329], "lot": [4, 5, 30, 34, 258, 259, 326, 328], "louboutin": [332, 336, 338], "loung": [332, 338], "love": [332, 338, 340, 347, 356, 361], "low": [7, 46, 48, 164, 165, 168, 170, 181, 184, 187, 225, 229, 231, 369, 372, 374, 388, 394, 395, 396, 404], "lower": [76, 77, 88, 89, 173, 175, 180, 181, 187, 332, 338, 356, 360], "lowercas": [356, 360], "lowest": [395, 401], "lr": [4, 5, 6, 31, 32, 35, 36, 40, 41, 258, 262, 273, 279, 285, 288, 289, 292, 293, 300, 302, 306, 310, 312, 313, 326, 329, 330, 348, 353, 354, 362, 365, 369, 372, 375, 379, 388, 392, 394, 395, 400, 401], "lr_schedul": [5, 35, 326, 329], "lssf": [11, 72, 207, 208], "lstm": [388, 394], "lstrip": [76, 88], "lt": [340, 347], "luck": [332, 338, 340, 346], "lucki": [332, 338], "lupin": [332, 336, 338, 339], "lustr": [7, 43, 225, 226], "ly": [340, 347], "m": [0, 2, 4, 11, 24, 31, 72, 207, 208, 215, 223, 292, 300, 332, 338, 340, 346, 347, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "m1": [11, 72, 207, 208], "m2": [11, 72, 207, 208], "m3": [11, 72, 207, 208], "m5": [77, 89, 193, 197], "mac": [332, 338, 348, 353], "machin": [2, 3, 8, 11, 20, 27, 43, 46, 55, 72, 73, 74, 75, 78, 82, 85, 86, 87, 90, 98, 101, 104, 111, 189, 190, 193, 195, 203, 205, 207, 208, 215, 219, 226, 229, 232, 239, 295, 321, 332, 333, 334, 337, 338, 339, 340, 341, 342, 347, 348, 349, 350, 354, 355, 356, 357, 358, 382, 383], "maco": [3, 11, 26, 72, 189, 192, 203, 204, 207, 208], "macosx": [11, 72, 207, 208], "maddon": [332, 338], "made": [5, 10, 36, 69, 252, 255, 326, 330, 340, 343, 346, 347, 375, 379], "madison": [332, 338], "magnitud": [388, 390], "mai": [2, 4, 5, 22, 24, 25, 29, 33, 75, 76, 77, 80, 82, 83, 87, 88, 89, 92, 96, 99, 112, 114, 119, 123, 126, 127, 129, 137, 140, 147, 150, 154, 155, 157, 162, 189, 192, 215, 221, 223, 224, 258, 272, 326, 327, 332, 338, 340, 346, 347, 356, 358, 382, 386, 395, 404], "maiden": [332, 338], "main": [0, 2, 4, 5, 8, 10, 23, 32, 35, 54, 71, 78, 79, 90, 91, 98, 99, 112, 114, 119, 123, 127, 129, 137, 140, 164, 165, 171, 173, 176, 193, 197, 198, 201, 202, 215, 222, 232, 238, 252, 257, 258, 262, 294, 315, 326, 329, 332, 338, 340, 347, 350, 375, 377, 388, 390], "maintain": [2, 7, 10, 25, 43, 48, 69, 76, 88, 101, 103, 164, 165, 168, 215, 224, 225, 226, 231, 252, 255, 340, 347, 369, 370], "mainten": [108, 109], "major": [340, 343], "make": [0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 19, 23, 28, 32, 35, 36, 41, 42, 48, 51, 54, 55, 71, 72, 74, 76, 79, 80, 83, 84, 86, 88, 91, 92, 100, 150, 162, 164, 165, 167, 181, 183, 184, 193, 197, 203, 206, 207, 208, 215, 218, 222, 225, 231, 232, 235, 238, 239, 252, 257, 258, 260, 266, 270, 272, 275, 276, 277, 278, 280, 281, 285, 289, 290, 291, 293, 298, 312, 326, 329, 330, 332, 334, 338, 340, 342, 343, 346, 347, 348, 350, 354, 356, 358, 360, 362, 363, 364, 369, 371, 375, 381, 382, 383, 384, 388, 389, 390, 393, 394, 395, 396, 398], "make_pendulum_dataset": [369, 371], "makedir": [362, 364, 366, 369, 373, 375, 377, 382, 384, 388, 390, 395, 397], "malaga": [332, 338], "male": [340, 343, 347], "mall": [332, 338], "malloc": [189, 192], "mamba": [333, 341, 349, 357], "man": [332, 338, 340, 343, 346, 347], "manag": [1, 4, 5, 7, 13, 17, 30, 34, 43, 73, 74, 75, 76, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 103, 104, 105, 106, 109, 111, 119, 121, 123, 127, 131, 135, 137, 143, 148, 150, 152, 159, 163, 170, 172, 173, 178, 189, 192, 193, 196, 198, 201, 209, 211, 216, 225, 226, 258, 259, 273, 291, 296, 326, 328, 332, 338, 348, 354, 356, 358, 362, 363, 366, 368, 369, 370, 373, 376, 381, 382, 383, 388, 389, 395, 396, 399, 400, 404], "mani": [1, 3, 8, 9, 10, 13, 17, 21, 22, 28, 51, 61, 68, 77, 79, 83, 89, 91, 100, 112, 114, 127, 129, 137, 140, 164, 165, 168, 173, 180, 181, 185, 187, 203, 206, 209, 211, 216, 220, 221, 232, 235, 240, 246, 252, 254, 258, 261, 263, 264, 266, 332, 336, 337, 338, 340, 343, 347, 356, 361, 375, 376, 377, 382, 385, 388, 394, 395, 396], "manipul": [340, 346], "mann": [340, 346, 347], "manner": [3, 8, 9, 28, 49, 51, 53, 56, 203, 206, 232, 233, 235, 237, 240, 241, 294, 314, 340, 342, 348, 354, 395, 396], "mansbridg": [332, 338], "manual": [4, 32, 119, 126, 150, 162, 259, 260, 262, 264, 265, 268, 278, 280, 284, 332, 338, 348, 353, 362, 363, 368, 369, 370, 375, 376, 380, 382, 383, 385, 387, 388, 389, 393, 395, 396, 399, 400, 402], "manual_se": [388, 392], "map": [5, 35, 181, 184, 186, 193, 197, 258, 276, 291, 295, 298, 322, 326, 329, 348, 353, 369, 370, 375, 377, 381, 382, 383, 384, 388, 394, 395, 396, 397, 398, 400, 404], "map_batch": [3, 8, 9, 28, 52, 61, 62, 64, 198, 200, 203, 206, 232, 236, 240, 246, 247, 249, 291, 294, 295, 298, 317, 318, 322, 332, 334, 337, 338, 339, 362, 364, 369, 371, 375, 377, 382, 386, 387, 388, 394, 395, 404], "map_group": [8, 9, 54, 55, 64, 232, 238, 239, 240, 249, 294, 318], "map_loc": [4, 5, 32, 36, 258, 271, 292, 306, 326, 330, 362, 368, 369, 374, 375, 379, 381, 388, 392, 394, 395, 400, 404], "mapbatch": [9, 63, 240, 248, 332, 339], "mapreduc": [7, 46, 225, 229], "mar": [356, 361], "marathon": [332, 338], "marc": [340, 347], "march": [332, 338], "mario": [332, 338], "mark": [189, 192, 340, 347], "markdown": 0, "marker": [362, 366, 369, 373, 375, 379, 388, 392, 394, 395, 402], "market_typ": [193, 197], "marlei": [332, 338], "marri": [340, 343], "martial": [340, 346], "martin": [332, 338], "mask": [348, 353], "mass": [332, 338], "massiv": [9, 57, 240, 242], "master": [11, 72, 181, 183, 207, 208, 293, 313, 340, 346, 348, 355, 388, 390], "mat1_ref": [2, 18, 215, 217], "mat2_ref": [2, 18, 215, 217], "match": [2, 9, 22, 62, 77, 79, 83, 89, 91, 100, 127, 135, 137, 148, 173, 176, 181, 184, 185, 187, 215, 221, 240, 247, 258, 282, 332, 338, 382, 384], "matching_analysi": [181, 184], "materi": [3, 8, 10, 28, 51, 52, 54, 56, 57, 59, 60, 61, 62, 64, 70, 193, 197, 198, 200, 203, 206, 232, 235, 236, 238, 241, 242, 244, 245, 246, 247, 249, 252, 256, 291, 295, 298, 316, 318, 322, 323, 332, 334, 339, 375, 377, 382, 384, 385, 387, 395, 404], "materialized_d": [332, 339], "materializeddataset": [332, 339, 340, 344], "math": [1, 16, 209, 214, 369, 371, 388, 390, 391], "mathbb": [362, 363, 369, 370, 375, 376, 382, 383, 388, 389, 395, 396], "mathcal": [362, 363, 369, 370, 375, 376, 395, 396], "mathemat": [181, 187], "matmul": [2, 18, 215, 217, 375, 381], "matplotlib": [4, 6, 9, 29, 38, 56, 240, 241, 258, 260, 285, 286, 292, 293, 295, 300, 309, 323, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "matric": [395, 404], "matrix": [379, 381], "matrixfactorizationmodel": [375, 378, 379, 381], "matt": [332, 338], "matter": [164, 165, 169, 332, 338, 340, 343, 395, 398], "matur": [7, 47, 79, 83, 91, 99, 225, 230], "max": [8, 9, 54, 61, 64, 76, 88, 173, 176, 232, 238, 240, 246, 249, 294, 295, 317, 318, 323, 340, 347, 362, 366, 369, 373, 375, 379, 388, 390, 392, 395, 400], "max_": [294, 317], "max_depth": [3, 28, 203, 206, 291, 298, 382, 385, 387], "max_epoch": [5, 35, 36, 326, 329, 330, 362, 366, 368, 369, 373], "max_failur": [258, 280, 284, 362, 366, 369, 373, 375, 379, 382, 385, 388, 392, 395, 396, 401], "max_len": [388, 391], "max_length": [348, 353], "max_lora": [181, 184], "max_lora_rank": [181, 184], "max_model_len": [164, 165, 171, 176, 181, 184, 185, 186], "max_nod": [127, 134, 137, 146, 193, 197], "max_num_adapters_per_replica": [181, 184], "max_ongoing_request": [7, 48, 225, 231], "max_replica": [164, 165, 171, 173, 176, 179, 181, 186, 295, 323], "max_retri": [2, 20, 215, 219], "max_siz": [9, 62, 240, 247], "max_step": [5, 36, 326, 330], "max_t": [362, 365, 369, 372], "maxim": [7, 8, 43, 48, 54, 164, 165, 167, 169, 170, 225, 226, 231, 232, 238, 332, 334], "maximum": [73, 75, 85, 87, 127, 134, 137, 146, 164, 165, 167, 168, 173, 175, 179, 180, 181, 184, 187, 258, 282, 295, 323], "maxpool": [292, 300, 306], "maxpool2d": [292, 300, 306], "maxpumperla": [0, 348, 355], "mayb": [340, 346], "mb": [388, 390], "mcintir": [340, 346], "md": [0, 198, 201, 333, 341, 349, 357], "mdmad": [332, 338], "me": [101, 106, 173, 177, 178, 332, 338, 340, 343, 346, 347], "mean": [2, 6, 8, 9, 11, 18, 22, 41, 51, 52, 54, 60, 64, 72, 150, 153, 164, 165, 168, 207, 208, 215, 217, 221, 232, 235, 236, 238, 240, 245, 249, 258, 265, 271, 285, 289, 293, 294, 311, 312, 318, 362, 363, 369, 370, 375, 376, 381, 388, 390, 394, 395, 398, 399, 404], "meant": [7, 43, 45, 225, 226, 228, 375, 381], "meantim": [340, 346], "measur": [375, 381], "meat": [340, 343], "mechan": [7, 9, 43, 57, 189, 191, 225, 226, 240, 242, 395, 396, 400], "medium": [164, 165, 169, 172, 177, 180, 181, 187], "meet": [9, 10, 11, 57, 68, 72, 164, 165, 168, 207, 208, 240, 242, 252, 254, 295, 321, 332, 338], "melodrama": [340, 347], "member": [80, 92], "memori": [1, 2, 4, 5, 8, 9, 13, 18, 22, 24, 29, 31, 32, 33, 35, 46, 47, 50, 51, 57, 59, 60, 61, 63, 64, 77, 89, 167, 168, 170, 172, 173, 175, 177, 179, 181, 183, 184, 187, 189, 191, 193, 195, 197, 209, 211, 215, 217, 221, 223, 229, 230, 232, 234, 235, 240, 242, 244, 245, 246, 248, 249, 258, 260, 266, 271, 276, 291, 293, 294, 298, 311, 313, 317, 318, 326, 327, 329, 334, 338, 340, 342, 347, 362, 364, 368, 375, 377, 384, 388, 394, 395, 397, 398, 404], "memory_usag": [8, 51, 232, 235], "memorydb": 105, "men": [340, 343, 346], "mental": [340, 343], "mention": [340, 347, 388, 394], "merg": [8, 55, 232, 239, 375, 381], "merlin": [332, 338], "messag": [2, 7, 11, 25, 46, 72, 164, 165, 171, 173, 177, 178, 181, 184, 185, 186, 193, 195, 202, 207, 208, 215, 224, 225, 229, 292, 293, 295, 305, 311, 322, 362, 366, 369, 373], "messages_cv": [181, 184], "messages_nemoguard": [181, 184], "messages_yara": [181, 184], "messi": [332, 336, 338], "meta": [164, 165, 171, 173, 175, 176, 179, 181, 184, 375, 379, 388, 392, 395, 400], "meta_path": [395, 400], "metadata": [7, 8, 48, 55, 77, 89, 193, 197, 225, 231, 232, 239, 258, 280, 332, 336, 339, 340, 342, 344, 346, 369, 373, 375, 379, 381, 382, 387, 395, 398], "method": [2, 4, 5, 6, 8, 9, 10, 18, 25, 30, 34, 35, 41, 52, 60, 62, 63, 64, 70, 112, 113, 119, 120, 127, 128, 137, 138, 150, 151, 189, 192, 215, 217, 224, 232, 236, 240, 245, 247, 248, 249, 252, 256, 258, 259, 285, 289, 293, 294, 295, 313, 317, 322, 326, 328, 329, 332, 334, 337, 340, 347, 348, 353, 362, 368, 375, 376, 381], "method_nam": [2, 25, 215, 224], "metric": [3, 5, 6, 28, 30, 34, 36, 40, 41, 74, 79, 82, 86, 91, 96, 101, 106, 173, 176, 179, 181, 188, 189, 191, 192, 193, 195, 196, 197, 199, 203, 206, 259, 260, 261, 262, 269, 273, 277, 279, 280, 282, 284, 285, 288, 289, 291, 293, 295, 298, 299, 302, 306, 310, 311, 312, 313, 323, 326, 328, 330, 350, 354, 355, 362, 366, 367, 368, 369, 370, 373, 374, 376, 377, 381, 382, 384, 385, 387, 388, 389, 392, 393, 394, 395, 396, 400, 401, 402, 403, 404, 405], "metrics_datafram": [4, 5, 32, 36, 258, 270, 292, 306, 326, 330, 362, 366, 369, 373, 375, 379, 388, 392, 395, 402], "metrics_interval_": [295, 323], "mf_ray_train": [375, 379], "miami": [332, 338], "mic": [332, 336, 338], "michael": [332, 338, 340, 347], "micro": [395, 400], "microservic": [81, 94, 164, 165, 169, 202], "mid": [258, 282, 382, 383, 395, 403], "mid_block_scale_factor": [5, 35, 326, 329], "middl": [332, 338], "midwai": [332, 338], "might": [3, 4, 5, 6, 9, 26, 28, 30, 34, 41, 61, 108, 110, 112, 114, 127, 129, 137, 140, 150, 153, 164, 165, 168, 203, 204, 206, 240, 246, 258, 259, 285, 289, 291, 298, 326, 328, 340, 343, 362, 368, 382, 385, 387, 395, 404], "migrat": [10, 35, 70, 252, 256, 258, 261, 295, 299, 322, 329, 369, 370], "milan": [332, 338], "mile": [3, 7, 8, 28, 46, 47, 51, 203, 206, 225, 229, 230, 232, 235, 291, 294, 298, 315], "million": [3, 28, 203, 206, 291, 298, 332, 336, 338, 340, 347], "min": [3, 6, 8, 9, 28, 41, 54, 60, 61, 64, 173, 176, 203, 206, 232, 238, 240, 245, 246, 249, 285, 289, 291, 293, 294, 295, 298, 311, 312, 313, 317, 318, 323, 382, 385, 392, 394, 395, 401], "min_": [294, 317], "min_nod": [127, 134, 137, 146], "min_replica": [164, 165, 171, 173, 176, 179, 181, 186, 295, 323], "min_siz": [9, 62, 240, 247], "mind": [332, 338, 340, 343, 347], "mine": [332, 338], "minecraft": [332, 336, 338, 339], "miner": [340, 346], "mini": [4, 5, 31, 32, 36, 258, 259, 326, 330, 362, 363, 369, 370], "miniconda": [11, 72, 207, 208], "miniforge3": [11, 72, 207, 208], "minilm": [332, 337], "minim": [4, 5, 6, 7, 30, 34, 35, 41, 43, 46, 101, 104, 106, 108, 110, 225, 226, 229, 258, 259, 285, 289, 291, 293, 298, 311, 312, 326, 328, 329, 348, 354, 362, 365, 369, 370, 374, 375, 376, 382, 383, 395, 396, 404], "minimalist": 0, "minimum": [73, 75, 85, 87, 101, 106, 127, 134, 137, 146, 295, 323], "minu": [291, 298], "minut": [4, 8, 31, 51, 73, 75, 85, 87, 119, 123, 127, 129, 137, 140, 150, 154, 157, 232, 235, 332, 338, 388, 389, 390], "mirror": [388, 389, 395, 396], "mise": [340, 347], "miseenscen": [340, 347], "misfortun": [340, 346], "mismatch": [388, 392], "miss": [332, 338, 340, 346, 347, 362, 368, 369, 373], "missouri": [332, 338], "mistak": [340, 346], "mistral": [181, 187], "mitch": [332, 338], "mix": [5, 35, 36, 326, 329, 330, 362, 368, 369, 374, 395, 404], "mkdir": [4, 31, 292, 300], "ml": [3, 7, 8, 10, 11, 27, 28, 45, 47, 48, 55, 67, 68, 69, 70, 72, 75, 76, 78, 80, 82, 83, 84, 87, 88, 90, 92, 96, 99, 203, 205, 206, 207, 208, 225, 228, 230, 231, 232, 239, 252, 253, 254, 255, 256, 291, 294, 295, 297, 298, 315, 319, 320, 321, 322, 332, 334, 339, 356, 358, 359, 360, 375, 377, 381, 395, 396], "mlbcentral": [332, 338], "mlflow": [258, 284, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "mlogloss": [382, 385], "mlop": [3, 27, 181, 184, 203, 205, 291, 297, 298, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "mlp": [369, 372, 374, 375, 381], "mm": [2, 22, 215, 221], "mmlu": [181, 187], "mnist": [4, 6, 9, 10, 29, 31, 32, 38, 39, 40, 41, 59, 61, 62, 64, 70, 198, 201, 240, 244, 246, 247, 249, 252, 256, 259, 262, 265, 266, 268, 270, 271, 275, 283, 284, 285, 286, 287, 288, 289, 293, 294, 295, 303, 305, 306, 309, 310, 311, 313, 316, 317, 318, 322, 323], "mnist_app": [10, 70, 71, 198, 201, 252, 256, 257, 295, 322, 323], "mnist_app_handl": [10, 70, 252, 256], "mnist_classifi": [10, 70, 252, 256, 295, 322, 323], "mnist_classifier_arg": [9, 62, 240, 247], "mnist_deploy": [295, 322], "mnist_deployment_handl": [295, 322, 323], "mnist_pr": [9, 65, 66, 240, 250, 251, 294, 319], "mnist_preprocessor": [295, 323], "mnistclassifi": [9, 10, 62, 63, 70, 240, 247, 248, 252, 256, 294, 295, 317, 322, 323], "mnt": [3, 4, 5, 8, 9, 10, 28, 31, 35, 36, 37, 53, 62, 70, 76, 88, 198, 200, 203, 206, 232, 237, 240, 247, 252, 256, 258, 260, 261, 266, 268, 270, 275, 283, 291, 292, 294, 295, 298, 300, 305, 306, 307, 317, 319, 322, 323, 325, 326, 329, 330, 331, 362, 364, 366, 368, 369, 373, 374, 375, 377, 379, 381, 382, 384, 385, 387, 388, 389, 390, 395, 396, 397, 398, 400, 401, 404], "mock": [340, 346], "modal": [8, 9, 55, 66, 232, 239, 240, 251, 294, 319], "modano": [332, 338], "mode": [0, 3, 6, 10, 28, 41, 56, 71, 181, 185, 203, 206, 241, 252, 257, 258, 262, 271, 285, 289, 291, 293, 298, 311, 312, 313, 348, 353], "model": [2, 7, 8, 9, 10, 22, 25, 29, 33, 37, 38, 40, 43, 44, 47, 48, 52, 55, 57, 62, 64, 66, 68, 69, 70, 71, 75, 76, 78, 82, 87, 88, 90, 96, 167, 169, 170, 171, 174, 177, 178, 180, 182, 183, 184, 185, 186, 188, 215, 221, 224, 225, 226, 227, 230, 231, 232, 236, 239, 240, 242, 247, 249, 251, 252, 254, 255, 256, 257, 259, 260, 262, 268, 269, 270, 271, 273, 278, 279, 280, 282, 284, 286, 288, 291, 294, 295, 298, 299, 302, 304, 306, 307, 308, 312, 317, 318, 321, 322, 323, 324, 325, 327, 331, 333, 334, 337, 339, 340, 341, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 359, 361, 362, 363, 365, 366, 368, 369, 370, 371, 373, 374, 377, 379, 380, 381, 383, 384, 386, 387, 389, 390, 392, 394, 397, 400, 404], "model1": [3, 28, 203, 206], "model1_predict": [3, 28, 203, 206], "model2": [3, 28, 203, 206], "model2_predict": [3, 28, 203, 206], "model_config": [5, 35, 326, 329], "model_dump": [3, 28, 181, 186, 203, 206], "model_id": [164, 165, 171, 173, 176, 179, 181, 184, 185, 186], "model_json_schema": [181, 185], "model_kwarg": [388, 394], "model_loading_config": [164, 165, 171, 173, 176, 179, 181, 184, 185, 186], "model_nam": [5, 35, 36, 75, 87, 326, 329, 330, 332, 337], "model_path": [3, 4, 10, 28, 32, 70, 203, 206, 252, 256, 258, 271, 292, 306, 382, 385], "model_predict": [3, 28, 203, 206], "model_select": [3, 26, 203, 204, 382, 384], "model_sourc": [164, 165, 171, 173, 176, 179, 181, 184, 185, 186], "model_state_dict": [258, 279], "modelcheckpoint": [362, 366, 368, 369, 373], "modelwork": [258, 271], "moder": [164, 165, 168, 181, 184, 187], "modern": [7, 43, 46, 225, 226, 229, 332, 334, 339, 340, 342, 348, 350, 355], "modif": [79, 83, 91, 100], "modifi": [2, 3, 4, 8, 9, 10, 24, 28, 31, 53, 62, 70, 76, 77, 79, 83, 88, 89, 91, 100, 112, 114, 119, 123, 127, 129, 137, 140, 150, 155, 198, 200, 201, 203, 206, 215, 223, 232, 237, 240, 247, 252, 256, 278, 362, 363, 395, 396], "modul": [4, 31, 32, 101, 105, 106, 119, 123, 137, 141, 164, 165, 166, 171, 172, 173, 178, 180, 181, 183, 188, 198, 201, 265, 268, 272, 278, 279, 280, 292, 300, 303, 304, 375, 378, 381, 388, 391, 394, 395, 396, 404], "modular": [101, 105, 106, 375, 376], "mofo": [332, 338], "mom": [332, 338], "momentum": [292, 300, 306, 348, 353], "mondai": [332, 338], "monei": [340, 343, 346], "mongodb": [7, 43, 225, 226], "monitor": [4, 5, 7, 30, 32, 34, 46, 74, 78, 79, 84, 86, 90, 91, 108, 109, 164, 174, 176, 178, 180, 181, 187, 188, 189, 191, 192, 193, 195, 196, 197, 198, 199, 200, 225, 229, 258, 259, 267, 268, 292, 304, 326, 328, 382, 387, 388, 394], "monro": [332, 338], "month": [3, 8, 28, 51, 181, 186, 203, 206, 232, 235, 332, 338], "moon": [332, 338], "more": [1, 2, 6, 7, 8, 9, 10, 16, 19, 20, 22, 23, 24, 30, 31, 34, 37, 40, 41, 45, 47, 48, 54, 55, 57, 61, 64, 66, 68, 69, 71, 77, 81, 89, 94, 101, 106, 110, 112, 114, 127, 128, 129, 137, 138, 140, 150, 151, 164, 165, 168, 170, 171, 175, 180, 183, 189, 192, 193, 195, 197, 198, 200, 209, 214, 215, 218, 219, 221, 222, 223, 225, 228, 230, 231, 232, 238, 239, 240, 242, 246, 249, 251, 252, 254, 255, 257, 258, 259, 260, 264, 268, 270, 284, 285, 288, 289, 292, 293, 295, 302, 303, 306, 307, 310, 312, 313, 315, 318, 319, 321, 323, 328, 331, 333, 340, 341, 346, 347, 348, 349, 353, 355, 356, 357, 358, 360, 361, 362, 368, 375, 381, 382, 386, 387, 388, 392, 395, 404], "morn": [332, 338], "moron": [340, 346], "morri": [340, 346], "morti": [332, 338], "mosh": [332, 338], "most": [2, 7, 8, 9, 19, 25, 45, 52, 58, 60, 73, 75, 76, 81, 85, 87, 88, 94, 108, 110, 181, 184, 185, 215, 218, 224, 225, 228, 232, 236, 240, 243, 245, 258, 270, 282, 294, 317, 340, 346, 347, 356, 361, 362, 366, 369, 373, 375, 377, 380, 382, 386, 395, 397, 400, 402], "most_rec": [76, 88], "mostli": [164, 165, 169], "motion": [369, 370], "motiv": [340, 343], "mount": [76, 88, 101, 106], "mountaincar": [369, 374], "mouth": [340, 346], "move": [4, 5, 6, 7, 31, 32, 35, 40, 41, 43, 84, 164, 165, 172, 225, 226, 258, 261, 262, 265, 266, 268, 269, 271, 273, 274, 285, 288, 289, 292, 293, 300, 303, 310, 313, 326, 329, 332, 334, 340, 347, 348, 353, 362, 368, 369, 370, 374, 382, 384, 388, 390, 395, 396], "movement": [5, 35, 326, 329], "movi": [332, 338, 340, 343, 346, 347, 376, 377], "movielen": [376, 381], "mp": [332, 337, 338, 339, 348, 350, 353, 354], "mse": [362, 363, 366, 369, 373, 375, 376, 379], "mse_loss": [5, 35, 326, 329, 375, 379], "mseloss": [362, 365, 369, 372], "mta": [332, 338], "mtv": [340, 347], "mtvstar": [332, 338], "mtvstarsof2015": [332, 338], "much": [7, 8, 47, 51, 53, 164, 165, 169, 181, 184, 193, 197, 225, 230, 232, 235, 237, 332, 338, 340, 343, 346, 347, 362, 368, 375, 376, 382, 384], "muck": [340, 347], "muddi": [340, 346], "multi": [8, 9, 10, 53, 55, 66, 68, 75, 87, 101, 103, 164, 165, 168, 169, 170, 173, 175, 179, 180, 181, 184, 187, 188, 232, 237, 239, 240, 251, 252, 254, 258, 259, 260, 269, 272, 277, 284, 294, 295, 319, 321, 362, 363, 366, 368, 369, 370, 375, 376, 377, 381, 382, 383, 385, 395, 396, 404], "multi_actor_tracing_ray_serve_exampl": 202, "multiclass": [292, 300, 302, 306], "multiclassaccuraci": [395, 400], "multimod": [362, 363], "multipl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 16, 18, 22, 23, 27, 30, 32, 34, 36, 41, 43, 46, 53, 55, 61, 62, 68, 69, 75, 81, 87, 94, 101, 106, 108, 110, 163, 164, 165, 168, 169, 170, 173, 174, 175, 176, 179, 180, 181, 183, 184, 187, 188, 193, 195, 198, 201, 202, 203, 205, 209, 214, 215, 217, 221, 222, 225, 226, 229, 232, 237, 239, 240, 246, 247, 252, 254, 255, 258, 259, 266, 268, 272, 275, 285, 289, 291, 293, 294, 295, 297, 298, 311, 316, 317, 321, 326, 328, 330, 332, 334, 337, 340, 342, 345, 348, 350, 353, 354, 355, 356, 358, 362, 363, 364, 368, 369, 370, 374, 375, 377, 379, 381, 382, 383, 387, 388, 392, 394, 395, 397, 402, 404, 405], "multiplex": [9, 10, 57, 68, 240, 242, 252, 254, 295, 321], "multipli": [2, 25, 215, 224, 388, 394], "multiprocess": [2, 22, 215, 221, 395, 398], "multithread": [2, 9, 22, 61, 215, 221, 240, 246], "multivari": [388, 394], "mum": [332, 336, 338], "muslim": [332, 338], "must": [181, 184, 258, 282, 362, 363, 369, 370], "mutat": [2, 25, 215, 224, 332, 339], "mutual": [164, 165, 169], "my": [0, 2, 21, 74, 86, 101, 106, 119, 122, 123, 164, 165, 171, 173, 176, 177, 178, 179, 181, 184, 185, 186, 202, 215, 220, 332, 336, 338, 340, 343, 347], "my_custom_env": [2, 21, 215, 220], "my_simple_model": [6, 41, 285, 289, 293, 311], "my_xgboost_func": [3, 28, 203, 206], "myself": [332, 338, 340, 343, 347], "mysentimentmodel": [356, 360], "mysql": [7, 43, 225, 226], "n": [2, 4, 11, 22, 24, 32, 72, 76, 88, 108, 110, 137, 147, 173, 178, 181, 184, 186, 207, 208, 215, 221, 223, 258, 262, 332, 333, 336, 338, 339, 340, 341, 347, 349, 357, 362, 363, 365, 366, 369, 370, 374, 376, 382, 386, 387, 395, 404], "n_step": [369, 371, 374], "nab": [388, 390], "naiv": [9, 10, 57, 68, 240, 242, 252, 254, 362, 368], "naiveti": [340, 346, 347], "nake": [340, 346], "nam": [137, 141], "name": [4, 5, 6, 7, 10, 11, 31, 32, 36, 41, 48, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 85, 86, 87, 88, 89, 90, 91, 92, 98, 101, 105, 106, 107, 112, 114, 115, 116, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 134, 137, 140, 141, 142, 143, 146, 150, 153, 154, 159, 161, 162, 164, 165, 171, 173, 178, 181, 184, 185, 186, 193, 197, 198, 200, 201, 202, 207, 208, 225, 231, 252, 256, 257, 258, 262, 268, 269, 271, 277, 280, 282, 285, 289, 291, 292, 293, 295, 298, 300, 305, 311, 313, 322, 323, 326, 330, 340, 343, 346, 362, 364, 366, 368, 369, 373, 374, 375, 377, 379, 381, 382, 385, 388, 392, 395, 397, 401, 404], "namespac": [127, 129, 130, 132, 133, 134, 135, 137, 140, 142, 144, 145, 146, 148, 150, 157, 160, 162, 258, 268], "nandito": [332, 338], "narrat": [340, 347], "naruto": [332, 338], "nash": [332, 338], "nashnewvideo": [332, 338], "nat": [101, 106, 108, 110, 112, 114, 127, 129, 137, 140], "natgatewai": [112, 114, 127, 129, 137, 140], "nation": [332, 338, 340, 346, 356, 361], "nativ": [1, 3, 7, 15, 27, 43, 45, 46, 47, 84, 108, 109, 111, 164, 165, 169, 170, 193, 196, 197, 203, 205, 209, 213, 225, 226, 228, 229, 230, 340, 346, 347, 362, 366, 368, 369, 370, 373, 374, 388, 389, 395, 396], "nativesbr": [340, 347], "natur": [181, 186, 356, 361], "navig": [74, 78, 79, 80, 83, 86, 90, 91, 92, 100, 189, 192, 198, 200, 202], "nbsp": [73, 76, 85, 88], "nc": [340, 343], "nccl": [348, 354, 395, 396], "ndarrai": [6, 9, 10, 41, 61, 62, 64, 70, 240, 246, 247, 249, 252, 256, 285, 289, 293, 294, 295, 311, 317, 318, 322, 332, 337, 339, 388, 394], "ndcg": [375, 381], "ndim": [258, 271], "necessari": [4, 8, 32, 52, 112, 113, 114, 118, 119, 122, 123, 127, 128, 129, 136, 137, 138, 140, 147, 149, 150, 151, 153, 232, 236, 258, 266, 292, 295, 303, 323, 332, 336, 348, 350, 351, 356, 360, 382, 384, 395, 396], "need": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 16, 18, 19, 21, 30, 32, 34, 36, 41, 43, 46, 51, 53, 55, 57, 62, 65, 68, 70, 72, 73, 74, 75, 79, 85, 86, 87, 91, 101, 102, 103, 111, 112, 113, 114, 115, 119, 120, 121, 123, 124, 126, 127, 128, 129, 131, 137, 139, 140, 141, 143, 147, 150, 152, 154, 155, 159, 162, 163, 164, 165, 169, 173, 174, 175, 176, 178, 180, 181, 182, 184, 185, 186, 187, 189, 192, 193, 197, 207, 208, 209, 214, 215, 217, 218, 220, 225, 226, 229, 232, 235, 237, 239, 240, 242, 247, 250, 252, 254, 256, 258, 259, 260, 261, 264, 266, 268, 272, 273, 276, 283, 284, 285, 289, 291, 292, 293, 294, 295, 296, 298, 304, 311, 315, 322, 326, 328, 330, 332, 338, 340, 346, 347, 348, 354, 356, 358, 362, 364, 368, 369, 370, 375, 377, 379, 381, 382, 384, 385, 386, 395, 396, 397, 398, 399, 400, 402], "neg": [7, 47, 225, 230, 340, 343, 356, 361], "nemoguard": [181, 184], "nephew": [332, 338], "nest": [17, 19, 216, 218], "net": [5, 35, 326, 329, 362, 365, 369, 372, 395, 400], "netflix": [8, 9, 55, 66, 232, 239, 240, 251, 294, 319], "network": [4, 5, 6, 8, 9, 30, 34, 40, 54, 57, 64, 76, 88, 101, 104, 106, 108, 110, 111, 137, 147, 150, 162, 163, 164, 165, 169, 189, 191, 193, 195, 197, 232, 238, 240, 242, 249, 258, 259, 285, 288, 293, 294, 310, 318, 326, 328, 362, 363, 365, 395, 396], "networkinterfaceid": [112, 114, 127, 129, 137, 140], "neural": [6, 40, 285, 288, 293, 310, 375, 381, 388, 391, 395, 396], "never": [0, 332, 338, 340, 346, 347], "new": [2, 3, 7, 8, 24, 25, 28, 44, 51, 73, 74, 75, 76, 77, 78, 80, 83, 85, 86, 87, 88, 89, 90, 92, 98, 99, 108, 111, 112, 114, 130, 134, 137, 142, 146, 164, 165, 168, 173, 178, 181, 186, 203, 206, 215, 223, 224, 225, 227, 232, 235, 258, 282, 292, 295, 302, 323, 332, 333, 338, 340, 341, 343, 346, 347, 349, 357, 366, 369, 374, 382, 383, 387, 388, 389, 395, 403, 405], "newaxi": [382, 386], "newli": [150, 156], "newsha": [332, 338], "next": [2, 6, 8, 24, 41, 53, 73, 75, 78, 79, 83, 85, 87, 90, 91, 100, 101, 104, 119, 121, 127, 131, 137, 143, 150, 152, 159, 167, 182, 184, 187, 191, 198, 200, 215, 223, 232, 237, 260, 265, 285, 289, 292, 293, 295, 305, 311, 312, 313, 323, 332, 338, 364, 377, 385, 389, 390, 397, 400], "nf": [76, 88], "nfl": [332, 336, 338], "nginx": [108, 111, 135, 136, 148, 149, 162], "nhead": [388, 391, 392, 394], "nhl": [332, 336, 338, 339], "nia": [332, 338], "niall": [332, 338], "nice": [258, 284], "nicer": [7, 47, 225, 230], "nick": [332, 338], "nicki": [332, 338], "nigga": [332, 338], "night": [332, 336, 338, 339, 340, 346, 347], "nightli": [369, 374, 388, 394], "nightmar": [340, 346, 347], "nightmarish": [340, 347], "nine": [362, 364, 395, 397], "nirvana": [332, 338], "nlb": [108, 111], "nlp": [258, 284], "nn": [4, 5, 6, 29, 31, 32, 33, 38, 40, 41, 258, 260, 261, 265, 268, 280, 285, 286, 288, 289, 292, 293, 300, 303, 304, 310, 313, 326, 327, 348, 351, 362, 364, 365, 369, 371, 372, 375, 377, 378, 388, 390, 391, 392, 395, 397, 400], "no_grad": [4, 9, 10, 31, 32, 62, 70, 240, 247, 252, 256, 292, 294, 295, 300, 306, 317, 322, 362, 368, 369, 374, 375, 379, 381, 388, 392, 395, 400], "no_restart": [258, 271], "node": [1, 2, 4, 5, 6, 8, 9, 10, 11, 13, 18, 20, 22, 30, 31, 32, 34, 40, 51, 53, 61, 68, 72, 73, 76, 77, 78, 79, 82, 85, 88, 89, 90, 91, 96, 99, 101, 104, 105, 106, 108, 110, 111, 112, 114, 119, 120, 123, 127, 129, 130, 134, 140, 142, 146, 147, 150, 154, 156, 164, 165, 168, 169, 173, 175, 176, 178, 179, 180, 181, 187, 191, 193, 195, 196, 197, 207, 208, 209, 211, 215, 217, 219, 221, 232, 235, 237, 240, 246, 252, 254, 258, 259, 260, 262, 268, 269, 272, 276, 280, 281, 284, 285, 288, 291, 293, 295, 296, 310, 311, 313, 321, 326, 328, 332, 338, 340, 342, 344, 362, 363, 368, 369, 370, 375, 376, 381, 382, 383, 384, 385, 390, 393, 394, 395, 396, 400, 404], "node_ip": [292, 306], "nodegroup": [137, 141], "noderol": [137, 141], "nofril": [340, 347], "noir": [340, 346, 347], "noirlik": [340, 347], "nois": [5, 35, 326, 329, 365, 368, 369, 370, 371, 372, 374, 388, 390], "noise_schedul": [5, 35, 326, 329], "noised_lat": [5, 35, 326, 329], "noiser": [362, 368], "noisi": [362, 365, 369, 370, 372], "noisy_act": [369, 371, 372], "noisy_img": [362, 365], "non": [4, 10, 31, 71, 164, 165, 169, 170, 171, 173, 177, 179, 181, 184, 185, 186, 198, 201, 252, 257, 258, 259, 260, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397, 400], "non_block": [258, 271], "none": [4, 5, 6, 9, 31, 32, 35, 41, 62, 240, 247, 258, 267, 268, 271, 280, 285, 289, 292, 293, 300, 304, 311, 312, 326, 329, 348, 355, 362, 366, 368, 369, 373, 374, 375, 379, 381, 382, 385, 388, 391, 392, 395, 398, 404], "norm": [258, 271, 388, 390, 394], "norm_ep": [5, 35, 326, 329], "norm_num_group": [5, 35, 326, 329], "normal": [4, 6, 9, 29, 31, 32, 38, 39, 41, 56, 61, 63, 240, 241, 246, 248, 258, 260, 266, 271, 272, 276, 285, 286, 287, 289, 292, 293, 294, 295, 300, 303, 306, 309, 313, 317, 323, 362, 363, 368, 370, 372, 374, 375, 376, 381, 382, 384, 386, 389, 394, 395, 396, 398, 404], "normalci": [340, 347], "normalis": [388, 390, 395, 398], "normalize_cpu": [258, 271], "normalized_batch": [9, 61, 240, 246, 294, 295, 317, 323], "normalized_img": [4, 31, 32], "north": [332, 338, 340, 346], "not_ready_ref": [2, 24, 215, 223], "note": [6, 8, 10, 11, 12, 17, 19, 20, 31, 35, 41, 52, 53, 54, 60, 61, 64, 70, 71, 72, 101, 104, 108, 111, 112, 114, 119, 123, 127, 129, 131, 137, 140, 143, 150, 154, 159, 164, 165, 170, 189, 191, 192, 198, 201, 207, 208, 210, 216, 218, 219, 232, 236, 237, 238, 245, 246, 249, 252, 256, 257, 260, 272, 274, 276, 285, 289, 292, 293, 294, 295, 303, 304, 311, 317, 318, 322, 329, 332, 338, 339, 340, 345, 346, 347, 356, 361, 375, 381, 382, 384, 395, 396, 400], "notebook": [1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 17, 19, 26, 29, 31, 33, 38, 49, 56, 67, 73, 75, 76, 81, 84, 85, 87, 88, 93, 112, 113, 119, 120, 127, 128, 137, 138, 164, 165, 166, 173, 174, 181, 182, 189, 190, 193, 194, 198, 199, 203, 204, 209, 210, 215, 216, 218, 232, 233, 240, 241, 252, 253, 258, 259, 260, 285, 286, 292, 293, 294, 295, 299, 308, 314, 320, 326, 327, 332, 333, 334, 339, 341, 347, 348, 349, 350, 355, 356, 357, 358, 361, 362, 363, 369, 370, 374, 375, 376, 377, 382, 387, 388, 389, 395, 396, 397, 404, 405], "noth": [258, 271, 332, 338, 340, 347], "notic": [4, 8, 32, 53, 232, 237, 258, 262, 332, 338, 340, 347], "notif": [198, 201, 202], "notificationservic": 202, "nov": [292, 300, 332, 338], "novelti": [375, 381], "now": [2, 3, 4, 5, 9, 10, 11, 19, 28, 31, 32, 36, 62, 70, 72, 74, 77, 78, 80, 86, 89, 90, 92, 101, 106, 112, 114, 118, 119, 123, 127, 129, 135, 136, 137, 147, 148, 149, 150, 154, 164, 165, 171, 173, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 198, 200, 201, 203, 206, 207, 208, 215, 218, 240, 247, 252, 256, 258, 261, 266, 268, 269, 271, 273, 274, 275, 276, 277, 279, 280, 292, 294, 295, 300, 301, 302, 317, 322, 323, 326, 330, 332, 338, 340, 346, 347, 362, 363, 364, 366, 368, 369, 374, 375, 377, 379, 381, 382, 384, 387, 395, 404], "nowher": [340, 343], "np": [1, 2, 4, 5, 6, 9, 10, 12, 17, 18, 22, 24, 29, 31, 32, 33, 35, 38, 41, 56, 61, 62, 64, 67, 70, 193, 197, 198, 201, 209, 210, 215, 216, 217, 221, 223, 240, 241, 246, 247, 249, 252, 253, 256, 258, 260, 271, 276, 285, 286, 289, 293, 294, 295, 311, 312, 317, 318, 322, 323, 326, 327, 329, 332, 335, 337, 338, 348, 351, 352, 362, 364, 369, 371, 374, 375, 377, 382, 384, 385, 386, 388, 390, 394, 395, 397, 404], "nthread": [382, 385], "ntop": [375, 381], "nude": [340, 343], "nuditi": [340, 343], "nuge": [332, 338], "nugent": [332, 338], "null": [112, 114, 127, 129, 137, 140], "num": [189, 192, 292, 302], "num_actor": [395, 404], "num_block": [332, 339, 340, 344], "num_boost_round": [3, 28, 203, 206, 382, 385], "num_class": [4, 31, 258, 261, 292, 300, 302, 306, 382, 385, 395, 400, 404], "num_cpu": [2, 8, 9, 22, 54, 61, 215, 221, 232, 238, 240, 246, 362, 364, 382, 386, 387], "num_decoder_lay": [388, 391], "num_encoder_lay": [388, 391], "num_epoch": [4, 6, 31, 32, 40, 41, 258, 262, 263, 269, 273, 277, 279, 280, 282, 285, 288, 289, 292, 293, 300, 302, 305, 306, 310, 313], "num_gpu": [2, 6, 9, 22, 40, 61, 62, 215, 221, 240, 246, 247, 258, 271, 285, 288, 294, 295, 317, 322, 323, 332, 338, 388, 394, 395, 404], "num_imag": [193, 197], "num_item": [375, 377, 378, 379, 381], "num_label": [348, 353], "num_lay": [388, 391, 392, 394], "num_parquet_shard": [375, 377], "num_partit": [340, 346], "num_replica": [295, 322, 323, 356, 360, 361], "num_return": [2, 24, 215, 223], "num_row": [332, 336, 339, 340, 343, 344, 345, 395, 398], "num_row_group": [395, 398], "num_sampl": [3, 6, 28, 41, 203, 206, 285, 289, 291, 293, 298, 311, 312, 313], "num_to_keep": [362, 366, 369, 373, 375, 379, 382, 385, 388, 392, 395, 401], "num_training_step": [5, 35, 326, 329], "num_us": [375, 377, 378, 379, 381], "num_warmup_step": [5, 35, 36, 326, 329, 330], "num_work": [3, 4, 5, 28, 32, 35, 36, 203, 206, 258, 259, 264, 284, 291, 292, 298, 302, 326, 329, 330, 348, 354, 355, 362, 366, 369, 373, 375, 379, 382, 385, 388, 390, 392, 395, 396, 398, 399, 401, 404], "number": [2, 3, 4, 5, 6, 8, 9, 22, 24, 28, 32, 36, 39, 41, 51, 53, 59, 61, 62, 73, 75, 77, 85, 87, 89, 108, 111, 173, 176, 179, 181, 185, 193, 195, 198, 200, 201, 203, 206, 215, 221, 223, 232, 235, 237, 240, 244, 246, 247, 258, 261, 262, 263, 269, 277, 282, 285, 287, 289, 291, 292, 293, 294, 295, 298, 302, 305, 309, 311, 312, 316, 317, 323, 326, 330, 332, 334, 337, 340, 343, 345, 348, 350, 353, 354, 355, 356, 360, 361, 369, 371, 375, 377, 379, 395, 404], "numenta": [388, 390], "numer": [8, 51, 181, 184, 232, 235, 258, 260, 362, 368, 382, 383, 395, 397], "numpi": [1, 2, 4, 5, 6, 8, 9, 10, 12, 17, 29, 33, 38, 52, 56, 59, 62, 67, 70, 193, 197, 198, 201, 209, 210, 215, 216, 232, 236, 240, 241, 244, 247, 252, 253, 256, 258, 260, 271, 276, 285, 286, 293, 294, 295, 311, 317, 322, 323, 326, 327, 332, 335, 339, 348, 351, 362, 364, 368, 369, 371, 375, 377, 382, 384, 385, 388, 390, 394, 395, 397, 404], "nuremburg": [332, 338], "nutshel": [291, 297], "nvdp": [127, 130, 135, 137, 142, 148], "nvidia": [108, 111, 135, 136, 148, 149, 181, 184, 332, 338], "nvlink": [173, 179], "nvme": [4, 31, 258, 259, 260], "nyc": [3, 8, 28, 51, 54, 198, 200, 203, 206, 232, 235, 238, 394], "nyc_taxi": [388, 390], "nyc_taxi_2021": [291, 298], "nyc_taxi_t": [388, 390], "nyc_taxi_transform": [388, 392], "o": [1, 2, 4, 5, 10, 12, 17, 21, 22, 29, 31, 32, 33, 35, 36, 71, 75, 76, 87, 88, 164, 173, 176, 179, 181, 184, 186, 189, 191, 193, 197, 209, 210, 215, 216, 220, 221, 252, 257, 258, 260, 268, 271, 279, 280, 283, 292, 300, 304, 306, 326, 327, 329, 330, 332, 333, 336, 338, 341, 348, 349, 351, 357, 362, 364, 366, 368, 369, 371, 373, 374, 375, 377, 379, 381, 382, 384, 385, 387, 388, 390, 392, 394, 395, 397, 400, 402, 404], "ob": [369, 371, 372, 374], "obj": [76, 88, 181, 184], "obj_ref": [2, 18, 215, 217], "object": [1, 3, 4, 6, 7, 8, 9, 10, 15, 16, 19, 25, 28, 32, 40, 41, 47, 48, 51, 63, 64, 68, 70, 77, 79, 83, 89, 91, 100, 101, 106, 119, 126, 150, 162, 164, 165, 168, 173, 176, 181, 184, 186, 203, 206, 209, 213, 214, 218, 224, 225, 230, 231, 232, 235, 240, 248, 249, 252, 254, 256, 258, 268, 269, 270, 276, 282, 284, 285, 288, 289, 291, 292, 293, 294, 295, 298, 302, 305, 306, 310, 311, 312, 316, 317, 318, 322, 332, 334, 338, 339, 377, 381, 382, 385, 387, 395, 397, 402], "object_ref": [2, 24, 215, 223], "objectref": [1, 2, 15, 18, 19, 24, 209, 213, 215, 217, 218, 223], "oblig": [340, 347], "oblivi": [340, 347], "obs_dim": [369, 372, 374], "obs_sampl": [369, 374], "observ": [4, 5, 30, 32, 34, 79, 83, 91, 99, 164, 181, 188, 197, 258, 259, 293, 313, 326, 328, 348, 355, 369, 370, 371, 372, 382, 384, 388, 391, 395, 398], "observed_data": [198, 200], "obtain": [76, 88, 348, 353], "obtus": [340, 343], "obviou": [340, 343], "occupi": [258, 283], "occur": [7, 46, 193, 197, 225, 229, 258, 276, 281, 375, 377], "ocean": [332, 338], "oct": [332, 336, 338], "octob": [332, 338], "off": [0, 4, 6, 9, 31, 32, 39, 60, 173, 179, 181, 184, 187, 240, 245, 258, 260, 271, 285, 287, 292, 293, 300, 306, 309, 332, 336, 338, 340, 347, 362, 364, 368, 375, 379, 380, 382, 386, 387, 388, 393, 395, 397, 398, 401, 404], "offenc": [332, 338], "offend": [332, 338], "offer": [3, 7, 10, 27, 43, 45, 46, 47, 68, 69, 78, 81, 82, 90, 95, 96, 108, 109, 110, 173, 175, 179, 203, 205, 225, 226, 228, 229, 230, 252, 254, 255, 340, 343, 347, 362, 364], "offici": [74, 75, 86, 87, 101, 106, 119, 123, 189, 192, 198, 201], "offlin": [77, 89, 291, 298, 369, 370, 371, 375, 377, 382, 383], "offlinemnistclassifi": [295, 322], "offlinepredictor": [3, 28, 203, 206, 291, 298], "offload": [76, 88, 395, 396], "often": [7, 43, 46, 47, 84, 225, 226, 229, 230, 258, 271, 375, 377, 382, 386], "oh": [332, 338], "olap": [7, 43, 225, 226], "old": [83, 99, 332, 338, 340, 343, 347, 382, 387, 388, 394, 395, 404], "older": [198, 201, 362, 368], "oltp": [7, 43, 225, 226], "olympics2012": [332, 338], "omp_num_thread": [2, 22, 215, 221], "on_demand": [193, 197], "on_epoch": [362, 365, 369, 372], "on_fit_start": [5, 35, 326, 329], "on_step": [5, 35, 326, 329], "onc": [1, 9, 16, 17, 19, 23, 25, 61, 62, 74, 75, 76, 78, 86, 87, 88, 90, 112, 116, 119, 125, 127, 134, 137, 146, 150, 161, 164, 165, 168, 171, 173, 177, 178, 181, 184, 209, 214, 216, 218, 222, 224, 240, 246, 247, 258, 259, 260, 268, 271, 291, 294, 298, 317, 332, 334, 337, 348, 353, 362, 366, 375, 376, 382, 386, 388, 389, 394, 395, 396, 398, 404], "one": [1, 2, 3, 4, 5, 7, 8, 9, 10, 16, 20, 22, 23, 24, 28, 30, 34, 44, 48, 53, 55, 57, 68, 69, 75, 76, 77, 81, 83, 87, 88, 89, 94, 99, 101, 106, 108, 110, 111, 112, 114, 127, 129, 137, 140, 164, 165, 167, 168, 169, 170, 181, 183, 184, 187, 189, 192, 198, 200, 201, 203, 206, 209, 214, 215, 219, 221, 222, 223, 225, 227, 231, 232, 237, 239, 240, 242, 252, 254, 255, 258, 259, 261, 264, 266, 270, 272, 284, 292, 295, 300, 321, 326, 328, 332, 334, 338, 340, 343, 346, 347, 362, 366, 382, 384, 385, 389, 392, 393, 395, 396, 398, 400, 401], "onehellofanighttour": [332, 338], "ones": [2, 7, 24, 45, 74, 86, 112, 114, 127, 129, 137, 140, 164, 165, 168, 173, 175, 215, 223, 225, 228, 332, 338, 356, 358], "ongo": [108, 109, 163, 295, 323], "onli": [1, 2, 4, 8, 9, 16, 25, 32, 51, 53, 60, 61, 63, 64, 75, 76, 77, 80, 81, 84, 87, 88, 89, 92, 94, 101, 104, 108, 110, 112, 115, 119, 124, 127, 131, 137, 143, 150, 159, 164, 165, 168, 170, 181, 184, 189, 192, 193, 196, 197, 200, 209, 214, 215, 224, 232, 235, 237, 240, 245, 246, 248, 249, 259, 261, 262, 267, 280, 283, 284, 292, 294, 295, 304, 317, 318, 323, 332, 338, 340, 342, 343, 345, 346, 347, 348, 353, 354, 362, 368, 369, 370, 374, 375, 377, 379, 381, 382, 383, 385, 388, 390, 392, 394, 395, 396, 398, 400, 402], "onlin": [7, 10, 43, 70, 77, 83, 89, 99, 225, 226, 252, 256, 258, 272, 291, 295, 298, 322, 332, 333, 338, 341, 349, 357, 360, 388, 394, 395, 404], "onlinemnistclassifi": [10, 70, 252, 256, 295, 322, 323], "onlinemnistpreprocessor": [295, 323], "onlinepredictor": [291, 298], "onto": [2, 6, 9, 22, 40, 60, 215, 221, 240, 245, 258, 271, 285, 288, 293, 310], "onu": [7, 46, 225, 229], "oom": [4, 5, 9, 29, 33, 61, 193, 197, 240, 246, 326, 327], "op": [395, 397], "open": [0, 1, 4, 7, 11, 13, 31, 43, 72, 74, 75, 76, 77, 78, 84, 86, 87, 88, 89, 90, 119, 122, 181, 186, 187, 189, 192, 193, 196, 198, 200, 202, 207, 208, 209, 211, 225, 226, 292, 300, 332, 338, 340, 346, 362, 364, 395, 397, 398, 404], "openai": [164, 165, 170, 171, 173, 176, 177, 178, 181, 184, 185, 186], "openapi": [295, 323], "opentelemetri": [189, 191, 202], "oper": [7, 43, 44, 47, 49, 55, 56, 57, 60, 61, 81, 94, 101, 103, 110, 119, 123, 128, 129, 130, 133, 135, 136, 138, 140, 142, 145, 147, 148, 149, 151, 154, 162, 163, 164, 165, 167, 169, 189, 191, 192, 198, 199, 200, 202, 225, 226, 227, 230, 233, 239, 241, 242, 245, 246, 291, 298, 314, 332, 339, 340, 342, 344, 345, 346, 348, 351, 362, 363, 364, 395, 396], "opinion": [101, 105, 340, 343], "oppos": [340, 347], "opt": [189, 192], "opt_path": [395, 400], "opt_state_path": [388, 392], "optim": [4, 5, 6, 7, 8, 9, 10, 29, 31, 32, 35, 38, 40, 41, 43, 47, 52, 54, 55, 61, 68, 101, 106, 108, 110, 166, 170, 172, 174, 180, 181, 187, 188, 225, 226, 230, 232, 236, 238, 239, 240, 246, 252, 254, 258, 260, 262, 273, 278, 279, 280, 282, 284, 285, 286, 288, 289, 291, 292, 293, 295, 298, 300, 302, 306, 310, 311, 312, 313, 321, 326, 329, 332, 334, 337, 348, 353, 362, 365, 369, 372, 375, 379, 381, 388, 390, 392, 395, 396, 397, 400, 404], "optimizerlrschedul": [5, 33, 35, 326, 327, 329], "option": [2, 3, 4, 8, 9, 10, 20, 22, 26, 27, 31, 54, 59, 62, 64, 69, 71, 75, 87, 104, 105, 110, 112, 114, 118, 119, 120, 123, 126, 129, 135, 136, 140, 148, 149, 162, 164, 165, 168, 171, 181, 184, 185, 193, 197, 198, 201, 203, 204, 205, 215, 219, 221, 232, 238, 240, 244, 247, 249, 252, 255, 257, 258, 260, 271, 274, 291, 293, 294, 295, 297, 298, 313, 318, 322, 323, 332, 334, 338, 348, 355, 356, 360, 361, 362, 364, 366, 369, 373, 375, 379, 385, 387, 388, 391, 392, 394, 405], "optuna": [6, 38, 41, 285, 286, 289, 293, 311, 312], "optunasearch": [6, 41, 285, 289, 293, 312], "orang": [2, 18, 215, 217], "orc": [7, 43, 225, 226], "orchestr": [43, 108, 109, 110, 169, 173, 176, 202, 226, 258, 259, 260, 264, 269, 362, 363, 368, 369, 370, 375, 376, 379, 381, 382, 387, 388, 389, 390, 392, 394, 395, 396, 397, 400], "order": [1, 6, 13, 41, 73, 85, 193, 195, 209, 211, 285, 289, 293, 312, 332, 338, 340, 346, 382, 384, 385], "ordinari": [340, 343], "oregon": [332, 338], "org": [81, 94, 95, 375, 377, 405], "org_967t9ah1lbk1yqf1zau6a1v247": [76, 88], "org_xxxxxxx": [119, 123], "organ": [7, 8, 43, 51, 77, 80, 84, 89, 92, 95, 101, 103, 106, 119, 123, 163, 225, 226, 232, 235, 258, 268], "organiz": [84, 108, 110], "orient": [291, 298], "origin": [4, 32, 137, 147, 258, 261, 292, 302, 332, 336, 338, 339, 340, 347, 362, 364, 375, 380, 381, 388, 390, 395, 396], "original_user_id": [375, 381], "oscar": [332, 338], "oss": [193, 196, 197], "ossci": [292, 293, 305, 311, 313], "other": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 23, 25, 27, 28, 30, 31, 32, 34, 36, 41, 43, 45, 47, 51, 69, 72, 74, 76, 77, 86, 88, 89, 101, 106, 108, 109, 150, 162, 181, 183, 189, 191, 203, 205, 206, 207, 208, 209, 211, 215, 222, 224, 225, 226, 228, 230, 232, 235, 252, 255, 258, 259, 260, 263, 271, 272, 285, 289, 291, 293, 294, 297, 298, 312, 315, 316, 326, 328, 330, 332, 338, 339, 340, 346, 347, 348, 350, 356, 358, 362, 366, 368, 369, 374, 375, 377, 379, 388, 392, 395, 396], "otherwis": [4, 7, 31, 48, 181, 184, 225, 231, 375, 377], "otlp": 202, "our": [2, 4, 5, 6, 8, 9, 10, 23, 32, 35, 36, 39, 40, 41, 51, 59, 65, 70, 77, 78, 89, 90, 176, 177, 178, 181, 184, 185, 186, 198, 200, 202, 215, 222, 232, 235, 240, 244, 250, 252, 256, 258, 268, 285, 287, 288, 289, 293, 294, 295, 302, 310, 311, 316, 319, 323, 326, 329, 330, 332, 338, 340, 347, 348, 352], "out": [2, 3, 4, 5, 7, 8, 9, 20, 24, 28, 29, 32, 33, 38, 41, 47, 55, 58, 75, 76, 77, 78, 79, 83, 87, 88, 89, 90, 91, 99, 100, 189, 191, 193, 197, 203, 206, 215, 219, 223, 225, 230, 232, 239, 240, 243, 258, 259, 286, 289, 295, 323, 326, 327, 334, 336, 338, 340, 343, 346, 347, 362, 363, 364, 369, 371, 375, 377, 381, 382, 387, 388, 394, 395, 398, 404], "out_channel": [4, 5, 31, 35, 258, 261, 292, 300, 326, 329], "out_featur": [292, 300, 306], "out_img_byt": [362, 364], "out_label": [362, 364], "out_proj": [388, 391], "out_ref": [2, 19, 215, 218], "outbound": [101, 106], "outbr": [340, 347], "outdoor": [332, 338], "outhous": [332, 338], "outlier": [10, 68, 252, 254], "outlook": 174, "output": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 16, 20, 28, 31, 32, 35, 40, 41, 50, 51, 53, 59, 61, 63, 65, 70, 72, 77, 79, 82, 89, 91, 96, 112, 114, 115, 119, 123, 124, 126, 127, 129, 131, 137, 140, 141, 143, 150, 153, 154, 157, 159, 162, 164, 165, 167, 169, 172, 173, 176, 182, 183, 184, 186, 188, 198, 200, 201, 203, 206, 207, 208, 209, 214, 215, 219, 232, 234, 235, 237, 240, 244, 246, 248, 250, 252, 256, 258, 259, 260, 261, 262, 268, 270, 273, 279, 283, 285, 288, 289, 292, 293, 294, 300, 302, 306, 310, 313, 315, 316, 317, 319, 326, 329, 332, 334, 348, 353, 362, 365, 368, 375, 377, 381, 388, 389, 391, 394], "output_column": [340, 347], "output_csv": [375, 377], "output_dir": [362, 364, 395, 397], "output_path": [193, 197], "output_s": [292, 300, 306], "outsid": [4, 5, 32, 36, 108, 111, 292, 302, 326, 330], "outstand": [7, 48, 225, 231], "over": [2, 3, 6, 8, 9, 25, 28, 41, 52, 55, 57, 58, 73, 75, 76, 77, 78, 79, 85, 87, 88, 89, 90, 91, 108, 110, 203, 206, 215, 224, 232, 236, 239, 240, 242, 243, 258, 262, 273, 278, 285, 289, 291, 293, 298, 312, 332, 338, 340, 346, 347, 348, 353, 362, 368, 375, 379, 381, 382, 383, 387, 392, 394, 395, 396, 404], "overal": [294, 315, 348, 350, 382, 385], "overcom": [332, 338], "overfit": [395, 402], "overhead": [1, 4, 5, 7, 13, 30, 34, 46, 74, 84, 86, 164, 165, 168, 173, 179, 209, 211, 225, 229, 258, 259, 326, 328, 369, 374], "overlap": [193, 196, 258, 259, 388, 389], "overload": [193, 197], "overr": [340, 347], "overrid": [79, 83, 91, 100, 112, 114, 119, 123, 127, 129, 137, 140, 258, 261], "overriden": [78, 82, 90, 96], "overse": [292, 302], "oversubscrib": [2, 22, 215, 221], "overview": [6, 7, 8, 9, 12, 26, 36, 40, 43, 49, 56, 67, 76, 88, 174, 180, 182, 190, 192, 193, 194, 198, 200, 204, 210, 225, 226, 232, 233, 240, 241, 253, 258, 259, 285, 288, 293, 294, 296, 299, 310, 314, 320, 330, 405], "overwhelm": [193, 197], "overwrit": [74, 86], "own": [2, 4, 8, 10, 18, 31, 53, 69, 73, 76, 79, 81, 83, 85, 88, 91, 94, 99, 108, 110, 119, 123, 173, 178, 181, 188, 215, 217, 232, 237, 252, 255, 258, 260, 291, 296, 332, 336, 338, 340, 347, 356, 358, 361, 362, 363, 364, 366, 369, 370, 373, 375, 376, 379, 382, 383, 384, 385, 388, 389, 395, 398, 400, 404], "owner": [81, 94, 119, 121, 150, 152], "ownership": [340, 346], "ox": [332, 338], "p": [340, 347, 362, 363, 388, 394], "p50": [198, 201], "p90": [198, 201], "p99": [198, 201], "pa": [362, 364, 382, 384, 385, 388, 390, 395, 397], "pack": [332, 338, 362, 365], "packag": [11, 72, 75, 76, 87, 88, 207, 208, 258, 280, 333, 341, 349, 357, 362, 368, 369, 371, 375, 381, 382, 387], "pad": [4, 6, 31, 40, 41, 258, 261, 285, 288, 289, 292, 293, 300, 306, 310, 313, 348, 353, 362, 365], "page": [0, 8, 9, 54, 64, 164, 165, 172, 173, 179, 198, 200, 232, 238, 240, 249, 294, 318], "pagedattent": [164, 165, 170], "pagerduti": [198, 201], "pai": [164, 165, 170, 340, 347], "paid": [3, 8, 28, 51, 203, 206, 232, 235], "pain": [7, 46, 225, 229], "pair": [4, 31, 375, 376, 395, 398], "pal": [332, 338], "pale": [340, 347], "pan": [340, 346], "pancak": [395, 396], "panda": [3, 4, 5, 8, 26, 29, 33, 49, 51, 52, 53, 54, 203, 204, 232, 233, 235, 236, 237, 238, 258, 260, 270, 275, 291, 292, 298, 300, 326, 327, 342, 343, 362, 364, 369, 371, 375, 377, 382, 384, 385, 386, 387, 388, 390, 394, 395, 397, 404], "panel": [1, 2, 16, 24, 209, 214, 215, 223], "pant": [332, 338], "paper": [332, 338], "par": [340, 347], "parallel": [6, 7, 8, 9, 11, 12, 35, 41, 46, 50, 52, 54, 57, 59, 72, 167, 169, 176, 180, 207, 208, 210, 225, 229, 232, 234, 236, 238, 240, 242, 244, 262, 264, 272, 275, 276, 277, 285, 289, 293, 294, 302, 311, 316, 317, 329, 332, 334, 336, 338, 339, 340, 342, 344, 345, 348, 353, 356, 358, 362, 363, 364, 368, 369, 370, 371, 373, 375, 376, 377, 381, 382, 383, 384, 386, 388, 389, 394, 395, 396, 397, 404], "parallel_strategi": [4, 32, 258, 265, 284], "parallel_strategy_kwarg": [4, 32, 258, 265], "param": [3, 28, 203, 206, 291, 298, 356, 361, 375, 379, 382, 385], "param_nam": [258, 263], "param_spac": [3, 6, 28, 41, 203, 206, 285, 289, 291, 293, 298, 311, 312, 313], "paramet": [1, 3, 4, 5, 6, 8, 9, 16, 28, 31, 32, 35, 40, 41, 52, 54, 61, 62, 64, 75, 79, 83, 87, 91, 100, 112, 115, 119, 124, 127, 131, 137, 143, 150, 159, 164, 165, 169, 173, 175, 180, 181, 184, 186, 188, 203, 206, 209, 214, 232, 236, 238, 240, 246, 247, 249, 258, 262, 263, 265, 272, 273, 277, 279, 284, 285, 288, 289, 292, 293, 294, 300, 302, 306, 310, 312, 313, 318, 326, 329, 332, 338, 340, 345, 348, 350, 353, 356, 360, 362, 365, 369, 372, 375, 379, 382, 385, 388, 392, 395, 396, 400], "parameter": [10, 71, 252, 257, 258, 279], "paramor": [332, 338], "parcel": [340, 347], "parent": [4, 31, 292, 300], "parish": [332, 338], "pariti": [108, 110], "park": [332, 338, 356, 361], "parquet": [3, 5, 7, 8, 9, 28, 35, 43, 51, 53, 54, 55, 59, 65, 76, 88, 193, 197, 198, 200, 203, 206, 225, 226, 232, 235, 237, 238, 239, 240, 244, 250, 258, 272, 275, 283, 284, 291, 294, 298, 319, 326, 329, 363, 368, 369, 374, 376, 383, 385, 387, 389, 392, 396, 400, 404], "parquet_256": [362, 364, 395, 397, 398], "parquet_dir": [375, 377, 382, 384, 388, 390, 392], "parquet_fil": [395, 398], "parquet_path": [362, 364, 388, 390, 395, 398, 399, 404], "parquetdataset": [5, 35, 326, 329], "parquetfil": [395, 398], "pars": [7, 10, 48, 70, 77, 89, 165, 171, 173, 177, 181, 185, 225, 231, 252, 256, 295, 322, 388, 390], "parseabl": [181, 183, 185], "part": [0, 6, 8, 38, 49, 51, 74, 86, 137, 141, 173, 176, 232, 233, 235, 285, 286, 292, 293, 294, 295, 299, 308, 314, 320, 340, 347, 348, 350, 354, 375, 377], "parti": [189, 191, 332, 338], "particular": [9, 61, 240, 246, 340, 343], "particularli": [2, 23, 215, 222, 332, 338], "partit": [9, 57, 240, 242, 332, 334, 336, 362, 363, 369, 370, 382, 384, 395, 398], "partner": [332, 338, 340, 346], "pass": [3, 4, 5, 6, 7, 8, 9, 10, 17, 22, 25, 28, 32, 35, 36, 41, 47, 51, 53, 57, 62, 70, 79, 91, 203, 206, 216, 221, 224, 225, 230, 232, 235, 237, 240, 242, 247, 252, 256, 258, 259, 262, 263, 264, 265, 269, 272, 273, 275, 276, 277, 279, 280, 282, 284, 285, 289, 291, 292, 293, 294, 295, 298, 300, 302, 311, 313, 316, 317, 322, 323, 326, 329, 330, 332, 338, 348, 353, 375, 376, 382, 385, 395, 404], "passeng": [3, 8, 28, 51, 54, 203, 206, 232, 235, 238, 291, 298, 340, 347, 394], "passenger_count": [3, 8, 28, 51, 203, 206, 232, 235, 291, 298], "passrol": [101, 106], "past": [74, 75, 77, 78, 86, 87, 89, 90, 98, 332, 338, 388, 389, 390, 391, 392, 394], "past_list": [388, 394], "past_norm": [388, 394], "patch": [7, 47, 108, 110, 225, 230], "path": [3, 4, 5, 7, 8, 9, 10, 28, 29, 31, 32, 35, 36, 48, 53, 60, 61, 62, 64, 65, 70, 71, 76, 88, 108, 111, 150, 153, 173, 176, 181, 184, 193, 197, 198, 200, 201, 203, 206, 225, 231, 232, 237, 240, 245, 246, 247, 249, 250, 252, 256, 257, 258, 260, 268, 269, 270, 271, 277, 279, 280, 282, 283, 291, 292, 293, 294, 298, 300, 304, 305, 306, 311, 318, 326, 329, 330, 348, 355, 362, 364, 366, 367, 368, 369, 373, 374, 375, 377, 379, 381, 382, 384, 385, 387, 388, 390, 392, 394, 395, 397, 400, 404], "pathlib": [3, 4, 28, 29, 31, 203, 206, 258, 260, 292, 300, 388, 390], "paths_to_delet": [258, 283, 395, 404], "patient": [332, 338], "pattern": [7, 10, 12, 17, 19, 22, 43, 71, 210, 216, 218, 221, 225, 226, 252, 257, 258, 268, 273, 284, 368, 377, 381, 387, 404], "payload": [3, 28, 203, 206, 291, 298], "payment_typ": [8, 51, 54, 232, 235, 238], "pb": [193, 197], "pc": [332, 336, 338, 339], "pd": [3, 4, 5, 8, 26, 28, 29, 31, 33, 35, 49, 51, 52, 203, 204, 206, 232, 233, 235, 236, 258, 260, 275, 291, 292, 298, 300, 326, 327, 329, 340, 343, 362, 364, 369, 371, 375, 377, 381, 382, 384, 386, 387, 388, 390, 394, 395, 397], "pdf": [375, 377], "pe": [388, 391], "peac": [332, 338], "peak": [164, 165, 169], "peer": [108, 110], "penalti": [198, 201], "pend": [291, 292, 298, 305, 348, 355], "pendulum": [373, 374], "pendulum_diffus": [369, 373, 374], "pendulum_diffusion_ft": [369, 373], "pendulum_diffusion_result": [369, 373], "peopl": [332, 338, 340, 343, 347], "per": [8, 9, 51, 54, 59, 60, 76, 83, 88, 99, 164, 165, 169, 170, 173, 176, 179, 181, 184, 189, 191, 198, 200, 201, 232, 235, 238, 240, 244, 245, 261, 263, 264, 268, 269, 277, 294, 295, 316, 323, 350, 354, 362, 365, 366, 369, 372, 373, 377, 379, 382, 383, 385, 386, 387, 388, 389, 392, 394, 395, 396, 400, 402, 404], "per_worker_batch": [258, 262], "percentag": [8, 52, 232, 236], "percentil": [388, 394], "perceptu": [362, 368], "perfect": [173, 175, 332, 338, 340, 347, 362, 364], "perform": [1, 2, 3, 5, 6, 7, 8, 9, 10, 16, 22, 26, 27, 28, 35, 36, 38, 41, 43, 46, 47, 48, 49, 52, 54, 55, 56, 57, 61, 62, 64, 67, 68, 70, 75, 76, 77, 79, 83, 87, 88, 89, 91, 99, 164, 165, 166, 167, 173, 175, 179, 180, 181, 185, 186, 187, 188, 189, 191, 193, 196, 198, 201, 203, 204, 205, 206, 209, 214, 215, 221, 225, 226, 229, 230, 231, 232, 233, 236, 238, 239, 240, 241, 242, 246, 247, 249, 252, 253, 254, 256, 258, 268, 270, 272, 274, 278, 284, 285, 286, 289, 291, 293, 294, 295, 297, 298, 312, 315, 317, 318, 322, 323, 326, 329, 330, 332, 337, 338, 339, 340, 345, 346, 347, 348, 350, 355, 362, 364, 368, 369, 370, 374, 375, 381, 382, 384, 386, 387, 388, 389, 392, 394, 395, 396, 400, 404], "performantli": [11, 72, 207, 208], "perhap": [6, 7, 41, 47, 225, 230, 285, 289, 293, 312, 340, 346, 347], "period": [73, 75, 85, 87, 164, 165, 169, 295, 323, 388, 394], "permiss": [76, 80, 88, 92, 101, 106, 108, 110, 112, 113, 119, 120, 127, 128, 137, 139, 147], "permut": [362, 368], "persi": [332, 338], "persis": [258, 260], "persist": [4, 5, 31, 32, 36, 56, 57, 76, 77, 82, 88, 89, 96, 101, 105, 106, 108, 110, 189, 191, 193, 196, 241, 242, 259, 260, 261, 262, 266, 275, 278, 280, 283, 304, 314, 326, 330, 369, 373, 375, 377, 380, 382, 383, 384, 396, 400], "person": [340, 347, 375, 376, 381], "perspect": [340, 343, 347], "pertain": [77, 89], "phase": [172, 348, 353], "philip": [332, 338], "philosop": [340, 347], "philosophi": [340, 346], "photo": [332, 338, 395, 396], "photograph": [340, 347, 362, 363, 395, 397], "physic": [2, 9, 22, 61, 193, 195, 215, 221, 240, 246], "pi": [77, 89, 369, 370, 371, 374], "pi4_sampl": [77, 89], "pi_": [369, 370], "pic": [332, 338], "pick": [137, 141, 164, 165, 171, 258, 282, 284, 332, 338, 340, 347, 375, 380, 388, 393, 395, 396, 403, 404], "pickup": [388, 389], "pid": [292, 293, 305, 306, 311, 313, 348, 355], "piec": [198, 200, 332, 338], "pil": [4, 29, 258, 260, 266, 271, 276, 362, 364, 395, 397], "pile": [340, 343], "pin": [258, 271, 362, 364, 395, 396, 399], "pine": [382, 383], "pinecon": [7, 43, 225, 226], "pink": [340, 343], "pinterest": [9, 66, 240, 251], "pioneer": [7, 46, 225, 229], "pip": [0, 11, 17, 72, 74, 75, 76, 86, 87, 88, 150, 158, 173, 177, 189, 192, 202, 207, 208, 216, 333, 341, 349, 357, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "pipelin": [3, 5, 7, 8, 9, 17, 28, 35, 43, 46, 53, 55, 57, 61, 62, 66, 75, 87, 164, 165, 168, 169, 180, 181, 188, 193, 197, 199, 203, 206, 216, 225, 226, 229, 232, 237, 239, 240, 242, 246, 247, 251, 258, 260, 272, 274, 275, 277, 284, 294, 315, 317, 319, 326, 329, 340, 342, 347, 356, 359, 360, 362, 363, 364, 369, 370, 374, 375, 376, 382, 383, 387, 388, 389, 394, 395, 396, 398, 404], "pipeline_parallel_s": [173, 179], "pitch": [332, 338], "pivot": [369, 370], "pixel": [6, 9, 39, 61, 240, 246, 258, 260, 266, 275, 276, 285, 287, 293, 309, 363, 364, 366, 369, 371, 395, 397], "pixeldiffus": [362, 365, 366, 368], "pizza": [395, 396], "pl": [5, 33, 35, 36, 326, 327, 329, 330, 362, 364, 365, 366, 369, 371, 372, 373], "pl_ckpt": [362, 368], "place": [0, 7, 48, 164, 165, 168, 225, 231, 258, 260, 279, 281, 332, 338, 340, 347, 356, 361], "placehold": [74, 86, 112, 113, 119, 120, 127, 128, 135, 137, 138, 148, 150, 151, 164, 165, 171, 173, 177], "placement": [258, 262, 265, 266, 269, 369, 370, 388, 394, 395, 396, 399, 400, 404], "plai": [74, 86, 332, 338, 340, 346, 395, 404], "plain": [362, 364, 395, 396], "plan": [9, 60, 61, 63, 101, 106, 108, 110, 111, 112, 114, 119, 123, 127, 129, 135, 137, 140, 148, 150, 154, 163, 181, 184, 198, 201, 240, 245, 246, 248, 332, 336, 338], "plane": [103, 105], "planner": [388, 389], "plate": [332, 338], "plateau": [388, 394], "platform": [7, 43, 45, 46, 77, 82, 83, 84, 89, 96, 99, 101, 104, 108, 110, 163, 164, 165, 169, 189, 191, 192, 193, 196, 198, 199, 200, 201, 225, 226, 228, 229, 258, 260, 295, 324, 332, 336, 348, 350, 354], "plausibl": [369, 374], "pleas": [84, 101, 106, 112, 115, 119, 124, 127, 128, 131, 135, 137, 138, 143, 148, 150, 151, 159, 162, 181, 184, 198, 200, 201, 333, 341, 349, 357, 375, 381, 395, 396], "plot": [258, 260, 270, 271, 295, 323, 340, 343, 346, 347, 364, 365, 371, 372, 377, 382, 384, 387, 390, 394, 397, 404], "plotlin": [340, 347], "plt": [4, 6, 9, 29, 31, 32, 38, 39, 56, 60, 240, 241, 245, 258, 260, 271, 285, 286, 287, 292, 293, 295, 300, 306, 309, 323, 362, 364, 366, 368, 369, 371, 373, 375, 377, 379, 382, 384, 386, 388, 390, 392, 394, 395, 397, 402, 404], "plu": [101, 106, 258, 260, 369, 371, 395, 397], "plugin": [5, 36, 108, 111, 135, 136, 148, 149, 150, 156, 326, 330, 362, 366, 369, 373], "pm": [369, 370], "pndm": [362, 368], "png": [9, 61, 240, 246], "poc": [108, 110], "pod": [108, 110, 111, 127, 133, 134, 135, 137, 145, 146, 148, 150, 157, 164, 165, 169], "point": [4, 9, 10, 31, 61, 71, 76, 88, 101, 104, 108, 110, 112, 113, 119, 120, 127, 128, 137, 138, 150, 151, 164, 165, 171, 173, 178, 202, 240, 246, 252, 257, 258, 262, 268, 282, 332, 334, 338, 340, 346, 347, 382, 384], "pointless": [340, 343], "pole": [382, 383], "polici": [101, 105, 106, 108, 110, 111, 119, 123, 126, 147, 150, 154, 365, 368, 371], "polish": [340, 347], "polit": [181, 184, 340, 343, 347], "politician": [340, 343], "poll": [332, 338], "pont": [332, 338], "pool": [9, 62, 240, 247], "poor": [10, 68, 252, 254], "poorli": [6, 41, 285, 289, 293, 312], "popul": [8, 51, 112, 114, 127, 129, 232, 235], "popular": [3, 7, 27, 28, 45, 46, 181, 184, 203, 205, 206, 225, 228, 229, 332, 337, 375, 377], "porn": [340, 343], "porno": [340, 343], "pornograph": [340, 343], "port": [189, 192, 382, 383], "portion": [348, 353], "pos_enc": [388, 391], "posit": [7, 47, 225, 230, 332, 336, 338, 340, 342, 343, 345, 347, 356, 361, 388, 391], "posix": [101, 106], "possibl": [173, 180, 181, 186, 188, 340, 342], "possibli": [7, 48, 225, 231], "post": [3, 4, 5, 6, 10, 28, 32, 37, 42, 70, 101, 106, 198, 201, 202, 203, 206, 252, 256, 285, 290, 291, 292, 295, 298, 307, 322, 323, 326, 331, 356, 360, 362, 363, 375, 376, 381], "poster": [340, 347], "postgresql": [7, 43, 225, 226], "postwar": [340, 346, 347], "potato": [340, 343], "potemkin": [340, 347], "potenti": [2, 20, 193, 195, 215, 219], "potter": [332, 338], "power": [2, 23, 181, 182, 183, 186, 215, 222, 332, 334, 340, 342, 348, 350, 354, 382, 387], "powershel": [181, 184], "pq": [362, 364, 388, 390, 395, 397, 398], "practic": [4, 11, 32, 72, 81, 93, 101, 104, 119, 123, 163, 164, 182, 183, 184, 188, 189, 191, 207, 208, 258, 259, 268, 271, 284, 332, 339, 340, 344, 348, 350, 388, 390, 395, 396], "practition": [3, 27, 203, 205, 291, 297], "prayer": [332, 338], "pre": [9, 62, 74, 75, 76, 86, 87, 88, 119, 123, 240, 247, 294, 315, 316, 317, 348, 353, 356, 359, 360, 362, 368, 375, 381, 388, 389, 395, 396], "preced": [340, 347], "precis": [5, 35, 36, 164, 165, 169, 173, 175, 326, 329, 330, 362, 368, 369, 374, 395, 404], "precomput": [164, 165, 167, 395, 398], "preconfigur": [258, 261], "pred": [4, 31, 32, 258, 271, 369, 372, 375, 379, 382, 386, 387, 388, 391, 392, 394, 395, 400, 404], "pred_d": [382, 386, 387, 388, 394, 395, 404], "pred_label": [382, 385, 386], "pred_nois": [362, 365, 368, 369, 374], "pred_norm": [388, 394], "pred_prob": [382, 385], "pred_row": [388, 394, 395, 404], "predefin": [75, 87], "predic": [8, 55, 232, 239], "predict": [3, 6, 7, 9, 10, 28, 41, 44, 62, 65, 70, 181, 187, 203, 206, 225, 227, 240, 247, 250, 252, 256, 285, 289, 292, 293, 294, 295, 300, 306, 311, 317, 319, 322, 323, 332, 334, 348, 352, 353, 356, 358, 360, 361, 362, 363, 365, 368, 369, 370, 372, 375, 376, 378, 381, 382, 383, 385, 386, 387, 388, 389, 390, 391, 394, 395, 397, 404], "predicted_label": [9, 10, 62, 64, 70, 198, 201, 240, 247, 249, 252, 256, 294, 295, 317, 318, 322, 323, 395, 404], "predicted_prob": [291, 298], "prediction_pipelin": [3, 28, 203, 206], "predictor": [3, 28, 164, 165, 167, 203, 206, 291, 298, 395, 404], "preemption": [9, 57, 77, 89, 240, 242, 258, 281], "prefer": [74, 86, 108, 110, 112, 115, 119, 124, 127, 131, 137, 143, 150, 157, 159, 181, 187, 202, 340, 347, 362, 368], "prefer_spot": [193, 197], "prefetch": [395, 404], "prefetch_batch": [5, 36, 258, 274, 326, 330], "prefil": 172, "prefix": [4, 8, 32, 53, 76, 88, 119, 123, 232, 237, 375, 381, 388, 394, 395, 404], "prefix_for_the_resources_ad": [119, 123], "preinstal": [73, 85], "prem": [73, 85], "premier": [332, 338], "premis": [80, 92, 101, 104], "prepar": [2, 5, 21, 36, 79, 83, 91, 100, 163, 181, 184, 215, 220, 262, 265, 269, 272, 284, 326, 330, 340, 342, 346, 347, 348, 350, 353, 369, 373, 392, 394, 396, 404], "prepare_data_load": [4, 32, 259, 261, 262, 268, 284, 292, 303, 388, 390, 395, 396, 397, 399, 404], "prepare_model": [4, 32, 259, 261, 262, 268, 284, 292, 303, 375, 376, 377, 379, 388, 390, 392, 395, 396, 397, 400, 404], "prepare_train": [362, 366, 369, 373], "preprocess": [4, 5, 7, 8, 9, 32, 35, 43, 51, 55, 61, 75, 87, 225, 226, 232, 235, 239, 240, 246, 258, 260, 266, 271, 272, 276, 277, 284, 291, 294, 295, 298, 315, 323, 326, 329, 333, 341, 342, 348, 349, 350, 357, 362, 363, 364, 369, 370, 374, 375, 377, 381, 388, 389, 395, 396, 397, 398], "preprocess_imag": [362, 364], "preprocessed_df": [340, 347], "preprocessor": [8, 55, 232, 239, 295, 323, 340, 343], "preprocessor_app": [295, 323], "preprocessor_handl": [295, 323], "prerequisit": [120, 138, 151], "presenc": [382, 387], "present": [4, 7, 31, 46, 164, 165, 169, 181, 185, 198, 199, 225, 229, 258, 260, 340, 346, 347, 375, 377, 382, 383, 385, 388, 390, 394, 395, 404], "preserv": [258, 259, 261, 382, 384, 388, 389], "press": [11, 72, 207, 208], "pressur": [164, 165, 168, 193, 197, 356, 361], "pretend": [340, 344], "pretenti": [340, 343], "pretrain": [5, 35, 36, 37, 326, 329, 330, 331, 332, 337], "pretrainedconfig": [5, 35, 326, 329], "pretti": [340, 346, 395, 404], "prevent": [9, 61, 240, 246, 388, 390], "preview": [0, 112, 114, 119, 123, 127, 129, 137, 140, 182], "previou": [74, 86, 127, 132, 137, 144, 150, 160, 164, 165, 167, 168, 181, 186, 198, 199, 258, 272, 273, 279, 282, 356, 361, 375, 381, 382, 383, 395, 396], "previous": [4, 31, 258, 279], "price": [3, 28, 203, 206, 291, 298, 332, 336, 338, 388, 389], "priest": [332, 338], "primari": [7, 46, 189, 192, 225, 229], "primarili": [5, 9, 35, 63, 108, 110, 240, 248, 294, 295, 317, 323, 326, 329, 388, 392], "prime": [332, 338], "primit": [395, 397], "princip": [101, 106], "print": [2, 3, 4, 5, 6, 9, 11, 18, 20, 22, 24, 28, 31, 32, 35, 40, 41, 61, 72, 74, 75, 76, 77, 78, 82, 86, 87, 88, 89, 90, 97, 164, 165, 171, 173, 177, 178, 181, 184, 185, 186, 198, 200, 203, 206, 207, 208, 215, 217, 219, 221, 223, 240, 246, 258, 262, 267, 283, 285, 288, 289, 292, 293, 300, 304, 306, 310, 312, 313, 326, 329, 332, 336, 339, 340, 343, 344, 345, 346, 347, 348, 353, 354, 356, 361, 362, 364, 366, 367, 368, 369, 371, 373, 374, 375, 377, 379, 381, 382, 384, 385, 386, 387, 388, 390, 392, 393, 394, 395, 397, 398, 400, 401, 403, 404], "print_metrics_ray_train": [4, 32, 258, 262, 267, 273, 279, 292, 302, 304, 306], "printout": [395, 404], "prior": [7, 43, 74, 86, 225, 226, 382, 385], "priorit": [6, 41, 285, 289, 293, 312], "privat": [76, 80, 88, 92, 101, 104, 106, 108, 110, 112, 114, 115, 119, 124, 127, 129, 131, 137, 140, 143, 150, 153, 159], "private_subnet": [101, 106], "privileg": [101, 106, 108, 110], "pro": [181, 187], "prob": [2, 20, 215, 219, 382, 386], "probabilist": [388, 394], "probabl": [332, 338, 395, 396], "problem": [8, 51, 77, 89, 164, 165, 170, 181, 187, 189, 191, 232, 235], "proce": [5, 35, 292, 295, 300, 305, 306, 323, 326, 329], "process": [1, 3, 4, 5, 6, 8, 9, 10, 14, 15, 16, 17, 19, 21, 23, 28, 31, 32, 35, 36, 40, 41, 43, 48, 50, 53, 55, 57, 58, 59, 61, 62, 69, 75, 77, 79, 83, 87, 89, 91, 99, 101, 104, 106, 150, 151, 168, 170, 171, 172, 173, 174, 185, 186, 193, 195, 198, 200, 203, 206, 209, 212, 213, 214, 216, 218, 220, 222, 226, 231, 232, 234, 237, 239, 240, 242, 243, 244, 246, 247, 252, 255, 258, 259, 261, 262, 264, 266, 268, 269, 271, 272, 275, 285, 288, 289, 292, 293, 294, 295, 300, 301, 302, 310, 312, 315, 317, 321, 326, 329, 330, 332, 334, 336, 337, 338, 339, 347, 348, 350, 353, 354, 355, 356, 358, 364, 369, 370, 374, 375, 376, 377, 382, 383, 386, 388, 389, 390, 394, 395, 398], "processed_d": [362, 364], "prod": [2, 21, 215, 220], "produc": [3, 4, 5, 7, 8, 9, 28, 31, 32, 36, 44, 53, 59, 203, 206, 225, 227, 232, 237, 240, 244, 258, 268, 292, 294, 300, 306, 316, 326, 330, 340, 346, 362, 363, 375, 381, 388, 394], "product": [2, 7, 11, 22, 29, 33, 38, 47, 49, 56, 72, 75, 76, 87, 88, 101, 104, 163, 164, 165, 166, 167, 169, 170, 173, 174, 175, 178, 179, 180, 181, 182, 183, 185, 187, 188, 198, 201, 207, 208, 215, 221, 225, 230, 233, 241, 258, 268, 284, 286, 320, 327, 332, 334, 340, 347, 356, 358, 362, 368, 375, 376, 377, 378, 381, 382, 383, 385, 395, 396], "production": [78, 82, 83, 84, 90, 96, 99, 258, 284], "profession": 163, "profil": [108, 110, 112, 114, 118, 189, 191, 369, 374, 395, 404], "profile_data": 202, "prog_bar": [5, 35, 326, 329, 362, 365, 369, 372], "program": [2, 24, 181, 187, 198, 201, 215, 223], "programm": [295, 321], "programmat": [78, 82, 90, 96, 98, 198, 201, 295, 323], "progress": [4, 32, 77, 89, 258, 259, 267, 270, 278, 280, 281, 292, 304, 375, 377, 379, 395, 396, 397], "project": [0, 9, 10, 57, 68, 76, 88, 93, 95, 101, 103, 106, 119, 121, 122, 123, 150, 152, 153, 154, 156, 162, 202, 240, 242, 252, 254, 332, 338, 340, 347], "project_numb": [119, 123], "prometheu": 191, "promot": [388, 394], "promote_opt": [382, 385], "prompt": [11, 72, 73, 74, 85, 86, 164, 165, 167, 168, 181, 184, 207, 208], "promptli": [340, 346], "proof": [108, 110, 332, 338], "proper": [112, 113, 119, 120, 127, 128, 137, 139, 258, 262], "properli": [7, 11, 46, 72, 181, 186, 189, 192, 207, 208, 225, 229, 333, 341, 348, 349, 350, 356, 357, 361, 395, 397], "properti": [7, 43, 181, 186, 225, 226], "proport": [8, 9, 53, 59, 62, 232, 237, 240, 244, 247, 294, 316, 375, 377], "proprietari": [7, 43, 225, 226], "prosper": [332, 338], "protect": [382, 383], "protocol": [7, 10, 43, 48, 68, 202, 225, 226, 231, 252, 254], "prototyp": [74, 86, 173, 175, 180], "prove": [295, 323, 362, 367, 395, 403], "provid": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 17, 27, 30, 31, 34, 43, 46, 48, 49, 50, 56, 64, 68, 69, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 88, 89, 90, 91, 92, 95, 98, 99, 103, 104, 105, 106, 108, 111, 112, 114, 119, 123, 125, 129, 134, 137, 140, 150, 154, 163, 164, 165, 166, 168, 170, 173, 175, 176, 178, 179, 180, 181, 183, 184, 185, 186, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 205, 207, 208, 209, 210, 211, 215, 216, 225, 226, 229, 231, 232, 233, 234, 240, 241, 249, 252, 254, 255, 257, 258, 259, 260, 263, 272, 277, 282, 291, 292, 293, 294, 295, 297, 298, 305, 311, 313, 314, 315, 318, 321, 323, 326, 328, 340, 342, 348, 350, 354, 356, 358, 362, 366, 375, 377, 379, 382, 386, 388, 390, 392, 395, 396], "provis": [4, 5, 9, 30, 34, 57, 81, 94, 108, 109, 110, 111, 163, 240, 242, 291, 298, 326, 328, 362, 363, 382, 383, 395, 396], "proxi": [7, 48, 198, 201, 202, 225, 231], "proxim": [382, 383], "proxy_http_request": [198, 201, 202], "proxy_route_to_replica": [198, 201, 202], "prune": [362, 368, 369, 374, 382, 387], "pseudo": [362, 368], "pt": [4, 9, 10, 31, 32, 62, 66, 70, 71, 240, 247, 251, 252, 256, 257, 258, 268, 271, 279, 280, 292, 294, 295, 300, 304, 306, 317, 322, 323, 325, 362, 368, 375, 379, 381, 388, 392, 394, 395, 400, 404], "public": [3, 8, 9, 10, 28, 51, 54, 59, 61, 62, 64, 70, 101, 104, 106, 173, 176, 198, 200, 203, 206, 232, 235, 238, 240, 244, 246, 247, 249, 252, 256, 294, 295, 316, 317, 318, 322, 323, 332, 334, 338, 339, 340, 342, 343, 346, 347], "public_subnet": [101, 106], "publicli": [80, 92, 181, 184], "publish": [79, 91], "pull": [74, 86, 332, 338, 362, 364, 375, 379, 382, 385, 388, 392, 395, 396, 397, 398, 402], "pulocationid": [8, 51, 232, 235], "pumpkin": [332, 338], "pun": [340, 343], "punchestown": [332, 338], "punctuat": [340, 347], "pure": [362, 363, 375, 376], "purpl": [332, 338], "purpos": [1, 11, 13, 43, 72, 106, 207, 208, 209, 211, 226, 294, 317, 340, 343, 344, 395, 396], "push": [74, 86, 332, 338, 340, 347, 395, 396], "pushdown": [8, 55, 232, 239], "put": [2, 12, 18, 101, 106, 210, 215, 217, 332, 338, 340, 346, 347], "putobject": [101, 106], "pwd": [4, 31], "py": [0, 9, 10, 11, 60, 64, 71, 72, 74, 76, 77, 78, 79, 86, 88, 89, 90, 91, 98, 99, 112, 116, 119, 125, 127, 134, 137, 146, 150, 161, 164, 165, 171, 173, 176, 179, 181, 184, 185, 186, 189, 192, 193, 197, 198, 200, 207, 208, 240, 245, 249, 252, 257], "py311": [164, 165, 171, 173, 178], "py312": [193, 197], "pyarrow": [7, 9, 43, 59, 198, 200, 225, 226, 240, 244, 362, 364, 369, 371, 375, 377, 382, 384, 385, 388, 390, 395, 396, 397], "pydant": [3, 26, 181, 185, 203, 204, 295, 323], "pydata": [388, 390], "pyflink": [7, 46, 225, 229], "pypi": [76, 88], "pyplot": [4, 6, 9, 29, 38, 56, 240, 241, 258, 260, 285, 286, 292, 293, 295, 300, 309, 323, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "pyproj": [75, 87], "pyspark": [7, 46, 225, 229], "python": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 19, 20, 25, 27, 32, 36, 41, 43, 45, 46, 47, 50, 68, 72, 74, 75, 76, 77, 78, 79, 84, 86, 87, 88, 89, 90, 91, 96, 112, 116, 119, 125, 127, 134, 137, 146, 150, 161, 164, 165, 169, 171, 173, 176, 178, 181, 184, 186, 189, 192, 198, 200, 201, 202, 203, 205, 207, 208, 209, 211, 212, 213, 215, 218, 219, 224, 225, 226, 228, 229, 230, 232, 234, 252, 254, 258, 261, 271, 285, 289, 291, 293, 295, 297, 311, 321, 326, 330, 333, 341, 348, 349, 350, 355, 356, 357, 358, 362, 364, 369, 371, 375, 376, 377, 382, 384, 388, 390, 395, 397], "python3": [0, 76, 88], "pythonmalloc": [189, 192], "pytorch": [9, 30, 34, 38, 59, 240, 244, 258, 259, 260, 261, 262, 266, 268, 272, 273, 274, 276, 284, 286, 299, 302, 303, 304, 308, 328, 351, 354, 355, 356, 358, 362, 363, 364, 366, 368, 369, 370, 371, 373, 375, 376, 377, 378, 379, 381, 389, 391, 395, 396, 397, 398, 404], "pyyaml": 0, "q": [164, 165, 168, 181, 187, 375, 377], "q2": [332, 338], "q_q": [332, 338], "qp": [198, 201], "qt": [332, 336, 338, 339], "qtr": [332, 338], "quad": [362, 363, 369, 370, 375, 376], "qualif": [181, 184], "qualit": [395, 404], "qualiti": [7, 43, 173, 175, 225, 226, 362, 368, 375, 381], "quantiz": [164, 165, 168, 180], "queri": [7, 43, 77, 79, 89, 91, 112, 114, 127, 129, 137, 140, 141, 173, 177, 181, 184, 193, 196, 197, 198, 201, 202, 225, 226, 356, 361], "question": [332, 338], "queu": [108, 110], "queue": [1, 7, 10, 13, 48, 69, 108, 110, 198, 201, 209, 211, 225, 231, 252, 255, 295, 321], "quick": [1, 4, 12, 26, 31, 32, 77, 89, 101, 104, 108, 110, 181, 184, 204, 209, 210, 258, 260, 268, 269, 291, 296, 362, 364, 366, 375, 377, 382, 384, 385, 395, 397, 404], "quickli": [8, 11, 51, 72, 74, 80, 86, 92, 164, 165, 169, 207, 208, 232, 235, 340, 347, 362, 364, 382, 384, 388, 392, 395, 397, 402], "quickstart": [112, 113, 119, 121, 127, 128, 137, 139, 150, 152], "quit": [332, 338, 340, 347], "quot": [332, 338], "quota": [101, 103, 164, 165, 169], "qwen": [181, 185, 186, 187], "qwen2": [181, 185], "qwen3": [181, 186], "r": [0, 7, 11, 43, 72, 119, 126, 150, 162, 202, 207, 208, 225, 226, 292, 300, 332, 333, 338, 340, 341, 343, 349, 357, 369, 370, 375, 376, 377, 382, 383, 385, 388, 389, 395, 396, 397], "r1": [181, 187], "r2": [7, 43, 225, 226], "race": [332, 338, 340, 343, 346], "radio": [332, 338], "rafe": [332, 338], "ragnarok": [332, 338], "rahul": [332, 338], "rai": [13, 14, 15, 18, 19, 20, 21, 22, 23, 35, 40, 46, 51, 52, 53, 54, 59, 60, 61, 63, 64, 65, 70, 71, 73, 74, 75, 76, 78, 79, 81, 83, 85, 86, 87, 88, 90, 91, 94, 95, 96, 99, 100, 101, 103, 104, 106, 109, 111, 118, 126, 133, 134, 135, 136, 145, 146, 148, 149, 163, 169, 172, 178, 179, 180, 183, 185, 186, 188, 190, 191, 196, 197, 211, 212, 213, 217, 218, 219, 220, 221, 222, 229, 235, 236, 237, 238, 244, 245, 246, 248, 249, 250, 256, 257, 260, 261, 263, 264, 265, 266, 267, 269, 270, 279, 280, 281, 282, 283, 288, 300, 304, 305, 306, 310, 316, 317, 318, 322, 329, 335, 336, 337, 338, 351, 353, 354, 359, 360, 365, 368, 371, 374, 378, 380, 381, 387, 393, 397, 400, 401, 402, 403], "railwai": [340, 347], "rais": [2, 20, 215, 219, 362, 366, 368, 369, 373, 395, 404], "ram": [9, 61, 240, 246], "ramen": [395, 396], "rammstein": [332, 338], "rand": [2, 10, 18, 22, 70, 198, 201, 215, 217, 221, 252, 256, 295, 322, 323], "randint": [2, 4, 5, 6, 24, 31, 32, 35, 41, 181, 186, 193, 197, 215, 223, 258, 260, 271, 285, 289, 291, 293, 298, 311, 312, 326, 329, 362, 365, 369, 371], "randn": [362, 368, 369, 371, 374], "randn_lik": [5, 35, 326, 329, 362, 365], "random": [1, 2, 4, 6, 8, 9, 10, 12, 17, 18, 20, 22, 24, 31, 32, 41, 54, 64, 70, 77, 89, 119, 125, 137, 146, 181, 186, 193, 197, 198, 201, 209, 210, 215, 216, 217, 219, 221, 223, 232, 238, 240, 249, 252, 256, 258, 260, 271, 285, 289, 291, 293, 294, 295, 298, 312, 318, 322, 323, 362, 364, 368, 369, 370, 371, 374, 375, 377, 381, 382, 384, 395, 396, 397], "random_shuffl": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318, 362, 364, 369, 371, 382, 384], "random_st": [3, 28, 203, 206, 382, 384, 395, 398], "randomize_block_ord": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318, 375, 377], "randomli": [4, 8, 9, 31, 32, 54, 64, 232, 238, 240, 249, 258, 260, 294, 318, 375, 381], "rang": [1, 2, 4, 6, 9, 16, 18, 20, 24, 31, 32, 40, 41, 61, 77, 89, 101, 106, 193, 197, 209, 214, 215, 217, 219, 223, 240, 246, 258, 260, 262, 271, 273, 276, 279, 285, 288, 289, 291, 292, 293, 295, 298, 300, 302, 306, 310, 312, 313, 322, 323, 340, 344, 348, 353, 356, 358, 362, 368, 369, 371, 374, 375, 379, 382, 386, 388, 389, 390, 392, 395, 398, 400], "rank": [3, 4, 5, 28, 32, 36, 181, 184, 203, 206, 259, 261, 262, 267, 269, 280, 284, 292, 304, 326, 330, 362, 366, 379, 381, 382, 385, 386, 387, 388, 392, 395, 399, 400], "rap": [332, 338], "rapid": [74, 86], "rapidli": [73, 85], "rate": [5, 6, 35, 41, 108, 111, 164, 165, 168, 198, 201, 258, 262, 285, 289, 293, 312, 326, 329, 332, 338, 340, 343, 348, 353, 354, 362, 368, 369, 374, 378, 379, 381, 388, 394, 395, 404], "rather": [9, 60, 164, 165, 167, 240, 245, 340, 343, 347, 375, 381, 382, 384, 388, 389], "ratings_d": [375, 377], "ratings_parquet": [375, 377], "ratings_parquet_uri": [375, 377], "ratio": [202, 382, 384, 386], "rattl": [340, 347], "rattler": [332, 338], "ravenstein": [340, 347], "raw": [7, 43, 137, 141, 193, 196, 197, 225, 226, 258, 275, 276, 291, 292, 293, 298, 305, 311, 313, 332, 338, 348, 353, 362, 364, 368, 375, 377, 381, 382, 383, 384, 386, 388, 390, 395, 396, 397, 404], "raw_path": [375, 377], "ray_actor_opt": [295, 322, 323], "ray_data_synthet": [193, 197], "ray_dedup_log": [293, 313, 348, 355], "ray_enable_windows_or_osx_clust": [189, 192], "ray_pl_ckpt": [362, 366, 369, 373], "ray_result": [293, 311, 348, 355], "ray_scheduler_ev": [292, 293, 295, 305, 311, 322], "ray_train_v2_en": [362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "rayddp": [362, 366], "rayddpstrategi": [5, 33, 36, 326, 327, 330, 362, 366, 369, 373], "raylightningenviron": [5, 33, 36, 326, 327, 330, 362, 364, 366, 369, 371, 373], "rayproject": [75, 87], "rayserv": [356, 360], "raytaskerror": [2, 20, 215, 219], "raytrainreportcallback": [5, 33, 36, 326, 327, 330, 362, 363, 366, 369, 370, 373, 374, 382, 383, 384, 385, 386, 387], "raytrainwork": [292, 305, 348, 355], "raytrainxgboosttrain": [3, 26, 28, 203, 204, 206], "rayturbo": [9, 10, 57, 68, 240, 242, 252, 254], "rbac": [81, 94, 95], "rbi": [332, 336, 338], "rd": [101, 106, 332, 338, 382, 384], "rdata": [388, 390, 394, 395, 404], "re": [2, 6, 9, 10, 11, 20, 40, 64, 71, 72, 74, 77, 78, 79, 86, 89, 90, 91, 112, 115, 117, 119, 124, 126, 127, 130, 131, 137, 142, 143, 150, 159, 162, 163, 173, 177, 178, 181, 188, 207, 208, 215, 219, 240, 249, 252, 257, 258, 265, 266, 271, 283, 284, 285, 288, 294, 318, 332, 338, 340, 343, 362, 363, 364, 368, 369, 370, 374, 375, 376, 381, 382, 383, 384, 387, 388, 394, 395, 396, 397], "reach": [108, 110, 164, 165, 167, 258, 282, 340, 346], "read": [1, 2, 4, 5, 7, 10, 16, 19, 23, 24, 31, 32, 37, 43, 51, 53, 56, 59, 71, 81, 94, 101, 106, 209, 214, 215, 218, 222, 223, 225, 226, 235, 237, 241, 244, 252, 257, 258, 260, 271, 272, 275, 291, 292, 298, 307, 316, 326, 331, 340, 346, 347, 362, 364, 375, 377, 382, 384, 388, 390, 395, 396, 397, 398, 404], "read_csv": [4, 8, 31, 51, 232, 235, 292, 300, 375, 377, 381, 388, 390], "read_databricks_t": [9, 59, 240, 244], "read_imag": [9, 59, 61, 64, 240, 244, 246, 249, 294, 295, 316, 318, 323], "read_json": [8, 51, 232, 235], "read_parquet": [3, 5, 8, 9, 28, 35, 51, 54, 59, 198, 200, 203, 206, 232, 235, 238, 240, 244, 258, 275, 291, 298, 326, 329, 362, 364, 375, 377, 382, 384, 395, 404], "read_row_group": [395, 398], "read_tabl": [388, 390, 395, 398], "readabl": [8, 51, 232, 235, 258, 268], "readfil": [9, 63, 240, 248], "readi": [2, 11, 24, 72, 73, 74, 79, 83, 85, 86, 91, 99, 112, 115, 119, 124, 127, 130, 131, 137, 142, 143, 150, 159, 163, 164, 165, 172, 173, 175, 180, 181, 184, 185, 188, 207, 208, 215, 223, 258, 266, 276, 284, 332, 338, 348, 353, 369, 371, 374, 375, 376, 377, 388, 390, 395, 396, 398], "readm": [198, 201, 333, 341, 349, 357, 405], "ready_ref": [2, 24, 215, 223], "real": [7, 46, 164, 165, 167, 181, 186, 188, 225, 229, 332, 338, 340, 344, 348, 353, 370, 374, 375, 376, 381, 382, 387, 388, 394, 395, 396], "realist": [340, 347, 362, 363, 375, 377, 395, 404], "realiti": [340, 343], "realknowncaus": [388, 390], "realli": [332, 338, 340, 343, 346, 347], "reason": [76, 88, 164, 165, 168, 170, 173, 175, 181, 187, 193, 195, 369, 374], "reasoning_pars": [181, 186], "reassur": [395, 398], "rebuild": [0, 258, 271, 375, 381], "rec": [362, 364, 388, 390, 395, 397], "rec_sys_tutori": [375, 377, 379, 381], "recal": [295, 322], "recalcul": [164, 165, 168], "recap": [6, 41, 285, 289, 293, 311], "receiv": [4, 5, 7, 32, 36, 48, 108, 110, 181, 184, 186, 225, 231, 258, 259, 326, 330, 356, 358, 375, 376, 377, 379, 388, 390], "recent": [76, 88, 258, 270, 282, 340, 347, 362, 366, 369, 373, 375, 380, 388, 394, 395, 400, 402], "recent_kei": [76, 88], "recent_nam": [76, 88], "recip": [4, 31, 332, 338], "recipi": 202, "reclaim": [362, 368, 375, 381], "recommend": [0, 3, 4, 5, 6, 7, 8, 9, 10, 26, 29, 32, 33, 35, 38, 46, 49, 52, 56, 66, 67, 71, 75, 87, 101, 106, 108, 110, 164, 165, 166, 173, 174, 182, 184, 185, 198, 199, 203, 204, 225, 229, 232, 233, 236, 240, 241, 251, 252, 253, 257, 258, 260, 268, 284, 285, 286, 326, 327, 329, 378], "recomput": [375, 381], "record": [3, 8, 28, 51, 189, 191, 203, 206, 232, 235, 291, 298, 362, 364, 388, 390, 395, 397, 402], "recov": [9, 57, 240, 242, 258, 278, 362, 363, 382, 387, 388, 389, 394], "recoveri": [258, 268, 278, 280, 284, 362, 363, 369, 374, 375, 376, 379, 388, 392, 395, 396, 404], "recreat": [295, 323, 388, 394], "recurr": [388, 389], "recurs": [112, 117, 127, 135, 137, 148, 258, 283], "red": [164, 165, 168, 332, 338, 340, 347, 362, 363, 395, 396], "redefin": [3, 28, 203, 206], "redeploi": [369, 370], "redi": [101, 105], "redshift": [7, 43, 225, 226], "reduc": [3, 6, 7, 8, 9, 10, 26, 38, 43, 49, 56, 60, 61, 67, 75, 87, 164, 165, 166, 181, 183, 185, 203, 204, 225, 226, 232, 233, 240, 241, 245, 246, 252, 253, 285, 286, 332, 339, 348, 354, 388, 394], "reduct": [173, 179], "redund": [164, 165, 168, 258, 268, 395, 404], "ref": [1, 2, 15, 16, 18, 19, 22, 24, 25, 209, 213, 214, 215, 217, 218, 221, 223, 224], "refer": [1, 2, 5, 8, 9, 13, 15, 18, 19, 20, 22, 35, 51, 61, 65, 74, 76, 81, 86, 88, 94, 101, 106, 112, 113, 119, 121, 127, 128, 137, 138, 139, 150, 151, 152, 164, 165, 167, 189, 191, 192, 198, 201, 209, 211, 213, 215, 217, 218, 219, 221, 232, 235, 240, 246, 250, 258, 270, 271, 292, 294, 303, 316, 319, 326, 329, 348, 352], "reflect": [7, 43, 225, 226, 395, 402], "refresh": [340, 346], "reg": [3, 28, 203, 206], "regard": [332, 338], "regardless": [4, 5, 32, 35, 326, 329, 388, 392], "region": [76, 88, 101, 107, 112, 114, 119, 122, 123, 127, 129, 130, 132, 137, 140, 142, 144, 150, 153, 154, 156, 160, 181, 184, 291, 292, 293, 298, 305, 311, 313], "regist": [75, 81, 84, 87, 94, 104, 106, 108, 110, 113, 114, 117, 118, 120, 123, 125, 128, 129, 133, 136, 138, 140, 145, 149, 151, 154, 189, 191, 198, 199, 356, 360, 362, 368, 375, 381, 395, 404], "register_buff": [388, 391], "register_us": 202, "registr": [119, 123, 126, 150, 162, 163], "registration_complet": 202, "registri": [395, 404], "regress": [6, 41, 285, 289, 293, 312, 382, 387], "regular": [1, 14, 77, 89, 209, 212, 258, 261, 375, 381, 395, 398, 404], "reimplement": [258, 273], "reinforc": [7, 46, 225, 229], "rel": [0, 4, 32, 388, 394], "rel_path": [181, 184], "relat": [77, 89, 127, 135, 137, 141, 148, 202], "relationship": [6, 41, 101, 103, 106, 285, 289, 293, 312], "releas": [11, 72, 112, 114, 127, 129, 135, 137, 140, 148, 207, 208, 258, 271, 332, 338, 340, 343, 369, 374], "relev": [4, 8, 9, 32, 54, 55, 64, 181, 184, 232, 238, 239, 240, 249, 294, 318, 375, 381, 388, 392, 395, 398], "reli": [7, 10, 43, 46, 48, 68, 225, 226, 229, 231, 252, 254, 258, 272, 382, 384, 395, 397], "reliabl": [4, 5, 7, 9, 30, 34, 46, 57, 78, 79, 82, 83, 90, 91, 96, 99, 181, 183, 185, 188, 225, 229, 240, 242, 258, 259, 278, 284, 326, 328, 395, 400], "religi": [332, 338], "religion": [332, 338], "reload": [10, 71, 181, 184, 252, 257, 258, 271, 280, 281, 375, 381], "relpath": [181, 184], "relu": [292, 300, 306, 362, 365, 369, 372], "remain": [173, 175, 193, 197, 258, 261, 268, 332, 336, 338, 339, 362, 364, 375, 377, 388, 392], "remaind": [375, 377], "remark": [332, 338], "remast": [332, 338], "remateri": [382, 384], "rememb": [77, 78, 79, 89, 90, 91, 173, 179, 258, 268, 340, 347, 362, 368], "remind": [332, 338, 340, 347], "remot": [2, 3, 6, 9, 10, 11, 12, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 40, 59, 70, 72, 74, 77, 78, 82, 86, 89, 90, 97, 202, 203, 206, 207, 208, 210, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 240, 244, 252, 256, 258, 271, 285, 288, 294, 295, 316, 322, 323, 382, 383, 386, 387, 395, 404], "remote_add": [1, 2, 14, 15, 19, 22, 23, 209, 212, 213, 215, 218, 221, 222], "remote_funct": [1, 15, 209, 213], "remote_path": [9, 10, 62, 70, 240, 247, 252, 256], "remov": [2, 5, 8, 11, 25, 35, 53, 72, 127, 135, 137, 148, 164, 165, 170, 207, 208, 215, 224, 232, 237, 258, 260, 268, 283, 326, 329, 375, 381, 395, 404], "remove_code_output": 0, "remu": [332, 336, 338, 339], "renam": [74, 86, 382, 384, 388, 390], "renew": [108, 111], "rent": [340, 343], "repackag": [369, 370], "repartit": [8, 54, 193, 197, 232, 238, 332, 334, 336, 339], "repeat": [292, 293, 305, 313, 348, 355, 382, 386, 388, 391], "repeatedli": [332, 337], "replac": [74, 76, 79, 86, 88, 91, 112, 113, 114, 115, 119, 120, 122, 124, 125, 127, 128, 129, 131, 132, 137, 138, 140, 141, 143, 144, 146, 150, 151, 153, 156, 159, 160, 164, 165, 168, 170, 181, 184, 193, 197, 258, 272, 273, 276, 332, 338, 340, 347, 362, 368, 369, 370, 374, 375, 381, 388, 394, 395, 404], "replic": [2, 4, 5, 18, 32, 36, 215, 217, 258, 259, 268, 326, 330], "replica": [7, 48, 68, 79, 91, 164, 165, 170, 171, 176, 181, 184, 198, 201, 202, 225, 231, 254, 258, 259, 295, 321, 323, 356, 360, 361, 395, 404], "replica_handle_request": [198, 201, 202], "repo": [0, 127, 130, 132, 137, 142, 144, 150, 157, 160, 164, 165, 171, 181, 184], "repo_id": [181, 184], "report": [5, 6, 7, 31, 36, 40, 41, 44, 225, 227, 259, 260, 261, 262, 270, 273, 277, 279, 280, 284, 285, 288, 289, 291, 293, 295, 298, 299, 302, 306, 310, 311, 312, 313, 323, 326, 330, 332, 338, 362, 363, 365, 366, 368, 369, 370, 371, 375, 376, 377, 379, 382, 385, 388, 389, 392, 394, 395, 396, 400, 402, 404], "report_metrics_torch": [4, 31, 292, 300], "reportedli": [332, 338], "repositori": [0, 79, 91, 150, 157], "repres": [3, 6, 8, 28, 39, 51, 164, 165, 169, 203, 206, 232, 235, 285, 287, 291, 298, 340, 347, 375, 376, 378], "represent": [164, 165, 167, 169], "reproduc": [11, 72, 207, 208, 333, 341, 349, 357, 362, 364, 375, 377, 382, 383, 384, 395, 398], "republican": [332, 338], "req": [74, 86], "request": [1, 3, 7, 9, 10, 16, 17, 23, 26, 28, 48, 62, 67, 68, 69, 70, 108, 110, 111, 164, 165, 167, 168, 170, 176, 179, 181, 184, 185, 186, 198, 201, 203, 204, 206, 209, 214, 216, 222, 225, 231, 240, 247, 252, 253, 254, 255, 256, 258, 271, 291, 295, 298, 321, 322, 323, 358, 360, 388, 390, 394, 395, 404], "request_data": [291, 298], "requir": [0, 2, 4, 5, 7, 8, 9, 10, 22, 23, 29, 30, 33, 34, 43, 46, 54, 63, 64, 68, 69, 75, 76, 78, 81, 82, 84, 87, 88, 90, 94, 96, 101, 103, 104, 105, 106, 108, 110, 111, 121, 123, 130, 136, 142, 149, 152, 158, 162, 163, 168, 170, 173, 175, 176, 177, 180, 185, 186, 202, 215, 221, 222, 225, 226, 229, 232, 238, 240, 248, 249, 252, 254, 255, 258, 259, 265, 272, 280, 294, 317, 318, 326, 327, 328, 332, 333, 338, 341, 348, 349, 353, 354, 357, 362, 363, 369, 370, 375, 377, 388, 390, 395, 396, 400, 402], "rerun": [382, 387], "res18": [258, 277], "resampl": 389, "rescal": [362, 368], "research": [173, 175, 180, 181, 185, 332, 334, 348, 354], "reserv": [1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 17, 22, 26, 29, 33, 38, 43, 49, 56, 112, 113, 119, 120, 127, 128, 137, 138, 150, 151, 164, 165, 166, 173, 174, 181, 182, 189, 190, 193, 194, 198, 199, 203, 204, 209, 210, 215, 216, 221, 225, 226, 232, 233, 240, 241, 285, 286, 326, 327, 332, 334, 340, 342, 348, 350, 356, 358], "reset": [258, 262, 292, 300, 302, 306, 369, 371], "reshap": [5, 9, 35, 57, 240, 242, 326, 329], "resid": [388, 394], "residu": [388, 389], "resili": [79, 83, 91, 99, 173, 178, 258, 278, 280, 284, 369, 370, 382, 383, 388, 389], "resiz": 396, "resnet": [259, 260, 265, 271, 292, 300, 306, 362, 368, 395, 396], "resnet18": [4, 6, 29, 31, 32, 38, 40, 41, 258, 260, 261, 268, 270, 285, 286, 288, 289, 292, 293, 300, 305, 306, 310, 313, 395, 397, 400, 404], "resolut": [5, 35, 36, 326, 329, 330], "resolv": [4, 32, 137, 147], "resourc": [4, 5, 6, 7, 10, 17, 23, 25, 32, 36, 41, 47, 48, 57, 68, 69, 73, 75, 77, 78, 79, 81, 83, 85, 87, 89, 90, 91, 94, 95, 100, 102, 103, 106, 107, 108, 109, 110, 111, 117, 118, 120, 121, 126, 134, 135, 136, 141, 146, 147, 148, 149, 152, 162, 163, 167, 168, 175, 187, 189, 191, 198, 200, 216, 222, 224, 225, 230, 231, 242, 252, 254, 255, 258, 261, 264, 269, 271, 277, 280, 282, 285, 289, 291, 292, 293, 295, 298, 305, 311, 312, 313, 321, 323, 325, 326, 330, 332, 334, 340, 345, 348, 350, 354, 355, 369, 370, 374, 388, 389, 395, 396], "resources_per_work": [348, 354, 382, 385], "resp": [198, 201], "respect": [340, 346, 347], "respond": [181, 184], "respons": [10, 70, 75, 76, 87, 88, 108, 111, 164, 165, 167, 169, 171, 173, 177, 178, 181, 183, 184, 185, 186, 198, 201, 202, 252, 256, 295, 321, 322, 323, 356, 358, 361], "response_format": [181, 185], "rest": [127, 135, 137, 148, 258, 261, 273, 279, 340, 347, 356, 358, 375, 377, 395, 397], "restart": [11, 72, 75, 76, 87, 88, 181, 184, 207, 208, 258, 260, 278, 280, 281, 356, 361, 369, 373, 374, 375, 379, 382, 383], "restor": [270, 278, 279, 280, 284, 340, 347, 362, 363, 368, 375, 380, 381], "restored_train": [258, 282], "restrict": [80, 92], "result": [3, 6, 9, 11, 12, 16, 17, 18, 19, 25, 28, 41, 57, 72, 74, 77, 78, 82, 86, 89, 90, 97, 112, 116, 119, 125, 127, 134, 137, 146, 150, 161, 181, 186, 203, 206, 207, 208, 210, 214, 216, 217, 218, 224, 240, 242, 259, 260, 261, 268, 269, 271, 282, 284, 285, 289, 291, 293, 298, 299, 305, 311, 312, 313, 332, 334, 340, 346, 347, 348, 353, 354, 355, 356, 360, 361, 362, 366, 367, 369, 370, 373, 375, 377, 379, 380, 381, 382, 385, 387, 392, 393, 395, 397, 401, 402, 403, 404], "resum": [4, 5, 30, 34, 259, 268, 278, 279, 280, 281, 284, 326, 328, 363, 366, 368, 369, 370, 373, 376, 379, 381, 382, 383, 385, 387, 392, 394, 395, 396, 400, 403], "resume_from_checkpoint": [375, 380], "retain": [77, 89, 193, 196, 382, 385, 388, 392], "retent": [340, 347, 395, 396], "rethink": [340, 347], "retrain": [369, 374, 375, 376, 382, 387, 388, 394, 395, 404], "retri": [4, 5, 9, 17, 30, 34, 61, 82, 96, 216, 240, 246, 259, 278, 281, 282, 284, 326, 328, 362, 366, 369, 370, 375, 376, 379, 382, 385, 395, 396, 400, 401], "retriev": [1, 2, 15, 25, 209, 213, 215, 224, 258, 271, 274, 375, 379, 382, 385], "retry_except": [2, 20, 215, 219], "return": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 31, 32, 35, 39, 41, 52, 61, 62, 64, 70, 71, 72, 74, 77, 78, 82, 86, 89, 90, 97, 181, 185, 186, 193, 197, 198, 200, 203, 206, 207, 208, 209, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 232, 236, 240, 246, 247, 249, 252, 256, 257, 258, 261, 262, 265, 266, 267, 270, 271, 274, 276, 282, 285, 287, 289, 291, 292, 293, 294, 295, 298, 300, 303, 304, 306, 309, 311, 317, 318, 322, 323, 326, 329, 332, 337, 338, 340, 347, 348, 352, 353, 356, 360, 362, 364, 365, 368, 369, 371, 372, 374, 375, 376, 377, 378, 382, 384, 385, 386, 387, 388, 390, 391, 394, 395, 398, 399, 404], "reus": [2, 9, 18, 62, 101, 106, 164, 165, 168, 215, 217, 240, 247, 258, 260, 271, 294, 317, 332, 337, 382, 384, 386, 387, 388, 394], "reusabl": [388, 389], "reveal": [375, 377], "reveng": [340, 346], "revers": [382, 386, 388, 390, 395, 404], "review": [9, 59, 76, 88, 112, 114, 119, 123, 127, 129, 137, 140, 150, 154, 240, 244, 340, 342, 345, 346, 347, 348, 350, 355], "rewrit": [4, 5, 30, 34, 258, 259, 326, 328, 375, 381, 395, 396], "rf": [3, 4, 5, 6, 8, 9, 28, 32, 37, 42, 53, 55, 66, 203, 206, 232, 237, 239, 240, 251, 285, 290, 291, 292, 294, 295, 298, 307, 319, 325, 326, 331], "rg_idx": [395, 398], "rg_meta": [395, 398], "rgb": [258, 261, 271, 362, 363, 364, 395, 396, 398, 404], "rice": [395, 396], "rich": [7, 46, 74, 86, 225, 229], "richer": [369, 374], "rick": [332, 338], "ricki": [332, 338], "ride": [3, 28, 203, 206, 291, 298, 340, 346, 388, 389, 394], "ridicul": [340, 347], "ridlei": [340, 347], "rifl": [340, 346], "riget": [340, 347], "right": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 16, 17, 26, 29, 32, 33, 38, 43, 49, 56, 60, 70, 74, 86, 112, 113, 119, 120, 127, 128, 137, 138, 150, 151, 164, 165, 166, 168, 173, 174, 181, 182, 187, 188, 189, 190, 193, 194, 198, 199, 203, 204, 209, 210, 214, 215, 216, 225, 226, 232, 233, 240, 241, 245, 252, 256, 258, 261, 268, 274, 285, 286, 292, 295, 303, 322, 326, 327, 332, 334, 338, 340, 342, 346, 347, 348, 350, 356, 358, 369, 370], "rightarrow": [382, 383], "rigid": [7, 45, 225, 228], "rip": [340, 346], "rise": [395, 402], "risibl": [340, 343], "risk": [340, 347], "riskbr": [340, 347], "river": [332, 338, 340, 347], "riverboat": [340, 346], "rkn": [193, 197], "rllib": [7, 46, 225, 229], "rm": [3, 4, 5, 6, 8, 9, 10, 28, 32, 37, 42, 53, 55, 66, 71, 112, 117, 119, 126, 127, 135, 137, 148, 150, 162, 203, 206, 232, 237, 239, 240, 251, 252, 257, 285, 290, 291, 292, 294, 295, 298, 307, 319, 325, 326, 331], "rmse": [3, 6, 28, 41, 203, 206, 285, 289, 293, 311, 312, 375, 381], "rmtree": [258, 283, 362, 368, 369, 374, 375, 377, 381, 382, 387, 388, 394, 395, 404], "road": [382, 383], "roadmap": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 17, 26, 29, 32, 33, 38, 43, 49, 56, 67, 164, 165, 166, 173, 174, 181, 182, 198, 199, 203, 204, 209, 210, 215, 216, 225, 226, 232, 233, 240, 241, 252, 253, 258, 261, 285, 286, 291, 292, 293, 294, 295, 296, 299, 308, 314, 320, 326, 327], "roar": [340, 346], "robert": [340, 346], "robin": [108, 111, 332, 338], "robot": [369, 374], "robust": [0, 7, 43, 181, 185, 225, 226, 258, 281, 284, 369, 370, 388, 394, 395, 396], "rock": [332, 336, 338], "role": [76, 88, 105, 107, 108, 110, 111, 112, 114, 118, 119, 121, 127, 129, 140, 147, 150, 152, 164, 165, 171, 173, 177, 178, 181, 184, 185, 186, 193, 196, 340, 347], "roll": [79, 83, 91, 99, 173, 178, 198, 201, 332, 338, 369, 371], "rollin": [332, 338], "rollout": [10, 68, 198, 201, 252, 254, 369, 370], "roma": [332, 338], "roman": [340, 346], "ronda": [340, 346], "roof": [332, 338], "root": [1, 4, 5, 6, 16, 30, 31, 32, 34, 39, 41, 76, 88, 181, 184, 189, 192, 198, 201, 202, 209, 214, 258, 259, 260, 266, 285, 287, 289, 292, 293, 300, 303, 309, 313, 326, 328, 375, 381], "roughli": [362, 364, 369, 371, 395, 397], "round": [108, 111, 332, 338, 340, 347, 375, 377, 382, 383, 385, 387], "rout": [2, 10, 25, 68, 101, 106, 108, 110, 111, 164, 165, 169, 202, 215, 224, 252, 254, 295, 323, 356, 360], "route_prefix": [3, 28, 79, 83, 91, 100, 181, 185, 203, 206, 295, 323], "row": [4, 5, 31, 32, 35, 51, 59, 61, 198, 200, 235, 244, 246, 258, 260, 270, 271, 275, 276, 316, 326, 329, 332, 334, 336, 338, 339, 340, 342, 343, 344, 345, 346, 347, 362, 364, 366, 375, 376, 377, 379, 381, 382, 383, 384, 386, 388, 390, 394, 395, 396, 398, 402, 404], "row_group": [395, 398], "row_group_idx": [395, 398], "row_group_map": [395, 398], "royal": [332, 338], "rpc": [2, 7, 25, 43, 215, 224, 225, 226], "rstrip": [76, 88], "rubbish": [340, 347], "rubbl": [340, 346, 347], "rube": [340, 346], "ruin": [340, 347], "rule": [7, 48, 75, 87, 101, 106, 181, 184, 225, 231, 332, 338], "rumor": [332, 338], "run": [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 17, 19, 21, 25, 26, 28, 29, 33, 35, 37, 38, 40, 41, 42, 47, 49, 50, 51, 53, 55, 56, 57, 60, 62, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 84, 85, 86, 87, 88, 89, 91, 94, 98, 99, 101, 103, 105, 109, 111, 112, 114, 115, 116, 117, 118, 124, 125, 126, 127, 129, 130, 131, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 153, 159, 161, 162, 164, 165, 166, 169, 171, 174, 175, 177, 179, 180, 181, 182, 183, 184, 185, 186, 189, 191, 192, 193, 195, 196, 197, 199, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 215, 216, 218, 220, 224, 225, 230, 232, 233, 234, 235, 237, 239, 240, 241, 242, 245, 247, 251, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 264, 266, 268, 269, 270, 272, 276, 277, 278, 281, 282, 283, 284, 285, 286, 288, 289, 290, 292, 293, 294, 295, 301, 305, 306, 307, 310, 311, 312, 313, 315, 322, 323, 327, 329, 331, 334, 337, 338, 340, 342, 346, 347, 348, 350, 353, 354, 355, 356, 358, 360, 361, 362, 363, 364, 366, 367, 368, 369, 370, 373, 374, 375, 376, 379, 380, 381, 382, 383, 385, 387, 389, 392, 393, 396, 398, 400, 401, 402, 403], "run_command": [74, 86], "run_config": [3, 4, 5, 28, 32, 36, 203, 206, 258, 268, 269, 277, 280, 282, 291, 292, 298, 305, 306, 326, 330, 362, 366, 369, 373, 375, 379, 382, 385, 388, 392, 395, 401], "runawai": [332, 338], "runconfig": [3, 4, 5, 26, 28, 29, 32, 36, 203, 204, 206, 259, 260, 277, 280, 282, 284, 291, 292, 298, 305, 326, 330, 362, 364, 366, 369, 371, 373, 375, 377, 379, 382, 383, 384, 385, 388, 389, 390, 392, 395, 396, 397, 400, 401, 402, 404], "runnabl": [198, 199], "runnng": [77, 89], "runtim": [10, 17, 69, 73, 75, 85, 87, 181, 183, 184, 198, 201, 216, 252, 255, 348, 351, 356, 360, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397, 405], "runtime_env": [2, 21, 22, 173, 176, 179, 181, 184, 185, 186, 215, 220, 221, 348, 351], "runtimeenv": [348, 351], "runwai": [8, 55, 232, 239, 294, 319], "ruse": [340, 346], "rust": [7, 43, 225, 226], "ruth": [340, 346], "rw": [292, 300], "ryan": [332, 338], "s3": [3, 7, 8, 9, 10, 28, 43, 51, 53, 54, 59, 61, 62, 64, 70, 76, 88, 105, 107, 108, 110, 112, 114, 117, 118, 127, 129, 135, 137, 140, 141, 147, 148, 181, 184, 198, 200, 203, 206, 225, 226, 232, 235, 237, 238, 240, 244, 246, 247, 249, 252, 256, 258, 268, 284, 291, 292, 293, 294, 295, 298, 305, 311, 313, 316, 317, 318, 322, 323, 362, 368, 375, 381, 395, 404], "s3_bucket_id": [101, 107, 112, 114], "s3_f": [198, 200], "s3_kei": [76, 88, 181, 184], "s3_path": [5, 35, 326, 329], "s3f": [5, 33, 35, 326, 327, 329], "s3filesystem": [5, 35, 198, 200, 326, 329], "s5": [164, 165, 168], "s6": [164, 165, 168, 332, 338], "s7": [164, 165, 168], "s_": [369, 370], "s_k": [369, 370], "saatchi": [332, 338], "sacrif": [369, 370], "safe": [83, 99, 112, 114, 127, 129, 137, 140, 258, 260, 278, 332, 338, 362, 364, 388, 392, 395, 400], "safetensor": [181, 184], "safeti": [181, 185], "sai": [2, 19, 78, 82, 90, 98, 101, 106, 215, 218, 332, 338, 340, 346, 347], "said": [332, 338, 340, 343], "sake": [8, 52, 232, 236], "salad": [395, 396], "sam": [332, 338], "same": [2, 3, 4, 5, 6, 8, 10, 11, 21, 28, 32, 35, 36, 41, 52, 54, 69, 70, 72, 76, 78, 88, 90, 96, 108, 110, 112, 114, 127, 129, 137, 140, 164, 165, 171, 173, 178, 180, 181, 188, 203, 206, 207, 208, 215, 220, 232, 236, 238, 252, 255, 256, 258, 261, 264, 265, 266, 268, 273, 276, 277, 279, 282, 284, 285, 289, 291, 292, 293, 295, 298, 304, 313, 322, 326, 329, 330, 332, 338, 339, 340, 343, 347, 362, 363, 364, 366, 369, 374, 375, 381, 382, 385, 387, 388, 394, 395, 398, 402, 404], "sampl": [3, 4, 5, 6, 28, 32, 35, 41, 76, 88, 101, 106, 112, 114, 118, 119, 123, 127, 129, 130, 137, 140, 142, 150, 154, 157, 189, 191, 203, 206, 259, 262, 263, 271, 285, 289, 291, 293, 294, 295, 298, 311, 312, 317, 323, 326, 329, 340, 343, 347, 356, 360, 364, 371, 375, 381, 382, 384, 388, 390, 395, 396, 397, 398, 404], "sample_act": [369, 374], "sample_batch": [291, 298, 382, 386], "sample_count": [77, 89], "sample_idx": [4, 31, 32, 258, 260], "sample_imag": [362, 368], "sample_s": [5, 35, 326, 329], "sampler": [4, 5, 32, 36, 258, 259, 262, 273, 292, 302, 306, 326, 330, 395, 400], "samsara": [295, 324], "samsung": [332, 338], "san": [181, 186, 332, 338], "sander": [332, 338], "saniti": [258, 260, 269, 366, 369, 373, 375, 377, 382, 384], "sat": [332, 338], "satisfi": [2, 18, 215, 217], "satur": [193, 197], "saturdai": [332, 338], "save": [2, 4, 5, 22, 31, 32, 36, 75, 76, 77, 87, 88, 89, 137, 147, 164, 165, 169, 181, 184, 215, 221, 259, 261, 262, 270, 273, 277, 278, 279, 282, 284, 302, 304, 305, 306, 326, 330, 340, 346, 362, 363, 364, 365, 368, 369, 370, 373, 374, 375, 379, 380, 381, 382, 383, 385, 387, 388, 389, 392, 395, 396, 397, 400, 404], "save_checkpoint_and_metrics_ray_train": [4, 32, 258, 262, 268, 273, 292, 302, 304, 306], "save_checkpoint_and_metrics_ray_train_with_extra_st": [258, 279, 280], "save_checkpoint_and_metrics_torch": [4, 31, 292, 300], "save_hyperparamet": [5, 35, 326, 329], "save_last": [362, 366, 369, 373], "save_model": [3, 28, 203, 206], "save_top_k": [362, 366, 369, 373], "saw": [332, 338], "sayhellodebuglog": [198, 201], "sayhellodefaultlog": [198, 201], "scaffold": [10, 71, 252, 257], "scala": [7, 46, 225, 229], "scalabl": [3, 7, 8, 10, 27, 43, 46, 47, 50, 67, 69, 76, 78, 79, 81, 82, 83, 84, 88, 90, 91, 95, 96, 99, 101, 106, 167, 172, 173, 180, 181, 188, 203, 205, 225, 226, 229, 230, 232, 234, 252, 253, 255, 258, 272, 284, 291, 295, 297, 320, 332, 334, 339, 340, 342, 347, 348, 354, 355, 356, 358, 362, 363, 369, 374, 375, 376, 377, 382, 383, 386, 387, 388, 389, 394, 395, 396, 398], "scalar": [2, 25, 215, 224, 362, 365, 369, 370, 372], "scale": [1, 2, 6, 7, 8, 9, 10, 11, 13, 22, 30, 34, 35, 41, 43, 46, 48, 51, 55, 61, 62, 69, 72, 75, 77, 79, 81, 83, 84, 87, 89, 91, 95, 99, 101, 106, 108, 109, 110, 111, 127, 134, 137, 146, 147, 163, 164, 165, 166, 169, 170, 175, 176, 178, 181, 187, 193, 197, 207, 208, 209, 211, 215, 221, 225, 226, 229, 231, 232, 235, 239, 240, 246, 247, 252, 255, 259, 260, 261, 266, 269, 272, 276, 278, 280, 282, 284, 285, 289, 291, 293, 294, 295, 298, 301, 311, 319, 321, 323, 328, 329, 334, 339, 340, 342, 348, 350, 354, 358, 361, 362, 363, 364, 368, 371, 375, 376, 377, 378, 381, 382, 383, 384, 387, 388, 389, 390, 394, 395, 396, 397, 398, 404], "scaling_config": [3, 4, 5, 28, 32, 36, 203, 206, 258, 264, 269, 277, 280, 282, 291, 292, 298, 302, 305, 306, 326, 330, 348, 354, 362, 366, 369, 373, 375, 379, 382, 385, 388, 392, 395, 401], "scalingconfig": [3, 4, 5, 28, 29, 32, 36, 203, 206, 259, 260, 284, 291, 292, 298, 302, 326, 330, 348, 351, 354, 362, 363, 364, 366, 369, 370, 371, 373, 375, 376, 377, 379, 382, 383, 384, 385, 388, 389, 390, 392, 395, 397, 401], "scan": [340, 346], "scari": [340, 347], "scenario": [2, 7, 22, 24, 43, 101, 106, 112, 114, 127, 129, 137, 140, 173, 175, 180, 215, 221, 223, 225, 226, 295, 321, 348, 353, 395, 396], "scene": [340, 343, 347, 375, 376], "schedul": [1, 2, 3, 4, 5, 6, 8, 9, 13, 15, 16, 22, 23, 25, 28, 31, 35, 41, 53, 61, 62, 77, 89, 108, 110, 164, 165, 170, 203, 206, 209, 211, 213, 214, 215, 221, 222, 224, 232, 237, 240, 246, 247, 285, 289, 291, 293, 298, 305, 311, 312, 313, 326, 329, 332, 338, 348, 355, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 396, 404], "schema": [7, 8, 43, 51, 181, 185, 186, 225, 226, 232, 235, 332, 336, 339, 340, 344, 345, 362, 364, 375, 377, 388, 390], "schemat": [4, 5, 32, 36, 258, 259, 326, 330], "schlong": [340, 343], "school": [332, 338], "schumer": [332, 338], "scienc": [7, 46, 225, 229], "scientif": [7, 46, 181, 187, 225, 229, 369, 371, 382, 384], "scikit": [356, 358, 382, 384], "scipt": [198, 201], "scope": [76, 81, 88, 94, 101, 103, 193, 196], "score": [181, 184, 332, 338, 356, 361, 362, 366, 368, 375, 376, 377, 381, 382, 385, 387, 388, 390, 392], "scoreless": [332, 336, 338], "scott": [340, 347], "scotu": [332, 338], "scratch": [6, 41, 112, 114, 127, 129, 137, 140, 285, 289, 293, 312, 362, 366, 369, 373, 395, 396, 404], "screen": [73, 74, 80, 85, 86, 92, 340, 347], "script": [0, 74, 77, 79, 81, 86, 89, 91, 94, 181, 184, 193, 197, 198, 201, 362, 368, 369, 374, 382, 383, 395, 396], "scroll": [137, 147], "scrumptiou": [112, 114, 127, 129, 137, 140], "sdk": [78, 90, 119, 121, 150, 152, 153], "sea": [332, 338], "seaborn": [382, 384], "seal": [340, 347], "seamless": [7, 43, 46, 47, 76, 88, 164, 165, 170, 181, 186, 225, 226, 229, 230, 340, 342, 369, 370, 374, 388, 393, 394], "seamlessli": [7, 8, 11, 47, 55, 72, 84, 207, 208, 225, 230, 232, 239, 258, 273, 280, 332, 334, 362, 363, 369, 370, 375, 381, 382, 383, 387, 388, 389, 390, 395, 396], "search": [3, 6, 28, 38, 41, 77, 89, 101, 106, 203, 206, 285, 286, 289, 291, 293, 298, 311, 312, 313, 362, 368, 369, 374, 382, 387, 388, 394, 395, 404], "search_alg": [6, 41, 285, 289, 293, 312, 313], "season": [388, 390], "seattl": [340, 346], "second": [0, 1, 2, 6, 16, 19, 41, 137, 141, 150, 153, 173, 176, 198, 200, 201, 209, 214, 215, 218, 285, 289, 291, 293, 298, 313, 332, 338, 342, 382, 387, 395, 396, 403], "secondarili": [9, 63, 240, 248, 294, 317], "secret": [101, 106, 332, 338, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "section": [0, 6, 40, 74, 75, 77, 86, 87, 89, 101, 104, 105, 108, 110, 189, 191, 192, 198, 200, 201, 258, 260, 285, 288, 293, 310], "secur": [81, 95, 103, 105, 107, 108, 110, 112, 114, 118, 119, 123, 137, 147, 163, 164, 165, 169, 170, 173, 178, 181, 188], "security_group_descript": [101, 106], "security_group_id": [101, 107, 112, 114], "security_group_nam": [101, 106], "securitygroup": [101, 105, 106], "sedan": [181, 185], "see": [1, 2, 4, 5, 6, 8, 9, 10, 11, 16, 19, 25, 32, 35, 36, 40, 42, 53, 54, 55, 64, 66, 71, 72, 76, 79, 80, 81, 88, 91, 92, 94, 101, 106, 108, 109, 112, 114, 116, 119, 123, 125, 127, 129, 134, 137, 140, 146, 147, 150, 153, 161, 164, 165, 169, 171, 173, 176, 178, 181, 184, 185, 186, 189, 192, 193, 197, 198, 200, 201, 207, 208, 209, 214, 215, 218, 224, 232, 237, 238, 239, 240, 249, 251, 252, 257, 258, 262, 264, 269, 270, 278, 285, 288, 290, 292, 293, 294, 295, 302, 303, 304, 306, 310, 313, 318, 319, 323, 324, 326, 329, 330, 332, 333, 336, 338, 340, 341, 343, 346, 347, 348, 349, 355, 356, 357, 360, 361, 362, 363, 368, 369, 370, 388, 392, 394, 395, 396], "seed": [362, 368, 369, 371, 375, 377, 395, 398], "seek": [362, 364], "seem": [340, 347], "seen": [173, 180, 332, 338, 340, 343, 347], "segment": [101, 106, 294, 317, 388, 394], "seiz": [340, 343], "select": [4, 11, 31, 32, 72, 73, 74, 79, 80, 85, 86, 91, 92, 112, 114, 127, 129, 137, 140, 173, 179, 186, 188, 198, 200, 207, 208, 258, 260, 348, 350, 353, 375, 381, 382, 385, 388, 394, 395, 402], "select_column": [3, 28, 203, 206], "selector": [80, 92], "self": [2, 3, 5, 9, 10, 25, 28, 35, 62, 70, 198, 201, 203, 206, 215, 224, 240, 247, 252, 256, 258, 271, 291, 294, 295, 298, 317, 322, 323, 326, 329, 332, 337, 356, 360, 362, 365, 366, 369, 372, 373, 375, 378, 382, 386, 388, 389, 390, 391, 394, 395, 396, 398, 404], "sell": [340, 346], "semant": [2, 23, 25, 215, 222, 224], "semi": [7, 43, 225, 226], "send": [2, 25, 181, 185, 186, 193, 197, 198, 201, 202, 215, 224, 291, 295, 298, 321, 323, 358, 360], "send_welcome_email": 202, "sens": [3, 6, 26, 41, 203, 204, 285, 289, 291, 293, 296, 312, 340, 346, 347], "sent": [7, 48, 198, 201, 202, 225, 231, 258, 271, 340, 346], "sentenc": [181, 184, 187, 258, 264, 332, 334, 335, 337, 338], "sentence_transform": [332, 335], "sentencetransform": [332, 334, 335, 337, 338, 339], "sentiment": [332, 336, 356, 358, 360, 361], "sep": [375, 377, 381], "separ": [1, 2, 4, 6, 7, 10, 15, 23, 32, 41, 43, 69, 76, 81, 88, 95, 189, 192, 209, 213, 215, 222, 225, 226, 252, 255, 258, 266, 285, 289, 293, 312, 375, 376, 382, 384], "sept": [332, 338], "sequenc": [8, 51, 164, 165, 168, 232, 235, 340, 347, 348, 350, 351, 353, 355, 382, 383, 390, 391], "sequenti": [6, 40, 164, 165, 167, 285, 288, 292, 293, 300, 306, 310, 362, 365, 369, 372, 388, 389], "sequoia": [189, 192], "seri": [163, 390, 394], "serial": [1, 7, 13, 43, 46, 209, 211, 225, 226, 229, 382, 385, 395, 396], "serializ": [362, 364], "series_id": [388, 390], "serious": [340, 343, 347], "serv": [46, 47, 70, 71, 79, 80, 83, 91, 92, 99, 100, 101, 103, 104, 112, 113, 127, 128, 137, 138, 168, 172, 175, 178, 179, 180, 183, 185, 186, 188, 189, 192, 193, 196, 199, 229, 230, 256, 257, 258, 271, 284, 291, 298, 322, 325, 333, 341, 349, 357, 359, 360, 362, 368, 369, 374, 375, 377, 378, 381, 382, 387, 388, 394, 395, 404], "serve_llama": [164, 165, 171], "serve_llama_3_1_70b": [173, 176, 177, 178, 179], "serve_my_lora_app": [181, 184], "serve_my_qwen": [181, 185], "serve_my_qwen3": [181, 186], "server": [0, 164, 189, 192], "serverless": [101, 104], "servic": [6, 7, 42, 48, 67, 68, 75, 76, 77, 80, 81, 87, 88, 89, 92, 94, 101, 105, 106, 108, 110, 111, 112, 114, 119, 120, 122, 123, 127, 129, 137, 140, 147, 150, 153, 154, 157, 162, 164, 165, 168, 171, 174, 177, 179, 180, 198, 201, 202, 225, 231, 253, 254, 285, 290, 320, 323, 333, 341, 349, 356, 357, 358, 405], "session": [76, 81, 88, 94, 202], "session_2024": [291, 292, 298, 305], "session_2025": [348, 355], "session_latest": [189, 192, 198, 201, 202], "set": [0, 1, 2, 4, 5, 6, 9, 10, 16, 21, 22, 30, 32, 34, 35, 36, 39, 41, 61, 70, 71, 73, 75, 79, 81, 83, 85, 87, 91, 93, 100, 101, 102, 105, 108, 111, 112, 114, 118, 119, 122, 123, 127, 129, 130, 132, 136, 137, 140, 142, 144, 149, 150, 153, 154, 160, 174, 179, 180, 182, 184, 185, 190, 198, 201, 209, 214, 215, 220, 221, 240, 246, 252, 256, 257, 258, 259, 260, 261, 264, 266, 269, 271, 278, 285, 287, 289, 291, 292, 295, 298, 305, 308, 309, 311, 313, 321, 322, 323, 326, 328, 329, 330, 332, 338, 340, 345, 346, 347, 348, 350, 353, 354, 355, 356, 360, 362, 364, 375, 377, 379, 382, 385, 388, 389, 392, 395, 396, 398], "set_epoch": [4, 32, 258, 262, 273, 292, 302, 306, 395, 400], "set_float32_matmul_precis": [369, 374], "set_grad_en": [348, 353, 388, 394, 395, 404], "set_index": [388, 390], "set_titl": [6, 39, 285, 287, 292, 293, 300, 306, 309, 362, 364, 395, 397], "seth": [332, 338], "setup": [5, 7, 35, 36, 46, 75, 80, 84, 87, 92, 94, 95, 101, 102, 104, 108, 109, 110, 127, 135, 137, 148, 163, 173, 175, 179, 180, 181, 186, 191, 198, 199, 201, 225, 229, 258, 261, 269, 277, 279, 280, 282, 291, 298, 326, 329, 330, 333, 341, 349, 350, 355, 357, 366, 370, 377, 379, 384, 387, 390, 397, 405], "seven": [164, 165, 168], "sever": [7, 46, 77, 89, 101, 105, 164, 165, 168, 169, 170, 225, 229, 340, 346, 356, 358], "sevigni": [340, 343], "sex": [332, 338, 340, 343], "sexist": [332, 338], "sg": [101, 106, 112, 114], "sgd": [348, 353], "sh": [11, 72, 127, 128, 137, 139, 150, 152, 207, 208, 362, 364], "shallow": [382, 383], "shame": [340, 347], "shape": [2, 5, 8, 9, 22, 35, 53, 61, 75, 76, 87, 88, 108, 110, 193, 197, 215, 221, 232, 237, 240, 246, 258, 271, 294, 295, 317, 323, 326, 329, 332, 338, 339, 362, 365, 369, 371, 374, 382, 384, 388, 390, 391, 394, 395, 398], "shard": [3, 4, 5, 28, 32, 36, 164, 165, 169, 203, 206, 258, 259, 261, 262, 264, 266, 268, 272, 273, 274, 275, 277, 280, 292, 302, 326, 330, 362, 363, 364, 366, 368, 369, 370, 371, 373, 374, 375, 376, 377, 379, 381, 382, 383, 385, 387, 388, 389, 390, 395, 404], "shard_0": [395, 397, 398], "share": [0, 2, 4, 7, 8, 10, 18, 31, 43, 53, 68, 80, 84, 92, 101, 105, 106, 108, 110, 112, 118, 119, 120, 137, 147, 181, 184, 188, 189, 192, 215, 217, 225, 226, 232, 237, 252, 254, 258, 260, 268, 283, 332, 338, 365, 369, 372, 382, 383, 384, 388, 389, 390, 394, 395, 396], "shared_path": [76, 88], "shared_storag": [76, 88], "sharetea": [332, 338], "she": [332, 338, 340, 343, 346, 347], "sheeran": [332, 338], "shell": [9, 10, 62, 70, 150, 153, 240, 247, 252, 256], "sheriff": [340, 346], "shift": [74, 78, 79, 82, 83, 86, 90, 91, 98, 99, 382, 384, 388, 389, 392], "shine": [332, 338, 340, 346, 347], "shippuden": [332, 338], "shit": [332, 338], "shock": [340, 343], "shoe": [340, 347], "shoot": [332, 338, 340, 346], "shootout": [340, 346], "short": [340, 343, 382, 385, 388, 389], "shorter": [173, 179], "shot": [340, 343, 347], "should": [2, 4, 5, 8, 9, 10, 11, 24, 25, 32, 36, 50, 54, 63, 70, 72, 79, 83, 91, 100, 108, 110, 137, 147, 181, 184, 198, 200, 207, 208, 215, 223, 224, 232, 234, 238, 240, 248, 252, 256, 258, 261, 264, 292, 302, 326, 330, 332, 338, 340, 343, 346, 356, 361, 362, 368, 369, 374, 375, 381, 382, 387, 395, 404], "should_checkpoint": [292, 306], "show": [2, 3, 5, 6, 9, 22, 28, 35, 36, 41, 60, 62, 63, 77, 89, 112, 117, 119, 120, 127, 135, 137, 148, 164, 165, 168, 170, 181, 183, 198, 199, 202, 203, 206, 215, 221, 240, 245, 247, 248, 258, 259, 260, 268, 269, 270, 271, 273, 285, 289, 293, 295, 312, 323, 326, 329, 330, 332, 333, 334, 336, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 357, 362, 364, 366, 368, 369, 370, 373, 375, 377, 379, 382, 384, 386, 388, 390, 392, 394, 395, 396, 397, 402, 404], "showcas": [181, 182, 332, 333, 338, 340, 341, 343, 347, 349, 356, 357, 358], "shown": [198, 201, 258, 260, 340, 343], "shuffl": [4, 5, 6, 31, 32, 35, 36, 39, 41, 49, 56, 233, 241, 258, 262, 266, 272, 273, 274, 284, 285, 287, 289, 292, 293, 300, 303, 309, 313, 314, 326, 329, 330, 348, 351, 353, 369, 371, 375, 377, 382, 387, 388, 390, 392, 395, 398, 399, 400], "shut": [179, 258, 268, 332, 334, 340, 342, 348, 350], "shutdown": [173, 177, 179, 181, 184, 185, 186, 291, 295, 298, 323, 325, 350, 358], "shutil": [258, 260, 283, 362, 364, 368, 369, 371, 374, 375, 377, 381, 382, 384, 387, 388, 390, 394, 395, 397, 404], "sick": [332, 338], "sid": [101, 106], "side": [7, 47, 225, 230, 340, 346, 347, 362, 368, 375, 381, 395, 404], "sidebar": 0, "sidecar": [164, 165, 169], "sidestep": [362, 363], "sidewalk": [340, 346], "sight": [340, 343], "sign": [9, 10, 62, 70, 189, 191, 198, 199, 240, 247, 252, 256, 332, 338], "signal": [193, 195, 388, 390], "signatur": [5, 6, 36, 41, 285, 289, 293, 311, 312, 326, 330], "signifi": [8, 51, 232, 235], "signific": [4, 5, 7, 30, 34, 47, 164, 165, 169, 225, 230, 258, 259, 326, 328, 332, 334], "significantli": [75, 87, 193, 196], "signup": 84, "silicon": [11, 72, 207, 208, 332, 334, 338, 348, 350, 353], "silu": [5, 35, 326, 329], "sim": [362, 363, 369, 370], "similar": [3, 28, 108, 111, 173, 176, 177, 189, 192, 198, 200, 203, 206, 291, 298, 362, 368], "similarli": [2, 7, 25, 44, 215, 224, 225, 227, 356, 360, 375, 377], "simpl": [1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 28, 31, 35, 40, 41, 48, 50, 52, 70, 74, 76, 79, 80, 86, 88, 91, 92, 164, 165, 168, 171, 172, 173, 175, 181, 187, 199, 203, 206, 209, 211, 212, 225, 231, 232, 234, 236, 252, 256, 258, 260, 263, 269, 271, 285, 288, 289, 291, 293, 295, 298, 310, 312, 322, 323, 326, 329, 333, 340, 341, 346, 347, 349, 356, 357, 358, 360, 362, 363, 368, 375, 376, 377, 378, 381, 395, 396, 404], "simple_pipelin": [198, 200], "simpler": [173, 180, 181, 184], "simpli": [4, 31, 356, 358, 382, 387, 395, 403], "simplifi": [73, 84, 85, 119, 123, 294, 317, 395, 396], "simul": [2, 20, 202, 215, 219, 358, 369, 370, 374, 375, 377, 395, 396], "simultan": [164, 165, 167, 193, 197], "sin": [369, 370, 371, 374, 388, 391], "sinc": [2, 8, 22, 51, 76, 88, 164, 165, 168, 193, 197, 198, 201, 215, 221, 232, 235, 258, 261, 268, 332, 338, 340, 347, 362, 364, 375, 380], "sing": [332, 338], "singl": [2, 7, 8, 9, 11, 22, 29, 32, 33, 36, 46, 51, 60, 72, 164, 165, 167, 168, 169, 173, 175, 180, 181, 183, 184, 188, 198, 201, 207, 208, 215, 221, 225, 229, 232, 235, 240, 245, 258, 259, 260, 262, 271, 283, 291, 295, 298, 301, 323, 327, 330, 332, 338, 340, 342, 347, 362, 363, 364, 369, 373, 375, 376, 382, 383, 384, 387, 388, 389, 395, 396, 397, 398], "single_gpu_mnist": [292, 300, 307], "sink": [3, 9, 28, 58, 203, 206, 240, 243], "sinusoid": [388, 391], "sisterlif": [332, 338], "sit": [332, 336, 338, 340, 343], "site": [0, 76, 88, 101, 106, 340, 343], "situat": [340, 347], "six": [164, 165, 168], "size": [4, 6, 8, 9, 32, 39, 52, 57, 61, 73, 75, 77, 85, 87, 89, 164, 165, 168, 169, 172, 177, 179, 181, 184, 193, 197, 198, 201, 232, 236, 240, 242, 246, 258, 260, 261, 262, 263, 285, 287, 292, 293, 302, 309, 332, 336, 338, 340, 346, 348, 353, 354, 362, 365, 366, 368, 369, 371, 374, 375, 381, 385, 388, 390, 391, 394, 395, 397], "size_in_byt": [2, 18, 215, 217], "sj": [332, 336, 338, 339], "skagwai": [340, 346], "skew": [9, 57, 240, 242, 375, 377, 382, 384], "skill": [181, 184], "skip": [362, 364, 382, 383, 384, 395, 404], "sklearn": [3, 26, 203, 204, 382, 384], "skylynn": [332, 338], "slack": [198, 201], "sleazi": [340, 346], "sleep": [1, 2, 16, 19, 24, 198, 200, 209, 214, 215, 218, 223, 340, 347], "slice": [3, 28, 203, 206, 362, 363, 375, 377, 382, 383, 385, 395, 396, 398], "slick": [340, 347], "slide": [332, 338, 389], "slim": [75, 87], "slip": [340, 346], "slo": [164, 165, 168], "slope": [382, 383], "slot": [258, 260, 388, 389], "slow": [10, 68, 173, 175, 252, 254, 332, 334], "slow_adjust_total_amount": [198, 200], "slower": [340, 345], "slowest": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318], "slowli": [340, 347], "slowyourrol": [332, 338], "sm": [332, 338], "small": [7, 8, 9, 43, 51, 52, 60, 64, 77, 89, 164, 165, 169, 173, 175, 180, 181, 184, 187, 225, 226, 232, 235, 236, 240, 245, 249, 294, 295, 317, 318, 323, 362, 363, 369, 374, 375, 377, 381, 388, 394, 395, 396], "small_siz": [348, 353], "small_unet_model_config": [5, 35, 326, 329], "smaller": [0, 2, 22, 101, 106, 181, 184, 187, 193, 197, 215, 221], "smallest": [73, 85], "smart": [164, 165, 170, 340, 346], "smith": [332, 336, 338, 339], "smoke": [258, 284], "smoothl1": [388, 392], "smoothl1loss": [388, 392], "smoothli": [340, 342], "sn": [382, 384, 386], "snake": [332, 338], "snap": [332, 336, 338], "snapshot": [76, 88, 362, 367, 382, 387], "snapshot_download": [181, 184], "snicker": [340, 347], "snippet": [4, 5, 32, 36, 74, 76, 86, 88, 292, 306, 326, 330], "snowflak": [7, 9, 43, 59, 225, 226, 240, 244], "so": [0, 5, 6, 8, 35, 41, 52, 53, 73, 74, 75, 77, 79, 83, 85, 86, 87, 89, 91, 100, 181, 187, 189, 191, 193, 197, 232, 236, 237, 258, 259, 260, 261, 266, 267, 268, 269, 271, 272, 273, 275, 276, 278, 279, 280, 282, 285, 289, 292, 293, 304, 311, 313, 326, 329, 332, 336, 338, 340, 343, 346, 347, 356, 358, 362, 365, 369, 372, 375, 377, 382, 384, 385, 388, 389, 390, 392, 395, 396, 398, 404], "socket": [7, 46, 225, 229], "softbal": [332, 338], "softmax": [382, 383], "softprob": [382, 385], "softwar": [173, 177, 181, 184, 189, 191], "soil": [382, 383, 386], "sole": [101, 106, 340, 347], "solid": [375, 381], "solut": [1, 2, 4, 5, 6, 7, 9, 10, 16, 25, 30, 32, 34, 36, 41, 47, 57, 61, 68, 101, 105, 164, 165, 166, 170, 172, 181, 188, 209, 214, 215, 224, 225, 230, 240, 242, 246, 252, 254, 258, 259, 272, 285, 289, 292, 293, 294, 306, 312, 315, 326, 328, 330, 348, 354, 388, 394], "solv": [164, 165, 169, 181, 187], "some": [3, 4, 5, 6, 7, 8, 9, 28, 32, 37, 42, 45, 46, 54, 55, 59, 60, 64, 76, 77, 88, 89, 137, 147, 164, 165, 168, 173, 177, 181, 183, 185, 193, 196, 197, 198, 199, 203, 206, 225, 228, 229, 232, 238, 239, 240, 244, 245, 249, 285, 290, 292, 294, 307, 316, 318, 326, 331, 332, 338, 340, 343, 344, 345, 346, 347], "someth": [2, 19, 127, 131, 137, 143, 150, 159, 215, 218, 332, 338, 340, 346, 395, 396], "sometim": [2, 22, 112, 114, 127, 129, 137, 140, 215, 221, 340, 347], "somewher": [2, 25, 215, 224], "song": [332, 338], "sonnet": [181, 187], "soon": [2, 24, 215, 223, 332, 338], "sophist": [6, 7, 41, 47, 181, 183, 186, 188, 225, 230, 285, 289, 293, 312], "sorri": [332, 336, 338, 339], "sort": [7, 8, 43, 54, 76, 88, 225, 226, 232, 238, 340, 343, 375, 376, 377, 381, 382, 386, 395, 404], "sort_index": [375, 379, 388, 392, 395, 402], "soul": [332, 336, 338], "sound": [332, 338, 340, 347], "soup": [332, 338], "sourc": [0, 1, 9, 11, 13, 59, 72, 84, 101, 106, 150, 153, 189, 192, 193, 196, 207, 208, 209, 211, 240, 244, 258, 272, 284, 340, 344, 346, 347], "south": [332, 338], "sox": [332, 338], "space": [2, 3, 6, 7, 24, 28, 41, 44, 101, 106, 203, 206, 215, 223, 225, 227, 258, 283, 285, 289, 293, 311, 312, 340, 346, 362, 368, 369, 374, 375, 376, 381, 382, 387, 388, 394, 395, 404], "span": [202, 332, 338, 388, 390], "spark": [8, 46, 55, 229, 232, 239], "spatial": [382, 383], "spawn": [258, 269, 271], "speak": [340, 347], "speci": [382, 387], "special": [7, 8, 43, 53, 173, 180, 181, 183, 184, 187, 188, 225, 226, 232, 237, 332, 336, 338, 340, 346], "specif": [2, 5, 8, 12, 13, 22, 25, 35, 36, 54, 64, 75, 76, 77, 80, 87, 88, 89, 92, 108, 111, 119, 120, 123, 150, 154, 164, 165, 170, 173, 176, 181, 187, 189, 191, 192, 193, 195, 198, 201, 210, 211, 215, 221, 224, 232, 238, 249, 258, 269, 271, 294, 318, 326, 329, 330, 362, 363, 368, 382, 386, 387, 395, 398], "specifi": [2, 4, 5, 6, 8, 9, 10, 11, 20, 22, 32, 36, 41, 51, 61, 62, 69, 71, 72, 73, 74, 75, 79, 80, 83, 85, 86, 87, 91, 92, 100, 108, 110, 181, 184, 185, 202, 207, 208, 215, 219, 221, 232, 235, 240, 246, 247, 252, 255, 257, 258, 265, 277, 282, 285, 289, 292, 293, 295, 302, 305, 311, 312, 323, 326, 330, 348, 350, 353, 354, 355, 356, 360, 375, 379], "specific": [258, 261], "speed": [3, 4, 5, 6, 7, 10, 28, 30, 34, 40, 43, 68, 76, 88, 181, 187, 203, 206, 225, 226, 252, 254, 258, 259, 285, 288, 293, 295, 310, 323, 326, 328, 340, 342, 347, 362, 364, 395, 397, 404], "speedup": [332, 334], "speific": [77, 89], "spend": [340, 343], "spike": [164, 165, 169, 170, 173, 178], "spiki": [73, 75, 85, 87], "spill": [9, 63, 240, 248, 294, 317], "spillov": [77, 89], "spin": [9, 62, 77, 79, 89, 91, 99, 240, 247, 294, 317, 332, 334, 337, 382, 383], "split": [3, 9, 28, 61, 64, 76, 88, 164, 165, 169, 173, 176, 203, 206, 240, 246, 249, 258, 259, 260, 262, 263, 273, 291, 294, 298, 318, 332, 336, 338, 340, 343, 347, 363, 385, 386, 388, 390, 397, 404], "split_at_indic": [362, 364, 369, 371], "split_idx": [369, 371], "split_notebook": 0, "split_proportion": [375, 377], "spoil": [340, 346, 347], "spoiler": [340, 347], "spoken": [340, 346], "spot": [9, 57, 75, 77, 87, 89, 240, 242, 332, 338, 382, 386], "spotifi": [6, 8, 42, 55, 232, 239, 285, 290], "sprai": [340, 347], "sprang": [340, 347], "spruce": [382, 383], "spur": [340, 346], "spy": [189, 192], "sql": [7, 43, 47, 225, 226, 230], "sqrt": [1, 6, 16, 41, 209, 214, 285, 289, 293, 311, 312, 388, 391], "sqrt_add": [1, 16, 209, 214], "squad": [332, 338], "squar": [1, 2, 16, 19, 209, 214, 215, 218, 258, 260, 332, 338, 362, 363, 375, 376, 381], "square_ref": [2, 19, 215, 218], "square_ref_1": [2, 23, 215, 222], "square_ref_2": [2, 23, 215, 222], "square_valu": [2, 19, 215, 218], "squarederror": [3, 28, 203, 206], "squeez": [6, 39, 285, 287, 293, 309, 362, 368, 369, 374, 375, 381, 388, 391, 392], "src": [388, 391], "ssh": [101, 104, 106, 395, 396], "ssl": [108, 111], "sso": [164, 165, 170], "sst": [356, 360], "st": [101, 106, 332, 338], "stabil": [362, 368, 375, 379, 388, 390], "stabilityai": [5, 35, 36, 326, 329, 330], "stabl": [4, 32, 33, 36, 37, 164, 165, 171, 292, 307, 327, 330, 331], "stablediffus": [5, 35, 36, 326, 329, 330], "stack": [5, 35, 84, 112, 116, 119, 123, 125, 127, 129, 134, 137, 140, 146, 150, 154, 161, 193, 196, 197, 326, 329, 369, 371, 382, 384, 388, 389, 394, 395, 404], "stadium": [332, 338], "stage": [2, 4, 5, 7, 9, 22, 31, 35, 45, 57, 61, 62, 198, 200, 215, 221, 225, 228, 240, 242, 246, 247, 258, 260, 268, 326, 329, 332, 338], "stagnant": [388, 392], "stai": [258, 259, 273, 332, 338, 362, 363], "stakehold": [388, 394], "standalon": [258, 261], "standard": [5, 7, 35, 36, 43, 75, 78, 82, 87, 90, 96, 119, 123, 198, 201, 225, 226, 258, 260, 262, 266, 268, 276, 326, 329, 330, 340, 343, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 391, 395, 396, 397, 398], "stander": [340, 347], "stapl": [340, 343], "star": [332, 338, 340, 347, 369, 370, 375, 377], "stare": [340, 343], "starlett": [10, 67, 252, 253, 291, 295, 298, 322], "start": [2, 3, 4, 5, 8, 9, 10, 11, 17, 21, 22, 26, 28, 29, 31, 32, 33, 35, 36, 38, 49, 56, 59, 61, 62, 67, 72, 74, 75, 76, 77, 78, 82, 86, 87, 88, 89, 90, 96, 101, 104, 112, 113, 116, 119, 120, 125, 127, 128, 134, 137, 138, 139, 146, 150, 151, 153, 161, 166, 168, 172, 173, 174, 177, 181, 182, 184, 187, 191, 193, 197, 198, 199, 200, 201, 203, 204, 206, 207, 208, 215, 216, 220, 221, 232, 233, 240, 241, 244, 246, 247, 252, 253, 258, 259, 260, 261, 264, 265, 269, 277, 278, 279, 281, 286, 291, 292, 295, 296, 298, 300, 305, 310, 323, 326, 327, 329, 330, 332, 334, 340, 342, 343, 346, 350, 353, 354, 356, 358, 361, 362, 363, 368, 369, 370, 374, 375, 377, 388, 390, 392, 395, 396, 397, 403], "start_epoch": [258, 279, 375, 379, 388, 392, 395, 400], "start_token": [388, 392], "starter": [79, 91], "startswith": [375, 381, 395, 404], "startup": [2, 21, 108, 110, 173, 180, 189, 192, 215, 220], "starv": [340, 347], "state": [2, 3, 7, 10, 25, 28, 46, 47, 56, 68, 69, 74, 86, 101, 106, 112, 114, 127, 129, 137, 140, 164, 165, 170, 181, 186, 193, 195, 198, 200, 203, 206, 215, 224, 225, 229, 230, 241, 252, 254, 255, 278, 279, 282, 284, 291, 298, 332, 337, 338, 340, 343, 347, 362, 368, 371, 372, 374, 375, 380, 382, 386, 388, 389, 394, 395, 404], "state_dict": [4, 31, 32, 258, 268, 271, 280, 292, 300, 304, 306, 362, 368, 369, 374, 375, 379, 381, 388, 392, 394, 395, 400, 404], "stateless": [1, 9, 14, 62, 209, 212, 240, 247, 362, 364], "statement": [4, 31, 101, 106], "static": [7, 9, 48, 57, 164, 165, 168, 225, 231, 240, 242], "station": [340, 347], "statist": [8, 55, 193, 195, 232, 239], "stats_d": [382, 386, 387], "statu": [78, 79, 90, 91, 98, 112, 116, 119, 125, 127, 134, 137, 146, 150, 161, 193, 197, 198, 200, 202, 291, 292, 293, 295, 298, 305, 311, 313, 322, 332, 338, 348, 355], "std": [8, 9, 54, 64, 232, 238, 240, 249, 258, 271, 294, 318, 388, 390, 394, 395, 398, 404], "stderr": [198, 201], "steadi": [362, 366], "steadili": [258, 270, 388, 392], "steak": [395, 396], "steal": [340, 346], "steam": [340, 343], "step": [1, 2, 4, 5, 6, 7, 9, 12, 14, 16, 17, 31, 32, 35, 40, 41, 48, 58, 61, 79, 83, 84, 91, 100, 112, 113, 114, 119, 121, 123, 126, 127, 128, 129, 131, 132, 137, 138, 139, 140, 143, 144, 150, 151, 152, 155, 159, 160, 162, 168, 182, 187, 193, 197, 198, 199, 209, 210, 212, 214, 215, 216, 225, 231, 240, 243, 246, 259, 261, 262, 263, 266, 270, 271, 273, 275, 276, 279, 285, 288, 289, 292, 293, 300, 302, 303, 306, 310, 311, 312, 313, 326, 329, 332, 338, 340, 342, 348, 353, 363, 370, 371, 376, 377, 379, 383, 384, 389, 390, 392, 396, 400], "step_size_hour": [388, 394], "sterl": [332, 338], "steven": [332, 338], "stewart": [340, 346], "still": [2, 4, 7, 19, 32, 47, 74, 86, 215, 218, 225, 230, 258, 268, 273, 274, 280, 282, 292, 304, 332, 338, 340, 346, 356, 361, 362, 364, 388, 392, 395, 397], "stillkidrauhl": [332, 338], "stockholm": [340, 343], "stop": [6, 11, 41, 72, 164, 165, 167, 207, 208, 258, 271, 285, 289, 293, 312, 340, 347, 356, 361, 362, 368, 382, 387, 388, 394, 395, 404], "storag": [5, 7, 8, 9, 31, 35, 36, 43, 46, 50, 52, 53, 59, 65, 73, 84, 85, 101, 105, 106, 112, 118, 119, 120, 122, 123, 150, 153, 154, 181, 184, 193, 196, 197, 225, 226, 229, 232, 234, 236, 237, 240, 244, 250, 259, 260, 261, 266, 269, 270, 277, 278, 280, 282, 284, 294, 295, 304, 315, 316, 317, 319, 322, 326, 329, 330, 369, 374, 377, 388, 389, 390, 395, 396, 397, 404, 405], "storage_fold": [3, 4, 8, 9, 10, 28, 31, 32, 53, 55, 62, 65, 66, 70, 71, 203, 206, 232, 237, 239, 240, 247, 250, 251, 252, 256, 257], "storage_path": [3, 4, 5, 28, 32, 35, 36, 203, 206, 258, 259, 268, 277, 280, 282, 291, 292, 298, 305, 326, 329, 330, 362, 366, 369, 373, 375, 379, 380, 382, 385, 388, 392, 395, 400, 401], "store": [5, 7, 9, 10, 24, 25, 35, 36, 43, 47, 48, 63, 64, 68, 77, 89, 101, 105, 189, 192, 198, 200, 223, 224, 225, 226, 230, 231, 240, 248, 249, 252, 254, 258, 260, 261, 268, 269, 270, 275, 276, 277, 280, 284, 291, 294, 298, 317, 318, 326, 329, 330, 332, 334, 338, 339, 340, 343, 347, 362, 363, 366, 368, 369, 374, 375, 377, 379, 381, 382, 383, 384, 387, 388, 390, 392, 395, 396, 397, 400, 402], "stori": [340, 343, 347], "storylin": [340, 346, 347], "str": [3, 4, 5, 6, 9, 10, 28, 31, 32, 35, 41, 61, 62, 64, 70, 181, 185, 186, 193, 197, 203, 206, 240, 246, 247, 249, 252, 256, 258, 268, 280, 285, 289, 292, 293, 294, 295, 300, 304, 311, 317, 318, 322, 323, 326, 329, 332, 337, 356, 360, 382, 385, 388, 394, 395, 398, 399, 404], "strang": [340, 347], "stranger": [340, 346], "strategi": [5, 36, 79, 83, 91, 99, 180, 326, 330, 362, 364, 366, 369, 373], "stratifi": [382, 384], "streak": [332, 336, 338], "stream": [3, 8, 9, 10, 28, 48, 55, 57, 68, 164, 165, 169, 171, 173, 177, 178, 181, 184, 198, 201, 203, 206, 231, 232, 239, 240, 242, 252, 254, 258, 272, 273, 274, 276, 277, 284, 294, 295, 315, 317, 321, 332, 336, 338, 339, 362, 363, 369, 370, 374, 375, 376, 377, 379, 381, 382, 383, 384, 385, 388, 390, 394], "streaming_split": [9, 60, 240, 245], "streamlin": [78, 82, 90, 98, 101, 105, 108, 109], "street": [340, 346], "strength": [181, 184], "stretch": [332, 338], "strftime": [4, 31, 292, 300], "strict": [362, 368, 369, 374], "stride": [4, 6, 31, 40, 41, 258, 261, 285, 288, 289, 292, 293, 300, 306, 310, 313, 388, 390], "strike": [340, 346, 347], "string": [77, 89, 119, 123, 127, 129, 132, 137, 140, 144, 150, 160, 181, 185, 186, 332, 336, 339, 340, 344, 345, 347, 395, 397], "strip": [375, 381, 388, 394, 395, 404], "strong": [164, 165, 169, 173, 175, 193, 197, 375, 378, 388, 390], "stronger": [173, 175], "structur": [9, 47, 55, 59, 93, 95, 165, 172, 182, 183, 184, 186, 188, 198, 201, 230, 239, 240, 244, 291, 298, 340, 343, 362, 363, 369, 370, 374, 375, 376, 388, 391, 392, 405], "stuck": [10, 68, 193, 197, 252, 254], "student": [340, 343], "studi": [4, 5, 32, 37, 292, 307, 326, 331, 340, 343], "studio": [74, 86, 332, 338, 340, 346], "stuff": [332, 338], "stun": [340, 346, 347], "stupid": [340, 347], "style": [0, 5, 35, 258, 274, 284, 326, 329, 340, 347, 362, 368, 375, 377, 379, 388, 389, 395, 396], "sub": [2, 23, 215, 222], "subdirectori": 0, "subfold": [5, 35, 326, 329], "subject": [181, 187], "submiss": [6, 41, 78, 82, 90, 96, 285, 289, 293, 312], "submit": [6, 40, 74, 77, 86, 89, 112, 116, 119, 125, 127, 134, 137, 146, 150, 161, 193, 197, 285, 288, 293, 310, 332, 338], "subnet": [104, 107, 112, 114, 118, 119, 120, 123, 150, 154, 163], "subnet_id": [101, 107, 112, 114], "suboptim": [9, 57, 240, 242], "subplot": [6, 39, 258, 260, 271, 285, 287, 292, 293, 300, 306, 309, 362, 364, 368, 375, 377, 395, 397], "subprocess": [9, 10, 56, 62, 67, 70, 240, 241, 247, 252, 253, 256, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "subraman": [332, 338], "subsampl": [382, 387], "subsequ": [164, 165, 169, 189, 191, 192, 198, 201, 340, 347], "subset": [4, 6, 8, 9, 32, 41, 52, 59, 60, 80, 92, 232, 236, 240, 244, 245, 285, 289, 294, 317, 348, 353, 362, 363, 364, 375, 377, 382, 384, 388, 390, 395, 396, 397], "substanc": [340, 347], "substanti": [388, 392], "subtract": [362, 368], "subword": [164, 165, 167], "success": [6, 41, 202, 285, 289, 293, 312], "successfulli": [75, 78, 87, 90, 112, 115, 118, 119, 124, 127, 131, 136, 137, 143, 149, 150, 159, 173, 180, 181, 184, 369, 374], "suck": [332, 338], "sudo": [189, 192], "suffer": [10, 68, 252, 254], "suffici": [173, 177, 362, 364], "suffix": [1, 15, 209, 213], "suggest": [9, 62, 181, 184, 240, 247, 382, 386], "suit": [7, 43, 225, 226, 258, 259, 375, 378], "suitabl": [0, 340, 347, 348, 350, 362, 368, 375, 377], "sum": [2, 8, 9, 18, 51, 54, 60, 64, 77, 89, 215, 217, 232, 235, 238, 240, 245, 249, 294, 318, 340, 343, 375, 378, 379, 382, 386, 387], "sum_ref": [2, 19, 215, 218], "sum_valu": [2, 19, 215, 218], "summar": [164, 165, 168, 173, 180, 181, 184, 187, 188, 332, 339], "summari": [174, 181, 184, 188, 334, 350], "summer": [332, 336, 338, 340, 347], "summerslam": [332, 336, 338], "summit": [8, 9, 55, 66, 232, 239, 240, 251, 292, 294, 305, 306, 319], "sun": [332, 338, 340, 346, 347], "sunbeam": [112, 114], "sunda": [332, 338], "sundai": [332, 336, 338], "super": [5, 35, 326, 329, 332, 333, 338, 341, 349, 357, 362, 365, 369, 372, 375, 378, 388, 391], "superior": [340, 347], "supervis": [369, 371, 388, 390, 395, 396], "suppli": [340, 346, 369, 374], "support": [2, 4, 5, 7, 8, 9, 10, 11, 22, 25, 30, 31, 34, 43, 46, 47, 48, 55, 57, 59, 64, 65, 68, 71, 72, 84, 106, 108, 110, 111, 164, 173, 179, 181, 184, 185, 188, 189, 191, 193, 196, 198, 199, 201, 207, 208, 215, 221, 224, 225, 226, 229, 230, 231, 232, 239, 240, 242, 244, 249, 250, 252, 254, 257, 258, 259, 260, 274, 279, 280, 282, 294, 318, 319, 326, 328, 340, 342, 348, 354, 356, 358, 369, 370, 375, 380, 381, 382, 384, 387, 395, 400], "suppos": [332, 338], "suptitl": [362, 364, 368, 395, 397], "sur": [332, 338], "sure": [0, 4, 32, 74, 86, 150, 162, 181, 184, 258, 283, 332, 336, 338, 339, 362, 368, 375, 381, 395, 398], "surfac": [198, 201], "surg": [388, 394], "surpris": [340, 347], "surprisingli": [2, 25, 215, 224, 332, 338], "surround": [340, 343], "surviv": [332, 336, 338, 339, 369, 374], "sushi": [395, 396], "suspens": [340, 347], "suv": [181, 185], "swai": [340, 347], "swap": [75, 87, 362, 368, 369, 374, 395, 404], "swede": [340, 343], "swedish": [340, 343], "sweep": [362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "swing": [332, 338, 340, 343, 369, 370], "switch": [181, 183, 184, 258, 284, 375, 381], "switcher": 0, "sy": [1, 2, 12, 17, 18, 209, 210, 215, 216, 217, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "sydow": [340, 347], "symbol": [11, 72, 207, 208, 369, 370], "sync": [74, 86, 258, 259, 332, 338, 395, 396, 400], "sync_dist": [5, 35, 326, 329, 362, 365, 369, 372], "sync_on_comput": [395, 400], "synchron": [2, 4, 18, 32, 215, 217, 258, 259, 264, 265, 268, 280, 292, 304, 362, 366, 395, 400], "synthet": [193, 197, 369, 374], "synthetic_image_output": [193, 197], "system": [1, 2, 5, 7, 8, 9, 13, 20, 35, 43, 46, 53, 61, 66, 76, 79, 83, 84, 88, 91, 99, 101, 106, 108, 110, 127, 130, 135, 137, 142, 147, 148, 150, 153, 181, 183, 184, 185, 186, 189, 191, 192, 193, 195, 196, 198, 201, 209, 211, 215, 219, 225, 226, 229, 232, 237, 240, 246, 251, 258, 284, 291, 293, 298, 311, 313, 326, 329, 381, 388, 393, 395, 396], "t": [1, 2, 4, 7, 8, 9, 11, 16, 19, 20, 21, 31, 32, 47, 52, 54, 61, 64, 72, 76, 84, 88, 108, 110, 137, 147, 164, 165, 169, 198, 200, 207, 208, 209, 214, 215, 218, 219, 220, 225, 230, 232, 236, 238, 240, 246, 249, 258, 259, 260, 264, 266, 271, 292, 294, 303, 317, 318, 332, 336, 338, 340, 343, 346, 347, 362, 363, 364, 365, 368, 369, 370, 372, 374, 375, 377, 381, 388, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 404], "t10k": [292, 293, 305, 313], "t4": [9, 62, 75, 87, 150, 155, 240, 247, 291, 292, 293, 298, 305, 311, 313], "t_": [369, 370], "t_futur": [388, 394], "t_img": [362, 365], "t_past": [388, 394], "t_scale": [362, 365], "tab": [73, 74, 75, 76, 78, 79, 85, 86, 87, 88, 90, 91, 198, 200], "tabl": [6, 7, 9, 41, 43, 59, 112, 114, 127, 129, 137, 140, 225, 226, 240, 244, 285, 289, 382, 385, 388, 390, 395, 397, 398], "tabular": [8, 51, 232, 235, 258, 275, 294, 316, 375, 376, 381, 384, 387, 395, 397], "tackl": [388, 389], "tag": [7, 47, 112, 114, 127, 129, 137, 140, 225, 230, 375, 381, 382, 387], "tail": [375, 377], "tailor": [258, 261], "take": [2, 3, 4, 5, 6, 8, 9, 10, 25, 28, 30, 31, 32, 34, 36, 40, 41, 51, 52, 60, 61, 70, 101, 107, 112, 114, 119, 123, 127, 129, 137, 140, 150, 154, 157, 181, 183, 198, 200, 203, 206, 215, 224, 232, 235, 236, 240, 245, 246, 252, 256, 260, 261, 268, 285, 288, 289, 291, 292, 293, 295, 298, 301, 306, 310, 322, 326, 328, 330, 332, 338, 340, 343, 346, 347, 348, 352, 364, 378, 384, 390, 397], "take_al": [375, 377], "take_batch": [8, 9, 52, 60, 61, 62, 232, 236, 240, 245, 246, 247, 291, 294, 295, 298, 317, 322, 323, 332, 338, 382, 384], "takeawai": 166, "taken": [340, 343, 395, 404], "talent": [332, 338, 340, 347], "talk": [8, 9, 55, 66, 181, 184, 232, 239, 240, 251, 294, 319, 332, 338, 340, 347], "taman": [332, 338], "tank": [332, 338], "target": [3, 4, 5, 9, 28, 31, 35, 61, 101, 106, 181, 184, 203, 206, 240, 246, 258, 268, 275, 295, 323, 326, 329, 333, 341, 349, 357, 369, 371, 375, 376, 377, 382, 384, 387, 388, 390, 392], "target_num_rows_per_block": [193, 197], "target_ongoing_request": [295, 323], "target_path": [362, 368, 369, 374, 375, 381], "task": [1, 3, 6, 7, 8, 9, 10, 13, 14, 15, 16, 18, 24, 25, 28, 40, 45, 46, 47, 51, 53, 57, 59, 61, 62, 68, 74, 75, 77, 86, 87, 89, 127, 128, 137, 139, 150, 152, 164, 165, 169, 173, 175, 184, 198, 200, 203, 206, 209, 211, 212, 213, 214, 217, 223, 224, 225, 228, 229, 230, 232, 235, 237, 240, 242, 244, 246, 247, 252, 254, 285, 288, 292, 293, 294, 300, 302, 306, 310, 316, 317, 340, 342, 347, 348, 351, 354, 362, 364, 368, 369, 374, 375, 378, 381, 382, 386, 387, 395, 396], "task_id": [77, 89], "taskpoolmapoper": [9, 63, 240, 248], "tatum": [340, 346], "tavakolian": [332, 338], "tax": [3, 28, 203, 206, 291, 298, 332, 338], "taxi": [3, 8, 28, 51, 54, 198, 200, 203, 206, 232, 235, 238, 394], "taximet": [8, 51, 232, 235], "taxiwindowdataset": [388, 390], "tb": [9, 57, 240, 242], "tbh": [332, 338], "tbl": [382, 385], "tc": [181, 186], "tcm": [340, 346], "tcp": [101, 106], "td3": [369, 374], "tea": [332, 338], "teach": [362, 363, 369, 370], "teacher": [340, 343, 389, 391], "team": [7, 46, 80, 81, 92, 93, 95, 225, 229, 332, 338, 395, 396], "tear": [78, 82, 90, 96], "teardown": [108, 110], "tech": [332, 338], "technic": [1, 13, 209, 211, 340, 347], "techniqu": [6, 40, 285, 288, 293, 310, 340, 347], "technologi": [7, 43, 225, 226], "ted": [332, 338], "teen": [332, 338], "telemetri": [189, 191, 193, 197], "tell": [3, 5, 28, 36, 173, 177, 178, 203, 206, 258, 264, 268, 326, 330, 332, 338, 340, 343, 346, 395, 401], "temp": [112, 114, 127, 129, 137, 140, 258, 260, 268, 388, 392, 395, 397, 400], "temp_checkpoint_dir": [4, 32, 258, 268, 280, 292, 304], "tempdir": [395, 400], "temperatur": [2, 25, 181, 186, 215, 224], "tempfil": [4, 29, 32, 258, 260, 268, 280, 292, 304, 362, 364, 366, 369, 373, 375, 377, 379, 382, 384, 388, 392, 395, 397, 400], "templat": [79, 91, 108, 111, 164, 165, 172, 175, 258, 284], "tempor": [369, 374], "temporari": [164, 165, 169, 258, 268, 369, 374, 375, 379, 382, 387, 388, 394, 395, 400, 404], "temporarydirectori": [4, 32, 258, 268, 280, 292, 304, 375, 379, 388, 392, 395, 400], "ten": [395, 396], "tenant": [181, 188, 375, 381], "tenni": [332, 338], "tensor": [4, 5, 9, 10, 31, 32, 35, 62, 70, 164, 165, 169, 173, 176, 180, 240, 247, 252, 256, 258, 266, 267, 271, 274, 276, 292, 294, 295, 300, 304, 317, 322, 326, 329, 348, 351, 364, 365, 368, 369, 374, 375, 381, 388, 390], "tensor_parallel_s": [173, 176, 179, 181, 186], "tensorflow": [356, 358], "term": [2, 7, 19, 48, 101, 105, 215, 218, 225, 231, 340, 343, 388, 389], "termin": [4, 11, 31, 72, 74, 76, 77, 78, 79, 86, 88, 89, 90, 91, 99, 108, 111, 112, 115, 116, 117, 119, 124, 126, 127, 131, 134, 135, 137, 143, 146, 148, 150, 153, 159, 162, 165, 171, 173, 176, 178, 198, 200, 202, 207, 208, 258, 260, 282, 291, 292, 298, 305, 348, 355, 369, 371], "terminologi": [81, 93], "terraform": [101, 105, 106, 107, 113, 115, 117, 118, 121, 124, 126, 128, 131, 135, 136, 139, 141, 143, 148, 149, 152, 155, 159, 162, 163], "terrain": [382, 387], "terribl": [340, 347], "test": [3, 6, 10, 28, 39, 68, 70, 71, 74, 79, 86, 91, 114, 123, 129, 140, 154, 163, 173, 177, 180, 181, 185, 186, 187, 188, 189, 192, 203, 206, 252, 254, 256, 257, 258, 284, 285, 287, 291, 293, 295, 298, 309, 322, 323, 332, 338, 348, 353, 354, 358, 395, 398], "test_job": [112, 116, 119, 125, 127, 134, 137, 146, 150, 161], "test_siz": [3, 28, 203, 206, 291, 298, 382, 384], "texan": [332, 338], "text": [5, 7, 35, 43, 76, 88, 137, 141, 168, 172, 181, 186, 193, 196, 225, 226, 326, 329, 332, 334, 336, 337, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 350, 353, 356, 360, 361, 369, 370, 375, 376, 388, 389], "text_token": [340, 347], "textembedd": [332, 337, 338, 339], "tf": [112, 114, 119, 123, 127, 129, 137, 140], "tfenv": [112, 113, 127, 128, 137, 139, 150, 152], "tfi": [332, 338], "tfvar": [112, 114, 127, 129, 137, 140], "tgt": [388, 391], "than": [4, 7, 9, 32, 45, 47, 48, 60, 61, 74, 86, 164, 165, 167, 171, 173, 175, 181, 184, 193, 197, 225, 228, 230, 231, 240, 245, 246, 291, 298, 340, 343, 345, 346, 347, 375, 381, 382, 384, 386, 388, 389, 392], "thank": [181, 188, 202, 332, 338, 388, 392], "thats": [340, 347], "theater": [340, 343, 347], "thei": [2, 7, 8, 9, 10, 11, 21, 22, 24, 46, 47, 52, 60, 66, 69, 72, 73, 75, 85, 87, 112, 114, 127, 129, 137, 140, 164, 165, 167, 169, 193, 197, 207, 208, 215, 220, 221, 223, 225, 229, 230, 232, 236, 240, 245, 251, 252, 255, 258, 263, 272, 278, 294, 317, 332, 338, 340, 343, 346, 347, 356, 358, 382, 384], "them": [0, 1, 2, 4, 5, 7, 9, 13, 15, 21, 23, 24, 25, 31, 35, 48, 62, 74, 76, 77, 80, 86, 88, 89, 92, 101, 104, 107, 108, 111, 137, 147, 173, 178, 181, 184, 193, 197, 209, 211, 213, 215, 220, 222, 223, 224, 225, 231, 240, 247, 258, 260, 271, 326, 329, 332, 338, 340, 347, 362, 364, 365, 368, 369, 370, 373, 374, 375, 376, 379, 381, 395, 396, 397, 398, 402], "theme": [0, 202], "themselv": [340, 346], "theoret": [340, 347], "therefor": [78, 82, 90, 96, 340, 343], "theta": [362, 363, 369, 370, 374, 382, 383, 388, 389, 395, 396], "theta_": [369, 370], "theta_dot": [369, 374], "thfc": [332, 338], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 80, 81, 82, 84, 85, 86, 87, 88, 89, 92, 93, 94, 96, 101, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 118, 119, 120, 121, 122, 123, 127, 128, 129, 131, 134, 136, 137, 138, 140, 141, 143, 146, 147, 149, 150, 151, 152, 153, 154, 159, 163, 164, 165, 166, 167, 168, 170, 172, 173, 174, 175, 179, 181, 182, 183, 184, 186, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 209, 210, 214, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 281, 283, 285, 286, 288, 289, 290, 292, 293, 294, 295, 299, 301, 302, 303, 304, 306, 307, 308, 310, 311, 312, 314, 316, 317, 318, 319, 320, 322, 323, 324, 326, 327, 329, 330, 331, 332, 333, 334, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 360, 361, 364, 366, 373, 377, 378, 379, 380, 384, 385, 390, 391, 392, 393, 397, 398, 399, 400, 401, 402, 405], "thine": [332, 338], "thing": [2, 21, 181, 186, 215, 220, 332, 338, 340, 346, 347], "think": [1, 2, 12, 17, 181, 187, 209, 210, 215, 216, 332, 334, 338, 340, 342, 346, 347, 348, 350, 356, 358], "third": [6, 41, 137, 141, 189, 191, 285, 289, 293, 313, 332, 338, 340, 346, 347], "tho": [332, 338], "thoma": [332, 338], "thor": [332, 338], "those": [7, 47, 77, 89, 127, 134, 137, 146, 225, 230, 340, 343, 347, 382, 386], "though": [75, 87, 164, 165, 168, 332, 338], "thought": [340, 343], "three": [1, 5, 8, 9, 16, 35, 51, 58, 59, 164, 165, 170, 171, 172, 193, 196, 209, 214, 232, 235, 240, 243, 244, 258, 284, 294, 316, 326, 329, 340, 347, 362, 368, 395, 401], "thriller": [340, 347], "throb": [340, 343], "through": [2, 3, 4, 5, 6, 7, 19, 28, 29, 35, 38, 44, 47, 73, 74, 84, 85, 86, 98, 101, 106, 107, 108, 111, 112, 113, 127, 128, 137, 138, 150, 151, 164, 165, 167, 170, 172, 173, 174, 181, 183, 186, 193, 195, 196, 198, 201, 202, 203, 206, 215, 218, 225, 227, 230, 258, 260, 263, 284, 285, 286, 292, 293, 299, 308, 326, 329, 332, 334, 338, 339, 340, 346, 347, 362, 363, 369, 374, 382, 383, 385, 388, 389, 395, 396], "throughout": [11, 72, 207, 208, 395, 397], "throughput": [7, 9, 48, 66, 164, 165, 168, 198, 200, 201, 225, 231, 240, 251, 258, 272, 284, 332, 334, 339, 382, 386, 395, 404], "throw": [127, 135, 137, 148, 332, 339], "thru": [340, 343], "thu": [4, 31, 108, 111], "thumb": [7, 48, 225, 231], "thursdai": [332, 336, 338, 339], "ti": [4, 5, 32, 36, 258, 261, 326, 330], "ticket": [332, 336, 338], "tidi": [382, 387, 388, 390, 394, 395, 404], "tie": [332, 338], "tiger": [332, 338, 340, 347], "tight": [332, 338], "tight_layout": [258, 271, 362, 364, 366, 368, 369, 373, 375, 377, 379, 388, 390, 392, 394, 395, 397, 402], "tightli": [101, 106], "tild": [369, 370], "tilt": [7, 45, 225, 228], "timber": [332, 338], "time": [1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 16, 17, 18, 19, 20, 21, 22, 24, 25, 28, 30, 32, 34, 36, 40, 46, 48, 61, 68, 75, 77, 81, 87, 89, 94, 108, 110, 164, 165, 167, 168, 169, 173, 176, 180, 181, 186, 193, 197, 198, 200, 201, 203, 206, 209, 210, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 229, 231, 240, 246, 252, 254, 258, 259, 260, 272, 273, 280, 285, 288, 291, 292, 293, 298, 301, 304, 305, 310, 311, 313, 326, 328, 330, 332, 334, 338, 340, 343, 346, 347, 348, 355, 362, 363, 369, 370, 373, 374, 375, 376, 379, 381, 382, 385, 387, 390, 392, 394, 395, 396, 403], "time_since_restor": [292, 306], "time_this_iter_": [292, 306], "time_total_": [292, 306], "timedelta": [388, 390], "timelin": [2, 24, 215, 223], "timeseri": [198, 200], "timeseriesbatchpredictor": [388, 394], "timeseriestransform": [388, 391, 392, 394], "timestamp": [4, 31, 202, 258, 260, 292, 300, 306, 375, 377, 381, 388, 390], "timestep": [5, 35, 326, 329, 362, 363, 365, 368, 369, 370, 371, 372, 374], "tini": [362, 365, 368, 369, 372, 382, 384, 388, 394, 395, 398], "tint": [340, 347], "tip": [3, 8, 28, 51, 52, 203, 206, 232, 235, 236, 292, 293, 295, 305, 311, 322], "tip_amount": [3, 8, 28, 51, 52, 198, 200, 203, 206, 232, 235, 236], "tip_percentag": [8, 52, 232, 236], "titan": [332, 338], "titl": [4, 9, 31, 32, 60, 150, 153, 240, 245, 258, 260, 271, 332, 336, 338, 362, 366, 369, 373, 377, 379, 382, 384, 386, 388, 390, 392, 394, 395, 402, 404], "tl": [108, 111], "tlc": [8, 51, 232, 235], "tloss": [348, 353], "tmp": [77, 89, 189, 192, 198, 201, 202, 291, 292, 298, 305, 348, 355], "tmp_checkpoint": [395, 404], "tmpdir": [375, 379, 388, 392, 395, 400], "to_arrow_ref": [382, 385], "to_csv": [8, 53, 232, 237, 375, 377, 388, 390], "to_datetim": [388, 390], "to_json": [291, 298], "to_numpi": [382, 385, 386, 388, 390, 394], "to_panda": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318, 340, 347, 382, 385, 395, 398], "to_parquet": [8, 53, 232, 237, 258, 275, 375, 377, 382, 384, 395, 398], "to_pylist": [388, 390], "to_tensor": [258, 271], "todai": [11, 72, 207, 208, 332, 338], "todo": [198, 201], "togeth": [3, 4, 5, 9, 10, 12, 27, 32, 36, 61, 69, 203, 205, 210, 240, 246, 252, 255, 258, 261, 268, 269, 295, 321, 323, 326, 330, 332, 338], "toke": [173, 176], "token": [79, 91, 164, 165, 167, 168, 169, 170, 171, 173, 176, 177, 178, 179, 181, 184, 185, 186, 187, 202, 342, 343, 350, 351, 355], "tokenization_fn": [340, 347], "tokenize_funct": [348, 353], "toler": [4, 5, 7, 8, 9, 30, 34, 46, 50, 55, 57, 79, 83, 91, 99, 101, 105, 106, 173, 178, 225, 229, 232, 234, 239, 240, 242, 259, 279, 280, 282, 326, 328, 362, 363, 364, 366, 368, 369, 370, 373, 374, 375, 376, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 393, 394, 396, 400, 401, 404], "tolist": [10, 70, 198, 201, 252, 256, 258, 271, 275, 295, 322, 323, 375, 381, 388, 390], "toll": [3, 8, 28, 51, 203, 206, 232, 235], "tolls_amount": [3, 8, 28, 51, 203, 206, 232, 235], "tomorrow": [181, 186, 332, 336, 338, 339], "ton": [340, 347], "tone": [181, 184], "tonight": [332, 336, 338, 339], "tonit": [332, 338], "too": [3, 8, 9, 17, 28, 53, 61, 112, 114, 127, 129, 137, 140, 173, 175, 203, 206, 216, 232, 237, 240, 246, 332, 339, 340, 342, 346, 347, 388, 390], "took": [2, 22, 215, 221], "tool": [3, 7, 27, 43, 47, 48, 74, 77, 84, 86, 89, 108, 109, 112, 113, 119, 121, 127, 128, 137, 139, 150, 152, 165, 172, 182, 183, 188, 189, 191, 192, 193, 195, 196, 197, 198, 200, 203, 205, 225, 226, 230, 231, 291, 297, 298, 332, 334, 340, 342, 348, 350, 354, 355, 369, 370, 375, 377, 382, 384, 388, 390], "tool_cal": [181, 186], "tool_call_cli": [181, 186], "tool_call_id": [181, 186], "tool_call_pars": [181, 186], "tool_choic": [181, 186], "top": [1, 3, 8, 13, 17, 21, 24, 27, 50, 73, 80, 85, 92, 181, 184, 203, 205, 209, 211, 216, 220, 223, 232, 234, 291, 297, 332, 338, 356, 358, 369, 374, 376, 382, 386, 388, 392, 395, 404], "top20": [332, 338], "top_item_id": [375, 381], "top_items_df": [375, 381], "top_scor": [375, 381], "topic": [174, 180, 184, 332, 338], "topic_safety_output_restrict": [181, 184], "topk": [375, 381], "torch": [4, 6, 9, 10, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 56, 62, 67, 70, 240, 241, 247, 252, 253, 256, 258, 260, 261, 262, 265, 266, 267, 268, 271, 279, 280, 285, 286, 287, 288, 289, 292, 293, 294, 295, 300, 303, 304, 305, 306, 309, 310, 313, 317, 322, 327, 328, 330, 332, 335, 348, 351, 353, 362, 364, 365, 366, 368, 369, 371, 372, 373, 374, 375, 376, 377, 379, 381, 388, 390, 391, 392, 394, 395, 396, 397, 400, 404], "torch_": [4, 31, 292, 300], "torch_config": [348, 354], "torch_d": [9, 59, 240, 244], "torchconfig": [348, 351, 354], "torchmetr": [292, 300, 302, 306, 395, 400], "torchrec": [375, 376], "torchscript": [369, 374], "torchtrain": [4, 29, 32, 33, 260, 262, 263, 264, 272, 275, 280, 282, 284, 306, 327, 348, 350, 351, 354, 363, 364, 368, 370, 371, 375, 376, 377, 379, 380, 381, 388, 389, 390, 392, 394, 396, 397, 404], "torchtrainer_2025": [348, 355], "torchtrainer_4dd7a_00000": [348, 355], "torchtrainer_4dd7a_00000_0_2025": [348, 355], "torchtrainer_d89d0_00000_0_2024": [292, 306], "torchvis": [4, 6, 9, 29, 38, 56, 240, 241, 258, 260, 261, 276, 285, 286, 292, 293, 294, 295, 300, 309, 310, 317, 323, 362, 364, 395, 396, 397], "torqu": [369, 370, 374], "torranc": [332, 338], "total": [2, 3, 4, 8, 25, 28, 32, 51, 164, 165, 169, 173, 179, 203, 206, 215, 224, 232, 235, 258, 262, 263, 291, 292, 293, 298, 300, 311, 313, 348, 354, 362, 364, 369, 371], "total_amount": [8, 51, 52, 198, 200, 232, 235, 236], "total_amt": [6, 41, 285, 289, 293, 311], "totensor": [4, 6, 9, 29, 31, 32, 38, 39, 41, 56, 61, 240, 241, 246, 258, 260, 266, 271, 276, 285, 286, 287, 289, 292, 293, 294, 295, 300, 303, 306, 309, 313, 317, 323, 395, 398, 404], "touch": [340, 343, 375, 381, 382, 384], "tough": [356, 361], "tougher": [356, 361], "tour": [1, 12, 209, 210, 332, 338], "tourism": [332, 338], "tourist": [181, 184], "toward": [7, 45, 225, 228, 333, 341, 349, 356, 357, 361, 369, 370, 375, 377], "tower": [375, 381], "town": [332, 338, 340, 346], "tpot": [164, 165, 169], "tpu": [2, 4, 5, 22, 32, 36, 215, 221, 258, 261, 326, 330], "tqdm": [4, 31, 348, 351, 362, 364, 375, 377, 395, 397], "tr_model": [388, 391], "trace": [4, 5, 7, 30, 34, 46, 189, 191, 199, 225, 229, 258, 259, 326, 328, 340, 343], "traceback": [7, 46, 225, 229], "track": [4, 11, 32, 72, 77, 78, 89, 90, 193, 196, 207, 208, 258, 259, 270, 284, 333, 340, 341, 347, 349, 357, 362, 366, 369, 370, 374, 375, 376, 379, 381, 382, 387], "track_running_stat": [292, 300, 306], "tractabl": [362, 363], "trade": [173, 179, 181, 187], "tradit": [164, 165, 169, 375, 376, 382, 383], "traffic": [79, 83, 91, 99, 101, 106, 137, 147, 150, 157, 164, 165, 169, 170, 173, 178, 198, 201, 356, 358, 361, 388, 389], "trail": [332, 338, 340, 346], "train": [6, 7, 8, 9, 39, 40, 41, 42, 44, 46, 47, 50, 52, 55, 58, 60, 62, 66, 75, 76, 78, 82, 83, 87, 88, 90, 96, 99, 164, 165, 167, 225, 227, 229, 230, 232, 234, 236, 239, 240, 243, 245, 247, 251, 260, 261, 263, 264, 265, 266, 274, 275, 276, 280, 283, 285, 287, 288, 289, 290, 291, 293, 294, 298, 304, 309, 310, 311, 312, 313, 317, 332, 336, 338, 340, 343, 347, 351, 356, 359, 360, 365, 367, 368, 371, 372, 378, 381, 386, 390, 391, 397, 400, 404], "train_arrow": [382, 385], "train_batch": [395, 400], "train_bert": [348, 350, 354, 355], "train_config": [348, 354, 375, 379, 381], "train_count": [362, 364], "train_ctx": [3, 28, 203, 206], "train_d": [258, 275, 276, 277, 362, 364, 366, 369, 371, 373, 375, 377, 379, 382, 384, 385], "train_data": [4, 6, 32, 39, 41, 258, 266, 285, 287, 289, 292, 293, 300, 303, 306, 309, 313], "train_dataload": [5, 35, 36, 326, 329, 330, 362, 366, 369, 373], "train_dataset": [291, 298, 348, 353], "train_df": [382, 384], "train_frac": [375, 377], "train_func": [382, 383, 385, 387], "train_func_per_work": [348, 353, 354], "train_label": [292, 300], "train_linear_model": [6, 41, 285, 289, 293, 312], "train_load": [4, 5, 31, 32, 35, 258, 266, 292, 300, 303, 326, 329, 362, 366, 369, 373, 375, 379, 388, 392, 395, 400], "train_loop": [363, 368, 369, 370, 373], "train_loop_config": [3, 4, 5, 28, 32, 36, 203, 206, 269, 277, 280, 282, 292, 305, 306, 326, 330, 348, 354, 375, 379, 382, 385, 388, 392, 395, 401], "train_loop_per_work": [5, 36, 258, 280, 282, 326, 330, 348, 354, 362, 366, 375, 376, 379, 388, 389, 392, 396, 401], "train_loop_ray_train": [4, 5, 32, 36, 258, 261, 262, 263, 264, 269, 292, 302, 305, 306, 326, 330], "train_loop_ray_train_ray_data": [258, 273, 277], "train_loop_ray_train_with_checkpoint_load": [258, 279, 280, 282], "train_loop_torch": [4, 6, 31, 40, 285, 288, 292, 293, 300, 310], "train_loss": [362, 365, 366, 369, 372, 373, 375, 376, 379, 388, 392, 395, 400, 402], "train_loss_sum": [388, 392], "train_loss_tot": [395, 400], "train_my_simple_model": [6, 41, 285, 289, 293, 311, 312], "train_my_simple_model_2024": [293, 311], "train_my_simple_model_3207e_00000_0_a": [293, 311], "train_my_simple_model_3207e_00000terminated10": [293, 311], "train_my_simple_model_3207e_00001terminated10": [293, 311], "train_my_simple_model_3207e_00002terminated10": [293, 311], "train_my_simple_model_3207e_00003terminated10": [293, 311], "train_my_simple_model_3207e_00004terminated10": [293, 311], "train_parquet": [382, 384], "train_pytorch": [6, 41, 285, 289, 293, 311, 313], "train_pytorch_7cf0c_00000terminated10": [293, 313], "train_pytorch_7cf0c_00001terminated10": [293, 313], "train_record": [388, 390], "train_test_split": [3, 26, 28, 203, 204, 206, 291, 298, 375, 377, 382, 384], "trainabl": [3, 6, 28, 41, 203, 206, 285, 289, 293, 311, 312, 313], "trainbr": [340, 347], "traincontext": [4, 32, 258, 262], "trainer": [3, 4, 5, 28, 32, 35, 36, 203, 206, 260, 261, 270, 277, 280, 281, 282, 284, 291, 292, 298, 302, 305, 306, 326, 329, 330, 348, 351, 354, 362, 366, 367, 369, 373, 375, 376, 379, 380, 387, 388, 392, 393, 395, 396, 401, 403, 404], "training_iter": [292, 306], "training_step": [5, 35, 326, 329, 362, 365, 369, 372], "trainingargu": [348, 351], "trajectori": [369, 374], "transact": [7, 43, 225, 226], "transfer": [1, 2, 7, 8, 9, 13, 19, 43, 54, 61, 64, 193, 197, 209, 211, 215, 218, 225, 226, 232, 238, 240, 246, 249, 294, 318, 395, 404], "transform": [4, 5, 6, 7, 10, 29, 31, 32, 33, 38, 39, 41, 43, 44, 46, 49, 50, 51, 54, 55, 56, 58, 60, 64, 69, 70, 108, 111, 225, 226, 227, 229, 233, 234, 235, 238, 239, 241, 243, 245, 249, 252, 255, 256, 260, 266, 272, 277, 285, 286, 287, 289, 291, 292, 293, 295, 298, 300, 303, 309, 313, 314, 316, 318, 322, 323, 326, 327, 332, 335, 337, 339, 340, 342, 343, 347, 348, 350, 351, 353, 355, 356, 359, 360, 362, 363, 364, 369, 371, 374, 375, 377, 382, 384, 394, 396, 397, 399, 404], "transform_imag": [258, 276], "transient": [258, 280, 281, 395, 400], "transit": [76, 88, 362, 363, 369, 370, 375, 376, 382, 383, 388, 389], "transpar": [362, 366], "transpos": [362, 364], "travel": [181, 184, 332, 338], "treat": [340, 343, 346, 395, 396], "tree": [3, 4, 5, 28, 30, 31, 34, 35, 203, 206, 258, 259, 291, 298, 326, 328, 329, 332, 336, 338, 340, 343, 382, 383, 384], "tree_method": [3, 28, 203, 206, 382, 385], "tremend": [340, 347], "trend": [332, 338], "tri": [340, 343, 382, 383], "trial": [3, 6, 28, 41, 203, 206, 285, 289, 291, 292, 293, 298, 305, 311, 312, 313, 340, 347, 348, 355], "trial_id": [292, 306], "tribul": [340, 347], "trier": [340, 347], "trigger": [9, 60, 63, 240, 245, 248, 332, 339, 369, 371, 382, 384, 387], "trim": [362, 364, 395, 397], "trip": [3, 8, 28, 51, 54, 203, 206, 232, 235, 238, 291, 298, 340, 346, 388, 390, 394], "trip_amount": [3, 28, 203, 206], "trip_dist": [3, 8, 28, 51, 54, 203, 206, 232, 235, 238, 291, 298], "trip_dur": [291, 298], "trivial": [164, 165, 170], "trndnl": [332, 338], "troubleshoot": [74, 77, 86, 89, 181, 188, 189, 192], "truck": [181, 185], "true": [0, 2, 4, 5, 6, 8, 9, 10, 20, 31, 32, 35, 36, 39, 41, 51, 59, 61, 62, 70, 119, 123, 164, 165, 171, 173, 176, 177, 178, 179, 181, 184, 186, 198, 200, 201, 202, 215, 219, 232, 235, 240, 244, 246, 247, 252, 256, 258, 259, 260, 264, 266, 271, 285, 287, 289, 291, 292, 293, 294, 295, 298, 300, 302, 303, 306, 309, 313, 316, 323, 326, 329, 330, 340, 343, 348, 353, 362, 364, 365, 366, 369, 372, 373, 375, 377, 379, 380, 382, 384, 386, 388, 390, 391, 392, 394, 395, 396, 397, 398, 399, 400, 401, 402, 404], "truli": [332, 338, 340, 347], "trump": [332, 338], "truncat": [348, 353, 356, 360, 361, 362, 364, 369, 371], "trust": [101, 103, 106, 332, 338, 388, 394], "truth": [9, 61, 64, 240, 246, 249, 258, 260, 294, 318, 369, 371, 388, 389, 392, 394, 395, 404], "try": [1, 2, 6, 7, 16, 20, 41, 47, 112, 113, 127, 128, 135, 137, 139, 148, 150, 152, 173, 180, 181, 188, 209, 214, 215, 219, 225, 230, 258, 284, 285, 289, 292, 293, 305, 311, 312, 313, 340, 346, 347, 362, 364, 368, 382, 387, 395, 397], "tryna": [332, 338], "tsui": [340, 346], "ttft": [164, 165, 169], "ttm": [340, 346, 347], "tuesdai": [332, 338], "tune": [7, 9, 40, 46, 47, 61, 78, 82, 90, 96, 164, 165, 170, 173, 180, 181, 183, 184, 187, 188, 225, 229, 230, 240, 246, 258, 274, 284, 288, 291, 298, 310, 340, 347, 362, 368, 369, 374, 375, 381, 382, 386, 387, 388, 394, 395, 396, 404], "tune_config": [3, 6, 28, 41, 203, 206, 285, 289, 291, 293, 298, 311, 312, 313], "tuneconfig": [3, 6, 28, 41, 203, 206, 285, 289, 291, 293, 298, 311, 312, 313], "tuner": [3, 6, 28, 41, 203, 206, 285, 289, 291, 293, 298, 311, 312, 313], "tupl": [2, 5, 9, 19, 35, 62, 215, 218, 240, 247, 258, 272, 273, 326, 329], "turn": [1, 6, 8, 14, 41, 53, 209, 212, 232, 237, 285, 289, 332, 338, 340, 347, 382, 383], "tutori": [74, 76, 86, 88, 101, 104, 173, 175, 260, 283, 362, 363, 368, 369, 370, 375, 376, 377, 381, 382, 383, 388, 389, 390, 392, 394, 395, 396, 397], "tv": [332, 338, 340, 346, 347], "tweet": [332, 338], "tweet_ev": [332, 336], "twilight": [332, 338], "twitter": [332, 338], "two": [1, 2, 16, 18, 19, 20, 75, 78, 82, 87, 90, 98, 101, 106, 108, 110, 168, 189, 192, 198, 200, 202, 209, 214, 215, 217, 218, 219, 258, 261, 270, 275, 332, 338, 344, 347, 375, 377, 379, 381, 382, 384, 388, 390, 395, 396, 402], "txt": [0, 11, 72, 76, 88, 202, 207, 208, 333, 341, 349, 357], "type": [2, 4, 5, 6, 7, 8, 9, 10, 20, 32, 33, 35, 38, 43, 46, 55, 59, 61, 62, 67, 73, 75, 81, 85, 87, 94, 102, 106, 108, 110, 112, 116, 119, 125, 127, 134, 137, 146, 150, 155, 161, 164, 165, 169, 173, 176, 186, 187, 193, 197, 198, 201, 202, 215, 219, 225, 226, 229, 232, 239, 240, 244, 246, 247, 252, 253, 285, 286, 293, 295, 311, 322, 326, 327, 329, 332, 335, 340, 343, 348, 351, 383, 386, 387], "typic": [8, 50, 84, 108, 111, 173, 175, 181, 184, 232, 234, 332, 334, 340, 347, 362, 364, 375, 377, 395, 396], "u": [5, 6, 35, 36, 40, 76, 88, 112, 114, 119, 122, 123, 127, 129, 137, 140, 150, 153, 154, 155, 181, 184, 188, 189, 192, 198, 200, 258, 261, 285, 288, 291, 292, 293, 294, 295, 298, 305, 310, 311, 313, 317, 323, 326, 329, 330, 332, 338, 340, 343, 347, 369, 370, 375, 376, 377, 381], "u002c": [332, 338], "u002c000": [332, 338], "u2019": [332, 338], "u2019ll": [332, 338], "u2019m": [332, 338], "u2019r": [332, 338], "u2019t": [332, 338], "u2019v": [332, 338], "u_": [369, 370, 375, 376], "u_k": [369, 370], "uber": [6, 42, 285, 290], "ubj": [3, 28, 203, 206, 291, 298], "ubyt": [292, 293, 305, 311, 313], "udf": [7, 46, 225, 229], "ui": [0, 76, 78, 88, 90, 101, 106, 295, 323], "uid": [375, 377, 381], "uint8": [193, 197, 258, 276, 295, 323], "un": [340, 347], "unabl": [340, 347], "unassoci": [112, 114, 127, 129, 137, 140], "unattach": [112, 114, 127, 129, 137, 140], "unavail": [2, 22, 215, 221], "unavoid": [340, 343], "unbound": [9, 61, 240, 246], "uncas": [356, 360], "uncertainti": [388, 394], "unchang": [258, 276], "uncl": [340, 347], "uncom": [119, 123, 127, 130, 137, 142, 181, 185, 186, 348, 354], "uncondit": [362, 368], "unconnect": [340, 347], "unconnectedbr": [340, 347], "under": [2, 9, 19, 59, 75, 79, 83, 87, 91, 100, 150, 153, 198, 200, 215, 218, 240, 244, 258, 260, 261, 264, 268, 275, 340, 346, 362, 364, 366, 368, 369, 373, 374, 375, 377, 381, 388, 389, 390, 392, 395, 397, 400], "underbrac": [388, 389], "underli": [2, 3, 4, 5, 9, 18, 28, 30, 34, 60, 80, 92, 173, 176, 203, 206, 215, 217, 240, 245, 258, 259, 326, 328], "undersid": [340, 347], "understand": [6, 9, 40, 61, 77, 79, 89, 91, 101, 102, 104, 163, 164, 165, 166, 167, 169, 171, 172, 173, 175, 176, 189, 191, 193, 197, 198, 201, 240, 246, 285, 288, 293, 310, 340, 346, 347, 348, 353, 375, 381, 382, 383, 395, 396], "understat": [340, 347], "understood": [173, 180], "underutil": [164, 165, 167, 168], "uneasy": [332, 338], "unet": [5, 35, 326, 329], "unet2dconditionmodel": [5, 33, 35, 326, 327, 329], "unexpect": [4, 5, 30, 34, 189, 191, 258, 259, 326, 328, 332, 338, 388, 390], "ungat": [173, 176, 181, 184], "unifi": [3, 7, 11, 27, 43, 46, 72, 84, 101, 107, 164, 165, 170, 203, 205, 207, 208, 225, 226, 229], "uniform": [2, 3, 23, 28, 203, 206, 215, 222, 348, 353, 369, 370], "uniformli": [9, 57, 240, 242], "uniniti": [9, 62, 240, 247, 294, 317], "uninstal": [127, 135, 137, 148, 150, 162], "uniqu": [8, 51, 76, 88, 164, 165, 169, 173, 176, 232, 235, 258, 266, 268, 294, 316, 340, 344, 347, 375, 381, 395, 397], "unique_item": [375, 381], "unique_us": [375, 381], "unit": [9, 10, 64, 69, 71, 164, 165, 169, 181, 186, 240, 249, 252, 255, 257, 294, 318, 340, 343, 395, 397], "univari": [388, 391], "univers": [340, 346], "unless": [8, 52, 78, 80, 82, 90, 92, 96, 232, 236, 258, 271, 279, 340, 343], "unlik": [78, 82, 90, 96, 258, 260, 276, 332, 338], "unnecessari": [9, 10, 61, 68, 77, 78, 79, 89, 90, 91, 240, 246, 252, 254, 258, 268, 271, 332, 338, 369, 374, 382, 385], "unnot": [340, 347], "unpredict": [164, 165, 169], "unread": [362, 364], "unregist": [112, 117, 127, 135, 137, 148], "unreleas": [332, 338], "unrelentingli": [340, 346, 347], "unrival": [340, 347], "uns4": [332, 338], "unshuffl": [382, 384], "unsloth": [164, 165, 171, 173, 176, 181, 184], "unsqueez": [4, 31, 32, 258, 271, 292, 300, 306, 369, 374, 388, 390, 391, 392, 394], "unstabl": [362, 363], "unstructur": [7, 43, 57, 225, 226, 242, 405], "until": [2, 4, 7, 8, 18, 32, 48, 51, 52, 164, 165, 168, 169, 193, 197, 215, 217, 225, 231, 232, 235, 236, 258, 269, 292, 294, 305, 317, 332, 338, 340, 347, 382, 385], "untitl": [74, 86], "unus": [112, 114, 127, 129, 137, 140], "unveil": [332, 338], "unwrap": [4, 32, 258, 268, 280, 292, 304], "up": [0, 2, 4, 5, 6, 7, 8, 9, 10, 20, 21, 30, 31, 34, 35, 40, 41, 48, 51, 60, 62, 69, 70, 75, 81, 87, 93, 99, 101, 102, 105, 108, 111, 112, 114, 117, 118, 119, 122, 123, 126, 129, 130, 134, 136, 140, 142, 146, 149, 150, 153, 154, 162, 164, 165, 169, 171, 174, 179, 180, 182, 184, 187, 190, 191, 198, 199, 215, 219, 220, 225, 231, 232, 235, 240, 245, 247, 252, 255, 256, 259, 269, 280, 282, 285, 288, 289, 294, 308, 311, 317, 321, 322, 323, 326, 328, 329, 332, 334, 337, 338, 340, 342, 343, 346, 347, 348, 350, 354, 364, 366, 370, 373, 379, 380, 383, 384, 385, 393, 396, 397, 401, 403], "up_block_typ": [5, 35, 326, 329], "upblock2d": [5, 35, 326, 329], "upcom": [49, 233], "updat": [0, 3, 4, 5, 6, 7, 10, 11, 28, 32, 36, 41, 43, 71, 72, 75, 77, 79, 87, 89, 91, 100, 127, 130, 135, 137, 142, 148, 150, 157, 173, 178, 203, 206, 207, 208, 225, 226, 252, 257, 258, 259, 262, 268, 279, 285, 289, 293, 295, 300, 312, 323, 326, 330, 333, 341, 348, 349, 353, 356, 357, 358, 362, 368, 388, 394, 395, 400], "upgrad": [10, 69, 74, 79, 83, 86, 91, 99, 127, 129, 130, 132, 137, 140, 142, 144, 157, 160, 252, 255, 362, 368, 369, 370, 374], "upload": [4, 32, 76, 88, 181, 184, 292, 304, 382, 387], "upload_fil": [76, 88, 181, 184], "upon": [77, 89], "upper": [74, 86], "upright": [369, 370], "upscal": [295, 323], "upscale_delay_": [295, 323], "upset": [332, 338], "ur": [332, 338], "uri": [76, 88], "url": [7, 48, 78, 90, 225, 231, 388, 390], "urljoin": [165, 171, 173, 177], "urllib": [165, 171, 173, 177], "urmitz": [340, 347], "us": [1, 2, 10, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 33, 35, 36, 37, 40, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 104, 105, 107, 109, 111, 112, 113, 115, 118, 119, 120, 123, 124, 127, 128, 131, 136, 137, 138, 139, 143, 147, 149, 150, 151, 152, 153, 154, 155, 159, 164, 165, 167, 168, 169, 170, 171, 174, 175, 177, 178, 180, 183, 188, 189, 191, 192, 193, 196, 197, 199, 200, 202, 205, 206, 209, 211, 212, 213, 215, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 231, 233, 235, 236, 237, 241, 242, 243, 244, 245, 246, 247, 248, 250, 251, 252, 254, 256, 257, 260, 261, 262, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 282, 283, 284, 288, 290, 292, 297, 302, 303, 304, 305, 306, 307, 308, 310, 311, 312, 314, 316, 317, 319, 322, 324, 327, 329, 330, 331, 332, 333, 334, 336, 337, 338, 339, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 357, 360, 361, 364, 366, 368, 371, 373, 374, 378, 379, 381, 385, 386, 387, 390, 392, 394, 397, 400, 402, 404], "usabl": [181, 185, 258, 276], "usag": [10, 68, 77, 89, 164, 165, 168, 170, 181, 183, 184, 187, 189, 191, 193, 195, 197, 252, 254, 291, 292, 293, 295, 298, 305, 311, 313, 321, 348, 355, 375, 379], "use_gpu": [3, 4, 5, 28, 32, 36, 203, 206, 258, 259, 264, 291, 292, 298, 302, 326, 330, 362, 366, 369, 373, 375, 379, 382, 385, 388, 392, 395, 396, 401], "use_gpu_actor": [395, 404], "usecol": [375, 381], "user": [2, 4, 7, 9, 11, 18, 22, 32, 46, 47, 61, 72, 73, 76, 77, 78, 80, 82, 83, 85, 88, 89, 90, 92, 93, 96, 99, 101, 103, 108, 110, 150, 153, 164, 165, 167, 168, 169, 171, 173, 177, 178, 181, 184, 185, 186, 187, 193, 195, 196, 197, 198, 201, 207, 208, 215, 217, 221, 225, 229, 230, 240, 246, 258, 262, 265, 266, 292, 293, 300, 313, 332, 336, 338, 339, 348, 355, 356, 358, 378, 379], "user2idx": [375, 377, 381], "user_col": [375, 377], "user_embed": [375, 378, 381], "user_id": [202, 375, 377, 381], "user_idx": [375, 376, 377, 378, 379, 381], "user_nam": [150, 153], "user_storag": [76, 88], "user_vec": [375, 378], "user_vector": [375, 381], "userguid": [112, 113, 127, 128, 137, 139], "userservic": [198, 201, 202], "usual": [7, 8, 45, 52, 225, 228, 232, 236, 258, 271, 340, 346], "utc": [292, 300], "util": [2, 4, 5, 6, 9, 10, 22, 31, 32, 33, 35, 38, 39, 41, 57, 61, 66, 68, 69, 77, 79, 83, 89, 91, 99, 164, 165, 167, 168, 169, 170, 198, 201, 215, 221, 240, 242, 246, 251, 252, 254, 255, 258, 259, 260, 266, 268, 272, 284, 285, 286, 287, 289, 292, 293, 295, 300, 303, 304, 309, 323, 326, 327, 329, 348, 350, 351, 353, 362, 364, 369, 371, 374, 375, 377, 388, 390, 395, 396, 397], "uuid": [369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "uv": [333, 341, 349, 357], "ux": [7, 46, 225, 229], "v": [45, 46, 74, 78, 86, 90, 101, 104, 111, 127, 133, 134, 137, 145, 146, 164, 165, 168, 181, 187, 228, 229, 258, 259, 271, 283, 332, 338, 348, 353, 375, 376, 381, 388, 392, 394, 395, 404, 405], "v1": [108, 111, 165, 171, 173, 177, 178, 181, 184, 185, 186, 369, 370, 371, 374], "v2": [258, 259, 332, 337, 362, 363, 366, 369, 370, 375, 376, 382, 383, 388, 389], "v_": [375, 376], "val": [366, 371, 375, 377, 379, 382, 384, 385, 388, 390, 392, 394, 395, 398, 400, 402, 404], "val_batch": [395, 400], "val_d": [362, 364, 366, 369, 371, 373, 375, 377, 379, 382, 384, 385, 386, 387], "val_dataload": [362, 366, 369, 373], "val_df": [382, 384], "val_load": [362, 366, 369, 373, 375, 379, 388, 392, 395, 400], "val_loss": [362, 365, 366, 369, 372, 373, 375, 376, 379, 388, 392, 395, 400, 401, 402], "val_loss_sum": [388, 392], "val_loss_tot": [395, 400], "val_parquet": [382, 384], "val_pd": [382, 385, 386], "val_record": [388, 390], "val_xb": [395, 400], "val_yb": [395, 400], "valid": [3, 28, 79, 91, 163, 181, 185, 203, 206, 291, 295, 298, 323, 348, 353, 362, 365, 366, 369, 370, 371, 372, 373, 376, 385, 386, 387, 396, 400, 401, 404], "valid_dataset": [291, 298], "valid_dataset_featur": [291, 298], "validation_step": [362, 365, 369, 372], "valu": [2, 4, 6, 9, 18, 19, 23, 31, 39, 60, 61, 79, 83, 91, 100, 112, 113, 114, 119, 120, 123, 127, 128, 129, 130, 135, 137, 138, 140, 142, 148, 150, 151, 156, 157, 167, 198, 200, 201, 215, 217, 218, 222, 240, 245, 246, 258, 263, 266, 267, 270, 276, 285, 287, 292, 293, 300, 309, 340, 345, 362, 363, 366, 369, 370, 371, 375, 377, 381, 388, 389, 390, 391, 395, 400, 402], "valuabl": [340, 346], "value_count": [375, 377, 382, 384], "valueerror": [2, 20, 215, 219, 362, 366, 369, 373], "values_nginx": [127, 130, 137, 142], "values_nginx_gke_priv": [150, 157], "values_nginx_gke_publ": [150, 157], "values_nvdp": [127, 130, 137, 142], "vamp": [332, 338], "vampett": [332, 338], "vampir": [332, 338], "van": [332, 338], "vanilla": [5, 26, 36, 38, 164, 165, 168, 204, 286, 326, 330, 388, 389, 390], "var": [101, 106, 150, 162, 258, 260, 362, 364, 369, 371, 375, 377, 382, 384, 388, 390, 395, 397], "varepsilon": [362, 363], "varepsilon_": [369, 370], "varepsilon_k": [369, 370], "vari": [7, 8, 9, 43, 54, 57, 62, 64, 164, 165, 169, 225, 226, 232, 238, 240, 242, 247, 249, 294, 318], "variabl": [2, 21, 22, 75, 76, 77, 87, 88, 89, 112, 114, 119, 123, 127, 129, 137, 140, 150, 153, 215, 220, 221], "variat": [6, 41, 285, 289, 293, 312], "varieti": [9, 59, 64, 240, 244, 249, 294, 318, 340, 342], "variou": [7, 44, 75, 76, 87, 88, 173, 180, 225, 227, 258, 272, 348, 354], "vast": [7, 43, 225, 226], "ve": [112, 118, 164, 165, 172, 173, 180, 181, 183, 188, 332, 338, 340, 343, 347, 395, 404], "vector": [7, 9, 43, 61, 164, 165, 167, 225, 226, 240, 246, 332, 334, 369, 371, 374, 375, 376, 378, 382, 387], "veget": [382, 383], "veloc": [369, 370], "venu": [356, 361], "venv": 0, "verbos": [198, 201], "veri": [4, 5, 6, 7, 8, 31, 32, 35, 36, 41, 47, 52, 173, 175, 225, 230, 232, 236, 258, 260, 285, 289, 292, 293, 294, 301, 312, 317, 326, 329, 330, 332, 338, 340, 347, 388, 394], "verif": 163, "verifi": [5, 9, 35, 61, 75, 77, 78, 87, 89, 90, 112, 117, 119, 122, 135, 147, 148, 150, 153, 156, 157, 158, 240, 246, 326, 329, 384, 388, 390], "vermaelen": [332, 338], "version": [7, 11, 43, 72, 73, 83, 85, 99, 101, 106, 112, 113, 119, 121, 127, 128, 130, 137, 139, 142, 150, 152, 157, 158, 181, 184, 189, 192, 193, 196, 198, 201, 207, 208, 225, 226, 258, 273, 294, 318, 332, 333, 338, 341, 349, 356, 357, 358, 362, 364, 366, 388, 390], "versu": [362, 368, 382, 387, 395, 404], "via": [0, 1, 2, 4, 5, 7, 9, 13, 22, 30, 34, 46, 47, 57, 74, 80, 81, 82, 86, 92, 94, 96, 101, 104, 108, 110, 111, 112, 114, 119, 123, 127, 129, 137, 140, 189, 191, 198, 199, 201, 202, 209, 211, 215, 221, 225, 229, 230, 240, 242, 258, 259, 262, 263, 264, 271, 276, 284, 326, 328, 332, 338, 340, 346, 362, 365, 369, 373, 375, 377, 379, 395, 399, 400], "vicki": [332, 336, 338], "vid": [332, 338], "video": [7, 9, 43, 57, 225, 226, 240, 242, 332, 338, 340, 343, 347], "vietnam": [340, 343], "view": [6, 8, 9, 10, 11, 41, 51, 52, 61, 71, 72, 75, 77, 87, 89, 101, 106, 112, 114, 116, 119, 123, 125, 127, 129, 134, 137, 140, 146, 147, 150, 161, 173, 179, 189, 191, 193, 197, 198, 200, 201, 207, 208, 232, 235, 236, 240, 246, 252, 257, 285, 289, 292, 293, 295, 305, 311, 312, 322, 340, 343, 347, 362, 365, 369, 372], "viewer": [340, 343], "vincent": [340, 343], "violat": [181, 184], "viridi": [382, 386], "virtual": [0, 75, 87, 101, 104, 106, 111, 164, 165, 168, 189, 192], "virtuou": [340, 343], "visibl": [173, 179, 258, 267, 340, 343, 388, 394], "vision": [258, 284, 368, 404], "visit": [6, 41, 189, 192, 285, 289, 293, 295, 312, 323], "visual": [6, 7, 8, 9, 39, 44, 51, 60, 74, 77, 86, 89, 173, 179, 189, 191, 192, 193, 197, 225, 227, 232, 235, 240, 245, 285, 287, 294, 301, 308, 316, 340, 346, 347, 366, 368, 369, 370, 373, 379, 383, 392, 402], "visualis": [388, 390], "vit": [258, 280, 282], "vit_b_16": [395, 404], "vit_l_32": [395, 404], "vllm": [171, 172, 173, 179, 180, 181, 185], "vm": [101, 102, 104, 111, 112, 116, 119, 123, 125, 150, 154, 163, 405], "vocal": [332, 338], "voic": [332, 338, 340, 347], "volatil": [4, 31, 258, 260], "volleybal": [332, 338], "volum": [4, 7, 31, 43, 46, 76, 88, 193, 197, 225, 226, 229, 258, 260, 382, 384, 395, 396, 404], "von": [340, 347], "vpc": [104, 105, 107, 108, 110, 112, 114, 118, 119, 120, 123, 127, 128, 129, 137, 139, 140, 150, 154, 162, 163, 164, 165, 170], "vpc_cidr": [101, 106], "vpc_id": [101, 106, 107, 112, 114], "vpcid": [112, 114, 127, 129, 137, 140], "vram": [173, 176, 332, 338], "vscode": [79, 91], "vtripl": [181, 184], "vulva": [340, 343], "w": [6, 10, 41, 70, 76, 88, 252, 256, 258, 271, 285, 289, 293, 312, 332, 336, 338, 340, 347, 362, 363, 364, 365, 395, 404], "w0": [2, 25, 215, 224], "w1": [2, 25, 215, 224], "wa": [5, 8, 35, 51, 75, 78, 87, 90, 193, 197, 232, 235, 258, 282, 291, 298, 326, 329, 332, 338, 340, 343, 346, 347, 375, 380], "wai": [2, 7, 8, 9, 11, 19, 44, 45, 50, 60, 61, 72, 74, 78, 81, 82, 86, 90, 95, 98, 101, 104, 173, 179, 207, 208, 215, 218, 225, 227, 228, 232, 234, 240, 245, 246, 258, 268, 295, 323, 332, 338, 340, 342, 346, 347, 356, 358, 361, 369, 374, 395, 396, 398, 404], "wait": [1, 15, 16, 17, 23, 75, 87, 150, 157, 164, 165, 168, 209, 213, 214, 216, 222, 332, 338], "wake": [332, 338, 340, 347], "walk": [4, 6, 29, 38, 74, 76, 86, 88, 112, 113, 127, 128, 137, 138, 150, 151, 173, 174, 181, 184, 285, 286, 292, 293, 299, 308, 332, 338, 339, 362, 363, 382, 383, 388, 389], "walter": [340, 346], "wander": [340, 343], "wanna": [332, 338], "want": [0, 1, 2, 4, 5, 7, 8, 9, 10, 15, 18, 19, 24, 25, 32, 35, 44, 51, 53, 54, 61, 62, 64, 70, 71, 74, 77, 86, 89, 101, 106, 119, 123, 126, 137, 140, 150, 153, 162, 164, 165, 169, 209, 213, 215, 217, 218, 223, 224, 225, 227, 232, 235, 237, 238, 240, 246, 247, 249, 252, 256, 257, 258, 260, 266, 267, 271, 291, 294, 295, 298, 317, 318, 322, 326, 329, 332, 336, 337, 338, 340, 343, 346, 347, 348, 355, 388, 389, 392], "war": [332, 338, 340, 343], "warehous": [9, 59, 240, 244], "warm": [5, 35, 326, 329, 332, 338], "warmth": [332, 338], "warn": [332, 338, 340, 346, 347, 362, 366, 369, 373], "warner": [332, 336, 338], "wasn": [340, 346, 388, 390], "wast": [340, 347], "watch": [150, 157, 332, 338, 340, 347], "water": [340, 347], "wave": [340, 347], "wc": [8, 51, 232, 235], "we": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 16, 19, 20, 21, 23, 25, 28, 31, 32, 35, 36, 40, 41, 44, 45, 51, 52, 53, 54, 59, 61, 62, 63, 64, 70, 73, 74, 75, 76, 77, 78, 79, 84, 85, 86, 87, 88, 89, 90, 91, 112, 113, 119, 121, 127, 128, 130, 134, 137, 139, 142, 146, 150, 152, 154, 164, 165, 166, 168, 171, 172, 174, 175, 176, 178, 182, 184, 185, 198, 200, 203, 206, 209, 213, 214, 215, 218, 219, 220, 222, 224, 225, 227, 228, 232, 235, 236, 237, 238, 240, 244, 246, 247, 248, 249, 252, 256, 258, 260, 261, 262, 263, 264, 265, 268, 269, 271, 273, 274, 275, 276, 277, 279, 280, 285, 288, 289, 292, 293, 294, 295, 300, 301, 302, 304, 306, 310, 311, 312, 313, 316, 317, 318, 322, 323, 325, 326, 329, 330, 332, 334, 338, 340, 343, 344, 346, 347, 348, 352, 354, 355, 356, 358, 359, 361, 375, 376, 379, 395, 402], "wealth": [340, 347], "weather": [388, 394], "weaviat": [7, 43, 225, 226], "web": [74, 77, 86, 89, 189, 191, 199, 356, 358, 369, 374], "webservic": 359, "websit": [0, 189, 192], "webster": [340, 346], "wed": [332, 338], "wednesdai": [332, 336, 338], "week": [332, 338, 388, 389, 390], "weight": [2, 25, 164, 165, 169, 173, 176, 215, 224, 258, 259, 262, 268, 271, 280, 284, 292, 300, 362, 368, 369, 374, 375, 379, 381, 382, 384, 387, 388, 394, 395, 404], "weight_decai": [5, 35, 36, 326, 329, 330], "weights_onli": [4, 5, 32, 36, 258, 271, 292, 306, 326, 330], "welbeck": [332, 338], "welcom": [202, 291, 296], "well": [2, 7, 25, 47, 75, 81, 87, 95, 101, 106, 108, 110, 215, 224, 225, 230, 332, 338, 340, 346, 347, 356, 358, 375, 377, 378], "wellcraft": [340, 347], "welllll": [332, 338], "went": [340, 347], "were": [5, 35, 258, 282, 326, 329, 332, 338, 340, 346, 347, 382, 384], "werewolf": [340, 347], "west": [76, 88, 112, 114, 127, 129, 137, 140, 181, 184, 291, 292, 293, 298, 305, 311, 313], "west2": [119, 122, 123, 150, 153, 154, 155], "western": [340, 346, 347], "wget": [375, 377], "what": [1, 3, 5, 6, 9, 15, 26, 28, 35, 41, 49, 61, 73, 85, 102, 119, 120, 150, 154, 166, 171, 184, 186, 190, 193, 194, 196, 197, 203, 204, 206, 209, 213, 233, 240, 246, 264, 284, 285, 289, 291, 293, 296, 298, 311, 326, 329, 332, 338, 340, 343, 347, 377], "whatev": [382, 387, 388, 394, 395, 404], "when": [1, 2, 6, 11, 15, 16, 18, 20, 21, 22, 24, 25, 29, 33, 41, 48, 49, 52, 53, 56, 58, 59, 60, 61, 62, 63, 64, 67, 72, 74, 75, 76, 77, 78, 79, 83, 86, 87, 88, 89, 90, 91, 100, 112, 114, 117, 119, 123, 126, 127, 129, 130, 134, 137, 140, 142, 146, 150, 154, 162, 164, 165, 167, 168, 173, 177, 178, 179, 181, 186, 193, 196, 197, 198, 199, 201, 207, 208, 209, 213, 214, 215, 217, 219, 220, 221, 223, 224, 231, 233, 236, 237, 241, 243, 244, 245, 246, 247, 248, 249, 253, 266, 269, 270, 272, 280, 283, 285, 289, 293, 312, 314, 316, 317, 318, 323, 327, 332, 334, 337, 338, 340, 343, 347, 356, 361, 362, 364, 368, 369, 374, 375, 379, 381, 382, 384, 388, 392, 394, 395, 397, 400, 402], "where": [1, 4, 5, 6, 7, 8, 13, 32, 36, 39, 47, 48, 51, 76, 80, 81, 84, 88, 92, 94, 137, 140, 150, 155, 164, 165, 167, 173, 175, 189, 192, 193, 196, 209, 211, 225, 230, 231, 232, 235, 268, 269, 270, 277, 282, 285, 287, 291, 292, 293, 298, 301, 305, 309, 326, 330, 332, 338, 340, 343, 346, 347, 348, 353, 356, 358, 370, 376, 377, 380, 383, 389, 393, 396, 398], "wherea": [7, 45, 48, 225, 228, 231], "wherev": [332, 338], "whether": [4, 5, 6, 11, 32, 36, 41, 72, 76, 80, 88, 92, 163, 207, 208, 258, 261, 264, 265, 266, 285, 289, 291, 292, 293, 298, 302, 312, 326, 330, 348, 350, 375, 379, 382, 384, 388, 392], "which": [1, 2, 3, 4, 5, 6, 7, 8, 9, 16, 17, 18, 19, 23, 24, 25, 28, 32, 35, 41, 44, 47, 51, 52, 53, 54, 60, 61, 62, 63, 75, 79, 87, 91, 101, 104, 111, 112, 114, 127, 129, 137, 140, 141, 147, 150, 153, 173, 175, 179, 181, 184, 186, 189, 192, 193, 197, 198, 201, 203, 206, 209, 214, 215, 216, 217, 218, 222, 223, 224, 225, 227, 230, 232, 235, 236, 237, 238, 240, 245, 246, 247, 248, 258, 260, 262, 266, 267, 268, 270, 273, 285, 289, 292, 293, 294, 295, 306, 311, 312, 317, 323, 326, 329, 332, 334, 340, 343, 346, 347, 348, 350, 353, 354, 356, 358, 362, 363, 364, 382, 383, 386, 388, 392, 394, 395, 396, 397, 400, 404], "while": [2, 3, 7, 10, 23, 24, 27, 43, 47, 69, 74, 75, 77, 84, 86, 87, 89, 173, 175, 181, 184, 193, 196, 197, 198, 201, 203, 205, 215, 222, 223, 225, 226, 230, 252, 255, 258, 259, 261, 262, 272, 273, 274, 340, 343, 346, 347, 362, 364, 366, 375, 376, 377, 382, 384, 388, 389, 390, 395, 396, 397, 402], "whilst": [340, 347], "white": [6, 39, 285, 287, 293, 309, 332, 338, 340, 347], "who": [80, 92, 101, 106, 163, 164, 165, 169, 332, 338, 340, 343, 346, 347, 348, 355], "whole": [3, 28, 203, 206, 291, 298, 382, 385], "whose": [340, 346, 347], "why": [9, 56, 174, 180, 240, 241, 258, 259, 278, 332, 338, 340, 346], "whyyyyyyi": [332, 338], "wichita": [332, 338], "wide": [7, 46, 150, 157, 225, 229, 332, 338, 340, 347, 356, 358], "widescreen": [340, 346], "width": [9, 61, 193, 197, 240, 246, 294, 295, 317, 323, 362, 364], "wife": [340, 347], "wildlif": [356, 361], "wilki": [340, 346], "willam": [332, 336, 338], "william": [332, 338, 340, 346], "wilmer": [332, 338], "win": [7, 47, 225, 230, 332, 336, 338], "wind": [340, 346], "window": [11, 72, 74, 86, 119, 122, 173, 179, 189, 192, 207, 208, 258, 284, 340, 343, 389, 391, 394], "wire": [258, 284, 362, 366], "wise": [258, 271], "wish": [332, 338], "with_resourc": [6, 41, 285, 289, 293, 312, 313], "within": [2, 7, 22, 43, 74, 76, 78, 80, 81, 82, 86, 88, 90, 92, 94, 98, 101, 103, 106, 108, 110, 189, 192, 215, 221, 225, 226, 369, 374, 375, 377], "without": [2, 7, 10, 18, 19, 22, 24, 43, 69, 74, 75, 84, 86, 87, 101, 106, 164, 165, 168, 181, 184, 185, 189, 192, 215, 217, 218, 221, 223, 225, 226, 252, 255, 258, 259, 278, 280, 281, 340, 343, 347, 362, 363, 368, 369, 370, 375, 376, 377, 379, 380, 381, 382, 385, 386, 387, 388, 389, 390, 394, 395, 396, 403], "woman": [340, 346, 347], "women": [340, 343], "won": [2, 7, 20, 47, 215, 219, 225, 230, 340, 343], "wonder": [6, 41, 108, 110, 285, 289, 332, 336, 338], "wood": [332, 338], "wooden": [340, 346], "word": [164, 165, 167, 340, 347], "work": [1, 2, 4, 6, 8, 10, 11, 16, 18, 31, 32, 40, 53, 54, 56, 69, 72, 74, 76, 77, 79, 80, 84, 86, 88, 89, 91, 92, 108, 110, 111, 164, 165, 167, 173, 176, 180, 181, 183, 207, 208, 209, 214, 215, 217, 232, 237, 238, 241, 252, 255, 265, 275, 284, 285, 288, 292, 302, 332, 334, 337, 338, 340, 346, 347, 348, 354, 367, 369, 370, 375, 376, 377, 379, 382, 383, 384, 395, 396, 398, 403, 404], "worker": [2, 3, 8, 9, 10, 11, 18, 20, 21, 23, 25, 28, 50, 54, 62, 64, 69, 72, 73, 79, 85, 91, 101, 106, 108, 110, 127, 134, 137, 146, 193, 195, 197, 203, 206, 207, 208, 215, 217, 219, 220, 222, 224, 232, 234, 238, 240, 247, 249, 252, 255, 259, 261, 263, 264, 265, 266, 267, 268, 269, 271, 274, 275, 276, 277, 278, 280, 281, 292, 294, 302, 304, 318, 332, 338, 340, 345, 350, 354, 355, 362, 363, 364, 365, 366, 368, 369, 370, 373, 374, 375, 376, 377, 379, 383, 384, 387, 388, 389, 390, 392, 394, 395, 396, 397, 398, 399, 400, 401, 402, 404], "worker_devic": [332, 338], "worker_nod": [127, 134, 137, 146, 193, 197], "worker_rank": [3, 28, 203, 206], "workernodegroupconfig": [127, 134, 137, 146], "workflow": [7, 11, 43, 45, 46, 47, 67, 72, 73, 74, 77, 78, 84, 85, 86, 89, 90, 108, 110, 181, 186, 207, 208, 225, 226, 228, 229, 230, 253, 258, 259, 268, 271, 284, 332, 333, 334, 339, 340, 341, 342, 347, 348, 349, 354, 355, 356, 357, 358, 369, 370, 382, 383, 384, 388, 389, 394, 395, 396], "working_dir": [78, 82, 90, 98, 164, 165, 171, 173, 178], "workload": [2, 3, 4, 5, 7, 8, 9, 11, 22, 27, 28, 32, 35, 43, 46, 47, 55, 57, 72, 73, 75, 76, 77, 78, 82, 83, 84, 85, 87, 88, 89, 90, 95, 96, 99, 101, 106, 109, 111, 112, 118, 127, 136, 137, 149, 164, 165, 169, 173, 175, 180, 189, 192, 193, 196, 197, 199, 203, 205, 206, 207, 208, 215, 221, 225, 226, 229, 230, 232, 239, 240, 242, 258, 266, 272, 284, 291, 294, 297, 315, 319, 326, 329, 356, 358, 368, 374, 381, 394, 404], "workload_identity_pool_provid": [119, 123, 150, 154], "workloadidentitypool": [119, 123, 150, 154], "workloadserviceaccountnam": [127, 129, 132, 137, 140, 144, 150, 160], "workshop": [73, 82, 83, 85, 96, 99], "workspac": [74, 75, 76, 77, 78, 79, 80, 81, 86, 87, 88, 89, 90, 91, 92, 94, 96, 101, 105, 106, 108, 110, 173, 175, 179, 180, 369, 370, 382, 387, 388, 394, 395, 396, 404, 405], "workspace_v2": [74, 86], "world": [4, 32, 74, 78, 82, 86, 90, 97, 98, 181, 188, 198, 201, 258, 262, 332, 338, 340, 347, 348, 353, 362, 366, 375, 376, 381, 395, 396], "world_rank": [4, 32, 258, 267, 269], "world_siz": [4, 32, 258, 262, 273], "worri": [395, 396], "worth": [332, 338], "would": [4, 5, 8, 32, 35, 36, 52, 53, 54, 173, 175, 180, 193, 197, 232, 236, 237, 238, 258, 264, 292, 301, 326, 329, 330, 332, 338, 340, 342, 344, 346, 347, 348, 353], "wound": [340, 346], "wrangl": [258, 260], "wrap": [2, 4, 19, 32, 79, 83, 84, 91, 100, 215, 218, 259, 260, 261, 262, 266, 268, 269, 277, 292, 302, 303, 363, 370, 371, 377, 385, 389, 390, 396, 399], "wright": [332, 338], "write": [1, 2, 3, 4, 5, 6, 7, 9, 13, 16, 25, 28, 32, 36, 41, 43, 49, 50, 52, 56, 58, 60, 61, 65, 74, 76, 86, 88, 101, 106, 193, 197, 202, 203, 206, 209, 211, 214, 215, 224, 225, 226, 233, 234, 236, 240, 241, 243, 245, 246, 250, 258, 268, 275, 280, 285, 289, 292, 293, 294, 306, 312, 317, 319, 326, 330, 362, 364, 375, 376, 388, 390, 395, 396, 397, 398, 400], "write_csv": [8, 53, 232, 237], "write_parquet": [3, 8, 9, 28, 53, 60, 65, 193, 197, 198, 200, 203, 206, 232, 237, 240, 245, 250, 294, 319, 362, 364, 388, 390], "write_t": [388, 390, 395, 397], "writefil": [198, 200], "writer": [4, 31, 292, 300], "writerow": [4, 31, 292, 300], "written": [7, 11, 45, 72, 189, 192, 198, 201, 207, 208, 225, 228, 258, 260, 268, 340, 346, 362, 364, 382, 384, 388, 390, 395, 400], "wrong": [332, 338], "wrote": [8, 53, 232, 237, 332, 338, 362, 364, 375, 377, 382, 384, 395, 397], "wt": [332, 336, 338], "ww2": [340, 347], "wwe": [332, 336, 338], "wyom": [340, 346], "x": [1, 2, 5, 6, 7, 16, 18, 19, 20, 24, 35, 41, 44, 77, 89, 193, 197, 202, 209, 214, 215, 217, 218, 219, 223, 225, 227, 258, 271, 285, 289, 293, 312, 326, 329, 332, 338, 362, 363, 365, 369, 372, 374, 382, 385, 388, 391, 394, 395, 396, 404], "x_": [362, 363, 369, 370], "x_0": [362, 363, 365, 369, 370], "x_t": [362, 363, 365, 369, 370], "x_test": [3, 28, 203, 206], "x_train": [3, 28, 203, 206], "xb": [388, 390, 395, 400], "xgb": [4, 5, 30, 34, 258, 259, 326, 328, 382, 383, 384, 385, 386, 387], "xgb_model": [382, 385], "xgb_param": [382, 385], "xgboost": [6, 41, 285, 289, 291, 298, 384, 386, 387], "xgboost_predict": [3, 28, 203, 206], "xgboosterror": [3, 26, 203, 204], "xgboosttrain": [3, 26, 28, 203, 204, 206, 291, 298, 382, 384, 385], "xgboosttrainer_2024": [291, 298], "xgboosttrainer_81312_00000terminated10": [291, 298], "xgboosttrainer_81312_00001terminated10": [291, 298], "xgboosttrainer_81312_00002terminated10": [291, 298], "xgbpredictor": [382, 386, 387], "xing": [119, 123, 150, 154], "xlabel": [362, 366, 369, 373, 375, 377, 379, 382, 386, 388, 392, 394, 395, 402], "xxx": [119, 123, 137, 140, 150, 153, 154], "xxxx": [119, 123, 150, 154], "xxxxx": [112, 114, 119, 123, 124, 127, 131, 137, 143, 150, 154, 159], "xxxxxx": [112, 114, 127, 129, 137, 140], "xxxxxxx": [127, 129, 137, 140], "xxxxxxxx": [112, 114, 127, 129, 137, 140], "xxxxxxxxx": [112, 114], "xxxxxxxxxx": [112, 114], "xxxxxxxxxxxx": [112, 114, 127, 129, 137, 140], "y": [2, 4, 6, 11, 18, 31, 41, 72, 77, 89, 165, 171, 173, 177, 179, 181, 184, 185, 186, 207, 208, 215, 217, 285, 289, 292, 293, 300, 312, 332, 338, 382, 385, 395, 396], "y_test": [3, 28, 203, 206], "y_train": [3, 28, 203, 206], "ya": [332, 338], "yaml": [10, 71, 79, 91, 127, 130, 137, 142, 150, 157, 164, 165, 171, 173, 178, 181, 185, 193, 197, 202, 252, 257], "yanke": [332, 336, 338], "yann": [292, 293, 305, 311], "yara": [181, 184], "yard": [332, 338], "yb": [388, 390, 395, 400], "ye": [101, 106, 332, 338], "year": [3, 28, 181, 184, 186, 203, 206, 332, 338, 340, 343, 347], "yellow": [3, 28, 164, 165, 168, 203, 206, 291, 298, 340, 343], "yellow_tripdata_": [3, 28, 203, 206], "yellow_tripdata_2011": [8, 51, 54, 198, 200, 232, 235, 238], "yellow_tripdata_2021": [3, 28, 203, 206], "yelp": [348, 350, 355], "yelp_review_ful": [348, 353], "yepo": [332, 338], "yesterdai": [332, 338], "yet": [340, 347, 375, 376, 377, 395, 396], "yield": [2, 23, 215, 222], "ylabel": [362, 366, 369, 373, 375, 377, 379, 382, 384, 386, 388, 390, 392, 394, 395, 402], "yml": 0, "york": [3, 8, 28, 51, 203, 206, 232, 235, 388, 389], "you": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 38, 41, 49, 50, 51, 52, 53, 54, 55, 56, 60, 61, 62, 63, 64, 65, 67, 71, 72, 73, 74, 75, 76, 77, 79, 80, 84, 85, 86, 87, 88, 89, 91, 92, 98, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 159, 161, 162, 164, 165, 166, 168, 169, 170, 171, 173, 174, 177, 178, 180, 181, 182, 183, 184, 185, 186, 188, 189, 192, 193, 194, 195, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 213, 215, 216, 218, 219, 220, 221, 222, 223, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 245, 246, 247, 248, 249, 250, 252, 253, 257, 260, 263, 264, 265, 266, 267, 268, 269, 270, 271, 277, 282, 283, 284, 285, 286, 289, 291, 292, 293, 294, 295, 296, 299, 303, 306, 308, 312, 317, 318, 319, 320, 321, 326, 327, 328, 330, 332, 334, 336, 337, 338, 340, 342, 343, 344, 345, 346, 347, 348, 350, 353, 354, 355, 356, 358, 361, 364, 366, 371, 372, 373, 377, 379, 384, 385, 390, 391, 392, 397, 398, 399, 402], "young": [340, 343, 347], "your": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 14, 16, 21, 23, 25, 28, 31, 32, 36, 41, 53, 57, 58, 61, 62, 64, 65, 68, 70, 73, 74, 75, 76, 80, 81, 85, 86, 87, 88, 92, 94, 99, 102, 103, 105, 106, 109, 110, 112, 113, 114, 115, 116, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 138, 140, 142, 143, 144, 146, 147, 148, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 173, 176, 177, 178, 179, 181, 184, 185, 186, 187, 188, 198, 200, 201, 202, 203, 206, 209, 212, 214, 215, 220, 222, 224, 232, 237, 240, 242, 243, 246, 247, 249, 250, 252, 254, 256, 258, 259, 260, 261, 262, 263, 266, 268, 269, 272, 278, 281, 283, 285, 289, 291, 292, 293, 294, 295, 296, 303, 306, 312, 317, 318, 321, 326, 330, 332, 334, 337, 338, 340, 342, 346, 347, 348, 350, 354, 355, 362, 363, 369, 370, 375, 376, 377, 379, 381, 382, 383, 385, 387, 388, 389, 390, 392, 394, 395, 396, 401, 402, 404], "your_anyscale_org_id": [119, 123], "your_gcp_project_nam": [150, 162], "your_project_id": [119, 122], "yourself": [2, 21, 215, 220, 362, 363], "yr": [332, 338], "ytick": [382, 386], "yunikorn": [108, 110], "z": [332, 338, 388, 390], "zentropa": [340, 346, 347], "zero": [7, 43, 79, 83, 91, 99, 164, 165, 169, 170, 173, 180, 198, 201, 225, 226, 348, 353, 356, 361, 382, 384, 388, 391, 392, 394, 395, 400, 404], "zero_copy_onli": [382, 385], "zero_grad": [4, 6, 31, 32, 40, 41, 258, 262, 273, 279, 285, 288, 289, 292, 293, 300, 302, 306, 310, 313, 348, 353, 375, 379, 388, 392, 395, 400], "zeros_lik": [388, 392], "zilliz": [7, 43, 225, 226], "zip": [6, 39, 285, 287, 293, 309, 362, 364, 368, 375, 377, 381, 382, 386, 395, 397], "zip_ref": [375, 377], "zipfil": [375, 377], "zone": [8, 51, 101, 106, 127, 129, 137, 140, 150, 155, 232, 235], "zprofil": [11, 72, 207, 208], "zsh": [150, 153], "zshrc": [150, 153], "zuoma": [332, 338], "\u03b8": [369, 371, 374], "\u03c0": [77, 89, 369, 371], "\u03f5": [362, 365, 369, 372]}, "titles": ["Ray Enablement Content: Jupyter Book Publishing", "Introduction to Ray Core: Getting Started", "Introduction to Ray Core (Advancement): Object store, Tasks, Actors", "Introduction to the Ray AI Libraries: An example of using Ray data, Ray Train, Ray Tune, Ray Serve to implement a XGBoost regression model", "Introduction to Ray Train + PyTorch", "Introduction to Ray Train: Ray Train + PyTorch Lightning", "Introduction to Ray Tune", "Introduction to Ray Data: Industry Landscape", "Introduction to Ray Data: Ray Data + Structured Data", "Intro to Ray Data:  Ray Data + Unstructured Data", "Introduction to Ray Serve with PyTorch", "Introduction to Ray: Developer", "Introduction to Ray Core: Getting Started", "0. Overview", "1. Creating Remote Functions", "2. Executing Remote Functions", "4. Putting It All Together", "Introduction to Ray Core (Advancement): Object store, Tasks, Actors", "1. Object store", "2. Chaining Tasks and Passing Data", "3. Task retries", "4. Task Runtime Environments", "5. Resource allocation and management", "6. Nested Tasks", "7. Pattern: Pipeline data processing and waiting for results", "8. Ray Actors", "Introduction to the Ray AI Libraries: An example of using Ray data, Ray Train, Ray Tune, Ray Serve to implement a XGBoost regression model", "1. Overview of the Ray AI Libraries", "2. Quick end-to-end example", "Introduction to Ray Train + PyTorch", "1. When to use Ray Train", "2. Single GPU Training with PyTorch", "3. Distributed Data Parallel Training with Ray Train and PyTorch", "Introduction to Ray Train: Ray Train + PyTorch Lightning", "1. When to use Ray Train", "2. Single GPU Training with PyTorch Lightning", "3. Distributed Training with Ray Train and PyTorch Lightning", "4. Ray Train in Production", "Introduction to Ray Tune", "1. Loading the data", "2. Starting out with vanilla PyTorch", "3. Hyperparameter tuning with Ray Tune", "4. Ray Tune in Production", "Introduction to Ray Data: Industry Landscape", "The Compute Layer", "The Orchestration Layer", "Distributed Computing Frameworks", "Data Processing with Ray Data", "Ray Serve", "Introduction to Ray Data: Ray Data + Structured Data", "0. What is Ray Data?", "2. Loading Data", "3. Transforming Data", "4. Writing Data", "5. Data Operations: Shuffling, Grouping and Aggregation", "6. When to use Ray Data", "Intro to Ray Data:  Ray Data + Unstructured Data", "1. When to Consider Ray Data", "2. How to work with Ray Data", "3. Loading data", "3. Lazy execution mode", "4. Transforming data", "5. Stateful transformations with Ray Actors", "6. Materializing data", "7. Data Operations: grouping, aggregation, and shuffling", "8. Persisting data", "9. Ray Data in production", "Introduction to Ray Serve with PyTorch", "1. When to Consider Ray Serve", "2. Overview of Ray Serve", "3. Implement an image classification service", "4. Development workflow", "Introduction to Ray: Developer", "101 \u2014 Introduction to Anyscale Workspaces", "101 \u2013 Developing Application with Anyscale", "101 \u2013 Compute Configs and Execution Environments in Anyscale", "101 \u2013 Storage Options in the Anyscale Platform", "101 \u2013 Debug and Monitor Your Anyscale Application", "101 \u2013 Introduction to Anyscale Jobs", "101 \u2013  Introduction to Anyscale Services", "101 \u2013 Collaboration on Anyscale", "101 - Anyscale Organization and Cloud Setup", "Content Used", "Sources", "Last Updated 6/19", "101 \u2014 Introduction to Anyscale Workspaces", "101 \u2013 Developing Application with Anyscale", "101 \u2013 Compute Configs and Execution Environments in Anyscale", "101 \u2013 Storage Options in the Anyscale Platform", "101 \u2013 Debug and Monitor Your Anyscale Application", "101 \u2013 Introduction to Anyscale Jobs", "101 \u2013  Introduction to Anyscale Services", "101 \u2013 Collaboration on Anyscale", "101 - Anyscale Organization and Cloud Setup", "\ud83d\udccc Overview of Structure", "\ud83e\udde0 Summary", "Content Used", "Part 1. Creating and Submitting your first job", "Part 2. Automation and Scheduling", "Sources", "Part 1: Starting your first Anyscale Service", "Anyscale Administrator Overview", "Anyscale Administrator Overview", "1. What is an Anyscale Cloud?", "2. Cloud Deployment Types", "3. A Demonstrative Example of Resource Creation with AWS EC2", "3.1 IAM Role Definition", "4. Register Anyscale Cloud to Your Cloud Provider", "Deployment Options: Virtual Machines vs. Kubernetes", "Deployment Options: Virtual Machines vs. Kubernetes", "2. Virtual Machines (VM) vs. Kubernetes (K8s)", "3. (Optional) More Kubernetes Deployments Components", "Introduction: Deploy Anyscale Ray on AWS EC2 Instances", "Introduction: Deploy Anyscale Ray on AWS EC2 Instances", "1. Create Anyscale Resources with Terraform", "2. Register the Anyscale Cloud", "3. Test", "4. Cleanup", "5. Conclusion", "Introduction: Deploy Anyscale Ray on GCP Compute Engine Instances (GCE)", "Introduction: Deploy Anyscale Ray on GCP Compute Engine Instances (GCE)", "Prerequisites", "1. Installation", "2. Create Anyscale Resources with Terraform", "3. Register the Anyscale Cloud", "4. Test", "5. Cleanup", "Introduction: Deploy Anyscale Ray on A New AWS EKS Cluster", "Introduction: Deploy Anyscale Ray on A New AWS EKS Cluster", "1. Create Anyscale Resources with Terraform", "2. Install Kubernetes Components", "3. Register the Anyscale Cloud", "4. Install the Anyscale Operator", "5. Verify the Installation", "6. Test", "7. Clean up", "8. Conclusion", "Introduction: Deploy Anyscale Ray on An Existing AWS EKS Cluster", "Introduction: Deploy Anyscale Ray on An Existing AWS EKS Cluster", "Prerequisites", "1. Create Anyscale Resources with Terraform", "2. Attach Required IAM Policies to Your existing EKS\u2019s Node Role", "3. Install Kubernetes Components", "4. Register the Anyscale Cloud", "5. Install the Anyscale Operator", "6. Verify the Installation", "7. Test", "8. Troubleshooting", "9. Clean up", "10. Conclusion", "Introduction: Deploy Anyscale Ray on A New Google Kubernetes Engine (GKE) Cluster", "Introduction: Deploy Anyscale Ray on A New Google Kubernetes Engine (GKE) Cluster", "Prerequisites", "1. Installation", "2. Create Anyscale Resources with Terraform", "3. Troubleshooting GPU Availability", "4. kubectl Configuration", "5. Install NGINX Ingress Controller", "6. (Optional) Upgrade Anyscale Dependencies", "7. Register the Anyscale Cloud", "8. Install the Anyscale Operator", "8. Test", "9. Cleanup", "Welcome to Anyscale Administration", "Introduction to Ray Serve LLM: Foundations of Large Language Model Serving", "Introduction to Ray Serve LLM: Foundations of Large Language Model Serving", "Introduction to Ray Serve LLM: Foundations of Large Language Model Serving", "What is LLM Serving?", "Key Concepts and Optimizations", "Challenges in LLM Serving", "Ray Serve LLM + Anyscale Architecture", "Getting Started with Ray Serve LLM", "Key Takeaways", "Deploy a Medium-Sized LLM with Ray Serve LLM", "Deploy a Medium-Sized LLM with Ray Serve LLM", "Overview: Why Medium-Sized Models?", "Setting up Ray Serve LLM", "Local Deployment &amp; Inference", "Deploying to Anyscale Services", "Advanced Topics: Monitoring &amp; Optimization", "Summary &amp; Outlook", "Advanced LLM Features with Ray Serve LLM", "Advanced LLM Features with Ray Serve LLM", "Overview: Advanced Features Preview", "Example: Deploying LoRA Adapters", "Example: Getting Structured JSON Output", "Example: Setting up Tool Calling", "How to Choose an LLM?", "Conclusion: Next Steps", "Observability Introduction", "Observability Introduction", "Observability Overview", "Setting Up Local Ray Observability", "Ray and Anyscale Observability Introduction", "Ray and Anyscale Observability Introduction", "Ray Observability", "Anyscale Observability", "Example", "Ray and Anyscale Observability in Detail", "Ray and Anyscale Observability in Detail", "Data Pipeline Observability (Ray Data)", "Web Application Observability (Ray Serve)", "Multi-Actor Ray Serve Tracing Example", "Introduction to the Ray AI Libraries: An example of using Ray data, Ray Train, Ray Tune, Ray Serve to implement a XGBoost regression model", "Introduction to the Ray AI Libraries: An example of using Ray data, Ray Train, Ray Tune, Ray Serve to implement a XGBoost regression model", "1. Overview of the Ray AI Libraries", "2. Quick end-to-end example", "Introduction to Ray: Developer", "Introduction to Ray: Developer", "Introduction to Ray Core: Getting Started", "Introduction to Ray Core: Getting Started", "0. Overview", "1. Creating Remote Functions", "2. Executing Remote Functions", "4. Putting It All Together", "Introduction to Ray Core (Advancement): Object store, Tasks, Actors", "Introduction to Ray Core (Advancement): Object store, Tasks, Actors", "1. Object store", "2. Chaining Tasks and Passing Data", "3. Task retries", "4. Task Runtime Environments", "5. Resource allocation and management", "6. Nested Tasks", "7. Pattern: Pipeline data processing and waiting for results", "8. Ray Actors", "Introduction to Ray Data: Industry Landscape", "Introduction to Ray Data: Industry Landscape", "The Compute Layer", "The Orchestration Layer", "Distributed Computing Frameworks", "Data Processing with Ray Data", "Ray Serve", "Introduction to Ray Data: Ray Data + Structured Data", "Introduction to Ray Data: Ray Data + Structured Data", "0. What is Ray Data?", "2. Loading Data", "3. Transforming Data", "4. Writing Data", "5. Data Operations: Shuffling, Grouping and Aggregation", "6. When to use Ray Data", "Intro to Ray Data:  Ray Data + Unstructured Data", "Intro to Ray Data:  Ray Data + Unstructured Data", "1. When to Consider Ray Data", "2. How to work with Ray Data", "3. Loading data", "3. Lazy execution mode", "4. Transforming data", "5. Stateful transformations with Ray Actors", "6. Materializing data", "7. Data Operations: grouping, aggregation, and shuffling", "8. Persisting data", "9. Ray Data in production", "Introduction to Ray Serve with PyTorch", "Introduction to Ray Serve with PyTorch", "1. When to Consider Ray Serve", "2. Overview of Ray Serve", "3. Implement an image classification service", "4. Development workflow", "\ud83d\udcda 01 \u00b7 Introduction to Ray Train", "\ud83d\udcda 01 \u00b7 Introduction to Ray Train", "01 \u00b7 Imports", "04 \u00b7 Define ResNet-18 Model for MNIST", "05 \u00b7 Define the Ray Train Loop (DDP per-worker)", "06 \u00b7 Define <code class=\"docutils literal notranslate\"><span class=\"pre\">train_loop_config</span></code>", "07 \u00b7 Configure Scaling with <code class=\"docutils literal notranslate\"><span class=\"pre\">ScalingConfig</span></code>", "08 \u00b7 Wrap the Model with <code class=\"docutils literal notranslate\"><span class=\"pre\">prepare_model()</span></code>", "09 \u00b7 Build the DataLoader with <code class=\"docutils literal notranslate\"><span class=\"pre\">prepare_data_loader()</span></code>", "10 \u00b7 Report Training Metrics", "11 \u00b7 Save Checkpoints and Report Metrics", "14 \u00b7 Create the <code class=\"docutils literal notranslate\"><span class=\"pre\">TorchTrainer</span></code>", "16 \u00b7 Inspect the Training Results", "18 \u00b7 Load a Checkpoint for Inference", "\ud83d\udd04 02 \u00b7 Integrating Ray Train with Ray Data", "01 \u00b7 Define Training Loop with Ray Data", "02 \u00b7 Build DataLoader from Ray Data", "03 \u00b7 Prepare Dataset for Ray Data", "05 \u00b7 Define Image Transformation", "07 \u00b7 Configure <code class=\"docutils literal notranslate\"><span class=\"pre\">TorchTrainer</span></code> with Ray Data", "\ud83d\udee1\ufe0f 03 \u00b7 Fault Tolerance in Ray Train", "01 \u00b7 Modify Training Loop to Enable Checkpoint Loading", "02 \u00b7 Save Full Checkpoint with Extra State", "04 \u00b7 Launch Fault-Tolerant Training", "05 \u00b7 Manual Restoration from Checkpoints", "07 \u00b7 Clean Up Cluster Storage", "\ud83c\udf89 Wrapping Up &amp; Next Steps", "Introduction to Ray Tune", "Introduction to Ray Tune", "1. Loading the data", "2. Starting out with vanilla PyTorch", "3. Hyperparameter tuning with Ray Tune", "4. Ray Tune in Production", "Introduction to the Ray AI Libraries", "Introduction to Ray Train", "Intro to Ray Tune", "Intro to Ray Data", "Intro to Ray Serve", "Introduction to the Ray AI Libraries", "1. Overview of the Ray AI Libraries", "2. End-to-end example: predicting taxi tips in New York", "Introduction to Ray Train", "1. PyTorch introductory example (single GPU)", "2. Distributed Data Parallel Training with Ray Train and PyTorch (multiple GPUs)", "3. Overview of the training loop in Ray Train", "4. Migrating the model and dataset to Ray Train", "5. Reporting checkpoints and metrics", "6. Launching the distributed training job", "7. Accessing the training results", "8. Ray Train in Production", "Intro to Ray Tune", "1. Loading and visualizing data", "2. Setting up a PyTorch model", "3. Introduction to Ray Tune", "4. Diving deeper into Ray Tune concepts", "5. Hyperparameter tuning the PyTorch model using Ray Tune", "Intro to Ray Data", "1. When to use Ray Data", "2. Loading Data", "3. Transforming Data", "4. Data Operations: Grouping, Aggregation, and Shuffling", "5. Persisting Data", "Intro to Ray Serve", "1. Overview of Ray Serve", "2. Implement an Classifier service", "3. Advanced features of Ray Serve", "4. Ray Serve in Production", "Clean up", "Introduction to Ray Train: Ray Train + PyTorch Lightning", "Introduction to Ray Train: Ray Train + PyTorch Lightning", "1. When to use Ray Train", "2. Single GPU Training with PyTorch Lightning", "3. Distributed Training with Ray Train and PyTorch Lightning", "4. Ray Train in Production", "Batch Inference with Ray Data", "Data Processing and ML examples with Ray", "Batch Inference with Ray Data", "Architecture", "Load a dataset", "Batch Inference Class", "Create a batch data and call the model", "Run inference on the entire dataset", "Data Processing with Ray Data", "Data Processing and ML examples with Ray", "Data Processing with Ray Data", "Library Imports", "Convert to Ray Dataset", "Filter Ray Dataset", "Join Two Ray Datasets", "Preprocessing with a Tokenizer", "Distributed training with Ray Train, PyTorch and Hugging Face", "Data Processing and ML examples with Ray", "Distributed training with Ray Train, PyTorch and Hugging Face", "1. Architecture", "3. Metrics Setup", "4. Training function per worker", "5. Main Training Function", "6. Start Training", "Online Model Serving with Ray Serve", "Data Processing and ML examples with Ray", "Online Model Serving with Ray Serve", "Architecture", "FastAPI webservice and deploy a model", "Simulate Client: Send test requests", "04-d1 Generative computer-vision pattern with Ray Train", "04-d1 Generative computer-vision pattern with Ray Train", "1. Imports and setup", "8. Pixel diffusion LightningModule", "9. Ray Train <code class=\"docutils literal notranslate\"><span class=\"pre\">train_loop</span></code> (Lightning + Ray integration)", "12. Resume from latest checkpoint", "13. Reverse diffusion sampler", "04-d2 Diffusion-Policy Pattern with Ray Train", "04-d2 Diffusion-Policy Pattern with Ray Train", "1. Imports and setup", "4. DiffusionPolicy LightningModule", "5. Distributed Train loop with checkpointing", "8. Reverse diffusion helper", "04e Recommendation system pattern with Ray Train", "04e Recommendation system pattern with Ray Train", "1. Imports", "7. Define matrix factorization model", "8. Define Ray Train loop (with validation, checkpointing, and Ray-managed metrics)", "11. Resume training from checkpoint", "12. Inference: recommend top-N items for a user", "04b Tabular workload pattern with Ray Train", "04b Tabular workload pattern with Ray Train", "1. Imports", "8. Define the Ray Train worker loop (Arrow-based, memory-efficient)", "12. Confusion matrix visualization", "15. Continue training from the latest checkpoint", "04c Time-Series workload pattern with Ray Train", "04c Time-Series workload pattern with Ray Train", "1. Imports", "9. PositionalEncoding and Transformer model", "10. Ray Train training loop (with teacher forcing)", "13. Resume training from checkpoint", "14. Inference helper \u2014 Ray Data batch predictor on GPU", "04a Computer-vision pattern with Ray Train", "04a Computer-vision pattern with Ray Train", "1. Imports", "6. Custom <code class=\"docutils literal notranslate\"><span class=\"pre\">Food101Dataset</span></code> for Parquet", "10. Helper: Ray-prepared DataLoaders", "11. <code class=\"docutils literal notranslate\"><span class=\"pre\">train_loop_per_worker</span></code>", "12. Launch distributed training with <code class=\"docutils literal notranslate\"><span class=\"pre\">TorchTrainer</span></code>", "13. Plot training and validation loss curves", "14. Demonstrate fault-tolerant resumption", "15. Batch inference with Ray Data", "Ray Enablement Content"], "titleterms": {"": [75, 87, 137, 141, 189, 192, 369, 370, 382, 383, 388, 389], "0": [1, 8, 13, 50, 101, 102, 209, 211, 232, 234, 258, 268], "00": 405, "01": [258, 259, 260, 271, 273, 279, 284], "02": [258, 260, 272, 274, 280, 284], "02_service_hello_world": [83, 100], "03": [258, 260, 275, 278, 280, 284], "04": [258, 261, 275, 281, 362, 363, 369, 370], "04a": [395, 396], "04b": [382, 383], "04c": [388, 389], "04e": [375, 376], "05": [258, 262, 276, 282], "06": [258, 263, 276, 282], "07": [258, 264, 277, 283], "08": [258, 265, 277], "09": [258, 266], "1": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 14, 16, 18, 21, 22, 24, 27, 28, 30, 31, 32, 34, 35, 36, 39, 50, 57, 61, 62, 64, 68, 72, 76, 78, 79, 82, 83, 84, 88, 90, 91, 97, 98, 100, 101, 103, 106, 108, 109, 110, 112, 114, 119, 122, 123, 127, 129, 130, 137, 140, 142, 150, 153, 154, 164, 165, 168, 169, 170, 171, 173, 175, 179, 181, 187, 189, 192, 202, 203, 205, 206, 207, 208, 209, 212, 214, 215, 217, 220, 221, 223, 232, 234, 240, 242, 246, 247, 249, 252, 254, 285, 287, 291, 292, 293, 294, 295, 297, 300, 309, 315, 321, 326, 328, 329, 330, 348, 351, 362, 364, 369, 370, 371, 375, 377, 382, 384, 388, 390, 395, 397], "10": [4, 32, 137, 149, 258, 267, 362, 364, 366, 369, 374, 375, 379, 382, 385, 388, 392, 395, 397, 399], "100k": [375, 377], "101": [73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 99, 362, 364, 395, 396, 397, 405], "11": [258, 268, 362, 366, 375, 380, 382, 385, 388, 392, 395, 400], "12": [258, 268, 362, 367, 375, 381, 382, 386, 388, 392, 395, 401], "13": [258, 268, 362, 368, 375, 381, 382, 386, 388, 393, 395, 402], "14": [258, 269, 362, 368, 375, 381, 382, 386, 388, 394, 395, 403], "15": [258, 269, 362, 368, 382, 387, 388, 394, 395, 404], "16": [258, 270, 382, 387, 388, 394, 395, 404], "17": [258, 270, 382, 387, 395, 404], "18": [258, 261, 271], "19": [84, 258, 271], "2": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 15, 16, 19, 22, 24, 28, 31, 32, 35, 36, 40, 51, 58, 59, 61, 62, 64, 69, 72, 76, 78, 82, 83, 84, 88, 90, 97, 98, 100, 101, 104, 106, 108, 110, 112, 115, 119, 122, 123, 127, 130, 137, 141, 142, 150, 153, 154, 164, 165, 168, 169, 170, 171, 173, 179, 181, 187, 189, 192, 202, 203, 206, 207, 208, 209, 213, 214, 215, 218, 221, 223, 232, 235, 240, 243, 244, 246, 247, 249, 252, 255, 285, 288, 291, 292, 293, 294, 295, 298, 301, 310, 316, 322, 326, 329, 330, 348, 351, 362, 364, 369, 370, 371, 375, 377, 382, 384, 388, 390, 395, 397], "20": [258, 271], "3": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 15, 20, 22, 28, 31, 32, 35, 36, 41, 52, 59, 60, 64, 70, 72, 76, 82, 83, 84, 88, 97, 98, 100, 101, 105, 106, 108, 110, 111, 112, 116, 119, 124, 127, 130, 131, 137, 142, 150, 155, 164, 165, 168, 169, 170, 171, 173, 175, 179, 181, 187, 189, 192, 203, 206, 207, 208, 209, 213, 215, 219, 221, 232, 236, 240, 244, 245, 249, 252, 256, 285, 289, 291, 292, 293, 294, 295, 298, 302, 311, 317, 323, 326, 329, 330, 348, 352, 362, 364, 369, 370, 371, 375, 377, 382, 384, 388, 390, 395, 397], "30": [388, 390], "4": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 16, 21, 28, 31, 32, 35, 36, 37, 42, 53, 61, 71, 72, 76, 82, 83, 88, 97, 100, 101, 106, 107, 108, 110, 111, 112, 117, 119, 125, 127, 130, 132, 137, 142, 143, 150, 156, 164, 165, 168, 169, 171, 173, 179, 181, 187, 189, 192, 203, 206, 207, 208, 209, 214, 215, 220, 232, 237, 240, 246, 252, 257, 285, 290, 292, 293, 294, 295, 303, 312, 318, 324, 326, 329, 330, 331, 348, 353, 362, 364, 369, 372, 375, 377, 382, 384, 388, 390, 395, 397], "5": [2, 3, 4, 5, 8, 9, 11, 22, 28, 31, 32, 36, 54, 62, 72, 82, 83, 97, 100, 101, 106, 112, 118, 119, 126, 127, 133, 137, 144, 150, 157, 173, 179, 203, 206, 207, 208, 215, 221, 232, 238, 240, 247, 292, 293, 294, 304, 313, 319, 326, 330, 348, 354, 362, 364, 369, 373, 375, 377, 382, 384, 388, 390, 395, 397], "6": [2, 3, 4, 5, 8, 9, 11, 23, 28, 31, 32, 36, 55, 63, 72, 82, 84, 97, 101, 106, 127, 134, 137, 145, 150, 158, 203, 206, 207, 208, 215, 222, 232, 239, 240, 248, 292, 305, 326, 330, 348, 355, 362, 364, 369, 373, 375, 377, 382, 384, 388, 390, 395, 398], "7": [2, 4, 5, 8, 9, 11, 24, 32, 36, 55, 64, 72, 82, 97, 101, 106, 127, 135, 137, 146, 150, 159, 207, 208, 215, 223, 232, 239, 240, 249, 292, 306, 326, 330, 348, 355, 362, 364, 369, 373, 375, 378, 382, 384, 388, 390, 395, 398], "70b": [173, 175], "8": [2, 4, 8, 9, 11, 25, 32, 55, 65, 72, 101, 106, 127, 136, 137, 147, 150, 160, 161, 207, 208, 215, 224, 232, 239, 240, 250, 292, 307, 348, 355, 362, 365, 369, 374, 375, 379, 382, 385, 388, 390, 392, 395, 398], "9": [4, 9, 32, 66, 137, 148, 150, 162, 240, 251, 362, 366, 369, 374, 375, 379, 382, 385, 388, 391, 395, 398], "A": [101, 105, 127, 128, 150, 151], "For": [82, 98, 405], "In": [7, 11, 43, 72, 82, 83, 97, 100, 207, 208, 225, 226], "It": [1, 11, 16, 72, 207, 208, 209, 214], "On": [7, 9, 47, 61, 225, 230, 240, 246], "The": [7, 43, 44, 45, 78, 82, 90, 96, 97, 164, 165, 167, 225, 226, 227, 228], "These": [181, 183], "To": [108, 110], "about": [1, 2, 16, 21, 209, 214, 215, 220, 294, 316], "access": [4, 5, 32, 36, 108, 110, 292, 306, 326, 330], "accomplish": [173, 180, 181, 188], "action": [369, 370, 374], "activ": [4, 5, 11, 32, 36, 72, 207, 208, 292, 306, 326, 330], "actor": [2, 9, 17, 25, 62, 202, 215, 216, 224, 240, 247, 258, 271, 294, 317], "ad": [0, 362, 363], "adapt": [181, 184], "add": [11, 72, 207, 208], "addit": [189, 192], "admin": 405, "administr": [101, 102, 163], "advanc": [2, 17, 173, 179, 181, 182, 183, 188, 215, 216, 295, 323], "after": [82, 97], "again": [82, 98], "aggreg": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318], "ai": [3, 7, 26, 27, 44, 203, 204, 205, 225, 227, 291, 296, 297, 298, 405], "alert": [198, 201], "align": [181, 187], "all": [1, 8, 9, 16, 54, 64, 82, 98, 209, 214, 232, 238, 240, 249, 388, 394], "alloc": [2, 22, 215, 221], "also": [82, 97], "altern": [164, 165, 168], "an": [2, 3, 10, 18, 26, 28, 70, 75, 82, 87, 97, 101, 103, 137, 138, 173, 178, 181, 187, 203, 204, 206, 215, 217, 252, 256, 291, 295, 298, 322, 369, 374], "annot": [293, 312], "anti": [1, 16, 209, 214], "anyscal": [73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 108, 109, 110, 112, 113, 114, 115, 119, 120, 123, 124, 127, 128, 129, 131, 132, 137, 138, 140, 143, 144, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 173, 178, 193, 194, 196, 198, 199, 201, 362, 363, 369, 370, 375, 376, 382, 383, 388, 389, 395, 396, 405], "apach": [7, 43, 225, 226], "api": [119, 122, 150, 153, 202], "appli": [258, 276], "applic": [7, 10, 46, 69, 74, 77, 84, 86, 89, 198, 201, 225, 229, 252, 255], "approach": [181, 183], "ar": [101, 104, 362, 363, 369, 370, 375, 376, 382, 383, 388, 389, 395, 396], "architectur": [101, 106, 164, 165, 170, 202, 332, 335, 348, 351, 356, 359], "area": [292, 306], "argument": [2, 18, 82, 98, 215, 217], "arm": [11, 72, 207, 208], "arrow": [7, 43, 225, 226, 382, 385], "artifact": [388, 394], "assist": [181, 184, 186], "assumpt": [189, 192], "attach": [137, 141], "auroc": [292, 306], "authent": [119, 122, 150, 153], "auto": [83, 100], "autom": [78, 82, 90, 98], "automat": [258, 280], "autosc": [9, 62, 240, 247, 295, 323], "autoscal": [127, 130, 137, 142], "avail": [2, 22, 82, 98, 150, 155, 202, 215, 221], "aw": [101, 105, 112, 113, 127, 128, 130, 137, 138, 142], "awai": [258, 259, 272, 278, 362, 363, 369, 370, 375, 376, 382, 383, 388, 389, 395, 396], "backend": [108, 110], "balanc": [127, 130, 137, 142, 382, 384], "base": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318, 375, 376, 382, 385], "basic": [82, 97], "batch": [2, 3, 7, 8, 9, 24, 28, 46, 54, 64, 164, 165, 168, 203, 206, 215, 223, 225, 229, 232, 238, 240, 249, 294, 318, 332, 334, 337, 338, 382, 384, 386, 388, 390, 394, 395, 398, 404, 405], "below": [82, 83, 97, 100], "benchmark": [181, 187], "benefit": [83, 99, 181, 184, 185, 186], "best": [362, 368], "block": [8, 9, 54, 59, 64, 232, 238, 240, 244, 249, 294, 318], "book": 0, "bound": [2, 22, 215, 221], "breakdown": [173, 176], "build": [0, 4, 31, 258, 266, 274, 292, 300, 382, 385], "cach": [164, 165, 168], "california": [382, 384], "call": [1, 16, 181, 186, 209, 214, 332, 338], "can": [82, 97, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "car": [181, 185], "case": [11, 72, 181, 187, 207, 208], "caus": [2, 24, 215, 223], "chain": [2, 19, 215, 218], "challeng": [7, 46, 164, 165, 169, 225, 229], "characterist": [79, 91], "check": [82, 83, 97, 98, 100, 362, 364, 388, 390, 395, 397], "checkout": [83, 100], "checkpoint": [4, 5, 31, 32, 36, 258, 268, 271, 279, 280, 282, 292, 300, 304, 326, 330, 362, 367, 368, 369, 373, 375, 379, 380, 382, 387, 388, 393], "choos": [173, 175, 181, 187], "class": [332, 337, 382, 384], "classif": [10, 70, 252, 256, 382, 383, 395, 396], "classifi": [295, 322], "clean": [3, 11, 28, 72, 77, 78, 79, 89, 90, 91, 127, 135, 137, 148, 203, 206, 207, 208, 258, 271, 283, 295, 325, 362, 368, 369, 374, 375, 381, 382, 387, 395, 404], "cleanup": [82, 97, 112, 117, 119, 126, 150, 162, 388, 394], "cli": [82, 84, 98], "client": [356, 361], "clone": [80, 83, 84, 92, 100], "cloud": [76, 81, 88, 93, 94, 101, 103, 104, 107, 112, 115, 119, 122, 124, 127, 131, 137, 143, 150, 153, 159], "cluster": [2, 22, 76, 88, 127, 128, 130, 137, 138, 142, 150, 151, 189, 192, 215, 221, 258, 283, 332, 339, 348, 355, 356, 361], "code": [3, 28, 82, 83, 97, 100, 181, 184, 203, 206], "collabor": [80, 84, 92], "command": [82, 83, 97, 100, 119, 123], "comparison": [173, 175], "compon": [108, 111, 127, 130, 137, 142, 173, 176], "compos": [295, 323], "comput": [7, 11, 44, 46, 72, 75, 87, 119, 120, 207, 208, 225, 227, 229, 292, 306, 362, 363, 395, 396], "concept": [4, 5, 6, 32, 36, 41, 164, 165, 168, 285, 289, 293, 312, 326, 330], "conclus": [112, 118, 127, 136, 137, 149, 181, 188], "concurr": [9, 61, 173, 179, 240, 246], "conda": [11, 72, 207, 208], "config": [75, 87], "configur": [2, 4, 5, 22, 32, 36, 75, 83, 87, 100, 119, 122, 150, 153, 156, 164, 165, 171, 173, 176, 178, 181, 184, 198, 201, 202, 215, 221, 258, 264, 268, 277, 280, 292, 302, 305, 326, 330, 382, 385], "confus": [382, 386], "consid": [9, 10, 57, 68, 240, 242, 252, 254], "consider": [164, 165, 168, 181, 187], "consol": [82, 97], "contain": [75, 83, 87, 100], "content": [0, 82, 96, 405], "context": [164, 165, 168, 181, 187], "continu": [164, 165, 168, 382, 387], "control": [101, 106, 108, 110, 127, 130, 137, 142, 150, 157], "convert": [340, 344, 347], "core": [1, 2, 7, 12, 17, 47, 209, 210, 215, 216, 225, 230, 405], "cost": [164, 165, 169, 181, 187], "count": [388, 390], "cours": [0, 11, 72, 207, 208, 258, 284], "cover": [78, 79, 90, 91, 181, 183, 382, 383, 384], "cpu": [382, 386], "creat": [1, 4, 5, 11, 14, 31, 35, 36, 72, 75, 78, 82, 87, 90, 97, 98, 101, 106, 112, 114, 119, 123, 127, 129, 137, 140, 150, 154, 207, 208, 209, 212, 258, 269, 326, 329, 330, 332, 338, 340, 344, 375, 377], "creation": [101, 105], "cursor": [74, 86], "curv": [292, 306, 362, 366, 375, 379, 395, 402], "custom": [0, 8, 9, 54, 64, 101, 106, 232, 238, 240, 249, 294, 295, 318, 323, 395, 398], "cv": 405, "d1": [362, 363], "d2": [369, 370], "dashboard": [77, 89, 198, 200], "data": [2, 3, 4, 5, 6, 7, 8, 9, 19, 24, 26, 28, 32, 36, 39, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 108, 110, 198, 200, 203, 204, 206, 215, 218, 223, 225, 226, 227, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 258, 259, 268, 272, 273, 274, 275, 276, 277, 284, 285, 287, 292, 293, 294, 300, 301, 309, 314, 315, 316, 317, 318, 319, 326, 330, 332, 333, 334, 338, 340, 341, 342, 349, 357, 362, 364, 375, 377, 382, 386, 388, 394, 395, 404, 405], "databas": [7, 43, 225, 226], "datafram": [258, 270, 340, 347], "dataload": [4, 5, 31, 35, 258, 266, 274, 326, 329, 348, 353, 388, 390, 395, 398, 399], "dataset": [4, 8, 31, 32, 51, 232, 235, 258, 260, 275, 291, 292, 294, 298, 303, 316, 332, 336, 339, 340, 343, 344, 345, 346, 369, 370, 371, 375, 377, 382, 384, 388, 390], "ddp": [258, 259, 262], "de": [362, 363], "debug": [77, 89], "decod": [164, 165, 167, 362, 364], "deeper": [6, 41, 285, 289, 293, 312], "default": [83, 100, 293, 312], "defin": [5, 35, 101, 104, 258, 261, 262, 263, 273, 276, 292, 300, 326, 329, 375, 378, 379, 382, 385], "definit": [101, 106], "demand": [164, 165, 169, 388, 389], "demonstr": [101, 105, 395, 403], "depend": [2, 11, 21, 72, 108, 110, 150, 158, 207, 208, 215, 220], "deploi": [83, 84, 99, 100, 108, 109, 111, 112, 113, 119, 120, 127, 128, 137, 138, 150, 151, 154, 173, 174, 178, 181, 184, 332, 338, 356, 360], "deploy": [10, 69, 101, 104, 108, 109, 111, 163, 164, 165, 171, 173, 177, 202, 252, 255, 295, 321, 323, 356, 360], "descript": [181, 185], "detail": [198, 199], "develop": [10, 11, 71, 72, 74, 83, 84, 86, 100, 202, 207, 208, 252, 257, 405], "devic": [127, 130, 137, 142], "diagnost": [382, 386], "differ": [173, 180], "diffus": [5, 35, 326, 329, 362, 363, 365, 368, 369, 370, 374], "diffusionpolici": [369, 372], "digit": [258, 260], "directori": [292, 300], "disabl": 0, "displai": [82, 97, 362, 368], "distribut": [3, 4, 5, 7, 28, 32, 36, 46, 203, 206, 225, 229, 258, 259, 268, 292, 301, 305, 326, 330, 333, 341, 348, 349, 350, 357, 362, 363, 366, 369, 373, 375, 376, 379, 382, 383, 385, 388, 389, 394, 395, 396, 401, 405], "dive": [6, 41, 285, 289, 293, 312], "document": [82, 98], "doe": [395, 396], "domain": [181, 187], "down": [11, 72, 173, 177, 178, 207, 208], "download": [83, 100, 258, 260], "dual": [101, 106], "duplic": [80, 92], "each": [108, 110], "ec2": [101, 105, 112, 113], "editor": [82, 97], "ef": [101, 106], "effici": [382, 385], "ek": [127, 128, 137, 138, 141], "els": [83, 100], "embed": [375, 376], "enabl": [0, 119, 122, 150, 153, 173, 179, 258, 279, 405], "encod": [362, 364, 375, 377, 395, 397], "end": [3, 28, 203, 206, 258, 271, 291, 298], "endpoint": [83, 100, 202], "engin": [7, 44, 119, 120, 150, 151, 164, 165, 170, 225, 227], "ensembl": [3, 28, 203, 206], "enter": [83, 100], "entir": [332, 339], "environ": [2, 11, 21, 72, 75, 83, 87, 100, 207, 208, 215, 220, 369, 370], "error": [332, 339], "evalu": [382, 385], "everyth": [83, 100], "exampl": [0, 3, 11, 26, 28, 72, 82, 83, 97, 100, 101, 105, 108, 111, 163, 173, 175, 180, 181, 184, 185, 186, 193, 197, 202, 203, 204, 206, 207, 208, 291, 292, 298, 300, 333, 341, 349, 357], "execut": [0, 1, 8, 9, 15, 52, 60, 75, 82, 87, 97, 108, 110, 209, 213, 232, 236, 240, 245, 294, 317], "exercis": [6, 41, 285, 289, 293, 312], "exist": [101, 106, 137, 138, 141], "expect": [181, 185], "experi": [291, 293, 298, 312], "explor": [77, 89], "extern": [108, 110], "extra": [258, 280], "face": [348, 350], "factor": [375, 376, 378], "failur": [2, 24, 215, 223], "failureconfig": [258, 280], "fastapi": [295, 323, 356, 358, 360], "fault": [258, 278, 281, 284, 395, 403], "featur": [0, 8, 55, 82, 96, 181, 182, 183, 232, 239, 291, 295, 298, 321, 323, 382, 386], "fetch": [2, 24, 215, 223], "file": [8, 9, 54, 64, 76, 82, 83, 88, 97, 100, 173, 178, 232, 238, 240, 249, 294, 318, 382, 384], "filter": [340, 345], "find": [82, 97], "first": [78, 79, 82, 83, 90, 91, 96, 97, 100], "fit": [5, 36, 258, 269, 326, 330], "flask": [356, 358], "flow": [7, 48, 202, 225, 231], "folder": [82, 98], "follow": [78, 79, 82, 83, 90, 91, 96, 97, 100], "food": [362, 364, 395, 396, 397], "food101dataset": [395, 398], "forc": [388, 392], "forecast": [388, 389], "forest": [382, 383], "format": [7, 43, 225, 226], "forward": [362, 363], "foundat": [164, 165, 166, 405], "fraction": [2, 22, 215, 221, 295, 323], "framework": [7, 46, 181, 187, 225, 229], "from": [82, 97, 258, 274, 282, 362, 367, 368, 369, 374, 375, 377, 380, 382, 387, 388, 393], "full": [82, 98, 258, 280], "function": [1, 7, 14, 15, 44, 101, 103, 209, 212, 213, 225, 227, 348, 353, 354], "gce": [119, 120], "gcp": [119, 120], "gener": [0, 4, 5, 7, 31, 32, 36, 46, 164, 165, 167, 225, 229, 326, 330, 362, 363, 368, 369, 371, 405], "get": [1, 2, 6, 12, 15, 16, 24, 41, 84, 164, 165, 171, 181, 185, 202, 209, 210, 213, 214, 215, 223, 285, 289, 293, 311], "gettingstart": 405, "github": [83, 100], "give": [83, 100], "gke": [150, 151], "global": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318], "go": [258, 284], "googl": [119, 122, 150, 151, 153], "gpu": [4, 5, 31, 32, 35, 36, 150, 155, 292, 295, 300, 301, 302, 323, 326, 329, 330, 388, 392, 394], "grafana": [189, 192], "group": [8, 9, 54, 64, 101, 106, 232, 238, 240, 249, 294, 318], "groupbi": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318], "guid": [83, 99], "handl": [82, 97], "hardwar": [173, 179, 181, 187], "harm": [1, 16, 209, 214], "head": [82, 83, 97, 100, 189, 192], "hello_world": [82, 97], "helper": [369, 374, 388, 394, 395, 399], "hourli": [388, 390], "how": [0, 8, 9, 50, 58, 101, 104, 108, 110, 173, 180, 181, 187, 232, 234, 240, 243, 258, 259, 291, 298, 362, 363, 369, 370, 375, 376, 382, 383, 388, 389, 395, 396], "hug": [348, 350], "huggingfac": [333, 341, 349, 357], "hyperparamet": [3, 6, 28, 41, 203, 206, 285, 289, 293, 313], "i": [7, 8, 47, 48, 50, 82, 97, 101, 103, 164, 165, 167, 173, 178, 225, 230, 231, 232, 234, 356, 358], "iam": [101, 106, 137, 141], "id": [1, 16, 74, 86, 101, 106, 209, 214, 375, 377, 381], "imag": [10, 70, 75, 87, 252, 256, 258, 276, 362, 363, 364, 395, 396, 397, 398], "implement": [3, 10, 26, 70, 203, 204, 252, 256, 295, 322], "import": [258, 260, 332, 335, 340, 343, 348, 351, 356, 359, 362, 364, 369, 371, 375, 377, 382, 384, 386, 388, 390, 395, 397], "improv": [173, 179], "industri": [7, 43, 225, 226], "infer": [3, 28, 164, 165, 167, 170, 173, 177, 178, 203, 206, 258, 271, 332, 334, 337, 339, 375, 376, 381, 382, 386, 387, 388, 394, 395, 404, 405], "infrastructur": [101, 104, 108, 111, 150, 154, 164, 165, 170], "ingress": [127, 130, 137, 142, 150, 157], "initi": [340, 343], "input": [362, 363, 375, 376, 395, 396], "inspect": [83, 100, 258, 270, 291, 298, 382, 384, 388, 390, 395, 398], "instal": [0, 11, 72, 84, 119, 122, 127, 130, 132, 133, 137, 142, 144, 145, 150, 153, 157, 160, 189, 192, 202, 207, 208, 333, 341, 349, 357], "instanc": [101, 106, 112, 113, 119, 120, 356, 361], "instruct": [78, 82, 90, 96], "integr": [258, 272, 284, 295, 323, 362, 366], "intro": [6, 9, 41, 56, 240, 241, 285, 289, 293, 294, 295, 308, 314, 320, 405], "introduct": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 17, 26, 29, 33, 38, 43, 49, 67, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 96, 99, 112, 113, 119, 120, 127, 128, 137, 138, 150, 151, 164, 165, 166, 189, 190, 193, 194, 203, 204, 207, 208, 209, 210, 215, 216, 225, 226, 232, 233, 252, 253, 258, 259, 271, 284, 285, 286, 291, 292, 293, 296, 299, 311, 326, 327], "introductori": [292, 300], "invert": [369, 370], "io": [2, 22, 215, 221], "irvin": [382, 384], "item": [375, 376, 377, 381], "job": [4, 32, 78, 82, 84, 90, 96, 97, 98, 292, 305], "join": [340, 346, 375, 381], "json": [181, 185], "jupyt": [0, 11, 72, 207, 208], "just": [356, 358], "jvm": [7, 46, 225, 229], "k8": [108, 110], "kei": [4, 5, 32, 36, 79, 82, 91, 96, 101, 103, 164, 165, 168, 172, 173, 176, 180, 181, 184, 185, 186, 188, 292, 295, 302, 321, 326, 330], "kubectl": [150, 156], "kubernet": [108, 109, 110, 111, 127, 130, 137, 142, 150, 151, 164, 165, 169], "kv": [164, 165, 168], "label": [395, 396], "lake": [7, 43, 225, 226], "lakehous": [7, 43, 225, 226], "landscap": [7, 43, 225, 226], "languag": [164, 165, 166], "larg": [2, 22, 164, 165, 166, 215, 221], "last": [84, 258, 282], "latenc": [164, 165, 169], "latest": [362, 367, 382, 387], "launch": [4, 11, 32, 72, 73, 85, 173, 177, 178, 189, 192, 198, 201, 207, 208, 258, 269, 277, 281, 292, 305, 362, 366, 369, 373, 375, 379, 388, 392, 395, 401], "layer": [7, 43, 44, 45, 108, 110, 225, 226, 227, 228], "lazi": [9, 60, 240, 245], "learn": [7, 44, 84, 163, 181, 183, 184, 185, 186, 225, 227, 258, 259, 272, 278, 362, 363, 369, 370, 375, 376, 382, 383, 388, 389, 395, 396, 405], "leav": [83, 100], "legend": [11, 72, 207, 208], "level": [2, 18, 215, 217], "lib": 405, "librari": [3, 26, 27, 203, 204, 205, 291, 296, 297, 298, 332, 335, 340, 343, 348, 351, 356, 359], "lifecycl": [4, 32, 83, 99, 258, 268], "lightn": [5, 33, 35, 36, 326, 327, 329, 330, 362, 366, 405], "lightningmodul": [362, 365, 369, 372], "limit": [9, 61, 240, 246], "list": [82, 98], "lite": [395, 396], "ll": [163, 181, 183, 258, 259, 272, 278], "llama": [173, 175], "llm": [164, 165, 166, 167, 169, 170, 171, 173, 174, 176, 179, 181, 182, 184, 187, 405], "load": [4, 5, 6, 8, 9, 31, 36, 39, 51, 59, 127, 130, 137, 142, 232, 235, 240, 244, 258, 271, 275, 279, 285, 287, 292, 293, 294, 300, 309, 316, 326, 330, 332, 336, 340, 343, 362, 364, 375, 377, 382, 384, 388, 390, 395, 397], "loader": [292, 300], "local": [0, 11, 72, 74, 76, 86, 88, 173, 177, 189, 192, 202, 207, 208, 292, 300], "log": [77, 82, 89, 97, 198, 200, 201], "loop": [1, 4, 5, 16, 31, 32, 35, 209, 214, 258, 262, 273, 279, 292, 300, 302, 306, 326, 329, 369, 373, 375, 379, 382, 385, 388, 392], "lora": [181, 184], "loss": [362, 366, 369, 373, 375, 379, 388, 392, 395, 402], "mac": [11, 72, 207, 208], "machin": [7, 44, 108, 109, 110, 225, 227], "main": [82, 83, 97, 100, 348, 354], "manag": [2, 11, 22, 72, 83, 99, 108, 110, 164, 165, 169, 207, 208, 215, 221, 375, 379], "mani": [2, 24, 215, 223], "manual": [258, 282], "materi": [9, 63, 240, 248, 294, 317], "matrix": [375, 376, 378, 382, 386], "matter": [181, 183, 185, 186], "max_model_len": [173, 179], "medium": [173, 174, 175, 176], "memori": [7, 43, 164, 165, 169, 225, 226, 332, 339, 382, 385], "memorydb": [101, 106], "metric": [4, 31, 32, 77, 89, 198, 200, 201, 258, 267, 268, 270, 292, 300, 304, 348, 352, 375, 379], "migrat": [4, 5, 32, 36, 292, 303, 326, 330, 362, 363, 375, 376, 382, 383, 388, 389, 395, 396], "min": [388, 390], "mini": [382, 384], "miniforg": [11, 72, 207, 208], "ml": [333, 341, 349, 357], "mnist": [258, 260, 261, 292, 300], "mode": [8, 9, 52, 60, 232, 236, 240, 245, 294, 317], "model": [3, 4, 5, 6, 26, 28, 31, 32, 35, 36, 41, 164, 165, 166, 168, 173, 175, 176, 179, 181, 187, 203, 204, 206, 258, 261, 265, 285, 289, 292, 293, 300, 303, 310, 313, 326, 329, 330, 332, 338, 356, 358, 360, 375, 376, 378, 382, 385, 388, 391, 395, 396], "modifi": [258, 279], "modul": [258, 271, 284], "monitor": [77, 89, 173, 179], "more": [4, 5, 32, 36, 108, 111, 173, 179, 181, 184, 185, 186, 188, 294, 316, 326, 330], "movi": [375, 381], "movielen": [375, 377], "multi": [202, 388, 389], "multipl": [292, 301], "n": [375, 381], "name": [82, 83, 97, 100], "navig": [0, 82, 97], "need": [83, 100, 108, 110], "nest": [2, 23, 215, 222], "new": [0, 11, 72, 82, 97, 101, 106, 127, 128, 150, 151, 202, 207, 208, 291, 298, 362, 363], "next": [82, 97, 164, 165, 172, 173, 180, 181, 188, 189, 192, 258, 284, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "nginx": [127, 130, 137, 142, 150, 157], "node": [75, 83, 87, 100, 137, 141, 189, 192, 388, 389], "nois": [362, 363], "normal": [369, 371, 388, 390], "note": [1, 2, 4, 5, 9, 16, 21, 22, 24, 32, 36, 59, 62, 209, 214, 215, 220, 221, 223, 240, 244, 247, 258, 268, 326, 330], "notebook": [0, 11, 72, 74, 78, 79, 82, 86, 90, 91, 98, 207, 208, 291, 296, 340, 342], "now": [82, 97, 189, 192], "nvidia": [127, 130, 137, 142], "nyc": [291, 298, 388, 389, 390], "o": [11, 72, 207, 208], "object": [2, 17, 18, 24, 76, 84, 88, 108, 110, 215, 216, 217, 223, 362, 363, 369, 370, 375, 376], "observ": [189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 405], "onc": [2, 24, 82, 97, 215, 223], "one": [388, 390], "onli": [198, 201, 258, 268], "onlin": [356, 358, 405], "open": [82, 97], "oper": [8, 9, 54, 64, 108, 109, 127, 132, 137, 144, 150, 160, 232, 238, 240, 249, 294, 318], "optim": [164, 165, 168, 169, 173, 179], "option": [11, 72, 76, 84, 88, 101, 106, 108, 109, 111, 127, 130, 137, 142, 150, 158, 189, 192, 207, 208, 382, 384], "orchestr": [7, 45, 164, 165, 170, 225, 228], "order": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318], "organ": [81, 93, 94], "other": [173, 180], "our": [82, 97, 173, 175, 292, 300], "out": [6, 40, 82, 97, 98, 285, 288, 332, 339], "outlin": [332, 334, 340, 342, 348, 350, 356, 358], "outlook": [101, 102, 108, 111, 173, 180, 294, 319], "output": [0, 181, 185], "over": [7, 47, 82, 83, 97, 100, 225, 230, 388, 390], "overview": [1, 3, 4, 5, 10, 11, 13, 27, 31, 32, 35, 69, 72, 81, 84, 94, 101, 102, 173, 175, 181, 183, 189, 191, 202, 203, 205, 207, 208, 209, 211, 252, 255, 291, 292, 295, 297, 302, 321, 326, 329], "packag": [189, 192], "panda": [340, 347], "parallel": [1, 4, 5, 16, 32, 36, 164, 165, 168, 173, 179, 209, 214, 258, 259, 268, 292, 301, 326, 330], "parquet": [362, 364, 375, 377, 382, 384, 388, 390, 395, 397, 398], "part": [78, 79, 82, 83, 90, 91, 97, 98, 100], "pass": [2, 18, 19, 83, 100, 215, 217, 218], "passeng": [388, 390], "past": [82, 97], "path": 84, "pattern": [1, 2, 16, 18, 24, 209, 214, 215, 217, 223, 362, 363, 369, 370, 375, 376, 382, 383, 388, 389, 395, 396, 405], "pendulum": [369, 370, 371], "per": [258, 262, 348, 353, 375, 376], "persist": [9, 65, 240, 250, 258, 268, 292, 294, 305, 319, 362, 364, 395, 397], "phase": [164, 165, 167], "pip": [2, 21, 215, 220], "pipelin": [2, 24, 84, 173, 179, 198, 200, 215, 223], "pixel": [362, 365], "plane": [101, 106], "platform": [76, 88], "plot": [362, 366, 369, 373, 375, 379, 388, 392, 395, 402], "plugin": [127, 130, 137, 142], "point": [292, 302, 375, 377], "polici": [137, 141, 362, 363, 369, 370, 374, 405], "positionalencod": [388, 391], "post": [382, 387], "practic": [181, 187], "predict": [4, 5, 31, 32, 36, 258, 271, 291, 298, 326, 330], "predictor": [388, 394], "prefil": [164, 165, 167], "prepar": [258, 275, 388, 390, 395, 399], "prepare_data_load": [258, 266], "prepare_model": [258, 265], "preprocess": [340, 347], "prerequisit": [11, 72, 112, 113, 119, 121, 127, 128, 137, 139, 150, 152, 163, 173, 177, 189, 192, 198, 199, 202, 207, 208], "preview": [181, 183], "problem": [362, 363, 369, 370, 375, 376, 382, 383, 388, 389, 395, 396], "process": [2, 7, 24, 46, 47, 164, 165, 167, 181, 187, 215, 223, 225, 229, 230, 333, 340, 341, 342, 349, 357, 362, 363, 405], "product": [4, 5, 6, 8, 9, 32, 37, 42, 55, 66, 232, 239, 240, 251, 285, 290, 292, 294, 295, 307, 319, 324, 326, 331], "profil": 202, "project": [80, 81, 92, 94], "prometheu": [189, 192], "provid": [101, 107, 127, 128], "publish": [0, 83, 100], "purpos": [7, 46, 101, 103, 225, 229], "put": [1, 16, 209, 214], "py": [82, 83, 97, 100], "python": [82, 97, 98], "pytorch": [4, 5, 6, 10, 29, 31, 32, 33, 35, 36, 40, 41, 67, 252, 253, 285, 288, 289, 292, 293, 300, 301, 310, 313, 326, 327, 329, 330, 333, 341, 348, 349, 350, 357, 388, 390, 405], "qualiti": [181, 187], "quantiz": [173, 179], "queri": [164, 165, 171], "quick": [3, 28, 203, 206, 388, 390], "rai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 41, 42, 43, 47, 48, 49, 50, 55, 56, 57, 58, 62, 66, 67, 68, 69, 72, 77, 82, 84, 89, 97, 108, 110, 112, 113, 119, 120, 127, 128, 137, 138, 150, 151, 164, 165, 166, 170, 171, 173, 174, 176, 177, 181, 182, 184, 189, 192, 193, 194, 195, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 214, 215, 216, 223, 224, 225, 226, 230, 231, 232, 233, 234, 239, 240, 241, 242, 243, 247, 251, 252, 253, 254, 255, 258, 259, 262, 268, 271, 272, 273, 274, 275, 276, 277, 278, 284, 285, 286, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 301, 302, 303, 307, 308, 311, 312, 313, 314, 315, 319, 320, 321, 323, 324, 326, 327, 328, 330, 331, 332, 333, 334, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 355, 356, 357, 358, 361, 362, 363, 364, 366, 369, 370, 373, 375, 376, 377, 379, 382, 383, 384, 385, 386, 388, 389, 390, 392, 394, 395, 396, 399, 404, 405], "random": [388, 390], "rank": [258, 268, 375, 376], "rate": [375, 376, 377], "read": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318], "real": [369, 371], "rec": 405, "recap": [291, 298], "recommend": [11, 72, 84, 181, 187, 207, 208, 375, 376, 381], "reduc": [173, 179], "regist": [101, 107, 112, 115, 119, 124, 127, 131, 137, 143, 150, 159, 202], "registr": 202, "regress": [3, 26, 203, 204], "relat": [173, 175, 180], "remot": [1, 4, 14, 15, 32, 209, 212, 213], "remov": [388, 394], "replica": [10, 69, 173, 179, 252, 255], "report": [4, 32, 258, 267, 268, 292, 300, 304], "repositori": [83, 84, 100], "request": [2, 22, 173, 177, 202, 215, 221, 356, 361], "requir": [11, 72, 119, 122, 127, 128, 137, 141, 150, 153, 164, 165, 169, 181, 187, 189, 192, 207, 208], "resampl": [388, 390], "resiz": [362, 364, 395, 397], "resnet": [258, 261], "resourc": [2, 9, 22, 61, 62, 80, 92, 101, 104, 105, 112, 114, 119, 123, 127, 129, 137, 140, 150, 154, 164, 165, 172, 173, 180, 181, 188, 215, 221, 240, 246, 247], "restor": [258, 282], "result": [1, 2, 4, 5, 15, 24, 32, 36, 209, 213, 215, 223, 258, 270, 292, 306, 326, 330, 388, 394], "resum": [258, 282, 362, 367, 375, 380, 388, 393], "resumpt": [395, 403], "retri": [2, 20, 215, 219, 258, 280], "retriev": 202, "revers": [362, 363, 368, 369, 370, 374], "roc": [292, 306], "role": [81, 94, 101, 106, 137, 141], "row": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318], "run": [4, 5, 31, 32, 36, 78, 82, 83, 90, 96, 97, 100, 108, 110, 119, 123, 173, 178, 198, 200, 258, 271, 291, 296, 298, 326, 330, 332, 339, 388, 394, 395, 404], "runconfig": [258, 268], "runtim": [2, 21, 215, 220], "s3": [101, 106], "same": [82, 98], "sampl": [202, 258, 260, 362, 363, 368, 369, 370, 374], "sampler": [362, 368], "saniti": [362, 364, 388, 390, 395, 397], "save": [258, 268, 280, 292, 300], "scalabl": [164, 165, 169], "scale": [4, 5, 32, 36, 173, 179, 258, 264, 292, 302, 326, 330, 332, 338, 356, 360, 369, 370], "scalingconfig": [258, 264], "schedul": [78, 82, 90, 98, 292, 300], "script": [82, 97], "sdk": [82, 98], "second": [340, 344], "secur": [101, 106], "select": [83, 100, 181, 187], "send": [173, 177, 356, 361], "sequenc": [388, 389], "seri": [388, 389, 405], "serv": [0, 3, 7, 10, 26, 28, 48, 67, 68, 69, 164, 165, 166, 167, 169, 170, 171, 173, 174, 176, 177, 181, 182, 184, 198, 201, 202, 203, 204, 206, 225, 231, 252, 253, 254, 255, 295, 320, 321, 323, 324, 356, 358, 361, 405], "server": [11, 72, 207, 208], "servic": [10, 70, 79, 82, 83, 84, 91, 96, 99, 100, 173, 178, 252, 256, 295, 322], "set": [11, 72, 173, 176, 178, 181, 186, 189, 192, 207, 208, 293, 310, 312], "setup": [81, 93, 189, 192, 202, 348, 352, 362, 363, 364, 369, 371, 375, 376, 382, 383, 388, 389, 395, 396], "share": [76, 88, 362, 368, 375, 381], "shuffl": [8, 9, 54, 64, 232, 238, 240, 249, 294, 318, 362, 364], "shut": [11, 72, 173, 177, 178, 207, 208], "shutdown": [165, 171, 332, 339, 340, 347, 348, 355, 356, 361], "sign": 84, "simpl": [11, 72, 198, 200, 207, 208], "simul": [356, 361], "singl": [4, 5, 31, 35, 292, 300, 326, 329], "size": [173, 174, 175, 176, 180, 382, 384], "slide": [388, 390], "solv": [362, 363, 369, 370, 375, 376, 382, 383, 388, 389, 395, 396], "sourc": [83, 99], "spark": [7, 47, 225, 230], "specif": [1, 9, 16, 61, 62, 82, 97, 209, 214, 240, 246, 247], "spin": [83, 100], "split": [0, 362, 364, 369, 371, 375, 377, 382, 384, 395, 398], "stabl": [5, 35, 326, 329], "start": [1, 6, 12, 40, 41, 79, 83, 84, 91, 100, 164, 165, 171, 189, 192, 209, 210, 285, 288, 289, 293, 311, 348, 355, 382, 385], "starter": [83, 100], "state": [9, 62, 240, 247, 258, 280, 294, 317, 369, 370], "statu": [82, 97], "step": [164, 165, 171, 172, 173, 180, 181, 188, 189, 192, 258, 284, 291, 298, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "storag": [4, 32, 76, 88, 108, 110, 258, 268, 283, 292, 305, 362, 368, 375, 381], "store": [2, 17, 18, 76, 88, 108, 110, 215, 216, 217], "strategi": [173, 179], "stream": [7, 46, 225, 229], "structur": [7, 8, 43, 49, 81, 94, 163, 181, 185, 202, 225, 226, 232, 233], "style": [369, 370], "submit": [78, 82, 90, 97, 98], "subnet": [101, 106], "successfulli": [82, 97], "summari": [81, 95, 101, 106, 173, 180, 332, 339, 340, 347, 348, 355, 356, 361], "support": [101, 104], "sy": 405, "system": [375, 376], "tab": [77, 82, 83, 89, 97, 100], "tabl": [293, 312], "tabular": [382, 383, 405], "take": [258, 259, 272, 278, 362, 363, 368, 369, 370, 374, 375, 376, 381, 382, 383, 387, 388, 389, 394, 395, 396, 404], "takeawai": [164, 165, 172, 173, 180, 181, 188], "task": [2, 17, 19, 20, 21, 22, 23, 181, 187, 215, 216, 218, 219, 220, 221, 222, 291, 298], "taxi": [291, 298, 388, 389, 390], "teacher": [388, 392], "team": 84, "templat": [83, 100, 173, 180], "tensor": [362, 363], "termin": [82, 83, 97, 100, 189, 192], "terraform": [112, 114, 119, 123, 127, 129, 137, 140, 150, 154], "test": [0, 75, 87, 112, 116, 119, 125, 127, 134, 137, 146, 150, 161, 356, 361], "text": [164, 165, 167], "tfvar": [119, 123, 150, 154], "thi": [11, 72, 78, 79, 83, 90, 91, 99, 100, 207, 208, 291, 296, 298, 362, 363, 368, 369, 370, 374, 375, 376, 381, 382, 383, 387, 388, 389, 394, 395, 396, 404], "through": [78, 82, 83, 90, 96, 99], "time": [388, 389, 405], "tip": [291, 298], "titl": [375, 381], "togeth": [1, 16, 209, 214], "token": [340, 347, 348, 353], "toler": [258, 278, 281, 284, 395, 403], "too": [2, 24, 215, 223], "tool": [181, 186], "top": [2, 18, 215, 217, 375, 381], "topic": [173, 179, 181, 188], "torch": [5, 35, 326, 329], "torchtrain": [5, 36, 258, 269, 277, 292, 305, 326, 330, 362, 366, 369, 373, 395, 401], "trace": [198, 201, 202], "track": [82, 97], "train": [3, 4, 5, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 203, 204, 206, 258, 259, 262, 267, 268, 269, 270, 271, 272, 273, 277, 278, 279, 281, 282, 284, 292, 299, 300, 301, 302, 303, 305, 306, 307, 326, 327, 328, 329, 330, 331, 333, 341, 348, 349, 350, 353, 354, 355, 357, 362, 363, 364, 366, 369, 370, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 387, 388, 389, 392, 393, 394, 395, 396, 398, 401, 402, 405], "train_loop": [362, 366], "train_loop_config": [258, 263], "train_loop_per_work": [395, 400], "trainer": [258, 269, 382, 385], "transform": [8, 9, 52, 61, 62, 232, 236, 240, 246, 247, 258, 276, 294, 317, 388, 389, 391, 395, 398], "tripl": [375, 376], "troubleshoot": [137, 147, 150, 155], "tune": [3, 6, 26, 28, 38, 41, 42, 203, 204, 206, 285, 286, 289, 290, 293, 308, 311, 312, 313, 405], "tupl": [369, 370], "tutori": [258, 284], "two": [164, 165, 167, 340, 346], "type": [101, 104, 181, 185, 382, 384], "uci": [382, 384], "under": [292, 306], "univers": [382, 384], "unstructur": [9, 56, 240, 241], "up": [3, 11, 28, 72, 77, 78, 79, 83, 84, 89, 90, 91, 100, 127, 135, 137, 148, 173, 176, 178, 181, 186, 189, 192, 203, 206, 207, 208, 258, 271, 283, 284, 293, 295, 310, 325, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "upcom": [8, 55, 232, 239], "updat": [83, 84, 99, 292, 306], "upgrad": [150, 158, 173, 179], "uri": [375, 377], "url": [82, 97], "us": [3, 4, 5, 6, 7, 8, 9, 11, 26, 30, 31, 32, 34, 41, 47, 50, 54, 55, 64, 72, 82, 83, 96, 98, 99, 100, 101, 106, 108, 110, 173, 179, 181, 184, 185, 186, 187, 198, 201, 203, 204, 207, 208, 225, 230, 232, 234, 238, 239, 240, 249, 258, 259, 285, 289, 291, 293, 294, 295, 298, 313, 315, 318, 321, 323, 326, 328, 356, 358, 362, 363, 369, 370, 375, 376, 377, 382, 383, 388, 389, 395, 396], "usag": 0, "user": [81, 94, 202, 375, 376, 377, 381], "uv": [11, 72, 207, 208], "v": [7, 47, 48, 82, 97, 108, 109, 110, 225, 230, 231], "val": [362, 364, 369, 373], "valid": [375, 377, 379, 382, 384, 388, 392, 395, 398, 402], "valu": [164, 165, 168], "vanilla": [3, 6, 28, 40, 203, 206, 285, 288], "verifi": [11, 72, 82, 97, 127, 133, 137, 145, 207, 208, 382, 387], "view": [258, 270], "viewer": [77, 89], "virtual": [108, 109, 110], "vision": [362, 363, 395, 396, 405], "visual": [258, 260, 271, 292, 293, 300, 309, 362, 364, 375, 377, 382, 384, 386, 388, 390, 394, 395, 397, 404], "vllm": [164, 165, 170], "vm": [108, 110], "vpc": [101, 106], "vscode": [74, 83, 86, 100], "wa": [82, 97], "wait": [2, 24, 215, 223], "walk": [78, 82, 83, 90, 96, 99], "warehous": [7, 43, 225, 226], "we": [11, 72, 82, 83, 97, 100, 173, 180, 181, 183, 188, 207, 208, 291, 298], "weather": [181, 186], "web": [198, 201], "webservic": [356, 360], "welcom": [11, 72, 163, 207, 208], "what": [7, 8, 47, 48, 50, 101, 103, 108, 110, 163, 164, 165, 167, 173, 178, 180, 181, 183, 188, 189, 192, 225, 230, 231, 232, 234, 258, 259, 272, 278, 356, 358, 362, 363, 369, 370, 375, 376, 382, 383, 388, 389, 395, 396], "when": [4, 5, 7, 8, 9, 10, 30, 34, 47, 55, 57, 68, 108, 110, 225, 230, 232, 239, 240, 242, 252, 254, 258, 259, 294, 295, 315, 321, 326, 328], "where": [258, 284, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "which": [108, 110], "why": [7, 11, 47, 48, 72, 84, 164, 165, 169, 173, 175, 181, 183, 184, 185, 186, 207, 208, 225, 230, 231, 356, 358, 362, 363], "window": [164, 165, 168, 181, 187, 388, 390], "work": [0, 9, 58, 240, 243, 258, 259, 362, 363], "worker": [4, 5, 32, 36, 75, 83, 87, 100, 189, 192, 258, 262, 326, 330, 348, 353, 382, 385], "workflow": [0, 10, 71, 75, 82, 87, 97, 252, 257], "workload": [81, 94, 108, 110, 198, 200, 362, 363, 369, 370, 375, 376, 382, 383, 388, 389, 395, 396, 405], "workspac": [73, 82, 83, 84, 85, 97, 98, 100], "wrap": [258, 265, 284, 362, 368, 369, 374, 375, 381, 382, 387, 388, 394, 395, 404], "write": [8, 53, 232, 237, 382, 384], "xgboost": [3, 26, 28, 203, 204, 206, 382, 383, 385], "yaml": [83, 100], "york": [291, 298], "you": [78, 82, 83, 90, 96, 97, 99, 163, 258, 259, 272, 278, 362, 363, 368, 369, 370, 374, 375, 376, 381, 382, 383, 387, 388, 389, 394, 395, 396, 404], "your": [11, 72, 77, 78, 79, 82, 83, 84, 89, 90, 91, 96, 97, 100, 101, 107, 108, 111, 137, 141, 207, 208]}})